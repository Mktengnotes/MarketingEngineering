--- 
title: "Marketing Engineering"
author: "Marcel Goic"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
description: "Marketing Engineering"

---

# Prólogo {-}

- Estimado/a estudiante, tienes en tus manos el primer apunte oficial del curso de Ingeniería de Marketing, hecho con mucho esfuerzo por varios integrantes de los distintos equipos docente del curso a lo largo de los años. Cabe recordar que este documento está en constante actualización y mejora, por lo que cualquier sugerencia, corrección o comentario favor de comunicarse al correo mktengnotes@gmail.com. ¡Éxito en el estudio!
-----

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown','tinytext'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

---
output: 
  html_document2:
    css: styles.css
editor_options:
  markdown:
    wrap: 72
---

# Modelos de Regresión

## Conceptos básicos de regresión

Como bien ya se ha estudiado en otros cursos de la carrera de ingeniería
industrial, una *regresión* es una técnica para calcular el valor
esperado de una variable condicional en la realización de otras. Por
ejemplo:

-   ¿Cuál debería ser el precio de venta de una casa en la comuna de la
    Providencia, con 4 dormitorios, 170 $m^2$ de superficie construida?
-   ¿Cuáles deberían ser las ventas de Leche semidescremada Nestlé en la
    última semana del mes de Abril si el precio es \$723?
-   ¿Cuál debería ser el número de clientes que ve un aviso publicitario
    si se despliega en 4 programas durante 3 semanas y el rating
    promedio de los programas es 8.7 puntos?

### Notación

En general se denota con $y$ al vector que representa todas las
variables dependientes en un único vector columna, mientras que $X$
representa la matriz que incluye todas las variables independientes
(esto incluye una columna de 1s si se desea incluir un intercepto).

Es importante notar que:

-   Cada columna corresponde a una variable.
-   Cada fila corresponde a un caso.
-   Las dimensiones de las filas del vector $y$ y la matriz $X$ deben
    ser consistentes.
-   Todos los elementos de una misma fila deben tener los mismos
    índices.

Para estimar los parámetros de la recta de regresión, se utilizan
diferentes métodos, siendo uno de los más populares el método de Mínimos
Cuadrados Ordinarios (OLS).

## Mínimos Cuadrados Ordinarios (OLS) y supuestos

OLS proporciona una estimación óptima de los parámetros de la recta de
regresión, al encontrar la recta que minimiza la suma de los cuadrados
de las diferencias entre los valores reales y los valores estimados de
la variable dependiente. Sin embargo, para que este método sea un
estimador adecuado de los parámetros, se deben cumplir ciertos
supuestos:

1.  Existe una *relación lineal* entre la variable dependiente y las
    variables independientes. Debido a esto, la relación entre las
    variables se puede modelar mediante una recta. Sin este supuesto,
    OLS no es apropiado y se debe recurrir a otros métodos.

2.  Los errores tienen una **distribución normal y tienen una media
    igual a cero**. Es decir, los errores son insesgados y distribuyen
    de forma simétrica alrededor del cero. Si los errores no siguen una
    distribución normal, los resultados de la regresión pueden no ser
    confiables.

3.  Los errores tienen una *varianza constante* (homocedasticidad). Esto
    significa que la varianza de los errores es la misma para todos los
    valores de las variables independientes. Si no se cumple este
    supuesto, los errores pueden estar influenciados por alguna variable
    independiente y los resultados pueden ser incorrectos.

4.  Los errores son *independientes entre sí*. Es decir, no están
    correlacionados con los errores de otra observación. Si los errores
    están correlacionados, la varianza de los coeficientes puede ser
    demasiado baja, lo que puede llevar a una sobreestimación de la
    significancia estadística.

5.  No existe *multicolinealidad* perfecta entre las variables
    independientes. La multicolinealidad perfecta se refiere a la
    existencia de una relación lineal exacta entre las variables
    independientes. Esto puede ocurrir cuando dos o más variables
    independientes están altamente correlacionadas. Si no se cumple este
    supuesto, los coeficientes estimados pueden no ser confiables y los
    resultados pueden ser incorrectos.

En general, se utiliza OLS porque proporciona una estimación óptima de
los parámetros de la recta de regresión, es decir, los valores que mejor
se ajustan a los datos. El método OLS minimiza la suma de los cuadrados
de las diferencias entre los valores reales y los valores estimados de
la variable dependiente. Esto se logra al encontrar los valores de los
parámetros de la recta que minimizan esta suma de cuadrados.

### Estimación

Supongamos que queremos estimar los parámetros
$\beta_0, \beta_1, \ldots, \beta_n$ de la recta de regresión
$Y = \beta_0 + \beta_1 x_1 + \cdots + \beta_n x_n + \epsilon$, donde
$\epsilon$ es el término de error e $Y$ es la variable dependiente.
Queremos encontrar los valores de los parámetros
$\beta_0, \beta_1, \ldots, \beta_n$ que minimizan la suma de los
cuadrados de las diferencias entre los valores reales y los valores
estimados de $Y$.

La idea detrás del método de Mínimos Cuadrados Ordinarios (OLS) es
minimizar la función de pérdida
$S(\beta_0, \beta_1, \ldots, \beta_n) = \sum_{i=1}^N (Y_i - \beta_0 - \beta_1 x_{i1} - \cdots - \beta_n x_{in})^2$.
La solución de este problema de optimización se puede encontrar a través
del cálculo de las derivadas parciales de $S$ con respecto a cada uno de
los parámetros $\beta_j$, e igualar a cero. Esto nos lleva al siguiente
sistema de ecuaciones:

$$\hat{\beta}=(X^TX)^{-1}X^TY$$

donde $X$ es la matriz de variables independientes, $Y$ es el vector de
la variable dependiente y $\hat{\beta}$ es el vector de estimadores de
mínimos cuadrados.

La solución de este sistema entrega los valores de los parámetros
$\beta_0, \beta_1, \ldots, \beta_n$ que minimizan la función de pérdida
$S(\beta_0, \beta_1, \ldots, \beta_n)$. Estos valores se conocen como
los estimadores de mínimos cuadrados de los parámetros de la recta de
regresión.

### Propiedades

Si se cumplen los supuestos anteriormente mencionados, mínimos cuadrados
ordinarios cumple con las siguientes propiedades:

1.  *Insesgadez*: Los estimadores de mínimos cuadrados son insesgados,
    lo que significa que, en promedio, su valor esperado es igual al
    verdadero valor del parámetro que se está estimando.

2.  *Eficiencia*: Entre todos los estimadores insesgados y lineales, los
    estimadores de mínimos cuadrados tienen la menor varianza posible.

3.  *Linealidad*: Los estimadores de mínimos cuadrados son lineales en
    la variable de respuesta $Y$.

4.  *Consistencia*: Con un tamaño de muestra lo suficientemente grande,
    los estimadores de mínimos cuadrados se acercan al verdadero valor
    del parámetro que se está estimando.

5.  El estimador máximo verosímil, para el caso lineal con errores
    normales *coincide con el estimador de mínimos cuadrados*.

Según el teorema de Gauss-Markov, al cumplirse las propiedades de
\*Insesgadez, \*\*Eficiencia\* y *Linealidad*, los estimadores de OLS
son *BLUE* (Best Linear Unbiased Estimators).

## Estrategias de Modelamiento

### Arte vs. Procedimiento

El debate entre el arte y el procedimiento en el campo de la
modelización y análisis de datos se ha intensificado en los últimos años
con el auge de la inteligencia artificial y el aprendizaje automático.
Los defensores del arte argumentan que la experiencia y la intuición del
analista son esenciales para identificar patrones y relaciones complejas
en los datos que no son evidentes a simple vista. Por otro lado, los
defensores del procedimiento insisten en que la aplicación rigurosa de
algoritmos y técnicas estadísticas es la única manera de garantizar la
validez y precisión del modelo.

Es importante tener en cuenta que el uso exclusivo de uno u otro enfoque
puede llevar a resultados subóptimos. Por ejemplo, un modelo construido
únicamente a través del arte puede ser difícil de replicar o explicar a
otros, lo que limita su utilidad práctica. Por otro lado, un modelo
construido únicamente a través del procedimiento puede pasar por alto
aspectos importantes de los datos que son evidentes para un experto en
el campo.

En la práctica, los analistas suelen combinar ambos enfoques para
construir modelos efectivos y útiles. Un aspecto clave en este proceso
es la exploración exhaustiva de los datos y la definición de una lista
de modelos candidatos, que pueden incluir diferentes técnicas de
modelización y selección de variables. Luego, se pueden utilizar
diversas métricas de ajuste y predicción para evaluar la calidad de cada
modelo y seleccionar el que mejor se ajuste a los datos y sea capaz de
hacer predicciones precisas.

### Aprendizajes Preliminares

En el ámbito del modelado estadístico, existen innumerables modelos de
regresión, lo que hace imposible determinar cuál es el mejor en términos
absolutos.

Una forma de abordar este problema es equilibrar la complejidad del
modelo con su capacidad explicativa. Esto significa que el modelo debe
ser lo suficientemente simple como para ser fácilmente interpretable,
pero lo suficientemente complejo como para capturar todas las relaciones
relevantes entre las variables.

Para seleccionar un modelo de regresión adecuado, es fundamental tener
conocimientos previos del negocio y realizar una exploración exhaustiva
de los datos antes de aplicar cualquier modelo. Esta exploración ex-ante
puede ayudar a identificar las variables más relevantes y las posibles
relaciones entre ellas. Es importante evaluar cómo se relacionan las
variables, qué variables tienen mayor dispersión y qué variables se
mantienen relativamente constantes.

Después de la exploración ex-ante, es necesario aplicar el modelo y
evaluar su rendimiento mediante la evaluación ex-post. Esto implica
evaluar el modelo en datos nuevos y comprobar si se comporta de manera
similar a cómo lo hizo en los datos de entrenamiento.

*1. Elegir nivel de agregación*

Uno de los aspectos clave del análisis de datos es determinar el nivel
adecuado de agregación para realizar el análisis. Por ejemplo, se puede
analizar las ventas de un producto en un supermercado por hora, día,
semana, mes o año. También se puede considerar el análisis de ventas por
SKU (código de identificación), marca, cadena o sala.

Es importante tener en cuenta que el problema de gestión puede imponer
restricciones al nivel de agregación mínimo. Por ejemplo, si un gerente
de una cadena de supermercados necesita tomar decisiones en tiempo real
sobre la reposición de un producto, es posible que necesite datos a
nivel de hora o día. En este caso, analizar las ventas a nivel de semana
o mes no sería útil.

En el análisis de ventas, a menudo se enfrenta un trade-off entre la
sensibilidad al precio y la programación de reposición. Si el análisis
se realiza a nivel de SKU, se puede obtener una comprensión más
detallada de cómo el precio afecta a las ventas. Sin embargo, si el
análisis se realiza a nivel de cadena o sala, se puede obtener una mejor
comprensión de los patrones de reposición.

Agregar los datos a un nivel de agregación más alto puede ser más fácil,
ya que se requiere menos detalle y se puede tener una visión más
general. Sin embargo, puede llevar a una pérdida de precisión por
underfitting. Por ejemplo, si se analiza las ventas a nivel de mes, se
puede perder información valiosa sobre patrones diarios o semanales. Por
otro lado, si la cantidad de datos es limitada, es posible que se
necesite mantener un nivel de agregación más alto para obtener un modelo
preciso. En este caso, reducir el nivel de agregación puede significar
la pérdida de información importante y la reducción de la precisión del
modelo por overfitting.

*2. Descomposición en múltiples regresiones:*

La descomposición en múltiples regresiones es una técnica que permite
abordar problemas complejos y de alta dimensionalidad mediante la
partición del problema en componentes más pequeños y manejables. Este
enfoque puede adoptar diversas formas, incluyendo la descomposición por
índices y la descomposición por componentes latentes.

-   *Descomposición por índices:* Aunque en general es preferible
    utilizar una única regresión para analizar las relaciones entre las
    variables, en ciertas situaciones, como en casos de complejidad
    computacional elevada o cuando se abordan problemas con múltiples
    niveles de jerarquía, la descomposición por índices puede ser una
    solución adecuada. Esta técnica implica dividir el conjunto de datos
    en subconjuntos según algún criterio y ajustar modelos de regresión
    separados para cada subconjunto.

-   *Regresión lineal y modelos más complejos:* La regresión lineal es
    un enfoque simple y fácil de estimar que puede ser suficiente en
    muchos casos. Sin embargo, en situaciones donde las relaciones entre
    las variables no son lineales o donde se requiere una mayor
    flexibilidad en el modelado, se pueden justificar modelos más
    complejos, como regresiones polinómicas, regresiones no paramétricas
    o modelos de regresión con variables categóricas.

-   *Descomposición por componentes latentes:* En ciertos casos, la
    variable dependiente puede descomponerse de manera natural en
    componentes latentes, lo que facilita la interpretación de los
    resultados y la identificación de relaciones subyacentes entre las
    variables. Un ejemplo típico es la descomposición de las ventas en
    el número de compras y el número de unidades por compra. Al analizar
    estos componentes por separado, se puede obtener una comprensión más
    detallada de los factores que influyen en las ventas.

-   *Caso del cero inflado (zero inflated):* En algunas situaciones, se
    pueden observar una gran cantidad de ceros en los datos, lo que
    indica una distribución inflada en cero. En estos casos, se puede
    utilizar un modelo de regresión de ceros inflados que distingue
    entre dos procesos distintos: la incidencia de compra (probabilidad
    de que ocurra una compra) y el monto de compra (valor de la compra,
    condicional a que se haya realizado una compra). Este enfoque
    permite analizar de manera más efectiva los factores que afectan
    tanto la propensión a comprar como la cantidad gastada en las
    compras.

*3. Transformación de Variables*

La transformación de variables es una técnica utilizada para mejorar la
interpretación y el ajuste del modelo. Esta técnica consiste en aplicar
funciones matemáticas a las variables con el objetivo de modificar su
distribución y hacer que el modelo sea más interpretable y
significativo.

Un ejemplo común de transformación de variables es el modelo doble log,
en el cual se aplican logaritmos a las variables dependientes e
independientes para transformar la relación no lineal en una relación
lineal. Esta técnica puede ser útil cuando se analizan datos que siguen
una distribución log-normal o cuando se busca interpretar los
coeficientes de manera logarítmica.

Es importante tener en cuenta que, aunque la transformación de variables
puede mejorar la bondad del ajuste y la precisión de las predicciones,
no siempre es necesario aplicarla. En algunos casos, las variables ya
están en una forma adecuada para el modelo y cualquier transformación
adicional podría reducir la interpretabilidad del modelo. Por lo tanto,
es importante tener una comprensión sólida de los datos y del problema a
resolver antes de aplicar cualquier transformación de variables.

| *Modelo* | *Variable dependiente* | *Variable independiente* | *Interpretación* |
|----|----|----|----|
| Nivel-nivel | $Y$ | $X$ | $\Delta Y = \beta_1 \Delta X$ |
| Nivel-log | $Y$ | $\log(X)$ | $\Delta Y = \dfrac{\beta_1}{100}\% \Delta X$ |
| Log-nivel | $\log(Y)$ | $X$ | $\%\Delta Y = (100\beta_1)\Delta X$ |
| Log-log | $\log(Y)$ | $\log(X)$ | $\%\Delta Y = \beta_1 \%\Delta X$ |

*4. Selección de Variables*

En el campo de la regresión, existen diferentes enfoques para la
selección de variables, incluyendo métodos automáticos y manuales. Uno
de los métodos automáticos más utilizados es la regresión paso a paso
(stepwise regression), que implica la iterativa agregación o eliminación
de variables en función de algún criterio de bondad de ajuste.

En el enfoque forward de la regresión paso a paso, las variables se van
agregando al modelo una por una, comenzando con la variable que
proporciona el mejor ajuste según el criterio establecido. En cada
etapa, se evalúa si agregar una nueva variable mejora significativamente
el ajuste del modelo.

Por otro lado, en el enfoque backward de la regresión paso a paso, todas
las variables se incluyen inicialmente en el modelo y se van eliminando
una por una, comenzando con la variable que menos contribuye al ajuste
según el criterio establecido. En cada etapa, se evalúa si eliminar una
variable mejora significativamente el ajuste del modelo.

Otro enfoque de selección de variables es la penalización de uso de
parámetros no nulos al momento de minimizar la función de error. Dentro
de este enfoque se encuentra la regresión Ridge y LASSO (Least Absolute
Shrinkage and Selection Operator)

$$\text{Ridge: }\min_{β} \sum_{i}(y_i - \beta_0 - \sum_{j}\beta_{j}x_{ij})^2 + λ\sum_{j}\beta_{j}^2$$
$$\text{LASSO: }\min_{β}\sum_{i}(y_i - \beta_0 - \sum_{j}\beta_{j}x_{ij})^2 + λ\sum_{j}|\beta_{j}|$$

Aunque estos enfoques automáticos de selección de variables pueden ser
convenientes y ahorrar tiempo, es importante tener en cuenta algunas
limitaciones. En primer lugar, las implementaciones automáticas de
selección de variables no exploran todas las posibles combinaciones de
variables, lo que significa que podrían pasar por alto combinaciones
óptimas que un enfoque manual más exhaustivo podría descubrir.

Además, los resultados de la selección automática de variables pueden
generar conjuntos de variables poco intuitivos y difíciles de
interpretar. A veces, el algoritmo puede seleccionar variables que
tienen una relación estadística con la variable de respuesta, pero
carecen de una interpretación causal o intuitiva en el contexto del
problema.

Una alternativa es utilizar una mixtura entre métodos automáticos y
manuales, eligiendo aquellas variables que mejoran el modelo en ajuste y
que igualmente tienen un sentido interpretativo para la resolución de la
pregunta a responder.

*5. Selección de Índices*

La selección de índices en el análisis de regresión es un proceso
discrecional que puede influir significativamente en la interpretación y
el rendimiento de los modelos. Para abordar este problema de manera
efectiva, se pueden seguir algunas pautas generales que ayuden a
identificar y justificar la inclusión de índices en el análisis.

Condiciones para Indexar un Parámetro Es recomendable considerar la
inclusión de un índice en un modelo de regresión si se cumplen las
siguientes tres condiciones:

a)  Relevancia para el problema de gestión: El índice debe ser
    importante para abordar el problema de gestión en cuestión,
    proporcionando una distinción significativa entre diferentes
    aspectos del problema.

b)  Diferencias en el comportamiento de la variable dependiente: La
    variable dependiente debe mostrar comportamientos distintos para
    cada índice, lo que sugiere que la desagregación aporta información
    adicional útil.

c)  Suficiencia de datos: Deben estar disponibles suficientes datos para
    estimar de manera confiable los parámetros desagregados. La falta de
    datos puede conducir a estimaciones poco fiables y a un mayor riesgo
    de sobreajuste.

d)  Índices y Variables Binarias: En el análisis de regresión, los
    índices pueden representarse mediante variables binarias, también
    conocidas como variables dummy. Estas variables toman el valor de 1
    cuando se cumple una condición específica (por ejemplo, si un
    producto pertenece a una categoría determinada) y 0 en caso
    contrario. Aunque la representación de índices mediante variables
    binarias es matemáticamente equivalente, la notación de índices
    suele ser más compacta y se prefiere en la mayoría de los casos.

*6. Uso de Jerarquías*

Una jerarquía aparece cuando un parámetro del modelo aparece como una
función de otros parámetros, el uso de esta técnica es útil para
detectar posibles efectos de interacción entre las variables
predictoras, de esta forma se pueden escribir modelos más parsinomios
(es decir, modelos más sencillos y con menor cantidad de parámetros).
Sin embargo, es importante tener en cuenta que la inclusión de
jerarquías entre variables debe estar basada en una teoría clara o una
justificación empírica, y no simplemente probando diferentes
combinaciones de variables.

## Evaluación de modelos

La evaluación de modelos estadísticos es un tema amplio que involucra la
aplicación de los mismos principios y técnicas básicas a un gran grupo
de modelos. En la práctica, la evaluación de modelos se utiliza para
determinar la calidad y utilidad de los modelos estadísticos, es decir,
para determinar si un modelo se ajusta adecuadamente a los datos y si es
útil para hacer predicciones o inferencias sobre la población de
interés.

Es importante destacar que la evaluación de modelos estadísticos no es
un proceso estático y que puede requerir ajustes y modificaciones a
medida que se adquiere más información o se amplía el alcance del
modelo. Por lo tanto, es fundamental seguir actualizando y refinando los
modelos para asegurar su calidad y utilidad en la toma de decisiones
basadas en datos.

En la evaluación de modelos estadísticos, se utilizan diversas técnicas
que se verán a continuación.

### ¿Qué buscamos en un modelo?

Lo deseable en un modelo es que cualitativamente puedan contar una buena
historia, es decir, proporcionar información útil para poder tomar
decisiones que vayan en línea de lo que se busca estimar. Por otra
parte, se espera que cuantitativamente el modelo escogido ajuste bien a
los datos utilizados como insumo para la calibración, de tal manera que
reduzca el error de predicción y pueda generar un pronóstico creíble a
partir de lo observado.

Con esto en mente, queremos un criterio bien definido para comparar
modelos y determinar si un modelo dado es suficientemente bueno.

### Ajuste por métricas generales

Las siguientes métricas de ajuste se basan en reducir los errores de
predicción de los modelos, teniendo como fin cuantificar qué tanto error
tiene un modelo al predecir un conjunto de datos dado: 1. Coeficiente de
determinación o $R^2$: Indica la cantidad de variación en la variable
dependiente que puede ser explicada por las variable independientes en
un modelo. Se define como:

$$ R^2 = \frac{\sum_{i=1}^n (\hat{y}i - \bar{y})^2}{\sum{i=1}^n (y_i - \bar{y})^2} $$

Donde $\hat{y_i}$ son los valores predichos por el modelo, $\bar{y}$ es
la media de los valores observados $y_i$ y $n$ es el número de
observaciones.

2.  MAE (Mean Average Error):Calcula la diferencia promedio entre las
    predicciones del modelo y los valores reales observados en los
    datos.

$$MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y_i}|$$

La función valor absoluto ($|x|$) se utiliza para asegurar que el error
siempre sea positivo.

3.  MAPE (Mean Absolute Percentage Error): Se expresa en porcentaje y se
    calcula como el promedio de los valores absolutos de los errores
    porcentuales de cada observación.

$$MAPE = \frac{1}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|\cdot 100\%$$

4.  RMSE (Root Mean Squared Error): Es una medida de la diferencia entre
    los valores predichos y los valores reales en un conjunto de datos.
    La fórmula del RMSE es:

$$ RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2} $$

### Ajuste basado en la probabilidad

También es posible darle una interpretación probabilística al ajuste, es
decir, elegir aquellos parámetros que más se asemejen a la distribución
de probabilidad que generan los datos del modelo, para ello nos basamos
en la función de verosimilitud.

La fórmula general de la función de verosimilitud para un conjunto de
$n$ observaciones independientes y con distribución conjunta
$f(x_1, x_2, ..., x_n; θ)$ es:

$$L(\theta | x_1, x_2, ..., x_n) = f(x_1, x_2, ..., x_n; \theta) = \prod_{i=1}^{n} f(x_i;\theta)$$

donde $θ$ es el vector de parámetros desconocidos que se quieren estimar
y $f(x_i; θ)$ es la densidad de probabilidad (o función de masa de
probabilidad) de la variable aleatoria $x_i$ para un valor de $θ$.

Es común aplicar logaritmo a la función de verosimilitud, pues de esta
forma se facilitan los cálculos manteniendo sus propiedades (dado que el
logaritmo es una función monótona y creciente):

$$\ell(\theta | x) = \sum_{i=1}^{n} \log(f(x_i|\theta))$$

Las siguientes métricas se basan en la log-verosimilitud para evaluar el
nivel de ajuste:

1.  Razón de verosimilitud (o pseudo $R^2$): Esta métrica es utilzada
    cuando la variable de resultado es nominal u ordinal, de modo que el
    coeficiente de determinación no se puede aplicar como una medida de
    bondad de ajuste. Se define como:

$$\rho = 1 - \frac{\ell(\hat{\beta})}{\ell(0)} \text{(Asumiendo que $\beta=0$ es un modelo nulo razonable)}$$

2.  Criterio de Información de Akaike (AIC): Basado en la teoría de
    información, es una medida de la calidad del modelo que penaliza
    aquellos que son más complejos, lo que ayuda a prevenir el
    sobreajuste de los datos.

$$AIC = -2\ell({\hat{\beta}}) + 2k$$

Con $k$ el número de variables del modelo.

3.  Criterio de Información Bayesiano (BIC): Este criterio penaliza la
    complejidad del modelo de manera más fuerte que el AIC, en función
    del número de parámetros del modelo y del tamaño de la muestra de
    datos. El BIC es más efectivo que el AIC para prevenir el
    sobreajuste del modelo, lo que significa que es más probable que
    seleccione un modelo más simple y generalizable.

$$BIC = -2\ell(\hat{\beta}) + klog(n)$$

Con $n$ el número de observaciones en el set de datos.

### Errores dentro y fuera de la muestra

En general, se busca contruir modelos que sean generalizables a otros
datos fuera de aquellos que se utilizan para su construcción, para ello
se suele dividir el conjunto de datos en un set de *calibración* y otro
de *validación* para evaluar su capacidad de predicción.

En general, uno de los problemas que puede traer la excesiva
complejización de un modelo es la poca adaptabilidad a nuevos conjuntos
de datos, esto se conoce como sobreajuste (o overfitting), lo cual puede
ser detectado al comparar los errores de predicción entre el set de
calibración y validación:

```{r my-fig1, fig.cap="Error de calibración vs predicción",out.width='50%', fig.align='center'}
knitr::include_graphics(rep("images/fitting.png"))
```

### División de datos

La división de los datos en conjuntos de calibración y validación
depende de la estructura de los mismos. Por lo general se utiliza el 80%
de los datos en calibración y el 20% en validación. Si la estructura de
datos lo permite, podemos realizar crossvalidación ejecutamos múltiples
validaciones sobre diferentes muestras de prueba.

### Validación cruzada

Algunos modelos, en especial en el mundo del Machine learning, requieren
la calibración de sus hiperparámetros para una mejor predicción. Para
ello existen múltiples técnicas, donde una de las más populares es la
validación cruzada (cross validation).

El método de validación cruzada comienza con la división del conjunto en
$k$ subconjuntos (folds), dónde $k-1$ servirán para calibrar el modelo,
mientras que el conjunto restante se utilizará como validación. Este
proceso se repite cambiando el conjunto de validación por cada uno de
los folds, buscando los hiperparámetros que optimizan el rendimiento
para cada una de las combinaciones. Finalmente, el valor de los
hiperparámetros será la media de sus valores para cada fold.

```{r my-fig2, fig.cap="Ejemplo de validación cruzada",out.width='70%', fig.align='center'}
knitr::include_graphics(rep("images/cv.png"))
```

### Test de hipótesis

Además de la evaluación del ajuste del modelo a partir de métricas, es
posible hacer inferencias estadísticas sobre el modelo completo:

1.  Pruebas de bondad de ajuste: Este tipo de tests intentan responder
    la pregunta de si el modelo es lo suficientemente bueno para confiar
    en su rendimiento. Una de las pruebas más utilizadas es el test de
    $\chi ^2$ de Pearson. Se busca testear la siguiente hipótesis nula:

$H_0: \text{El modelo describe correctamente los datos observados}$

Para ello se separan los datos en $k$ posible categorías y se construye
el estadístico $\chi^2$

$$\chi^2 = \sum_{i = 1}^{K} \frac{(y_i - \hat{y_i})^2}{\hat{y_i}}$$

Se rechaza la hipótesis nula si $\chi^2 > \chi^{2}_{K-1, α}$.

Donde $\mathbb{P}(\chi^2 > \chi^{2}_{K-1, α}) = α$

2.  Comparación de modelos anidados: Supongamos que tenemos dos modelos
    A y B, diremos que el modelo B está anidado en el modelo A si el
    modelo B puede derivarse imponiendo algunas restricciones sobre los
    parámetros de A.

En el contexto de regresión, por ejemplo un modelo $y=a+bx$ está anidado
en otro modelo $y=a+bx+cz$, solo basta con imponer que $c=0$.

Para evaluar si vale la pena agregar más complejidad al modelo se
utiliza la prueba de Likelihood Ratio. De esta forma se puede determinar
si la mejora del rendimiento de un modelo en comparación al modelo
anidado se justifica en relación a la cantidad de nuevos parámetros.

La prueba de verosimilitud se basa en computar el estadístico del ratio:

$$LR = 2(LL_A - LL_B)$$

Supongamos que existen $k$ nuevos parámetros que se agregan en el modelo
A.

Si $LR > \chi^2(0.05, k)$, entonces el modelo A es mejor que el modelo B
(es decir, la adición de parámetros marca una diferencia
estadísticamente significativa al rendimiento del modelo.)

## Usos y limitaciones del análisis de regresión

Una vez que se construye y se estima un modelo, el siguiente paso es
interpretar sus resultados. Es posible enfocarse en el *aprendizaje*
sobre los parámetros retornados del modelo y cómo estos explican el
fenómeno a estudiar, como también es posible realizar un *pronóstico* a
futuro del desempeño de las variables a predecir.

### Aprendizaje de los parámetros

En general, la principal fuente de aprendizaje que provee un modelo de
regresión son los coeficientes calculados, los cuales entregan
información sobre el efecto de las variables independientes sobre lo que
se desea estudiar.

Dentro de las preguntas más importantes a responder se encuentran:

-   ¿Poseen las variables del modelo el signo esperado?
-   ¿Son estadísticamente significativos?
-   ¿Es relevante la magnitud de su efecto?

Para responder a estas preguntas se hace necesario el uso de heramientas
estadsticas tales como *t-test* para evaluaciones individuales o
*F-test* para la evaluación de un conjunto de regresores.

### Interpretación de los coeficientes

Supongamos un modelo lineal simple definido por $y = 12 + 1.5x$, es de
toda lógica pensar que el efecto de $x$ sobre $y$ al incrementar en una
unidad es, en promedio, de $1.5$. Sin embargo, esta afirmación sería
correcta *sólo* en el caso de que se tengan buenas razones para creer
que $x$ tiene un *efecto causal* en $y$.

Es importante recordar que los modelos de regresión solo indican la
correlación entre las variables dependientes con las independientes,
pero no necesariamente una relación causal entre ambas. Dentro de los
fenómenos que pueden explicar la correlación sin causalidad entre
variables, se encuentran los siguientes:

-   Causalidad inversa: $y$ causa $x$
-   Simultaneidad: $y$ causa $x$ y $x$ causa $y$
-   Tercera variable: $z$ causa $x$ e $y$

Para averiguar qué es lo que hace que una variable independiente tenga
un efecto sobre la variable dependiente, se suele recurrir a un método
llamado *análisis de mediación*, el cual consiste en la investigación
para examinar la relación entre una variable independiente y una
variable dependiente a través de una variable intermedia, conocida como
mediador. La mediación se produce cuando la relación entre la variable
independiente y la variable dependiente se explica por completo o
parcialmente por la influencia del mediador.

```{r my-fig3, fig.cap="Modelo de mediación",out.width='70%', fig.align='center'}
knitr::include_graphics(rep("images/Simple_Mediation_Model.png"))
```

Es importante no confundir el análisis de mediación con un efecto de
tercera variable. Por ejemplo, si $z$ causa $x$ y a la vez $z$ causa
$y$, entonces estamos bajo un escenario de tercera variable. Sin
embargo, si $x$ causa $z$ y $z$ causa $y$, es posible afirmar que $z$ es
una variable mediadora entre $x$ e $y$.

### Pronósticos

La principal razón de realizar buenas predicciones con los modelos
construidos es la toma de decisiones mediante la evaluación de
resultados en diversos escenarios posibles. Bajo el enfoque de regresión
lineal, el pronóstico está dado por la esperanza del valor de la
variable dependiente, es decir $\mathbb{E}[Y]$.

En el caso mas sencillo, el pronóstico está dado por
$\mathbb{E}[Y] = \beta X$, si dentro del desarrollo del modelo se
decidiera utilizar una transformación funcional en el modelo, la
expresión del pronóstico cambiará. Por ejemplo, para el caso de una
regresión log-lineal, el término de error no desaparece del pronóstico,
debido a que se está calculando la esperanza de una función de una
variable aleatoria, luego el resultado que se obtiene es
$\mathbb{E}[Y] = exp(\beta X + \frac{1}{2}S_ϵ^2)$, con $S_{ϵ}^2$ la
varianza muestral de $ϵ$.

### Errores de pronóstico

El error de pronóstico contiene dos componentes: errores residuales
(debido a la dispersión de los datos) y errores de muestra. Se puede
escribir de la siguiente manera:

$$\text{sef}(x_0) = s\sqrt{x_0^T(X^TX)^{-1}x_0 + 1}$$

La variabilidad en los prónosticos dependerá de las variables
explicativas del modelo y de la muestra utilizada para estimar la forma
funcional de la variable dependiente. Esta variabilidad debe ser
considerada en la evaluación de escenarios al momento de tomar una
decisión.

### Principios generales de pronóstico

1.  Incluir todas las variables que se esperan que contribuyan al
    pronóstico: A diferencia del enfoque anterior, no se está buscando
    el entendimiento de los parámetros sino predecir.
2.  Evaluar si algunas variables pueden ser agregadas para crear
    índices: Puede suceder que varias variables capturan un mísmo
    fenómeno, y por ende causar ruido en la predicción. Para evitar
    esto, se puede construir una variable que las agrupe a todas en una
    sola componente.
3.  Para variables importantes agregar interacciones: Puede que exista
    un efecto conjunto no observado.
4.  Evaluar la inclusión de variables explicativas basadas en su signo
    esperado y significancia estadística:
5.  Significativa y signo esperado: Mantener en el modelo.
6.  No significativa y signo esperado: Mantener en el modelo.
7.  Significativa y signo contrario: Puede causar ruido en el
    pronóstico, por lo que se debe quitar del modelo.
8.  No significativa y signo contrario: Es posible que algo esté pasando
    con esa variable, es importante considerar trabajar con mas datos
    y/o variables.

### Limitaciones de los modelos de regresión

Debido a su simpleza, los modelos de regresión poseen ciertas
limitaciones provocadas por la muestra de datos utilizadas, las
variables escogidas para el modelo o por la naturaleza del método de
estimación de mínimos cuadrados. Algunos de los problemas más frecuentes
que se encuentran al trabajar con modelos de regresión son los
siguientes:

1.  *Colinealidad*: Es la condición cuando uno o más regresores están
    correlacionados entre sí, dependiendo del grado de la misma se debe
    proceder de manera distinta. Si la correlación entre regresores es
    baja, no existe problema. Si la correlación es alta, se debe
    considerar eliminar una o más variables redundantes, reducir el
    número de variables en el modelo o transformar las variables para
    reducir su correlación. Finalmente, si existe **colinealidad
    perfecta** la matriz de regresores $X$ no es invertible y el modelo
    no puede ser calculado.
2.  Es posible requerir de *causalidad* para afirmar que existe un
    efecto entre variables. Para determinar un efecto causal se pueden
    realizar experimentos, proponer modelos estructurales o utilizar
    variables instrumentales.
3.  *Heteroscedasticidad*: Es la correlación entre los términos de error
    y las variables del modelo. En otras palabras, la
    heteroscedasticidad significa que la dispersión de los errores en
    los datos es diferente para diferentes valores de las variables
    independientes. El estimador sigue siendo insesgado, pero se torna
    estadísticamente ineficiente. Para coregir heteroscedasticidad se
    utiliza mínimos cuadrados generalizados, ponderando según la
    magnitud del error de cada observación.
4.  *Autocorrelación*: Los errores estan correlacionados entre sí. Al
    igual que en el caso anterior el estimador sigue siendo insesgado,
    pero se torna estadísticamente ineficiente. Para enfrentar este
    fenómeno se recurre al uso de series de tiempo.

### Modelos lineales generalizados

Muchas veces los modelos lineales son muy restrictivos, para ello se
utilizan modelos lineales generalizados, es decir, mantiene la
linealidad en los parámetros, pero la respuesta del modelo puede tener
una forma funcional distinta.

Dentro de la familia de modelos generalizados se encuentran:

-   Regresión de Poisson (La variable dependiente es positiva y
    discreta)
-   Regresión logística (Se busca predecir número de sucesos de un total
    de intentos)
-   Mínimos cuadrados generalizados

## Alternativas de Machine Learning para la regresión

### ¿Qué es Machine Learning?

El concepto de Machine Learning se ha vuelto muy popular últimamente,
obteniendo mucha atención y usos en una gran cantidad de tareas, pero ¿A
qué nos referimos cuando hablamos de modelos de machine learning?

En terminos sencillos, el aprendizaje automático, o machine learning en
inglés, es una rama de la inteligencia artificial que se centra en el
desarrollo de algoritmos y modelos que permiten a las computadoras
aprender patrones y realizar tareas específicas sin ser programadas
explícitamente. En lugar de seguir instrucciones detalladas, los
sistemas de aprendizaje automático utilizan datos para mejorar su
rendimiento en una tarea particular a lo largo del tiempo. Este enfoque
permite a las máquinas adaptarse y mejorar su desempeño a medida que se
exponen a más información.

### ¿La regresión cuenta como un modelo de ML?

Si bien la regresión utiliza datos para aprender a partir de ellos, no
se suele considerar completamente un modelo de aprendizaje automático.
El hecho de tener que seleccionar las variables adecuadas, aplicar
transformaciones funcionales y tener que verificar el cumplimiento de
supuestos estadísticos hace que la regresión sea menos automático que lo
que normalmente se entiende como ML.

Un acercamiento más próximo a un modelo de ML se da al utilizar técnicas
de selección automática de variables como Ridge o LASSO. De todas
formas, los límites son difusos, en este curso se entenderá como ML a
cualquier modelo que pueda aprender automáticamente sobre el conjunto de
variables predictivas y sus formas funcionales.

### Multivariate Adaptive Regression Splines (MARS)

MARS extiende OLS generando para cada variable independiente $x$ una
función bisagra (hinge)
$h(x, a) = \{ \max\{0, x-a\},  \max\{0, a-x\} \}$. De esta forma, un
modelo MARS genera una aproximación lineal por tramos.

Por ejemplo:

$$\text{OLS: }y = \beta_0 + \beta_1 x$$
$$\text{MARS: }y = \gamma_0 + \gamma_1 \max\{0, x-a\} + \gamma_2 \max\{0, a-x\}$$

Además, MARS puede incluir multiplicaciones entre dos o más funciones
bisagras para diferentes predictores, de tal manera que captura la
interacción entre estos.

Inicialmente, MARS busca el único punto en el rango de $x$ donde dos
relaciones lineales diferentes entre $y$ y $x$ logran un error más
pequeño, este punto se convierte en el primer corte (knot) $a$ del
modelo. Este procedimiento continúa hasta que se encuentren los demás
puntos de corte. Para evitar el sobreajuste, MARS elimina términos que
provoquen una pequeña contribución a la mejora del ajuste.

```{r mars, fig.cap="Regresión MARS para distinto número de bisagras",out.width='70%', fig.align='center'}
knitr::include_graphics(rep("images/mars.png"))
```

### K Nearest Neighbors Regression (KNN)

En la regresión con KNN, el objetivo es predecir un valor numérico para
una variable dependiente basándose en los valores de las variables
independientes. A diferencia de la regresión lineal, que ajusta una
línea o superficie a los datos, KNN no realiza una aproximación
paramétrica. En cambio, hace predicciones basándose en la similitud
entre los puntos de datos.

Hay una serie de parámetros que deben ajustarse en KNN. Para decidir qué
funciona mejor, la práctica común es decidir basándose en el error de
predicción:

1.  Vecinos más cercanos (Neighbors): $k$ representa el número de
    vecinos más cercanos que se tomarán en cuenta para hacer una
    predicción. Se calcula la distancia entre el punto a predecir y los
    demás puntos del conjunto de entrenamiento.

2.  Pesos (Weights): Para predecir el valor de la variable dependiente
    para un nuevo punto, se promedian los valores de la variable
    dependiente de los $k$ vecinos más cercanos. Uno de los parámetros
    del modelo es el peso que se le da a los vecinos más cercanos.

3.  Distancia: La medida de distancia más comúnmente utilizada en KNN es
    la distancia euclidiana, pero otras medidas también pueden ser
    empleadas según el tipo de datos y el problema específico
    (Manhattan, Coseno, Mahalanobis, etc.)

```{r knn, fig.cap="Regresión KNN para distinto número de vecinos cercanos",out.width='100%', fig.align='center'}
```

### Regression trees

Los arboles de regresión solo tienen sentido cuando el problema tiene
múltiples regresores, el objetivo es dividir el espacio de regresores en
subconjuntos y luego utilizar un modelo simple (constante) dentro de
cada región. Las particiones son secuenciales mediante divisiones
binarias generando una estructura de árbol.

El modelo busca cada valor distinto de cada variable de entrada para
encontrar el predictor y dividir el valor que divide los datos en dos.
regiones $R_1$ y $R_2$, con valores medios $c_1$ y $c_2$ para minimizar
la suma de los errores al cuadrado

$$\min SSE = \min \left\{ \sum_{i \in R_1}(y_i - c_1)^2 + \sum_{i \in R_2} (y_i - c_2)^2 \right\}$$

Es común agregar hiperparámetros de penalización para evitar el
sobreajuste.

*Ejemplo:* Sea $y = f(x_1, x_2)$. Los valores de $x_1$ y $x_2$ se pueden
representar en el plano mientras que los valores de $y$ se representan
con colores (cuanto más grandes, más oscuros)

```{r ej1, fig.cap="Región de ejemplo", out.width='40%', fig.align='center'}
knitr::include_graphics(rep("images/tree1.png"))
```

Luego, un arbol que representa la separación en regiones según $x_1$ y
$x_2$ es:

```{r ej2, fig.cap="Árbol de ejemplo",out.width='20%', fig.align='center'}
knitr::include_graphics(rep("images/tree2.png"))
```

### Bagging y Random forests

Un problema de los árboles de regresión es que son sensibles a pequeñas
variaciones en los datos. En general para solucionar este problema se
crean varios árboles y se promedian los resultados obtenidos, a esto se
le llama bosque aleatorio (random forest).

Para la construcción de este conjunto de arboles de regresión se hace
uso de una técnica llamada Bagging (\*Bootstrap \*\*Agg\*regation), la
cual sigue los siguientes pasos:

1.  *Bootstrap Sampling:* Se generan múltiples conjuntos de datos de
    entrenamiento mediante un muestreo con reemplazo, al que se conoce
    como bootstrap. Al hacerlo, algunos datos se pueden repetir en un
    conjunto de datos, mientras que otros pueden no aparecer en
    absoluto.

2.  *Construcción de árboles de regresión:* Se construyen múltiples
    árboles de decisión, generalmente utilizando el conjunto de datos de
    entrenamiento generado en cada iteración del bootstrap. Cada árbol
    se entrena de manera independiente y puede llegar a sobreajustarse a
    ciertos patrones del conjunto de datos de entrenamiento.

3.  *Promediar resultados:* Para hacer predicciones en un nuevo dato, se
    utiliza cada árbol de decisión para realizar una predicción,
    promediando los valores de cada árbol.

La combinación de múltiples árboles entrenados de esta manera ayuda a
reducir la varianza y mejora la capacidad de generalización del modelo.
Además, el Random Forest introduce aleatoriedad adicional al seleccionar
un subconjunto aleatorio de características para dividir en cada nodo de
los árboles, lo que agrega más diversidad al conjunto de árboles.

<!--chapter:end:01-regresión.Rmd-->

---
output: 
  bookdown::html_document2:
    css: style.css
editor_options:
  markdown:
    wrap: 72
---

# Modelos probabilísticos

## Introducción

Usualmente, y en el contexto de Marketing, interesa estudiar el
comportamiento de las personas, para realizar acciones estratégicas en
función de los aprendizajes adquiridos. Así, se pueden definir dos tipos
de enfoques a usar según distintos supuestos en el comportamiento de los
agentes (tomadores de decisiones):

-   *Enfoque Estructural*: Este enfoque asume que los los agentes se
    comportan de manera racional, tomando decisiones de modo de
    maximizar sus utilidades. Usualmente aparece cuando hay
    disponibilidad de largos volúmenes de datos.

-   *Modelos Probabilísticos*: Este enfoque asume que los agentes se
    comportan en base a decisiones aleatorias. Usualmente aparece cuando
    se tiene información reducida y/o agregada respecto al
    comportamiento de los agentes en estudio.

En esta unidad, se estudiará el enfoque probabilístico.

**Metodología**

La metodología consiste en:

1.  Determinar el problema de decisión a estudiar y la información
    requerida.

2.  Identificar el comportamiento observable de interés a nivel
    individual.

3.  Seleccionar la distribución de probabilidad que caracterice el
    comportamiento individual. Se consideran los parámetros de esta
    distribución, como características latentes a nivel individual.

4.  Escoger la distribución que caracterice cómo las características
    latentes están distribuidas en la población. Se le llama
    distribución mixta o heterogénea. Típicamente, se denota con
    $g(\theta)$.

5.  Derivar la distribución agregada, o distribución observable, del
    comportamiento de interés.

    $$
    \begin{array}{cc}
    f(x) = \int f(x \mid \theta)\, g(\theta)\, d\theta & \text{, para el caso continuo.} \\
    p(x) = \sum_{i}f(x \mid \theta)\, \Pr(\theta = \theta_{i}) & \text{, para el caso discreto.}
    \end{array}
    $$

6.  Estimar los parámetros del modelo (de la distribución mixta),
    mediante el ajuste de la distribución agregada a los datos
    observados.

7.  Usar los resultados para tomar una decisión sobre el problema de
    marketing en cuestión.

El enfoque de modelos probabilísticos permite abordar una gran cantidad
de problemas asociados al marketing, entre los cuales se considerarán:

-   *Duración*: Situaciones ligadas a la duración de una determinada
    conducta de un cliente, como por ejemplo el tiempo de permanencia en
    una compañía y el tiempo de adopción de un cierto producto
    innovador.

-   *Conteo*: Situaciones ligadas al estudio de llegadas de clientes y
    contabilización de una determinada conducta, como por ejemplo el
    número de visitas a un portal web y la cantidad de productos
    comprados en una tienda de retail.

-   *Elección*: Situaciones asociadas a las decisiones de elección de un
    determinado cliente, como por ejemplo el número de clientes que
    eligen responder una campaña publicitaria y la elección de cambiar o
    no de canal de televisión.

## Modelos de Duración

En años recientes, las mejoras en las tecnologías de información han
dado como resultado un aumento en la disponibilidad de data acerca de
los individuos en determinadas situaciones de consumo. Esta tendencia se
relaciona íntimamente con el creciente deseo de los gerentes de
marketing respecto a utilizar esta data disponible para aprender de
manera exhaustiva sobre el comportamiento de los clientes. Muchos
analistas tratan de describir y predecir el comportamiento de los
consumidores usando variables observables, como lo son variables
transaccionales (monto gastado, tienda donde se adquirió un determinado
producto, fecha de la compra, etc.), como así también variables que
caracterizan a los individuos (edad, nivel socio-económico, estado
civil, etc.). A partir de esta información es posible aplicar modelos de
regresión lineal o árboles de decisión, con el objetivo de poder
proyectar comportamientos, o bien rebatir hipótesis que previamente se
tenían respecto a un escenario determinado.

En este capítulo, se considera un enfoque distinto al anterior, en el
cual las decisiones de los individuos se desprenden de un comportamiento
**aleatorio**, en que las decisiones no dependen únicamente de variables
descriptivas del modelo, sino que también provienen del resultado de un
proceso estocástico no observable que opera intrínsecamente en los
individuos. Es decir, la asunción que el comportamiento se desprende de
una distribución de probabilidades que puede variar dependiendo del
modelo a estimar y de la complejidad del mismo. Alternativamente, se
puede considerar el enfoque racionalista que contempla a los individios
que siempre actúan racionalmente, lo que, de acuerdo a la experiencia
empírica, no se cumple siempre.

**Ejemplo 1**: Supongamos que un cliente hizo 2 compras el año pasado de
nuestro producto. ¿Esto implica inmediatamente que el consumidor
mantendrá ese patrón y este año volverá a ese nivel de consumo? ¿O
existe alguna posibilidad de que el cliente incremente o disminuya su
consumo? ¿Cuál es el proceso que hay detrás?

En lo que sigue, se considera 3 tipos de modelos de duración a estimar:

1.  **Modelos de duración en tiempo discreto.**

2.  **Modelos de duración en tiempo continuo sin dependencia en la
    duración.**

3.  **Modelos de duración en tiempo continuo con dependencia en la
    duración.**

### Modelos de duración de tiempo discreto

Como ejemplo, se tiene el siguiente escenario: a través de una propuesta
de valor atractiva, una empresa consigue un cliente. ¿Durante cuántos
periodos estará afiliado a la compañía?

Se considera que cada periodo se puede cuantificar en términos discretos
(días, semanas, meses, años). Algunos ejemplos a considerar:

-   Un usuario descarga una aplicación para su teléfono inteligente.
    ¿Por cuántos meses la utilizará?

-   Adquirimos un cliente en un banco. ¿Durante cuántos años permanecerá
    como cliente?

-   Un cliente se suscribe a un plan telefónico o de internet. ¿Por
    cuántos periodos se mantendrá suscrito?

#### Modelo Geométrico Desplazado {.unnumbered}

Como ejemplo, se asume que se tiene una cartera de clientes que van
abandonando la relación comercial para **nunca más retomarla** en
cualquier periodo definido. Al final de cada periodo, un cliente decide
de manera aleatoria si continúa afiliado. De acuerdo a un proceso de
Bernoulli, hay una probabilidad $\theta$ de cancelar la relación
comercial con la empresa y con el complemento $1-\theta$ decide su
permanencia.

Para cada individuo, se asume que la probabilidad con la que decide no
cambia en el tiempo. Como primer acercamiento, se asume que dicha
probabilidad es igual e idénticamente distribuida (iid). Sea T la
variable aleatoria relativa a la duración de la relación comercial entre
el cliente y la compañía, es decir la variable que describe el instante
en el cual esta relación se acaba. De acuerdo a la descripción anterior,
la variable aleatoria T sigue una distribución Geométrica Desplazada
(sG) con parámetro $\theta$, es decir, el comportamiento de los
individuos puede ser descrito formalmente de acuerdo a la siguiente
relación:

1.  Probabilidad de que un individuo cualquiera abandone la relación
    comercial exactamente en el periodo t:

    $$P(T=t| \theta) = \theta (1 - \theta)^{t-1}$$

2.  Probabilidad de que un individuo cualquiera abandone la relación
    comercial en un periodo posterior al periodo t:

    $$P(T>t \;|\; \theta) = (1 - \theta)^{t}$$

No es muy difícil aplicar un modelamiento a partir de lo anterior para
intentar dilucidar de qué forma se debería comportar un determinado
grupo de individuos a partir de la data transaccional que se tiene.

**Ejemplo:** Se considera una cohorte inicial de 1000 clientes (indexado
por el número 0). Se toma el supuesto de que, año a año, un determinado
número de clientes se retira del negocio por razones que se desconocen a
priori, pero que provienen de un proceso estocástico en el que cada
cliente en forma independiente toma la decisión de permanecer o
abandonar a partir del lanzamiento de una moneda (Bernoulli). Esto es,
con probabilidad $\theta$ abandona y con probabilidad $1 - \theta$
permanece en la compañía. La data histórica se presenta a continuación:

| Año | \# de Clientes | \% de Permanencia | \% de Retención |
|:---:|:--------------:|:-----------------:|:---------------:|
|  0  |      1000      |       100%        |       \-        |
|  1  |      631       |        63%        |       63%       |
|  2  |      468       |        47%        |       74%       |
|  3  |      382       |        38%        |       82%       |
|  4  |      326       |        33%        |       85%       |
|  5  |      289       |        29%        |       89%       |
|  6  |      262       |        26%        |       91%       |
|  7  |      241       |        24%        |       92%       |

Donde el % de Retención como el porcentaje de clientes que se mantuvo en
la relación comercial respecto al periodo anterior.

Sin embargo, aún no se desconoce el valor de $\theta$ (es un parámetro
poblacional). Dicho valor se estima mediante el método de máxima
verosimilitud, que busca encontrar el valor del parámetro óptimo de
acuerdo a los datos observados y asumiendo independencia entre las
muestras:

-   Densidad de probabilidades conjunta:

$$f(x_1,x_2,...,x_n|\theta) = f(x_1|\theta) \cdot f(x_2|\theta) \cdot ... \cdot f(x_n|\theta)$$

-   Función de verosimilitud:

$$
\begin{aligned}
L(\theta)  &= \left\{\prod_{t=1}^{\tau=7} P(T=t \mid \theta)^{\,n_t}\right\}\; P(T>\tau \mid \theta)^{\,n_{\tau}} \\  &= \left\{\prod_{t=1}^{\tau=7} \big[\theta(1-\theta)^{t-1}\big]^{\,n_t}\right\}\; \big[(1-\theta)^{\tau}\big]^{\,n_{\tau}}
\end{aligned}
$$ Notar que $n_\tau$ es el número de clientes activos después del
máximo tiempo observable $\tau$, $n_t$ es el número de abandonos (si hay
369 abandonos, se multiplica 369 veces), y $x_i$ el año. A partir de
esto y de la data disponible, las contribuciones a la verosimilitud son
las siguientes (asumiendo como modelo de comportamiento la distribución
geométrica desplazada)

| Año | \# de Clientes | \# de Abandonos | Pr |
|------------------|------------------|------------------|------------------|
| 0 | 1000 | \- | \- |
| 1 | 631 | 369 | $P(T=1\|\theta) = \theta^{369}$ |
| 2 | 468 | 163 | $P(T=2\|\theta) = ((1 - \theta)^{(2-1)} \cdot \theta)^{163}$ |
| 3 | 382 | 86 | $P(T=3\|\theta) = ((1 - \theta)^{(3-1)} \cdot \theta)^{86}$ |
| 4 | 326 | 56 | $P(T=4\|\theta) = ((1 - \theta)^{(4-1)} \cdot \theta)^{56}$ |
| 5 | 289 | 37 | $P(T=5\|\theta) = ((1 - \theta)^{(5-1)} \cdot \theta)^{37}$ |
| 6 | 262 | 27 | $P(T=6\|\theta) = ((1 - \theta)^{(6-1)} \cdot \theta)^{27}$ |
| 7 | 241 | 21 | $P(T=7\|\theta) = ((1 - \theta)^{(7-1)} \cdot \theta)^{21}$ |
| \>7 | \- | \- | $P(T>7\|\theta) = ((1-\theta)^7)^{241}$ |

Dado que maximizar un producto es complicado, se aplica logaritmo a lo
anterior, de modo de construir la función de log verosimilitud:

-   Función de log verosimilitud:

$$
\begin{aligned}
\hat{\ell}(\theta)  &= \sum_{t=1}^{\tau} n_t \,\ln P(T=t \mid \theta)\;+\; n_{\tau}\,\ln P(T>\tau \mid \theta) \\  &= \sum_{t=1}^{\tau} n_t \big[\ln \theta + (t-1)\ln(1-\theta)\big]\;+\;n_{\tau}\,\tau\ln(1-\theta) \end{aligned}
$$ Con lo anterior, es sencillo maximizar la función de log
verosimilitud para un $\theta$ desconocido utilizando un paquete
estadístico como R, con lo que se tiene:

$$
\begin{aligned}
\hat{\theta} &= 0, 226027 \\
\hat{l} &= -1794,62
\end{aligned}
\quad (\#eq:homogeneo)
$$El modelo presentado, si bien permite tomar medidas de gestión a
partir de un modelo sencillo, es poco realista, pues se asume que la
población posee igual probabilidad de abandono.

Una manera de incluir mayor complejidad al modelo y hacerlo más robusto,
se asume que la población no es homogénea, sino que existen segmentos de
individuos quienes al ser agrupados, presentan un comportamiento similar
(heterogéneo). La forma más sencilla de modelar esto es asumiendo que la
población presenta 2 patrones de comportamiento o 2 segmentos. Para un
segmento de individuos, la decisión de abandonar o permanecer se
identifica a partir de un parámetro $\theta_1$ (del mismo modo que en el
caso anterior) y, para el otro segmento, la decisión se determina a
partir de un parámetro $\theta_2$ distinto de $\theta_1$.

Formalmente, las relaciones que describen de mejor manera esto son las
siguientes:

1.  Probabilidad de que un individuo cualquiera abandone la relación
    comercial exactamente en el periodo $t$ en una población con 2
    segmentos:

$$P(T=t|\theta_1, \theta_2, \pi)= \theta_1 (1-\theta_1)^{t-1} \pi + \theta_2(1-\theta_2)^{t-1}(1-\pi)$$
2. Probabilidad de que un individuo cualquiera abandone la relación
comercial en un periodo posterior al periodo $t$ en una población con 2
segmentos:

$$P(T>t|\theta_1, \theta_2, \pi)= (1-\theta_1)^{t} \pi + (1-\theta_2)^{t}(1-\pi)$$

En el modelo anterior, $\pi$ representa el porcentaje de la población
que pertenece al segmento 1, de tal forma que su complemento $1-\pi$
representa el porcentaje de la población que pertenece al segmento 2.
Cabe mencionar que se puede expandir a más segmentos, siempre que
sepamos su proporción $\pi$.

#### Modelo Beta Geométrico desplazado {.unnumbered}

Los modelos anteriores funcionan bien cuando la población se comporta de
manera distinta entre clases latentes, y similar al interior de cada
clase latente. Sin embargo, puede ser mucho más realista e interesante
asumir que existe una heterogeneidad continua en la población, es decir,
que existe un número infinito de segmentos (o al menos tendiente a
infinito) de manera de capturar todas las preferencias individuales de
cada miembro de la población considerada.

Para estos propósitos, ya no asumiremos que la probabilidad de abandono
$\theta$ sigue una distribución discreta de Bernoulli (éxito-fracaso),
sino que asumiremos que el parámetro proviene de una distribución
continua $\text{Beta}$ de parámetros $\alpha$ y $\beta$.

Por tanto, es posible calcular las probabilidades antes presentadas en
forma análoga, aplicando el enfoque antes mencionado (probabilidades
totales):

1.  Probabilidad de que un individuo cualquiera abandone la relación
    comercial exactamente en el periodo t:

    $$P(T=t|\alpha,\beta) = \int_0^1 P(T=t|\theta)B(\theta|\alpha,\beta)d\theta$$

    Donde:

$$B(\theta|\alpha,\beta) = \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}$$

$$B(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}$$
2. Probabilidad de que un individuo cualquiera abandone la relación
comercial en un periodo posterior al periodo t:

$$P(T>t|\alpha,\beta) = \int_0^1 (T>t|\theta)B(\theta|\alpha,\beta)d\theta$$
Al desarrollar la primera integral antes mencionada, y reconociendo las
relaciones de la distribución *Beta*, se tiene que:

$$
\begin{aligned} P(T = t \mid \alpha, \beta) &= \int_0^1 \left( \theta(1-\theta)^{t-1} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) d\theta \\ &= \frac{1}{B(\alpha, \beta)} \int_0^1 (\theta \cdot \theta^{\alpha-1}) \cdot ((1-\theta)^{t-1} \cdot (1-\theta)^{\beta-1}) d\theta \\ &= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha} (1-\theta)^{t+\beta-2} d\theta \\ &= \frac{B(\alpha+1, t+\beta-1)}{B(\alpha, \beta)} \end{aligned}
$$

Notar que se usa indistintamente el $B(\alpha,\beta)$ para hacer alusión
tanto a la **función** como a la **distribución Beta**. Bajo ninguna
circunstancia dichos objetos son iguales.

El desarrollo de la segunda integral es:

$$
\begin{aligned}
P(T > t \mid \alpha, \beta) &= \int_0^1 (1-\theta)^{t} \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) d\theta \\
&= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha-1} \cdot ((1-\theta)^{t} \cdot (1-\theta)^{\beta-1}) d\theta \\
&= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha-1} (1-\theta)^{t+\beta-1} d\theta \\
&= \frac{B(\alpha, t+\beta)}{B(\alpha, \beta)}
\end{aligned}
$$

**Ejemplo:** Considerando la misma situación que se presentó en el
ejemplo anterior (clientes que año a año abandonan la relación
comercial), pero ahora asumiendo que existe un comportamiento
heterogéneo en la población, es posible reconocer que existe una
recursividad en la fórmula del cálculo de la probabilidad de abandono en
cada período:

$$
\begin{aligned}
\text{Caso Base (t=1):}& \\
P(T=1 \mid \alpha, \beta) &= \frac{B(\alpha+1, \beta)}{B(\alpha, \beta)} \\
&= \frac{\frac{\Gamma(\alpha+1)\Gamma(\beta)}{\Gamma(\alpha+1+\beta)}}{\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}} \\
&= \frac{\Gamma(\alpha+1)}{\Gamma(\alpha)} \cdot \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha+\beta+1)} \\
&= \frac{\alpha\Gamma(\alpha)}{\Gamma(\alpha)} \cdot \frac{\Gamma(\alpha+\beta)}{(\alpha+\beta)\Gamma(\alpha+\beta)} \\
&= \frac{\alpha}{\alpha+\beta} \\
\\
\text{Paso Recursivo (t > 1):}& \\
\frac{P(T=t \mid \alpha, \beta)}{P(T=t-1 \mid \alpha, \beta)} &= \frac{B(\alpha+1, t+\beta-1)}{B(\alpha+1, t+\beta-2)} \\
&= \frac{\frac{\Gamma(\alpha+1)\Gamma(t+\beta-1)}{\Gamma(\alpha+t+\beta)}}{\frac{\Gamma(\alpha+1)\Gamma(t+\beta-2)}{\Gamma(\alpha+t+\beta-1)}} \\
&= \frac{\Gamma(t+\beta-1)}{\Gamma(t+\beta-2)} \cdot \frac{\Gamma(\alpha+t+\beta-1)}{\Gamma(\alpha+t+\beta)} \\
&= \frac{(t+\beta-2)\Gamma(t+\beta-2)}{\Gamma(t+\beta-2)} \cdot \frac{\Gamma(\alpha+t+\beta-1)}{(\alpha+t+\beta-1)\Gamma(\alpha+t+\beta-1)} \\
&= \frac{\beta+t-2}{\alpha+\beta+t-1} \\
&= P(T=t-1 \mid \alpha, \beta) \frac{\beta+t-2}{\alpha+\beta+t-1}
\end{aligned}
$$

Modelo que al ser evaluado, da el siguiente resultado:

$$
\begin{array}{c}
\hat{\alpha} = 0,7041\\
\hat{\beta}= 1,1820\\
\hat{l} = -1680,27
\end{array}
\quad (\#eq:heterogeneo)
$$

Notar que existe una notoria diferencia en cuanto al valor de la log
verosimilitud obtenida por el modelo \@ref(eq:heterogeneo) respecto al
modelo \@ref(eq:homogeneo). Si bien esto indica una mejora del modelo,
es necesario realizar la comparación en base a métricas de evaluación
mas precisas (AIC, BIC, etc.)

### Modelos de duración en tiempo continuo sin dependencia en la duración

Para algunos modelos, medir el tiempo como si fueran períodos discretos
puede ser un buena aproximación de acuerdo a los objetivos del análisis
que se desea llevar a cabo.

En otros casos, puede ser en cambio más útil considerar el tiempo como
una variable continua, debido a que podría interesar medir la ocurrencia
de un suceso de manera más exacta. Algunos casos relativos a este
enfoque son:

-   Tiempos de respuesta a una campaña promocional de marketing directo.

-   Tiempo entre visitas a nuestro website.

-   Tiempos entre llamadas en un call center.

-   Tiempos de operación en la industria de servicios.

Al igual que en el caso de los modelos en tiempo discreto, lo que
interesa estudiar es poder implementar un modelo que tenga una forma
funcional flexible para ser trabajada y modificada fácilmente, que logre
ajustar a la data histórica que se tiene y proyectar el comportamiento
futuro de los clientes, es decir, que sea un buen modelo predictivo para
tomar acciones en función de aquello.

#### Modelo Exponencial {.unnumbered}

Se puede medir el tiempo que pasa desde que se lanza un producto hasta
que el consumidor decide adquirirlo. Existen muchos factores externos
que determinan esta decisión: exposición a publicidad, número de visitas
a la tienda, llamadas recibidas por call center, entre otras. Nuevamente
se asume que el comportamiento es aleatorio, es decir, que los
consumidores deciden el momento en el cuál van a consumir a partir de
una distribución de probabilidades.

Esto puede verse con una distribución exponencial, con la variable
aleatoria $t$ definida como el tiempo en que un cliente va a consumir el
producto por primera vez. Se asume que esta variable está
exponencialmente distribuida con una tasa $\lambda$. De esta forma, se
tiene que el comportamiento de los consumidores puede verse como:

1.  Probabilidad de que ocurra en $t$ o antes:

    $$P(T \leq t) = 1 - e^{-\lambda t}$$

2.  Probabilidad de que ocurra después de $t$:

    $$
    P(T > t) = e^{-\lambda t}
    $$

Por tanto, su función de verosimilitud para un tiempo continuo
corresponde a:

$$
\begin{aligned}
L(\theta) &= \prod_{i \in A} f(t_i | \theta) \prod_{i \notin A} (1 - P(T \leq t)) \\
&= \prod_{i \in A} (\theta e^{-\theta t_i}) \prod_{i \notin A} (e^{-\theta \tau_i})
\end{aligned}
$$

Acá $f(t_i \mid \theta)$ es la función de densidad, es decir, la
derivada de la función de probabilidad acumulada $P(T \leq t)$. El
índice $i$ corresponde a cada cliente y $A$ es el conjunto de clientes
que adquiere un producto o servicio. El parámetro $\tau$, al igual que
en el modelo de duración discreta, corresponde al tiempo máximo
observado.

Ahora bien, esto inmediatamente deja en evidencia una limitante a este
modelo: para un $t$ muy grande, todos los consumidores van a tener un
caso de éxito (Recordar que $\text{lim } e^{-t} = 0$), lo cual no es una
situación del todo realista. Es necesario, en consecuencia, imponer que
existe una fracción de clientes dentro de la muestra considerada que
nunca probará el producto (caso de éxito) y, así, es posible solucionar
la limitante encontrada (2 clases latentes).

1.  Segmento que prueba: Tamaño $\pi$:

    $$
    \begin{array}{c}
    \lambda = \theta\\
    \Rightarrow P(T \leq t) = 1 - e^{-\theta t}
    \end{array}
    $$

2.  Segmento que no prueba: Tamaño ($1-\pi$):

    $$
    \begin{array}{c}
    \lambda = 0\\
    \Rightarrow P(T \leq t) = 0
    \end{array}
    $$

Luego, la probabilidad total será:

$$
\begin{array}{c}
P(T \leq t) = P(T \leq t | \text{Prueba}) P(\text{Prueba}) + P(T \leq t | \text{No Prueba}) P(\text{No Prueba}) \\
= 1 - e^{-\theta t}\pi
\end{array}
$$

Es importante notar que si bien el modelo describe probabilidades en
tiempo continuo, la data aún se presenta y obtiene en tiempo discreto.
Incorporando esto, es posible construir la función de log verosimilitud
calculando las probabilidades de adopción del producto entre los límites
del intervalo temporal definido por el periodo de medición, es decir:

$$P(t_0 \leq T \leq t_1) = F(t_1) - F(t_0)$$ Cconsiderando n periodos
discretos para el cálculo, la log-verosimilitud es:

$$LL(\pi,\theta|\text{data}) = N_1 ln[P(1\leq T \leq 2)] + ... + (N_{panel} - \sum_{i=1}^{n}N_i)ln[P(T>n)]$$
Adicionalmente, es de interés calcular los valores predichos por el
modelo, de modo de realizar predicciones futuras. $F(t)$ representa la
probabilidad que un cliente escogido aleatoriamente pruebe el producto
en $t$, tal que $t=0$ corresponde al instante de lanzamiento del
producto. La estimación del futuro se puede hacer a través de la
esperanza:

$$\mathbb{E}[T(t)] = N_{\text{panel }} \cdot \hat{F}(t) $$

Antes de avanzar, es importante aclarar la distinción de un modelo *sin
dependencia en la duración*. Esto se puede explicar con la propiedad
fundamental de la distribución exponencial:

**Propiedad fundamental:** La distribución exponencial no tiene memoria,
es decir, poseer información de que un elemento ha sobrevivido un tiempo
’s’ hasta este momento no modifica la probabilidad de que sobreviva un
periodo $t$ más. Es decir la probabilidad de que ocurra un suceso no
depende del tiempo en que aún no ha ocurrido. Se puede demostrar
matemáticamente:

$$P(T > s + t|T>s) = \frac{P(T> s+t)}{P(T> s)} = \frac{1-P(T \leq s+t)}{1-P(T \leq s)}= \frac{e^{-\lambda(s+t)}}{e^{-\lambda s}} = e^{-\lambda t}$$

#### Modelo Gamma Exponencial

Análogamente al caso de duración discreta, hay casos en que el
comportamiento de la población heterogéneo. Esto busca complejizar la
suposición que antes se hizo al considerar un grupo de clientes que
nunca consume. Por tanto, el modelo con heterogeneidad no observada
ahora considerará que la tasa de prueba $\lambda$ se distribuye *Gamma*
en la población:

$$g(\lambda) = \frac{\alpha^r \lambda^{r-1} e^{-\alpha \lambda}}{\Gamma(r)}$$Donde
$r$ es un parámetro de forma mide la morfología. Con $r=1$ se reduce a
una exponencial y, a medida que crece, su la forma se vuelve más
simétrica y similar a una normal. Por otro lado, $\alpha$ es un
parámetro de escala que estira la distribución a medida que crece, o la
comprime en la medida que decrece.

Al incorporar la heterogeneidad mencionada, la probabilidad que un
cliente adquiera un producto antes de un tiempo $t$ es la siguiente:

$$ 
\begin{aligned} P(T\leq t) &= \int_{0}^{\infty} P(T \leq t|\lambda) g(\lambda)d \lambda \\ &= \int_{0}^{\infty} (1 - e^{-\lambda t}) \left( \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} \right) d\lambda \\ &= \int_{0}^{\infty} \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} d\lambda - \int_{0}^{\infty} e^{-\lambda t} \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} d\lambda \\ &= 1 - \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \frac{\lambda^{r-1} e^{-\lambda(\alpha+t)} \Gamma(r) (\alpha + t)^r}{\Gamma(r) (\alpha + t)^r} d\lambda \\ &= 1 - \frac{\alpha^r}{\Gamma(r)} \frac{\Gamma(r)}{(\alpha+t)^r} \\ &= 1 - \left(\frac{\alpha}{\alpha + t}\right)^r \end{aligned} $$

Donde en el cuarto paso se agregó un 1 en forma de
$\frac{\Gamma(r) (\alpha + t)^r}{\Gamma(r) (\alpha + t)^r}$ para obtener
una función de acumulación de dominio completo para la distribución
gamma (lo que al integrarlo da 1).

### Modelos de duración en tiempo continuo con dependencia en la duración

Otra de las grandes limitantes del modelo *Exponencial* es que posee
pérdida de memoria. En algunas aplicacioens se requiere incorporar esta
distinción, es decir, la probabilidad de que un evento ocurra dado que
hasta este momento no ha ocurrido. Esto último se conoce como *tasa de
riesgo* o *hazard rate*:

$$h(t) = \frac{f(t)}{1 - F(t)}$$

Donde

$$
\begin{aligned}
f(t) &= \frac{d}{dt} F(t) \\
&= -c\lambda t^{c-1} e^{-\lambda t^c}
\end{aligned}
$$

Gráficamente, la tasa de riesgo se comporta de la siguiente manera:

```{r my-fig, fig.cap="Ejemplos de tasas de riesgo",out.width='50%', fig.align='center'}
knitr::include_graphics(rep("images/tasa_riesgo.png"))
```

\FloatBarrier

En el primer caso, la intuición es que si una persona no ha respondido a
un e-mail, cada vez es menos probable que lo responda, pues en general
las personas tienden a ignorar los correos con una antigüedad superior a
un par de días. En la llegada de un bus - si bien en ramos pasados se ha
modelado con una exponencial - se asume que a medida que más se demora
en llegar al paradero, cada vez la espera debe ser menor, pues tarde o
temprano este deberá llegar. Con respecto al divorcio, es más probable
que en el caso de haber, este no ocurra inmediatamente y, con menor
probabilidad, ocurrirá en las etapas tardías de la vida del matrimonio.
Con respecto a la falla del disco duro, este tiene un comportamiento no
lineal (cuadrático). Sus mayores posibilidades de fallar se dan al
principio y al final de su vida útil esperada.

A partir de la tasa de riesgo, se puede definir unívocamente la
distribución de una variable aleatoria no negativa a través de la
siguiente integral:

$$F(t) = 1 - exp \left( -\int_{0}^{t} h(u)du \right)$$Este concepto será
útil para definir los modelos de duración en tiempo continuo en que la
duración sí es un factor relevante

#### Modelo Weibull {.unnumbered}

A pesar de las generalizaciones de las funciones de tasas de riesgo para
generar modelos de tiempo de ocurrencia, el foco será puesto en la
distribución Weibull, debido a que es fácil de trabajar y entrega una
fórmula cerrada muy similar a la de la distribución exponencial. Se
tiene que, para la misma variable aleatoria $T$ que se definió en la
sección anterior, la probabilidad de ocurrencia de que un cliente pruebe
nuestro producto en un tiempo inferior a t será:

$$F(t) = P(T \leq t) = 1 - e^{-\lambda t ^c}$$ Y la tasa de riesgo
asociada a esta distribución:

$$h(t) = c \lambda t ^{c-1}$$El primer parámetro $\lambda$ que compone
la fórmula es un parámetro de escala, mientras que el parámetro c es el
parámetro de forma. Es importante notar que para $c=1$, la distribución
se convierte en la distribución exponencial, por lo que se puede decir
que la distribución Weibull es una generalización de la exponencial.
Notar que para $c=1$, la tasa de riesgo es constante, lo que es
consistente con la propiedad de pérdida de memoria de la distribución
exponencial.

```{r riesgoc, fig.cap="Ejemplos de tasas de riesgo para distintos valores de c",out.width='50%', fig.align='center'}
knitr::include_graphics(rep("images/tasa_riesgo_c.png"))
```

\FloatBarrier

En la distribución de Weibull generalizada la propiedad de pérdida de
memoria no aplica como en el caso de la exponencial, es decir, la
probabilidad de ocurrencia varía a medida que pasa el tiempo:

$$P(T > s + t|T>s) = \frac{P(T> s+t)}{P(T> s)} = \frac{1-P(T \leq s+t)}{1-P(T \leq s)}= \frac{e^{-\lambda(s+t)^c}}{e^{-\lambda s^c}} $$

#### Modelo Gamma Weibull {.unnumbered}

Una de las propiedades interesantes de la distribución Weibull, es que
es sencillo introducir heterogeneidad sobre los parámetros y, de esa
forma, capturar los distintos posibles comportamientos de la población.

Al igual que en el modelo Gamma-Exponencial, asumiremos que el parámetro
de escala $\alpha$ está distribuido $\text{Gamma}(\alpha,r)$ en la
población. La probabilidad de ocurrencia del consumo de los clientes se
puede modelar a través de la

$$
\begin{aligned} P(T \leq t \mid \alpha,r, c) &= \int_{0}^{\infty} \frac{(1 - e^{-\lambda t^c}) \alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda \\ &= \int_{0}^{\infty} \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda - \int_{0}^{\infty} \frac{e^{-\lambda t^c} \alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda \\ &= 1 - \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{r-1}e^{-\lambda(\alpha + t^c)} d\lambda \\ &= 1 - \frac{\alpha^r}{\Gamma(r)} \frac{\Gamma(r)}{(\alpha + t^c)^r} \\ &= 1 - \left(\frac{\alpha}{\alpha + t^c}\right)^r \end{aligned}
$$

Si $c=1$, se recupera el modelo de duración Gamma-Exponencial.

## Modelos de Conteo

Permiten modelar cuántas veces los consumidores incurrirán en un
comportamiento determinado en un período de tiempo (ejemplo: problema de
exposición publicitaria).

Algunas medidas de efectividad son:

-   **Alcance:** Proporción de la población expuesta al evento al menos
    una vez durante el período: $1 − P(X_t = 0)$.

-   **Frecuencia promedio:** número promedio de exposiciones en el
    período entre aquellos que han experimentado el evento (por ejemplo,
    ver la valla publicitaria). $$\frac{\mathbb{E}(X_t)}{1-P(X_t =0)}$$

-   **Puntos de rating brutos (GRPs):** número promedio de exposiciones
    por cada 100 personas.

$$100 \cdot \mathbb{E}(X_t)$$

El fenómeno que se quiere estudiar es el número de veces que cada
individuo ve la valla publicitaria. Para ello, se define el modelo
individual *Poisson*.

$$
P(N_t=m|\lambda) = \frac{(\lambda t)^m e^{-\lambda t}}{m!} \quad (\#eq:poisson)
$$

lo cual corresponde a la probabilidad de que el número de exposiciones
sea $m$ en un intervalo de largo $t$.

Su verosimilitud corresponde a:

$$
\begin{aligned}
L(\lambda) &= \prod_{m} P(N_t = m | \lambda)^{n_m} \\
&= \prod_{m} \left( \frac{(\lambda t)^m e^{-\lambda t}}{m!} \right)^{n_m}
\end{aligned}
$$

Mientras que su log verosimilitud es:

$$
\begin{aligned}
LL(\lambda) &= \sum_{m} n_m \ln \left( P(N_t = m | \lambda) \right) \\
&= \sum_{m} n_m \ln \left( \frac{(\lambda t)^m e^{-\lambda t}}{m!} \right)
\end{aligned}
$$

Donde $m$ corresponde al número de ocurrencias de un suceso (cuántas
personas han visto un determinado número de anuncios), $n_m$ es el
número de casos en donde hubieron $m$ ocurrencias de un suceso (cuántas
veces un usuario ha visto un anuncio) y no se utiliza cuando las
observaciones están desagregadas (datos en los cuales cada fila del
conjunto de datos corresponde a una observación única y específica).
Cuando el tiempo es unitario, el modelo se simplifica a $t = 1$.

Al igual que en los modelos anteriores, es posible incluir
heterogeneidad asumiendo que el parámetro $\lambda$ no es el mismo para
todos. Para el caso en donde existe una mezcla finita y hay dos
segmentos, las tasas de eventos de la población pueden ser $\lambda_1$ o
$\lambda_2$, con una probabilidad $\pi$ de pertenecer al primer
segmento. El modelo de probabilidad queda representado por:

$$
P(N_t = m | \lambda_1, \lambda_2, \pi) = \left( \frac{(\lambda_1 t)^m e^{-\lambda_1 t}}{m!} \right) \pi + \left( \frac{(\lambda_2 t)^m e^{-\lambda_2 t}}{m!} \right) (1-\pi) \quad (\#eq-mfp)
$$

Para los modelos de heterogeneidad continua, $\lambda$ distribuye de
acuerdo a una determinada distribución. Suponiendo que dicha
distribución es *Gamma*.

$$
g(\lambda|\alpha, r) = \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} \quad (\#eq:gamma)
$$

Usando el modelo individual en \@ref(eq:poisson) y la distribución en
\@ref(eq:gamma), se puede estimar la probabilidad de un número de
exposiciones, conocido como modelo **Gamma Poisson (NBD):**

$$
\begin{aligned}
P(N_t = m \mid r, \alpha) &= \int_{0}^{\infty} P(N_t = m|\lambda) g(\lambda)d\lambda \\
&= \int_{0}^{\infty} \frac{(\lambda t)^m e^{-\lambda t}}{m!} \cdot \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)}d\lambda \\
&= \frac{t^m \alpha^r}{m! \Gamma(r)} \int_{0}^{\infty} \lambda^m \lambda^{r-1} e^{-\lambda t} e^{-\alpha \lambda} d\lambda \\
&= \frac{t^m \alpha^r}{m! \Gamma(r)} \int_{0}^{\infty} \lambda^{(r+m)-1} e^{-\lambda(\alpha+t)} d\lambda \\
&= \frac{t^m \alpha^r}{m! \Gamma(r)} \cdot \frac{\Gamma(r+m)}{(\alpha+t)^{r+m}} \\
&= \frac{\alpha^r}{(\alpha+t)^r} \cdot \frac{t^m}{(\alpha+t)^m} \cdot \frac{\Gamma(r+m)}{\Gamma(r)m!} \\
&= \left( \frac{\alpha}{\alpha+t}\right)^r \left( \frac{t}{\alpha + t}\right)^m \frac{\Gamma(r+m)}{\Gamma(r)m!}
\end{aligned}
\quad (\#eq:gammita)
$$

## Modelos de Elección Binaria binomial

Permiten modelar la probabilidad de que los individuos elijan un
determinado comportamiento, dado que tienen varias opciones para elegir.
Es aplicable en una situación de compras en un supermercado, exposición
a varios anuncios, las variadas formas de uso de un producto, etc.

Consideremos como variable de interés la probabilidad de que un
individuo perteneciente a un segmento responda positivamente a una
campaña de marketing. En el enfoque tradicional, se realiza una
segmentación de clientes en grupos homogéneos, se envía mensajes a
muestras aleatorias de cada segmento y se implementa un campaña en
segmentos con tasa de respuesta (TR) sobre cierto corte, por ejemplo,
$TR > \frac{\text{Costo de envío}}{\text{Margen unitario}}$.

Sin embargo, es posible incorporar un enfoque de modelos probabilísticos
para abordar el problema. Si se considera la probabilidad de responder
de manera positiva que tiene un segmento $s$, en particular $p_s$, es
posible interpretar de manera sencilla la cantidad de respuestas
obtenidas. Recordando que la suma de experimentos de $\text{Bernoulli}$
corresponde a una variable aleatoria Binomial, es posible interpretar
$X_s$ como la cantidad de respuestas obtenidas de un total de $m_s$
enviadas. Luego:

$$
\begin{aligned}
P(X_s = x_s|m_s,p_s) &= \binom{m_s}{x_s} p_s^{x_s}(1-p_s)^{m_s-x_s} 
\end{aligned}
\quad (\#eq:bin)$$

donde $m_s$ es la población del segmento $s$ y $p_s$ es la probabilidad
de respuesta del segmento $s$.

Se tiene que la verosimilitud es expresada como:

$$
\begin{aligned}
L(\theta) &= \prod_{s=1}^{S} P(X_s = x_s | m_s, \theta) \\
&= \prod_{s=1}^{S} \binom{m_s}{x_s} \theta^{x_s} (1-\theta)^{m_s - x_s}
\end{aligned}
\quad (\#eq:verosimilitud:bin)
$$

Mientras que su log verosimilitud es:

$$
\begin{aligned}
LL(\theta) &= \sum_{s=1}^{S} \ln \left( P(X_s = x_s | m_s, \theta) \right) \\
&= \sum_{s=1}^{S} \ln \left( \binom{m_s}{x_s} \theta^{x_s} (1-\theta)^{m_s - x_s} \right) \\
&= \sum_{s=1}^{S} \left[ \ln\binom{m_s}{x_s} + \ln(\theta^{x_s}) + \ln((1-\theta)^{m_s - x_s}) \right] \\
&= \sum_{s=1}^{S} \left[ \ln\binom{m_s}{x_s} + x_s \ln(\theta) + (m_s - x_s) \ln(1-\theta) \right]
\end{aligned}
\quad (\#eq:logverosimilitud:bin)
$$

Con respecto a la heterogeneidad, en el caso de una mezcla finita en
donde la probabilidad de éxito en cada uno de los intentos es distinta
de acuerdo a dos segmentos identificables, la probabilidad adopta el
valor de $\theta_1$ y $\theta_2$, donde $\pi$ corresponde a la
probabilidad de pertencer al primer segmento. El modelo de probabilidad
queda representado por:

$$P(X_s = x_s | m_s, \theta_1, \theta_2, \pi) = \binom{m_s}{x_s} \left[ \theta_1^{x_s}(1-\theta_1)^{m_s-x_s}\pi + \theta_2^{x_s}(1-\theta_2)^{m_s-x_s}(1-\pi) \right] \quad (\#eq:mezcla:b)$$

En el caso de mezcla infinita, la heterogeneidad no observable se extrae
aprovechando la distribución $B(\alpha,\beta)$:

$$
\begin{aligned}
P(X_s = x_s \mid \alpha, \beta) &= \int_{0}^{1} P(X_s = x_s|m_s,\theta_s) g(\theta_s|\alpha,\beta)d\theta_s \\
&= \int_{0}^{1} \binom{m_s}{x_s} \theta_s^{x_s}(1-\theta_s)^{m_s-x_s} \frac{\theta_s^{\alpha-1}(1-\theta_s)^{\beta -1}}{B(\alpha,\beta)}d\theta_s \\
&= \frac{\binom{m_s}{x_s}}{B(\alpha,\beta)} \int_{0}^{1} \theta_s^{x_s+\alpha-1}(1-\theta_s)^{m_s-x_s+\beta-1} d\theta_s \\
&= \binom{m_s}{x_s} \frac{B(\alpha + x_s, \beta + m_s - x_s)}{B(\alpha,\beta)}
\end{aligned}
\quad (\#eq:beta-binomial)
$$

## Heterogeneidad observable

Se ha expuesto modelos que intentan explicar y predecir el tiempo en que
los individuos realizarán una determinada acción (e.g: proponer la
probabilidad de fuga de un cliente), considerando que el comportamiento
de los agentes se debe netamente a factores aleatorios.

En esta sección se incorporará heterogeneidad observable a un modelo de
duración en tiempo continuo sin dependencia en la duración. Entendemos
por heterogeneidad observable, aquellos factores observables (que están
en los datos) intrínsecos a los individuos que los hacen distintos,
tales como sexo, edad, nivel socioeconómico, género, entre otras.

### Modelos de duración en tiempo discreto

Sea $T_i$ la variable aleatoria que describe el instante en que el
individuo $i$ termina su relación comercial. Se modelará dicha variable
con una distribución Geométrica Desplazada de parámetro $\theta_i$, que
es la probabilidad de abandono para el individuo $i$.

$$\mathbb{P}(T_i=t_i|\theta_i) = \theta_i(1-\theta_i)^{t_i-1}$$

Dado que se cuenta con información a nivel individual, es posible
estimar un parámetro de abandono para cada persona.

Sea $x_i$ el vector que contiene las variables explicativas del
individuo $i$. Se modela la probabilidad de abandono $\theta_i$
utilizando una transformación logística para asegurar que el resultado
se mantenga entre 0 y 1:

$$\theta_i = \frac{\exp(\beta_0 + \beta'x_i)}{1 + \exp(\beta_0 + \beta'x_i)} = \frac{1}{1 + \exp(-(\beta_0 + \beta'x_i))}$$

Donde $\beta$ corresponde al vector de coeficientes asociados a las
variables explicativas. La inclusión de esta función permite capturar el
efecto de las covariables sin restringir el signo de los coeficientes.

En el caso donde la probabilidad de abandono depende de las
características de cada individuo (heterogeneidad observable), la
probabilidad de que el individuo $i$ abandone en el tiempo $t_i$ es:

$$
\begin{aligned}
\mathbb{P}(T_i = t_i|\beta_0, \beta) &= \theta_i (1 - \theta_i)^{t_i-1} \\
\text{donde } \theta_i &= \frac{1}{1 + \exp(-(\beta_0 + \beta'x_i))}
\end{aligned}
$$

Con lo cual, para un panel de $N$ individuos, donde algunos abandonan en
el período $t_i$ y otros permanecen activos (censurados a la derecha),
la log-verosimilitud del problema resulta:

$$
\begin{aligned}
LL(\beta_0, \beta) &= \sum_{i \in \text{abandono}} \ln(\mathbb{P}(T_i = t_i|\beta_0, \beta)) + \sum_{i \in \text{activos}} \ln(\mathbb{P}(T_i > t_i|\beta_0, \beta)) \\
&= \sum_{i \in \text{abandono}} \left[ \ln(\theta_i) + (t_i-1)\ln(1-\theta_i) \right] + \sum_{i \in \text{activos}} t_i \ln(1-\theta_i)
\end{aligned}
$$

Para introducir heterogeneidad no observable en el modelo y así mezclar
ambos efectos, es análogo al desarrollo de la integral del Modelo
Beta-Geométrico desplazado. Se modelan los parámetros $\alpha_i$ y
$\beta_i$ de la distribución Beta de la siguiente forma para asegurar
que sean positivos:

$$\alpha_i = \exp(a'x_i) \quad \text{y} \quad \beta_i = \exp(b'x_i)$$

La obtención de la expresión de probabilidad con heterogeneidad mixta es
análoga a la obtención de la probabilidad con heterogeneidad no
observable, salvo que la interpretación de los coeficientes $\alpha_i$ y
$\beta_i$ son distintas.

Finalmente, la función de log-verosimilitud para el modelo mixto
resulta, con $\theta_{params} = (a, b)$:

$$
\begin{aligned}
LL(\theta_{params}) &= \sum_{i \in \text{abandono}} \ln(\mathbb{P}(T_i = t_i|a, b)) + \sum_{i \in \text{activos}} \ln(\mathbb{P}(T_i > t_i|a, b)) \\
&= \sum_{i \in \text{abandono}} \ln\left(\frac{B(\alpha_i+1, t_i+\beta_i-1)}{B(\alpha_i, \beta_i)}\right) + \sum_{i \in \text{activos}} \ln\left(\frac{B(\alpha_i, \beta_i+t_i)}{B(\alpha_i, \beta_i)}\right)
\end{aligned}
$$

### Modelos de duración en tiempo continuo sin dependencia de la duración

Sea $T_i$ la variable aleatoria que describe el instante en que el
individuo $i$ realiza una determinada acción. Se modelará dicha variable
aleatoria con una distribución exponencial de parámetro $\lambda_i$:

$$\mathbb{P}(T_i<t_i|\lambda_i) = 1-e^{-\lambda_it_i}$$Cabe destacar
que, dada la naturaleza de los datos, el comportamiento descrito se
realizará de manera desagregada (dependencia de $i$ en el parámetro), es
decir, dado que existe información individual para cada individuo, es
posible estimar el parámetro de cada uno de éstos (no así en los casos
agregados vistos anteriormente).

Sea $x_i$ el vector que contiene las variables explicativas pertinentes
del individuo $i$. Se modela la tasa de llegada de $i$ de la siguiente
manera:

$$\lambda_i = exp(\beta_0 + \beta'x_i) = \lambda_0 exp(\beta'x_i)$$
Donde $\beta$ corresponde al vector de coeficientes asociados a las
variables explicativas en cuestión.

La inclusión de la exponencial se debe a que, por razones de
convergencia e interpretación, la tasa de respuesta individual debe ser
positiva. De esta forma, se puede capturar el efecto marginal de las
variables demográficas sin restricción de signos. Así, el modelo no
tendrá problemas si hay valores de $\beta$ negativos.

En el caso con tasa homogénea (la misma para toda la población), la
probabilidad que un individuo $i$ realice un evento determinado antes
del tiempo $t_i$, incluyendo su información observable, es:

$$
\begin{aligned}
\mathbb{P}(T_i < t_i|\beta,\lambda_0) &= 1 - e^{-\lambda_it_i}\\
&= 1 - e^{-\lambda_0 \exp(\beta'x_i)t_i}
\end{aligned}
$$

Con lo cual (considerando instantes de tiempo $t_i^-$ y $t_i^+$ para
discretizar el tiempo, un panel de $N$ individuos y un vector de
parámetros $\theta = (\beta,\lambda_0)$), la log verosimilitud del
problema resulta:

$$
\begin{aligned}
LL(\theta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- < T_i < t_i^+|\beta,\lambda_0)) \\
&= \sum_{i=1}^{N} \ln((\mathbb{P}(T_i < t_i^+|\beta,\lambda_0)) - \mathbb{P}(T_i < t_i^-|\beta,\lambda_0)) \\
&=  \sum_{i=1}^{N} \ln \left((1 - e^{-\lambda_0 \exp(\beta'x_i)t_i^+}) - (1 - e^{-\lambda_0 \exp(\beta'x_i)t_i^-}) \right)\\
&= \sum_{i=1}^{N} \ln (e^{-\lambda_0 \exp(\beta'x_i)t_i^-} - e^{-\lambda_0 \exp(\beta'x_i)t_i^+})
\end{aligned}
$$

Para introducir heterogeneidad no observable en el modelo, se dejará el
parámetro $\lambda_0$ distribuyendo de manera continua en la población
según una ley $\Gamma(\alpha,r)$ pues, de esta forma, es posible mezclar
tanto la heterogeneidad no observable, como la observable. El desarrollo
de la integral es análogo al caso con heterogeneidad no observable, con
la diferencia de que se multiplica la constante $exp(\beta' x_i)$ a la
variable del tiempo $t$ .

Finalmente, la función de log verosimilitud resulta, con
$\theta = (\beta,\alpha,r)$:

$$
\begin{aligned}
LL(\theta) &= \sum_{i=1}^{N} \ln(\mathbb{P} (t_i^-<T_i<t_i^+|\alpha,r,\beta))\\
&= \sum_{i=1}^{N} \ln \left(\left(\frac{\alpha}{ \alpha + \exp(\beta'x_i)t_i^-}\right)^r - \left(\frac{\alpha}{ \alpha + \exp(\beta'x_i)t_i^+}\right)^r\right)
\end{aligned}
$$

### Modelos de duración en tiempo continuo con dependencia de la duración

Cuando el tiempo en que ocurre un determinado suceso posee dependencia
en la duración, el procedimiento es análogo que en el caso sin dicha
dependencia, pero considerando que $T_i$ distribuye según una ley
Weibull.

$$\mathbb{P}(T_i < t_i|\lambda_i,c) = 1 - e^{-\lambda_it_i^c}$$

En el caso con tasa homogénea (la misma para toda la población), la
probabilidad que un individuo $i$ realice un evento determinado antes
del tiempo $t_i$, incluyendo su información observable, es:

$$
\begin{aligned}
\mathbb{P}(T_i < t_i|\beta,\lambda_0,c) &= 1 - e^{-\lambda_i t_i}\\
&= 1 - e^{-\lambda_0 \exp(\beta'x_i) t_i^c}
\end{aligned}
$$

Por lo que, la función de log verosimilitud toma la siguiente forma:

$$
\begin{aligned}
LL(\theta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- < T_i < t_i^+|\beta,\lambda_0,c)) \\
&= \sum_{i=1}^{N} \ln((\mathbb{P}(T_i < t_i^+|\beta,\lambda_0,c)) - \mathbb{P}(T_i < t_i^-|\beta,\lambda_0,c)) \\
&=  \sum_{i=1}^{N} \ln \left((1 - e^{-\lambda_0 \exp(\beta'x_i)(t_i^+)^c}) - (1 - e^{-\lambda_0 \exp(\beta'x_i)(t_i^-)^c}) \right)\\
&= \sum_{i=1}^{N} \ln (e^{-\lambda_0 \exp(\beta'x_i)(t_i^-)^c} - e^{-\lambda_0 \exp(\beta'x_i)(t_i^+)^c})
\end{aligned}
$$

De manera análoga al caso anterior, se puede introducir adicionalmente
heterogeneidad no observable mediante el parámetro $\lambda_0$ según una
distribución $\Gamma(\alpha,r)$. Dando como conocido este resultado, la
log-verosimilitud queda descrita como:

$$
\begin{aligned}
LL(\theta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- < T_i < t_i^+|\beta,\lambda_0,r,c)) \\
&= \sum_{i=1}^{N} \ln \left( \left(\frac{\alpha}{\alpha + \exp(\beta'x_i)(t_i^-)^c}\right)^r - \left(\frac{\alpha}{\alpha + \exp(\beta'x_i)(t_i^+)^c}\right)^r \right)
\end{aligned}
$$

### Modelos de Conteo

Sea $Y_i$ la variable aleatoria que describe el número de veces que el
individuo $i$ incurre en un determinado comportamiento durante un
período de tiempo. Se modelará dicha variable con una distribución
**Poisson** de parámetro $\lambda_i$, que representa la tasa de
ocurrencia para el individuo $i$.

$$\mathbb{P}(Y_i=y_i|\lambda_i) = \frac{\lambda_i^{y_i} e^{-\lambda_i}}{y_i!}$$

Para incorporar heterogeneidad observable, se modela la tasa individual
$\lambda_i$ como una función de un vector $x_i$ que contiene las
variables explicativas del individuo:

$$\lambda_i = \exp(\beta_0 + \beta'x_i) = \lambda_0 \exp(\beta'x_i)$$

Donde $\beta$ es el vector de coeficientes y $\lambda_0 = \exp(\beta_0)$
es la tasa base. La probabilidad de que el individuo $i$ realice el
evento $y_i$ veces es:

$$
\mathbb{P}(Y_i = y_i|\beta_0, \beta) = \frac{(\lambda_0 \exp(\beta'x_i))^{y_i} \exp(-\lambda_0 \exp(\beta'x_i))}{y_i!}
$$

La función de log-verosimilitud para estimar los parámetros $\beta_0$ y
$\beta$ a partir de los datos de $N$ individuos es la suma de las
log-probabilidades individuales:

$$
\begin{aligned}
LL(\beta_0, \beta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(Y_i=y_i|\beta_0, \beta)) \\
&= \sum_{i=1}^{N} \left[ y_i \ln(\lambda_i) - \lambda_i - \ln(y_i!) \right] \\
&= \sum_{i=1}^{N} \left[ y_i (\beta_0 + \beta'x_i) - \exp(\beta_0 + \beta'x_i) - \ln(y_i!) \right]
\end{aligned}
$$

Para introducir heterogeneidad no observable y mezclarla con la
observable, se asume que la tasa base $\lambda_0$no es fija para toda la
población, sino que sigue una distribución Gamma con parámetros de forma
$r$ y de escala $\alpha$.

$$g(\lambda_0|r, \alpha) = \frac{\alpha^r \lambda_0^{r-1}e^{-\alpha\lambda_0}}{\Gamma(r)}$$

El desarrollo de la integral para obtener la probabilidad marginal es
análogo al caso NBD (Distribución Binomial Negativa) sin covariables. El
resultado es la distribución de probabilidad para un modelo de Regresión
Binomial Negativa:

$$
\mathbb{P} (Y_i = y_i|r, \alpha, \beta) = \frac{\Gamma(r+y_i)}{\Gamma(r)y_i!} \left(\frac{\alpha}{\alpha + \exp(\beta'x_i)}\right)^r \left(\frac{\exp(\beta'x_i)}{\alpha + \exp(\beta'x_i)}\right)^{y_i}
$$

Finalmente, la función de **log-verosimilitud** para el modelo mixto
(Regresión NBD) que estima los parámetros $(r, \alpha, \beta)$ es: $$
LL(r, \alpha, \beta) = \sum_{i=1}^{N} \ln(\mathbb{P}(Y_i = y_i|r, \alpha, \beta))
$$

### Modelos de Elección Binaria binomial

Sea $X_i$ la variable aleatoria que describe el número de "éxitos" (ej.
respuestas a una campaña, compras) en $m_i$ intentos para un individuo o
segmento $i$. Se modelará dicha variable con una distribución con
parámetros $m_i$ y $\theta_i$, donde $\theta_i$ es la probabilidad de
éxito para el individuo $i$.

$$\mathbb{P}(X_i=x_i|m_i, \theta_i) = \binom{m_i}{x_i} \theta_i^{x_i}(1-\theta_i)^{m_i-x_i}$$

Para incorporar heterogeneidad observable, se modela la probabilidad de
éxito individual $\theta_i$ como una función de un vector de covariables
$x_i$. Al igual que en el modelo de duración discreta, se utiliza una
transformación logística para asegurar que $\theta_i$ se mantenga en el
intervalo $(0,1)$:

$$\theta_i = \frac{\exp(\beta_0 + \beta'x_i)}{1 + \exp(\beta_0 + \beta'x_i)} = \frac{1}{1 + \exp(-(\beta_0 + \beta'x_i))}$$

Donde $\beta$ es el vector de coeficientes que captura el efecto de las
características observables.

La función de log verosimilitud para estimar los parámetros $\beta_0$ y
$\beta$ a partir de los datos de $N$ individuos o segmentos es la suma
de las log-probabilidades binomiales individuales:

$$
\begin{aligned}
LL(\beta_0, \beta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(X_i=x_i|\beta_0, \beta)) \\
&= \sum_{i=1}^{N} \left[ \ln\binom{m_i}{x_i} + x_i \ln(\theta_i) + (m_i - x_i) \ln(1-\theta_i) \right]
\end{aligned}
$$

Para introducir heterogeneidad no observable y mezclarla con la
observable, se asume que la probabilidad de éxito $\theta_i$ no es fija,
sino que sigue una distribución Beta. Para incorporar las covariables,
se modelan los parámetros $\alpha_i$ y $\beta_i$ de la distribución Beta
como una función de las características $x_i$:

$$\alpha_i = \exp(a'x_i) \quad \text{y} \quad \beta_i = \exp(b'x_i)$$

La probabilidad marginal de observar $x_i$ éxitos en $m_i$ intentos para
el individuo $i$ se obtiene a través de la integral análoga al caso sin
covariables:

$$
\mathbb{P} (X_i = x_i|a, b) = \binom{m_i}{x_i} \frac{B(\alpha_i + x_i, \beta_i + m_i - x_i)}{B(\alpha_i,\beta_i)}
$$

Finalmente, la función de log verosimilitud para el modelo mixto
(Regresión Beta Binomial) que estima los parámetros $(a, b)$ es: $$
LL(a, b) = \sum_{i=1}^{N} \ln \left( \binom{m_i}{x_i} \frac{B(\alpha_i + x_i, \beta_i + m_i - x_i)}{B(\alpha_i,\beta_i)} \right)
$$

## Esperanzas Condicionales

Primero, es fundamental establecer el valor esperado de las
distribuciones que se usaron para modelar la heterogeneidad no
observable. A continuación, se muestra el desarrollo para obtener la
esperanza de las distribuciones Gamma y Beta.

-   **Esperanza de la distribución Gamma**

    Para la distribución Gamma, con parámetro de forma $r$ y de tasa
    $\alpha$, que se utiliza para modelar tasas de ocurrencia (ej.
    $\lambda$), su función de densidad de probabilidad es:
    $$g(\lambda|r,\alpha) = \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha\lambda}$$
    La esperanza de una variable aleatoria $\lambda$ que sigue esta
    distribución es: $$
    \mathbb{E}[\lambda] = \frac{r}{\alpha}
    $$Este resultado se obtiene a partir de la definición de valor
    esperado para una variable continua: $$
    \begin{aligned}
    \mathbb{E}[\lambda] &= \int_{0}^{\infty} \lambda \cdot g(\lambda|r,\alpha) d\lambda \\
    &= \int_{0}^{\infty} \lambda \cdot \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha\lambda} d\lambda \\
    &= \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{r} e^{-\alpha\lambda} d\lambda \\
    &= \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{(r+1)-1} e^{-\alpha\lambda} d\lambda \\
    \end{aligned}
    $$ Reconociendo que la integral
    $\int_{0}^{\infty} x^{k-1}e^{-\theta x}dx = \frac{\Gamma(k)}{\theta^k}$,
    con $k=r+1$ y $\theta=\alpha$: $$
    \begin{aligned}
    \mathbb{E}[\lambda] &= \frac{\alpha^r}{\Gamma(r)} \left[ \frac{\Gamma(r+1)}{\alpha^{r+1}} \right] \\
    &= \frac{\alpha^r}{\Gamma(r)} \cdot \frac{r\Gamma(r)}{\alpha^r \cdot \alpha} \\
    &= \frac{r}{\alpha}
    \end{aligned}
    $$

-   **Esperanza de la distribución Beta**

    Para la distribución Beta con parámetros $\alpha$ y $\beta$ que se
    utilizan para modelar probabilidades (ej. $\theta$), su función de
    densidad de probabilidad es:
    $$g(\theta|\alpha,\beta) = \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}$$
    El desarrollo para obtener esta esperanza es el siguiente: $$
    \begin{aligned}
    \mathbb{E}[\theta] &= \int_{0}^{1} \theta \cdot g(\theta|\alpha,\beta) d\theta \\
    &= \int_{0}^{1} \theta \cdot \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)} d\theta \\
    &= \frac{1}{B(\alpha,\beta)} \int_{0}^{1} \theta^{\alpha}(1-\theta)^{\beta-1} d\theta \\
    &= \frac{1}{B(\alpha,\beta)} \int_{0}^{1} \theta^{(\alpha+1)-1}(1-\theta)^{\beta-1} d\theta \\
    \end{aligned}
    $$ Reconociendo que la integral
    $\int_{0}^{1} x^{a-1}(1-x)^{b-1}dx = B(a,b)$, con $a=\alpha+1$ y
    $b=\beta$: $$
    \begin{aligned}
    \mathbb{E}[\theta] &= \frac{1}{B(\alpha,\beta)} \left[ B(\alpha+1, \beta) \right] \\
    &= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \cdot \frac{\Gamma(\alpha+1)\Gamma(\beta)}{\Gamma(\alpha+1+\beta)} \\
    &= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)} \cdot \frac{\alpha\Gamma(\alpha)}{(\alpha+\beta)\Gamma(\alpha+\beta)} \\
    &= \frac{\alpha}{\alpha+\beta}
    \end{aligned}
    $$

### Modelo de Tiempo Discreto (Combinado con Beta)

Para el modelo de duración en tiempo discreto, una pregunta válida es
cuál es la probabilidad de abandono esperada para un cliente
determinado, dado su historial con la empresa. Intuitivamente, esta
probabilidad debería estar entre la tasa de abandono promedio de la
población y el comportamiento observado de ese cliente.

Recordando que la distribución del parámetro $\theta$ (la probabilidad
de abandono), condicionada a los datos observados de un cliente, se
obtiene por el Teorema de Bayes:

$$ 
\begin{aligned}
g(\theta|\text{datos}) &= \frac{\mathbb{P}(\text{datos}|\theta)g(\theta)}{\int \mathbb{P}(\text{datos}|\theta)g(\theta)d\theta}
\end{aligned}
\quad (\#eq:thetabayes) $$

donde $g(\theta)$ es la distribución a priori del parámetro (Beta) y
$\mathbb{P}(\text{datos}|\theta)$ es la verosimilitud del comportamiento
observado (Geométrica). Para el modelo Beta-Geométrico, la distribución
posterior de $\theta$ también es una distribución Beta con parámetros
actualizados.

Para el Modelo de Tiempo Discreto (Beta), la esperanza condicional
$E[\theta|t]$ representa la probabilidad de abandono esperada para un
cliente, la cual se actualiza y ajusta en función de su tiempo de
permanencia observado $t$.

El cálculo de esta esperanza se basa en el Teorema de Bayes, que
actualiza el conocimiento previo sobre el parámetro $\theta$ a la luz de
los datos observados:

$$ g(\theta|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\theta) \cdot g(\theta)}{\int \mathbb{P}(\text{datos} \mid \theta) \cdot g(\theta) d\theta} $$

El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:

-   **Distribución a Priori**: Se asume que la heterogeneidad en la
    probabilidad de abandono $\theta$ en la población sigue una
    distribución **Beta**:
    $$ g(\theta|\alpha, \beta) \sim \text{Beta}(\alpha, \beta) $$

-   **Función de Verosimilitud**: El comportamiento de abandono
    individual se modela con una distribución Geométrica Desplazada, que
    indica la probabilidad de que el evento ocurra exactamente en el
    período $t$: $$ \mathbb{P}(T=t|\theta) = \theta(1-\theta)^{t-1} $$

Con respecto a la Ley de Probabilidades Totales, ya se ha calculado en
anterioridad para el Modelo Beta Geométrico-Desplazado. A continuación,
se muestra el desarrollo: $$
\begin{aligned}
g(\theta|T=t) &= \frac{\mathbb{P}(T=t|\theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(T=t|\theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&= \frac{ \left( \theta(1-\theta)^{t-1} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \frac{B(\alpha+1, \beta+t-1)}{B(\alpha, \beta)} } \\
&= \frac{\theta^{\alpha}(1-\theta)^{\beta+t-2}}{B(\alpha+1, \beta+t-1)}
\end{aligned}
$$

La expresión resultante es la función de densidad de una distribución
Beta, con los parámetros actualizados.
$$g(\theta|T=t) \sim \text{Beta}(\alpha+1, \beta+t-1)$$

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
$$ \mathbb{E}(\theta|T=t) = \frac{\alpha+1}{\alpha+\beta+t} $$

Esta expresión representa la probabilidad de abandono esperada y
actualizada para un cliente que ha permanecido exactamente $t$ períodos.
El resultado combina la información previa sobre la población (contenida
en $\alpha$ y $\beta$) con la observación específica del cliente (su
duración $t$).

De forma análoga, para un cliente que sigue activo después de $t$
períodos (observación censurada):

-   **Función de Verosimilitud**: La probabilidad de que el evento aún
    no haya ocurrido es la función de supervivencia:
    $$ \mathbb{P}(T>t|\theta) = (1-\theta)^{t} $$

Obteniendo la distribución posterior: $$
\begin{aligned}
g(\theta|T > t) &= \frac{\mathbb{P}(T > t|\theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(T > t|\theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&= \frac{ \left( (1-\theta)^{t} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \frac{B(\alpha, \beta+t)}{B(\alpha, \beta)} } \\
&= \frac{\theta^{\alpha-1}(1-\theta)^{\beta+t-1}}{B(\alpha, \beta+t)}
\end{aligned}
$$

La expresión resultante es la función de densidad de otra distribución
Beta, con los parámetros actualizados.
$$g(\theta|T>t) \sim \text{Beta}(\alpha, \beta+t)$$

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
$$ \mathbb{E}(\theta|T>t) = \frac{\alpha}{\alpha+\beta+t} $$

Se podría replantear una regla de decisión y, por ejemplo, dirigir una
campaña de retención a los clientes aún activos después de $t$ períodos
si su probabilidad de abandono esperada supera cierto umbral:

$$\mathbb{E} (\theta|T > t) = \frac{\alpha}{\alpha + \beta + t} > \frac{\text{Costo de Retención}}{\text{Valor del Cliente}}$$

$$
\mathbb{E}(\theta \mid T>t) = \frac{\alpha}{\alpha + \beta + t} (\#eq:esp:discrete)
$$

### Modelo de Tiempo Continuo (Combinado con Gamma)

Para el modelo de duración en tiempo continuo, una pregunta válida es
cuál es la tasa de eventos esperada para un cliente determinado, dado su
historial. Intuitivamente, esta tasa debería estar entre la tasa
promedio de la población y el comportamiento observado de ese cliente.

Recordando que la distribución del parámetro $\lambda$ (la tasa de
eventos), condicionada a los datos observados de un cliente, se obtiene
por el Teorema de Bayes:

$$ 
\begin{aligned}
g(\lambda|\text{datos}) &= \frac{\mathbb{P}(\text{datos}|\lambda)g(\lambda)}{\int \mathbb{P}(\text{datos}|\lambda)g(\lambda)d\lambda}
\end{aligned}
\quad (\#eq:thetabayes) 
$$

La esperanza condicional $E[\lambda|t]$ representa la tasa de ocurrencia
esperada para un cliente, la cual se actualiza y ajusta en función del
tiempo transcurrido $t$.

El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:

-   **Distribución a Priori**: Se asume que la heterogeneidad en la tasa
    de eventos $\lambda$ en la población sigue una distribución
    **Gamma**: $$ g(\lambda|r, \alpha) \sim \text{Gamma}(r, \alpha) $$

-   **Función de Verosimilitud**: El comportamiento del tiempo hasta el
    evento se modela con una distribución Exponencial, que indica la
    probabilidad (densidad) de que el evento ocurra exactamente en el
    instante $t$:
    $$ \mathbb{P}(T=t|\lambda) = f(t|\lambda) = \lambda e^{-\lambda t} $$

Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Gamma-Exponencial. A continuación, se muestra el
desarrollo de la distribución posterior: $$
\begin{aligned}
g(\lambda|T=t) &= \frac{\mathbb{P}(T=t|\lambda) \cdot g(\lambda|r, \alpha)}{\int_0^\infty \mathbb{P}(T=t|\lambda) \cdot g(\lambda|r, \alpha) d\lambda} \\
&= \frac{ \left( \lambda t e^{-\lambda t} \right) \left( \frac{\alpha^r \lambda^{r-1} e^{-\alpha\lambda}}{\Gamma(r)} \right) }{\left(\frac{rt}{\alpha + t} \right) \left(\frac{1}{\alpha + t} \right)^r} \\
&= \frac{(\alpha+t)^{r+1}}{\Gamma(r+1)}\lambda^{r}e^{-\lambda(\alpha+t)}
\end{aligned}
$$

La expresión resultante es la función de densidad de una distribución
Gamma, con los parámetros actualizados.
$$g(\lambda|T=t) \sim \text{Gamma}(r+1, \alpha+t)$$

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
$$ \mathbb{E}(\lambda|T=t) = \frac{r+1}{\alpha+t} $$

### Modelo de Conteo (Combinado con Gamma)

Para el modelo de conteo, una pregunta válida es cuál es la tasa de
eventos esperada para un cliente determinado, dado su historial de
eventos en un período de tiempo $t$.

Recordando que la distribución del parámetro $\lambda$ (la tasa de
eventos), condicionada a los datos observados de un cliente, se obtiene
por el Teorema de Bayes:

$$
\begin{aligned}
g(\lambda|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\lambda)g(\lambda)}{\int \mathbb{P}(\text{datos}|\lambda)g(\lambda)d\lambda}
\end{aligned}
\quad (\#eq:thetabayes) $$

El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:

-   **Distribución a Priori**: Se asume que la heterogeneidad en la tasa
    de eventos $\lambda$ en la población sigue una distribución
    **Gamma**: $$ g(\lambda|r, \alpha) \sim \text{Gamma}(r, \alpha) $$

-   **Función de Verosimilitud**: El comportamiento de conteo de eventos
    se modela con una distribución **Poisson**, que indica la
    probabilidad de que ocurran exactamente $y$ eventos en un período de
    duración $t$:
    $$ \mathbb{P}(Y_t=y|\lambda,t) = \frac{(\lambda t)^y e^{-\lambda t}}{y!} $$

Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Gamma-Poisson (NBD). A continuación, se muestra el
desarrollo de la distribución posterior: $$
\begin{aligned}
g(\lambda|Y_t=y) &= \frac{\mathbb{P}(Y_t=y|\lambda, t) \cdot g(\lambda|r, \alpha)}{\int_0^\infty \mathbb{P}(Y_t=y|\lambda, t) \cdot g(\lambda|r, \alpha) d\lambda} \\
&= \frac{ \left( \frac{(\lambda t)^y e^{-\lambda t}}{y!} \right) \left( \frac{\alpha^r \lambda^{r-1} e^{-\alpha\lambda}}{\Gamma(r)} \right) }{ \frac{\Gamma(r+y)}{\Gamma(r)y!} \left(\frac{\alpha}{\alpha+t}\right)^r \left(\frac{t}{\alpha+t}\right)^{y} } \\
&= \frac{(\alpha+t)^{r+y}}{\Gamma(r+y)}\lambda^{r+y-1}e^{-\lambda(\alpha+t)}
\end{aligned}
$$

La expresión resultante es la función de densidad de una distribución
Gamma, con los parámetros actualizados.
$$g(\lambda|Y_t=y) \sim \text{Gamma}(r+y, \alpha+t)$$

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
$$ \mathbb{E}(\lambda|Y_t=y) = \frac{r+y}{\alpha+t} $$

### Modelo de Elección Binaria binomial (Combinado con Beta)

Recordando que la distribución del parámetro $\theta$ (la probabilidad
de éxito), condicionada a los datos observados, se obtiene por el
Teorema de Bayes:

$$
\begin{aligned}
g(\theta|\text{datos}) &= \frac{\mathbb{P}(\text{datos}|\theta)g(\theta)}{\int \mathbb{P}(\text{datos}|\theta)g(\theta)d\theta}
\end{aligned}
\quad (\#eq:thetabayes) $$

El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:

-   **Distribución a Priori**: Se asume que la heterogeneidad en la
    probabilidad de éxito $\theta$ en la población sigue una
    distribución **Beta**:
    $$ g(\theta|\alpha, \beta) \sim \text{Beta}(\alpha, \beta) $$

-   **Función de Verosimilitud**: El comportamiento de elección se
    modela con una distribución Binomial, que indica la probabilidad de
    obtener exactamente $x$ éxitos en $m$ intentos:
    $$ \mathbb{P}(X=x|m, \theta) = \binom{m}{x} \theta^x (1-\theta)^{m-x} $$

Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Beta-Binomial. A continuación, se muestra el
desarrollo de la distribución posterior: $$
\begin{aligned}
g(\theta|X=x) &= \frac{\mathbb{P}(X=x|m, \theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(X=x|m, \theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&= \frac{ \left( \binom{m}{x} \theta^x (1-\theta)^{m-x} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \binom{m}{x} \frac{B(\alpha+x, \beta+m-x)}{B(\alpha, \beta)} } \\
&= \frac{\theta^{\alpha+x-1}(1-\theta)^{\beta+m-x-1}}{B(\alpha+x, \beta+m-x)}
\end{aligned}
$$

La expresión resultante es la función de densidad de una distribución
Beta, con los parámetros actualizados.
$$g(\theta|X=x) \sim \text{Beta}(\alpha+x, \beta+m-x)$$

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
$$ \mathbb{E}(\theta|X=x) = \frac{\alpha+x}{\alpha+\beta+m} $$

En el modelo de elección en donde la $P(X_s = x_s)$ quedaba definida en
\@ref(eq:bin). Una pregunta válida que se puede hacer es cuál es la tasa
de respuesta de un segmento $s$ determinado. Intuitivamente debería
estar entre la tasa de respuesta esperada de la población y la
observada, es decir,

$$ 
\begin{aligned}
\mathbb{E}(\theta_s|m_s,x_s)=\gamma \frac{\alpha}{\alpha+\beta} + (1-\gamma) \frac{x_s}{m_s}
\end{aligned}
\quad (\#eq:tasa) 
$$

Esta última igualdad se encuentra al hacer el reemplazo
$\gamma = \frac{\alpha + \beta}{\alpha + \beta + m_s}$, la cual coincide
con \@ref(eq:thetabayes). Se podría replantear la regla de decisión y
enviar catálogos a los segmentos $s$ tales que

$$\mathbb{E} (\theta_s|x_s) =\frac{\alpha + x_s}{\alpha + \beta + m_s} > \frac{\text{costo de envío}}{\text{margen unitario}}$$

$$ 
\begin{aligned}
\mathbb{E}(\theta_s \mid x_s) &= \frac{\alpha + x_s}{\alpha + \beta + m_s}
\end{aligned}
\quad (\#eq:esp) $$

```{=html}
<!-- BEGIN: sección comentada
## Modelos Integrados

Los Modelos Integrados permiten modelar fenómenos complejos que
incorporan más de uno de los modelos básicos planteados anteriormente.

En un caso hipótetico de los items no reportados, se tiene que estos
siguen una distribución de *Poisson*. Por otro lado, la elección para
escoger cuántos items declarar sigue una distribución *Binomial*. La
heterogeneidad se incluye con una distribución *Gamma* para la tasa del
modelo de conteo y con una distribución Beta para la probabilidad de
declaración. Entonces:

$$
\begin{aligned}
P(X=k) &= \sum_{n=k}^{\infty} P(X=k|N=n)\cdot P(N=n)\\
&= \sum_{n=k}^{\infty} \left[ \int_{0}^{1} \binom{n}{k} \theta^k(1 - \theta)^{n-k} \cdot \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)} d\theta \right] \\
&\qquad \cdot \left[ \int_{0}^{\infty} \frac{\lambda^n e^{-\lambda}}{n!}\cdot \frac{r^\alpha \lambda^{\alpha-1}e^{-r\lambda}}{\Gamma(\alpha)}d\lambda \right] \\
&= \frac{\Gamma(\alpha+k)}{\Gamma(\alpha)k!} \left(\frac{r}{r+1}\right)^\alpha \left(\frac{1}{r+1}\right)^k \frac{\Gamma(\alpha'+k)}{\Gamma(\alpha')} \frac{\Gamma(\alpha'+\beta')}{\Gamma(\alpha'+\beta'+k)} \\
&\qquad \cdot {_2F_1}\left(r+k, \beta'; \alpha'+\beta'+k; \frac{1}{r+1}\right)
\end{aligned}
\quad (\#eq:integrado)
$$

El último termino es la función *Hypergeométrica Gaussiana*. Esta
función queda definida como:

$$
\begin{aligned}
_2 F_1 (a,b;c;z) = \frac{\Gamma(c)}{\Gamma(a)\Gamma(b)} \sum_{j=0}^{\infty} \frac{\Gamma(a+j)\Gamma(b+j)}{\Gamma(c+j)} \frac{z^j}{j!}
\end{aligned}
\quad (\#eq:hypergauss)
$$

Como su cálculo puede ser complicado, puede usarse la siguiente
recursión:

$$
\begin{aligned}
_2 F_1 (a,b;v;z) = \sum_{j=0}^{\infty} u_j \approx \sum_{j=0}^{M} u_j
\end{aligned}
\quad (\#eq:recursion)
$$

donde

-   $$u_0=1$$
-   

$$\frac{u_j}{u_{j-1}}=\frac{(a+j-1)(b+j-1)}{(c+j-1)j} \text{           ,} \forall j \geq 1$$

## Customer Lifetime Value: Caso Contractual

*Database Marketing* posee dos elementos esenciales, tiempo de
permanencia con la firma e intensidad de compra mientras el cliente está
en la firma. Para el caso determinista se define Life Time Value (CLV)
como

$$
\begin{aligned}
CLV = \sum_{t=0}^T m \cdot \frac{r^t}{(1+d)^t}
\end{aligned}
\quad (\#eq:clv)
$$

donde $m$ es el flujo neto por período (si el cliente está activo); $r$
es la tasa de retención; $d$ es la tasa de descuento; y T es el
horizonte de evaluación.

Para el caso estocástico, sean $\mathbb{E}(v(t))$ valor esperado de los
flujos del cliente en el instante $t$ (asumiendo que está activo);
$S(t)$ la probabilidad que el cliente siga activo en el instante $t$; y
$d(t)$ el factor de descuento que refleja el valor presente del dinero
recibido en el instante $t$. El cálculo de CLV es:

$$
\begin{aligned}
\mathbb{E}(CLV) = \int_{0}^{\infty} \mathbb{E}(v(t))S(t)d(t)dt
\end{aligned}
\quad (\#eq:eclv)
$$

Esta definición es inútil a menos que se operacionalice
$\mathbb{E}(v(t))$, $S(t)$ y $d(t)$ para la situación particular.

Es importante distinguir entre situaciones contractuales y no
contractuales:

-   **Contractual:** Observamos cuando un cliente deja de estar activo.
    Ejemplo: suscripción a una revista, plan VTR, etc.

-   **No Contractual:** No observamos cuando un cliente deja de estarlo.

El desafío de lo mercados contractuales: ¿Cómo diferenciamos aquellos
clientes que han terminado su relación con la firma, de aquellos que
simplemente están en un largo período de inactividad?

También se debe distinguir según la oportunidad de hacer la transacción:

-   **Discreta:** La acción puede realizarse en un número discreto de
    ocasiones.

-   **Continua:** La acción puede realizarse en cualquier momento.
    Ejemplo, transacción con una tarjeta de crédito.

### Modelo contractual a tiempo discreto

*En el mercado de las revistas, típicamente el 30 % renueva al final de
su primera suscripción, pero ese número salta al 50 % para la segunda
renovación y hasta el 75 % para subscriptores de mayor antigüedad
(Fielding, Michael (2005), "Get Circulation Going: DM Redesign Increases
Renewal Rates for Magazines", Marketing News, September 1, 9-10).*

Al evaluar las tasas de retención de una base de clientes, es necesario
considerar las diferencias entre las cohortes y proyectar los
comportamientos más allá de los que observamos.

Explicaciones alternativas (y complementarias) para el incremento de las
tasas de retención: Dinámicas a nivel individual (incremento de lealtad)
y un cambio en la mezcla de la composición de la población.

**Ejemplo:** En un caso donde se analiza una cohorte de 10.000 clientes
que, en promedio, gastan \$100 por período y que corresponden a dos
tipos de clientes:

-   **Segmento 1:** Un tercio de los clientes tiene una tasa de
    retención (constante en el tiempo) de 0.9.

-   **Segmento 2:** Dos tercios de los clientes tienen una tasa de
    retención anual de 0.5.

|   | #Clientes activos |   |   | Tasa de retención |   |   |
|----|----|----|----|----|----|----|
| Año | Seg-1 | Seg-2 | Total | Seg-1 | Seg-2 | Total |
| 1 | 3.333 | 6.667 | 10 |  |  |  |
| 2 | 3 | 3.334 | 6.334 | 0.9 | 0.5 | [0.633]{style="color: red;"} |
| 3 | 2.7 | 1.667 | 4.367 | 0.9 | 0.5 | [0.689]{style="color: red;"} |
| 4 | 2.43 | 0.834 | 3.264 | 0.9 | 0.5 | [0.747]{style="color: red;"} |
| 5 | 2.187 | 0.417 | 2.604 | 0.9 | 0.5 | [0.798]{style="color: red;"} |

$$\text{Cuadro 1.1: Rol de la heterogeneidad}$$

En el Cuadro 1.1 la tasa de retención agregada (en rojo en la tabla) es
decreciente aún cuando a nivel individual las retenciones son constantes
en el tiempo.

El valor residual de un cliente activo del cohorte, si pertenece al
segmento 1 es:

$$
\begin{aligned}
\mathbb{E}(RLV) = \sum_{t=1}^{\infty} \$100 \cdot \frac{0.9^t}{(1+0.1)^{t-1}} = \$495
\end{aligned}
\quad (\#eq:erlv1)
$$

Si el cliente pertenece al segmento 2:

$$
\begin{aligned}
\mathbb{E}(RLV) = \sum_{t=1}^{\infty} \$100 \cdot \frac{0.5^t}{(1+0.1)^{t-1}} = \$92
\end{aligned}
\quad (\#eq:erlv2)
$$

Sin embargo, la regla de Bayes permite mostrar que, condicional en estar
activo, un cliente es más probable que tenga una alta tasa de retención:

$$
\begin{aligned}
P(\text{seg-1|renovar 4 veces}) &= \frac{P(\text{renovar 4 veces|seg-1}) P(\text{seg-1})}{P(\text{renovar 4 veces})}\\
&= \frac{0.9^4 \cdot 0.3333}{0.9^4 \cdot 0.333 + 0.5^4 \cdot 0.6667}\\
&= 0.84
\end{aligned}
$$

Luego, el *Lifetime Value Residual* viene dado por:

$$\mathbb{E}(RLV) = 0.84 \cdot  \$495 + (0.84) \cdot \$ 92 = \$493.08 $$En
mercados contractuales, ¿cuánto se pierde si no no se considera la
heterogeneidad?. En este ejemplo, si se toma en cuenta la tasa de
retención agregada, el valor de la base de clientes es \$4.945.049. En
cambio, si se distingue por segmentos, este valor asciende a
\$7.940.992.

En estudios con bases de datos reales muestran que el error en el CLV se
eleva hasta el 50%. El impacto sobre el CLV de aumentar las tasas de
retención es hasta un 50%. Para calcular CLV hay que hacerlo condicional
en la duración.

Se postulan los siguientes supuestos para el caso discreto:

1.  La tasa de retención a nivel individual es $1- \theta$:

    $$
    \begin{array}{cc}
    S(t|\theta) = (1-\theta)^t, &t=1,2,3,...
    \end{array}
    \quad (\#eq:treti)
    $$

2.  La heterogeneidad en $\theta$ es capturada por una distribución
    $\text{Beta}$*:*

    $$
    f(\theta|\alpha,\beta) = \frac{\theta^{\alpha -1}(1-\theta)^{\beta -1}}{B(\alpha,\beta)} \quad (\#eq:hetebeta)
    $$

La probabilidad de que el cliente siga activo en $t$:

$$
\begin{array}{cc}
S(t|\alpha,\beta) = \int_{0}^{1} S(t|\theta) f(\theta|\alpha,\beta) d\theta = \frac{B(\alpha,\beta+t)}{B(\alpha,\beta)}, &t = 1,2,3,...
\end{array}
$$

Considerando a un cliente que ha estado activo por n períodos:

$$
\begin{aligned}
\mathbb{E}(\text{RLV}(d| \text{activo en } n \text{ períodos})) &= \sum_{t=n+1}^{\infty} \mathbb{E}(v(t)) \cdot \frac{S(t|t>n)}{(1+d)^{t-n}}\\
&= \bar{v} \sum_{t=n+1}^{\infty} \frac{S(t|t>n)}{(1+d)^{t-n}}, \quad \text{Asumiendo flujos constantes}
\end{aligned}
\quad (\#eq:erlvactivo)
$$

DERL es el valor esperado residual del cliente (condicional en la
antigüedad). Para el caso de la distribución geométrica desplazada:

$$
\begin{aligned}
\text{DERL}(d| \text{activo en } n \text{ períodos}) &= \sum_{t=n}^{\infty} \frac{S(t)}{S(n-1)} \cdot \left(\frac{a}{a+d}\right)^{t-n}\\
&= \frac{(1-\theta)(1+d)}{d+\theta}
\end{aligned}
\quad (\#eq:derl)
$$

Cuando la tasa de abandono $\theta$ no es observable, hay que encontrar
la distribución de esta variable en la población. Para ello se usa la
regla de Bayes para calcular la distribución posterior condicional en la
antigüedad.

$$
\begin{aligned}
\text{DERL}(d|\alpha,\beta, \text{activo en } n \text{ períodos}) &= \int_0^1 \frac{(1-\theta)(1+d)}{d+\theta} \cdot \frac{S(n-1|\theta)f(\theta|\alpha,\beta)}{S(n-1|\alpha, \beta)} d\theta \\
&= \left(\frac{\beta + n - 1}{\alpha + \beta + n - 1}\right) \\
&\quad \cdot_2 F_1 \left( 1,\beta + n; \alpha + \beta + n; \frac{1}{1+d}\right)
\end{aligned}
\quad (\#eq:derlno)
$$

### Modelo contractual a tiempo continuo

Algunos supuestos son:

1.  La duración de la relación de un cliente con la firma está
    caracterizada por una distribución exponencial, con densidad y
    función de sobrevivencia dadas por:

    $$
    f(t|\lambda) = \lambda e^{-\lambda t} \quad (\#eq:fsur)
    $$ $$
    S(t|\lambda) = e^{-\lambda t} \quad (\#eq:ssur)
    $$

2.  La heterogeneidad en $\lambda$ es capturada por una distribución
    $\text{Gamma}$:

    $$
    g(\lambda|r,\alpha) = \frac{\alpha^r\lambda^{r-1}e^{-\alpha\lambda}}{\Gamma(r)} \quad (\#eq:hgamma)
    $$

Entonces, la probabilidad de seguir activo en $t$ es:

$$
\begin{aligned}
S(t|r,\alpha) &= \int_0^{\infty} S(t|\lambda)g(\lambda|r,\alpha)d\lambda\\
&= \left(\frac{\alpha}{\alpha+t}\right)^r
\end{aligned}
\quad (\#eq:sactiv)
$$

El valor esperado de $\text{Residual Lifetime Value}$ es:

$$
\begin{aligned}
\mathbb{E}(\text{RLV}(\delta|\text{activo en }s)) &= \int_{s}^{\infty} \mathbb{E}(v(t))S(t|t>s)\delta(t)dt\\
&= \bar{v} \cdot \text{DERL}(\delta|r,\alpha,\text{activo en }s)
\end{aligned}
\quad (\#eq:sactiv)
$$

donde

$$
\text{DERL}(\delta|r,\alpha,\text{activo en }s) = (\alpha+s)^r\delta \Psi (r;r;(\alpha +s) \delta) \quad (\#eq:drldos)
$$

$\Psi$ es la *función hiper geométrica confluyente del segundo tipo*.
END: sección comentada -->
```

<!--chapter:end:02-probabilisticos.Rmd-->

# Modelos Estructurales

## Introducción a Modelos Estructurales

### Introducción

En esencia, un modelo econométrico estructural es aquel que deriva relaciones estimables estadísticamente a partir de supuestos bien definidos de comportamiento de los agentes que deciden respecto a las cantidades observables. En contraposición a los modelos estructurales están los modelos de forma reducida donde los modelos simplemente describen la variabilidad de alguna medida de interés en base a un conjunto de variables observables exógenas.

La disciplina económica suele llamar modelos estructurales a los resultantes de asumir que los consumidores maximizan una utilidad subyacente y que las firmas maximizan su rentabilidad esperada. Desde el marketing, se considera también en la definición aquellos que postulan hipótesis alternativas de comportamiento incluyendo así una variedad de teorías de comportamiento que nutren la disciplina tales como teoría de prospectos, contabilidad mental, elección sobre conjuntos de consideración, etc. Como se discutirá más adelante, no existe un modelo estructural puro y la línea que los separa de los modelos de forma reducida es ciertamente difusa.

Se incluirá en la discusión de modelos estructurales a cualquiera que considere alguna historia de comportamiento que permita añadir interpretabilidad a los parámetros del modelo.

**Ejemplo 1:** Supóngase que un analista busca estudiar cómo el precio en la región $i$ $(p_i)$ se ve afectado por la presencia o no de competencia. Si además de los precios se observa la cantidad de clientes en la región $(POP_i)$, el ingreso per cápita en la región $(INC_i)$ y una indicatriz $CMP_i$ que toma el valor 1 si en la región correspondiente presenta competencia (0 en caso contrario).

Entonces, un modelo de forma reducida sencillo para estudiar el problema viene dado por:

$$p_i = \beta_0+ \beta_1POP_i + \beta_2INC_i + \beta_3CMP_i + \varepsilon_i$$
Bajo este enfoque, se pueden usar técnicas de regresión tradicionales para estimar $\beta_3$ que en principio indicaría el impacto de la competencia en el nivel de precios. Sin embargo, la presencia de competencia en un determinado mercado depende también del nivel de precios. Si los precios en una región son altos, la rentabilidad esperada por entrar también es alta motivando a potenciales competidores a participar. En consecuencia, un modelo como el planteado podría subestimar
el efecto de la competencia.

Un modelo estructural buscaría derivar relaciones estimables a partir de supuestos básicos del comportamiento de la firma. Por ejemplo, se podría asumir que cada firma decide conjuntamente la entrada/salida de un mercado y los precios a cobrar de modo de maximizar la rentabilidad esperada.

**Ejemplo 2:** Supóngase que se busca describir la productividad de los miembros de la fuerza de venta medida como número de unidades vendidas $q$.

$$q=f(X,\beta)+\varepsilon$$

La especificación del término de error $\varepsilon$ puede por sí solo permitir dar una interpretación estructural a los estimadores. Si simplemente se asume un error normalmente distribuido, entonces corresponderá simplemente a un ruido blanco y la regresión simplemente indicará a través de los parámetros $\beta$ cómo las variables $X$ en promedio afectan las ventas $q$. Por el contrario, si se asume que el término $\varepsilon$ considera además del ruido una componente no observable positiva asociada a la brecha de productividad de los miembros menos eficientes de la fuerza de venta, entonces la regresión describirá la frontera eficiente de ventas. Esto puede hacerse por ejemplo especificando que $\varepsilon = \epsilon - \xi$ donde $\epsilon$ está normalmente distribuida centrada en cero, pero $\xi$ proviene de una normal truncada en los números positivos (este enfoque se le suele llamar de regresión estocástica de frontera).

El gran desafío de la aplicación de modelos econométricos a problemas comerciales es enriquecer el conocimiento respecto a cómo se comportan los agentes relevantes del negocio, para así tomar decisiones más consistentes y más rentables. Desde este punto de vista, se apunta a modelos que describan la lógica que determina el comportamiento de los clientes y firmas más allá de simples correlaciones estadísticas entre las variables observables. En general, son varias las ventajas de usar modelos estructurales por sobre modelos de forma reducida:

1. *La capacidad de contar una mejor historia del comportamiento de los agentes*. Esto se expresa por la capacidad de interpretación directa de los parámetros del modelo. Mientras los parámetros asociados a enfoques de regresión tradicionales típicamente indican la magnitud en que en promedio varía alguna magnitud de interés ante variaciones de otra, los parámetros de un modelo estructural indican entre otros la valoración relativa de un atributo en la función de utilidad, los precios de referencia de un producto o la aversión al riesgo de un tomador de decisión. La provisión de una historia de comportamiento más completa no se deriva exclusivamente de la interpretación directa de los parámetros del modelo sino que también de la capacidad de derivar métricas complementarias tales como elasticidades y excedentes de consumidores. Más aún, se puede proyectar el comportamiento para calcular probabilidades y frecuencias de compra, participaciones de mercado, etc.

2. La generación de estimaciones consistentes con las expectativas de los analistas. Frecuentemente, al analizar los datos se quiere dejar la mayor libertad posible al modelo *para dejar que la data hable*. Este enfoque puede tener valor y ser recomendable en estudios exploratorios, pero para tomar decisiones se necesitan estimaciones robustas y usar tanta información como sea posible. Las teorías usadas para derivar modelos econométricos estructurales suelen estar soportadas tanto por estudios experimentales como por amplia evidencia empírica en múltiples dominios. Por lo tanto, al incorporar teoría se está implícitamente usando información que ha demostrado consistentemente su validez.

**Ejemplo 3:** Supóngase que se quiere proponer un modelo que describa la participación de mercado de las distintas marcas en una industria. Si se usa un enfoque de regresión en que simplemente se disponen los _shares_ al lado izquierdo y una forma funcional flexible al lado derecho, el modelo resultante podría predecir participaciones fuera del rango [0,1], que difícilmente pueden justificarse. Por el contrario si se adscribe al axioma de elección de Luce (1959) que indica que la probabilidad de elección en un determinado conjunto depende del ratio entre una medida de atracción de la alternativa con respecto al atractivo total del conjunto, se fuerza a que las participaciones siempre estén en el rango deseado.

**Ejemplo 4:** La teoría económica predice que en general, las cantidades demandadas decrecen ante aumentos en su precio. Sin embargo, en muchas situaciones prácticas la disponibilidad de datos al nivel de agregación requerido es limitada dificultando la estimación de esta relación inversa entre precio y demanda. En estas situaciones no es raro que un modelo flexible prediga que la demanda crece en función del precio. Agregar estructura permite limitar la búsqueda solo entre aquellos modelos que son consistentes con la premisa de que las demandas decrecen en el precio. 

3. *Evaluación de impacto de modificación de políticas*. Una de las herramientas fundamentales de la función comercial es la generación de planes comerciales que buscan proponer un diseño del conjunto producto, plaza, precio y promoción que genere el mayor valor para el cliente y la captura del mayor excedente por parte de la firma. El rol de los modelos econométricos es estudiar el impacto que tendrían distintas estrategias en el comportamiento del consumidor. En esencia, un plan de marketing propone un cambio en las reglas del juego que han generado la data que se observa y por tanto se necesita apuntar a estimar los elementos más básicos del comportamiento que se mantendrán invariantes ante modificación de productos, precios, canales de distribución, etc. En este grupo se tienen valoraciones por atributos de productos, costo de transporte, aversión al riesgo, entre otros, que no pueden ser estimados a menos que se derive el modelo a partir de teorías individuales de comportamiento. En otras palabras, la derivación de modelos de demanda a partir de teorías de comportamiento permite evaluar contrafactuales que apoyan el diseño de propuestas de valor efectivas.

La necesidad de evaluar contrafactuales usando elementos fundamentales que no se vean afectados por cambios en los sistemas fue inicialmente discutida por Robert Lucas (1976) en la famosa crítica que lleva su nombre. En el contexto de la predicción de efectos macroeconómicos, Lucas postuló que cualquier cambio en las políticas variaría sistemáticamente la estructura de los modelos y por tanto se debe apuntar a describir parámetros profundos que gobiernan el comportamiento individual.

**Ejemplo 5:** Considere un retailer que vende múltiples productos a través de dos canales, las salas de venta tradicionales y un sitio web con despacho directo. El retailer está evaluando la posibilidad de reasignar el conjunto de productos que vende a través de cada canal para aumentar la rentabilidad del negocio. Para apoyar esta decisión, parece evidente que el simple análisis de las ventas de cada producto en cada canal no ayudará a predecir cómo dichos productos se venderían en el otro canal o cómo se afectaría la venta si un producto deja de venderse en algunos de los canales. Para hacer este ejercicio necesariamente se deberá investigar primitivas más fundamentales del comportamiento como preferencias intrínsecas por canal para cada categoría y patrones de sustitución entre las alternativas disponibles dentro del canal y con respecto al otro canal.

**Ejemplo 6:** En muchas industrias como la de vestuario de moda o de artículos tecnológicos, hay una alta variabilidad de la oferta con constantes entradas y salidas de diferentes versiones de los productos dificultando la proyección del desempeño de cada variante en el tiempo. Mientras el surtido de producto varía con frecuencia, hay parámetros de la demanda que pueden perdurar por varias temporadas tales como la elasticidad al precio, crecimiento de la categoría, factores estacionales y de sustitución/complementariedad de atributos. Un enfoque estructural apunta precisamente a la estimación de estos parámetros estables.

4. *Testear aplicabilidad de teoría*. Al usar un enfoque estructural, se fuerza a pensar detalladamente respecto al problema y explicitar cada uno de los supuestos de comportamiento. Las especificaciones alternativas de modelos de forma reducida simplemente corresponden a formas funcionales diferentes y por tanto no son informativas respecto a la lógica en que deciden los agentes. Por otra parte, dos modelos estructurales diferentes provienen de supuestos de comportamiento diferentes y por tanto cuando uno de ellos ajusta mejor a la data indica que hay una teoría de comportamiento que es más plausible que la otra en el dominio de aplicación del modelo. Así, los modelos estructurales no solo se nutren de teoría sino que también ayudan a su desarrollo.

Las ventajas antes descritas no implican que siempre deban preferirse modelos estructurales por sobre los de forma reducida. Como se ha descrito, los modelos de forma reducida suelen proveer suficiente flexibilidad para dejar que sea la data la que hable, lo que puede ser particularmente útil en análisis exploratorios del caso bajo estudio. Además, muchas veces la inclusión de más estructura en el modelo implica rutinas de estimación más sofisticadas siendo con frecuencia altamente intensivas computacionalmente.

Es importante destacar que no existe un modelo puramente estructural. Todo modelo requiere en algún momento suponer alguna forma funcional flexible sin fundamento teórico sólido. Por ejemplo, se puede asumir que los consumidores al elegir un producto están maximizando una utilidad subyacente, pero ¿cómo describir dicha función de utilidad? ¿Qué variables explicativas usar y cuál forma funcional escoger? Ciertamente la especificidad de las teorías disponibles no alcanza a responder a estas preguntas y se debe por lo tanto escoger en base a la intuición y empíricamente entre aquellas que generen mejor ajuste y/o capacidad de pronóstico. De esta forma, un buen modelo debe balancear adecuadamente el uso de la teoría con la simpleza y flexibilidad del modelo.

Para ser convincente, un modelo estructural debe al menos (i) entregar suficiente flexibilidad para aprender de la data, (ii) derivar las ecuaciones de comportamiento de supuestos razonables respecto de los agentes involucrados y (iii) incorporar explícitamente en la descripción la naturaleza no experimental de la data.

**Observación:** En la discusión se ha hecho la distinción entre modelos probabilísticos y modelos estructurales. Aunque los modelos probabilísticos proveen una historia de comportamiento de los agentes, los supuestos básicos usados para derivarlos no se sustentan en ninguna teoría de comportamiento. Por ejemplo, en modelos de duración en tiempo discreto se suele suponer que los clientes dejan de estar activos con cierta probabilidad. Más que una teoría de comportamiento esto es simplemente una descripción probabilística de un fenómeno. En determinadas situaciones, especialmente en casos en que no se dispone de una descripción rica del ambiente en que los agentes toman sus decisiones, se conforma con esta descripción agregada del comportamiento. El enfoque estructural sobre el que se ahondará en esta parte resulta particularmente útil cuando se tiene suficiente información para investigar las motivaciones profundas de las elecciones. Al definir un modelo estructural, tanto las teorías de comportamiento como la descripción probabilística del sistema son fuentes válidas de estructura. Sin embargo, se considerará como modelo econométrico estructural a aquellos que se nutren de ambas fuentes.

### Modelos Estructurales en Marketing

El desarrollo de modelos estructurales se ha gestado en varias áreas del conocimiento tales como economía, transportes, logística, finanzas y marketing. Entre estas áreas, la del marketing se ha constituido en un terreno particularmente fértil para el desarrollo y adopción del enfoque estructural. Se identifican al menos cuatro motivos por los cuales la adición de estructura en los modelos econométricos es particularmente útil para el análisis de problemas comerciales:

1. *Disponibilidad de datos*. Gran parte de los datos que registran las compañías dan cuenta de las interacciones entre clientes y firma como son ocasiones de compra, visitas a sitios web corporativos o llamadas a los centros de llamadas. De esta forma, un conjunto importante de los datos disponibles dentro de las organizaciones son informativos respecto a procesos claves de la función comercial. Así, los requerimientos de datos impuestos por los modelos estructurales están inmediatamente satisfechos por procesos operacionales.

2. *Atractivo de la evaluación de la intervención de sistemas*. En la función comercial, casi por definición se busca perturbar los sistemas para mejorar la oferta de valor cambiando precios, proponiendo nuevos diseños de productos, redefiniendo la cadena logística, etc. De esta forma se necesita disponer de modelos que describan la reacción de los consumidores ante dichos cambios del ambiente competitivo lo que, de acuerdo a la crítica de Lucas, solo puede hacerse con un modelo estructural.

3. *Importancia de heterogeneidad*. En marketing se busca hacer inferencia desagregada a nivel de cliente o segmento para poder diseñar versiones especializadas del marketing mix que sean atractivas para segmentos específicos de clientes. Como los modelos estructurales requieren especificar los supuestos de comportamiento a nivel individual, la generación de estimaciones desagregadas suele derivarse directamente.

4. *Pragmatismo en la aceptación de teorías*. Como se ha argumentado, una de las ventajas de los modelos estructurales es que permiten testear si una determinada teoría de comportamiento aplica a una situación. A diferencia de otras disciplinas, en marketing hay una tradición de revisión continua de las fuerzas que moldean el comportamiento de las personas y por tanto el enfoque de modelos estructurales entrega una herramienta alternativa a la verificación experimental de nuevas teorías.

### Taxonomía de Modelos Estructurales

Metodológicamente, es útil generar una clasificación de los tipos de modelos estructurales existentes en la literatura. Como se ha consignado, uno de los costos de la inclusión de teoría en modelos econométricos es la mayor complejidad en las rutinas de estimación. Es esta complejidad la que dificulta la generación de un mecanismo único que permita estimar modelos generales y por tanto se ve forzado a usar metodologías específicas dependiendo de la naturaleza del problema. En la discusión se basará la clasificación en la evaluación de cuatro factores.

1. *Nivel de agregación de los datos*. Se ha propuesto que un modelo estructural debe basarse en una descripción detallada de los supuestos de los tomadores de decisión a nivel individual. Por lo tanto, la disponibilidad de datos a nivel individual como la decisión de compra de cada uno de los individuos de un panel de consumidores habilita para, imponiendo las restricciones de identificación necesarias, estimar los parámetros de comportamiento de manera más o menos directa. Sin embargo, en ciertas situaciones solo se dispone de información agregada, como participaciones de mercado o datos agregados de venta. En estos casos, la identificación de parámetros de comportamiento requiere además de una descripción del mecanismo mediante el cual se agregan las decisiones individuales. Este mecanismo típicamente considera la especificación de un modelo de heterogeneidad describiendo como se distribuyen los parámetros entre los clientes la que se integra sobre la población para generar las métricas agregadas. Esto es precisamente lo propuesto por el método BLP (a partir de
Berry, Levinsohn y Pakes, quienes primero propusieron el método en 1995) que describe un método que, basado en un modelo logit, permite estimar ofertas y demandas de un modelo oligopólico con información agregada. Por simplicidad, en esta versión se concentrará en modelos estimables directamente sobre datos desagregados a nivel individual.

2. *Temporalidad de las decisiones*. Dependiendo de la amplitud temporal considerada por los agentes al evaluar las alternativas de decisión, se distingue entre problemas estáticos y dinámicos. Básicamente, si se considera que las acciones que se observan resultan de una evaluación completa del horizonte, entonces se habla de problemas dinámicos. En caso contrario, se dice que el problema es estático. La distinción es importante desde un punto de vista metodológico. Si el tomador de decisiones basa sus decisiones exclusivamente
mirando el pasado, entonces estas decisiones pueden caracterizarse directamente mediante condiciones de optimidad sencillas. Por el contrario, si el tomador de decisión además evalúa las repercusiones (inciertas) que sus acciones de hoy podrían tener en su bienestar futuro, entonces se necesita caracterizar las políticas óptimas a través de ecuaciones de Bellman que incorporen explícitamente la naturaleza multiperiodo del problema. En este caso, para encontrar la política óptima del problema se requiere usar técnicas como programación dinámica estocástica o control óptimo, aumentando de manera importante la complejidad computacional de la estimación.

3. *Naturaleza de las variables de decisión*. Si las variables sobre las que deciden los agentes son continuas (gasto, montos de inversión, unidades compradas, etc.), se habla de un modelo de decisión continuo. Si las variables sobre las que deciden los agentes son discretas (si visita o no visita la tienda, si elige la marca A o marca B, etc.), se habla de un modelo de decisión discreto. La distinción es relevante en cuanto las soluciones de un problema de decisión continua pueden caracterizarse directamente mediante condiciones de Karush-Kuhn-Tucker, mientras que las soluciones de un problema de decisión discreta requieren una enumeración del valor de las alternativas.

4. *Identidad de los agentes*. Los modelos estructurales pueden usarse para estudiar tanto el comportamiento de los clientes como de las otras firmas en el mercado. El área que estudia el comportamiento de las firmas ha tenido un gran desarrollo en los últimos años y se conoce como organización industrial empírica. En esta versión, se concentrará la discusión en el estudio de los clientes por dos motivos principales: la disponibilidad de datos de comportamiento de cliente y la simpleza de las nociones de equilibrio requeridas para describir a los clientes. Mientras cada cliente suele tener poco poder de mercado por si mismo, las acciones de marketing de las firmas competidoras típicamente pueden modificar de manera importante las condiciones del mercado. Así, la descripción de las decisiones de las firmas conlleva desafíos metodológicos importantes como la inclusión de nociones sofisticadas de equilibrio para internalizar que las decisiones de las firmas resultan tanto de mirar las respuestas esperadas de los clientes como las reacciones estratégicas de los competidores.

Metodológicamente es útil también distinguir los métodos de estimación de los modelos. La literatura reconoce dos grandes enfoques para estimar modelos estructurales como los aquí presentados: método de los momentos generalizados (GMM) y método de la máxima verosimilitud. Dada su eficiencia estadística (en el sentido que usa toda la información disponible), en esta primera versión se usará solo el método de la máxima verosimilitud. En lo que sigue se enfocará la discusión al estudio del comportamiento de clientes, en problemas estáticos (o con dinámica limitada a la incorporación del pasado) y con datos desagregados. Partiremos describiendo brevemente modelos de decisión continuos para luego iniciar una discusión más extensa en modelos de decisión discreta que tienen una tradición más larga en marketing.



## Logit

### Modelos de Elección Discreta

Un modelo de elección discreta consiste básicamente en situaciones en que la naturaleza de las variables de decisión a las que se enfrenta el tomador de decisión son discretas. Para ilustrar la intuición de la diferencia con respecto a modelos de decisión continua, es útil pensar que mientras estos últimos buscan describir decisiones de "el cuánto", los modelos de elección discreta se concentran en "el cuál". La distinción además relevante desde un punto de vista metodológico. A diferencia de los modelos de elección continua en que la optimidad de la elección queda bien descrita por
condiciones de primer orden, al enfrentar decisiones discretas caracterizaremos la optimidad por enumeración. Ejemplos típicos en que la decisión a evaluar es de naturaleza discreta incluye la elección de una marca por sobre otra en la góndola de un supermercado, la decisión de visitar o no a una tienda, la elección del color de una prenda de vestir, de un canal de venta y la elección de las firmas respecto a entrar o no entrar a un mercado.

Para que un problema de elección discreta esté bien definido, se necesita, además de variables de decisión discretas, que el conjunto de alternativas presente las siguientes tres características:

1. *EXHAUSTIVAS*:  El conjunto sobre el que los tomadores de decisión eligen deben incluir todas las alternativas posibles. En otras palabras, cualquiera sea la decisión observada, debe
estar incluida en el conjunto de elección. Esta condición es poco restrictiva ya que siempre es posible incluir en el set de alternativas la posibilidad “ninguna de las anteriores” o similar que por definición incluya toda las otras posibilidades no consideradas en conjunto. Sin embargo, esta estrategia debe usarse con precaución. Por ejemplo, al estudiar la elección de marca en una categoría en que se observa que los clientes no siempre compran alguna
de las marcas disponibles, se podría incluir la alternativa de no compra en el conjunto de elección. Si la proporción de no compras es alta en la muestra, la inclusión de la alternativa de no compra podría limitar la habilidad del modelo de aprender respecto a cómo los clientes eligen entre marcas. En este caso, podría convenir concentrarse en la elección de la marca condicional en haber hecho una compra en la categoría.

2. *MUTUAMENTE EXCLUYENTES:* El conjunto de decisión debe definirse de modo que en cada ocasión el tomador de decisión seleccione solo una de las alternativas disponibles. Esto es, la elección de una alternativa implica necesariamente la no elección de cualquiera de las alternativas restantes. Aunque aparentemente restrictiva, la definición de conjunto de elección puede acomodarse para generar conjuntos mutuamente excluyentes. Por ejemplo, considérese un modelo para describir la elección de los clientes entre la *tienda física tradicional* o la *tienda virtual*. Si simplemente se permite una alternativa de elección por cada canal, entonces se excluye la posibilidad de que un mismo cliente esté en más de un canal al mismo tiempo. Para incorporar esta posibilidad, se debe redefinir las alternativas agregando la opción de *tienda tradicional y virtual*.

3. *FINITO:* El conjunto de decisión debe contener un conjunto finito de alternativas. Esta condición es importante por dos motivos técnicos. Primero, un conjunto finito facilita la evaluación de la optimidad de las decisiones y, segundo, facilita la definición de probabilidades de elección. Existen situaciones en que la decisión teóricamente permite infinitas posibilidades, pero que en la práctica se concentran en un número reducido de alternativas y, por tanto, quedan bien representadas por un modelo de elección discreta. Por ejemplo, se puede usar el número de cajas de cereal compradas por los clientes en cada visita al supermercado. Aunque teóricamente los clientes siempre podrían comprar una unidad adicional, el problema queda bien descrito considerando sólo las alternativas de 0, 1, 2, 3 o más de 3 cajas. 

Un modelo estructural para describir la probabilidad de elegir cada alternativa necesita especificar el mecanismo que usan los agentes para decidir entre las alternativas. Se partirá asumiendo que, en cada oportunidad de compra $t$, el tomador de decisión $n$ elige la alternativa $i$ que le reporta mayor utilidad $u_{nit}$. Pese a que el tomador de decisión necesita conocer la utilidad que deriva de cada una de las alternativas, desde la perspectiva del analista solo se observan algunas características del ambiente de decisión y del tomador de decisión a partir de las cuales se puede intentar aproximar la utilidad del tomador de decisión a través de una función $v_{nit}(x_{nit}, \theta)$ donde $x_{nit}$ son las características observables del problema y $\theta$ el vector de parámetros que se busca estimar y que describen la relación de dichas características con la utilidad.

**Ejemplo:** Supóngase que se quiere describir la elección del medio de pago que usan los usuarios de una tienda determinada, la que permite pagar en efectivo o con alguna tarjeta bancaria. El analista observa 3 variables que intuye pueden ser relevantes en la elección del medio de pago: el género del cliente ($F_n = 1$ si cliente es de género femenino), su nivel de ingresos $(I_n)$ y el monto de la transacción $(M_{nt})$. Son precisamente estas características las que estarían incluidas en la matriz que se ha llamado $x_{nit}$. A partir de esta información pueden plantearse múltiples modelos para describir $v_{nit}$ (se asumirá que $i = 0$ corresponde al caso de pago con efectivo mientras que $i = 1$ al de pago con tarjeta).

* *Modelo Lineal Homogéneo*: Aquí, la utilidad para ambas alternativas crece linealmente con las variables observables. En este caso, los parámetros son los mismos para todos los tomadores de decisión y por tanto el vector de parámetros viene dado por $\theta = (\alpha_0, \alpha_1, \beta, \gamma, \delta)$

$$v_{nit} = \alpha_i + \beta F_n + \gamma I_n + \delta M_{nt}$$

* *Modelo lineal heterogéneo:* Aquí, la utilidad para ambas alternativas también crece linealmente con las variables observables, pero ahora los parámetros varían por alternativa y por agente, y por tanto el vector de parámetros viene dado por $\theta = ( \{ \alpha_{1n} \} _{n=1}^{N}, \beta_0,\beta_1,\gamma_0,\gamma_1,\{ \delta_n \}_{n=1}^{N} )$

 $$v_{nit} = \alpha_{in} + \beta_i F_n + \gamma_i I_n + \delta_n M_{nt}$$
 
La definición de que los interceptos dependen del cliente $n$ simplemente indica que cada cliente tiene una preferencia intrínseca por cada medio de pago. Del mismo modo, se está imponiendo que la influencia que tiene el monto en el atractivo que tiene cada alternativa depende del cliente. Por ejemplo, mientras para algunos clientes el monto de la transacción puede jugar un rol importante en la decisión del medio de pago, para otros este efecto podría no ser relevante. Por último, la dependencia de la alternativa en los parámetros asociados a género e ingreso podrían usarse para por ejemplo situaciones en que el nivel de ingreso afecta el atractivo de un medio de pago pero no del otro (la intuición para el género es análoga).

Por supuesto, también se pueden postular modelos no lineales u otras especificaciones de la heterogeneidad. Por ejemplo, que la influencia del ingreso varíe por medio de pago, pero que
el efecto del género sea constante entre las alternativas. Descubrir la especificación que mejor describe el problema es precisamente la tarea del analista.

**Observación:** En el ejemplo se ha introducido brevemente el concepto de heterogeneidad. Sin embargo, para facilitar la exposición de los temas básicos, en primera instancia se concentrará en modelos sin heterogeneidad. En marketing, los modelos que incluyen heterogeneidad en las preferencias son tan importantes que se postergará su discusión en un capítulo separado.

En la práctica, aún en situaciones en que se observa con detalle el ambiente de decisión, no se podrá describir con exactitud todos los factores que gobiernan el comportamiento de los agentes. Por lo tanto, se definirá $\varepsilon_{nit}$ como el error (aditivo) que se comete al aproximar $u_{nit}$ a través de $v_{nit}$.

$$u_{nit} = v_{nit} + \varepsilon_{nit}$$
Así, se descompone la utilidad de cada alternativa en una componente sistemática (u observable o explicable) $v_{nit}$ y en una componente aleatoria (o no observable o inexplicable) $\varepsilon_{nit}$. Como se verá, la tarea de modelamiento del problema involucra tanto la especificación de la componente sistemática como de la aleatoria.

La componente básica para estimar estadísticamente un modelo de elección discreta es la especificación de la probabilidad de elección de cada alternativa. Sea $P_{nit}$ la probabilidad de que el agente $n$ escoja la alternativa $i$ en la oportunidad de compra $t$. El supuesto de maximización de utilidades implica que $P_{nit}$ puede escribirse como:

\begin{aligned}
P_{nit} &= Pr(u_{nit}>u_{njt},\forall j \neq i)\\
&= Pr(v_{nit} + \varepsilon_{nit} >v_{njt} + \varepsilon_{njt} ,\forall j \neq i)\\
&= \int \textbf{1} (\varepsilon_{njt} - \varepsilon_{nit} > v_{nit} - v_{njt}) f(\varepsilon_{nt}) d \varepsilon_{nt}
\end{aligned}

donde $\textbf{1}(\cdot)$ toma el valor 1 si se cumple el argumento y el valor 0 en caso contrario. En esta expresión, $\varepsilon_{nt} = (\varepsilon_{n1t},\varepsilon_{n2t}, ...,\varepsilon_{nIt})$ es el vector de las componentes aleatorias de la elección del agente $n$ en la oportunidad $t$, y $f(·)$ la función de densidad que describe su comportamiento probabilístico. La elección de la distribución de la componente aleatoria es importante en cuanto impone restricciones a los patrones de comportamiento que pueden ser capturados por el modelo. Se concentrará la atención en los casos en que $\varepsilon_{nit}$ se distribuye valor extremo, que da origen al modelo *logit*, y normal, que da origen al modelo *probit*.

### Modelo Logit

El modelo logit resulta de asumir que cada $\varepsilon_{nit}$ es independientemente distribuido de acuerdo a una distribución gumbel o de valor extremo tipo I.

\begin{equation} 
  \begin{array}{cc}
  F(\varepsilon_{nit}) = e^{-e^{-\varepsilon_{nit}}}
   &f(\varepsilon_{nit}) = e^{-\varepsilon_{nit}}e^{-e^{-\varepsilon_{nit}}}
   \end{array}
  (\#eq:logituno)
\end{equation} 

Aplicando esta definición, se puede demostrar que la probabilidad de elección en un modelo logit corresponde a una fórmula cerrada sencilla (para el detalle de la derivación ver [apéndice](#apéndice)):

\begin{equation}
\begin{aligned}
P_{nit} &= \int Pr(\varepsilon_{njt} < v_{nit} - v_{njt} + \varepsilon_{nit}, \forall j \neq i | \varepsilon_{nit}) f(\varepsilon_{nit})d\varepsilon_{nit}\\
&= \int \left(\prod_{j \neq i} e^{-e^{-(v_{nit} - v_{njt} + \varepsilon_{nit})}}\right) e^{-\varepsilon_{nit}}e^{-e^{-\varepsilon_{nit}}}d \varepsilon_{nit} \\
&= \frac{e^{v_{nit}}}{\sum_j e^{v_{njt}}}
\end{aligned}
(\#eq:logitprob)
\end{equation}

En algunos libros de texto se justifica esta expresión simplemente como una regresión logística, esto es, una transformación lineal para normalizar la utilidad de modo de interpretarla directamente como una probabilidad de elección en el rango [0,1]. Aunque válido, resulta útil entender que, en efecto, dicha expresión puede derivarse a partir de supuestos de maximización de utilidades.

Para ganar algo de intuición respecto a la expresión de la probabilidad de elección, es útil graficarla con respecto a la utilidad derivada por cada alternativa. Por ejemplo, supóngase que se tiene una decisión binaria que, por ejemplo, corresponde a la decisión de comprar o no comprar un producto. En este caso, la probabilidad de comprar el producto crece *sigmoidalmente* con la utilidad derivada de la compra. Esto es, al graficar la probabilidad de compra con respecto a la utilidad derivada, se obtiene una curva S como muestra la Figura 1. En la figura, se ha agregado también la curva de la probabilidad de elección en el caso en que, en vez de asumir que el error se distribuye valor extremo como demanda el modelo logit, se asume que el error está normalmente distribuido como tradicionalmente se hace en otros modelos econométricos.

```{r probelec, fig.cap="Probabilidad de elección",out.width='50%', fig.align='center'}
knitr::include_graphics(rep("images/probabilidad_eleccion.png"))
```

\FloatBarrier

La disposición de una fórmula cerrada para la probabilidad de elección facilita el cálculo de múltiples métricas asociadas que permiten complementar el análisis. Supóngase que la utilidad de una alternativa viene dada por $v_{nit} = v(x_{nit}, \theta)$; entonces se pueden calcular:

+ Cómo varía la probabilidad de elegir la alternativa $i$ al variar alguna componente de la utilidad de la misma alternativa.

\begin{equation}
\frac{dP_{nit}}{dx_{nit}}  = \frac{\partial v_{nit}}{\partial x_{nit}} \cdot P_{nit}(1- P_{nit})
(\#eq:ownderivative)
\end{equation}

+ Cómo varía la probabilidad de elegir la alternativa $i$ al variar alguna componente de la utilidad de otra alternativa.

\begin{equation}
\frac{dP_{nit}}{dx_{njt}}  = \frac{\partial v_{njt}}{\partial x_{njt}} \cdot P_{nit}\cdot P_{njt}
(\#eq:crossderivative)
\end{equation}

+ Elasticidad de la probabilidad de elegir la alternativa $i$ con respecto a alguna componente de la utilidad de la misma alternativa.

\begin{equation}
e_{ix_{nit}} = \frac{\partial P_{nit}}{\partial x_{nit}}  \cdot \frac{x_{nit}}{P_{nit}}= \frac{\partial v_{nit}}{\partial x_{nit}} x_{nit} (1- P_{nit})
(\#eq:ownelasticity)
\end{equation}

+ Elasticidad de la probabilidad de elegir la alternativa $i$ con respecto a alguna componente de la utilidad de otra alternativa.

\begin{equation}
e_{ix_{njt}} = \frac{\partial P_{nit}}{\partial x_{njt}}  \cdot \frac{x_{njt}}{P_{nit}}= \frac{\partial v_{njt}}{\partial x_{njt}} x_{njt} P_{njt}
(\#eq:crosselasticity)
\end{equation}

Recuerde que una de las motivaciones para el uso de modelos estructurales es la posibilidad de analizar contrafactuales, esto es, ver qué pasaría con el mercado si hay cambio en alguna variable de control interesante. Por ejemplo que pasa con las participaciones de mercado si sube el precio de una alternativa, si se aumenta la frecuencia publicitaria, etc. Las métricas recién presentadas permiten precisamente hacer dichas evaluaciones de manera directa.

#### Propiedades del modelo Logit

El modelo logit es bastante flexible para acomodar una amplia variedad de situaciones. En efecto, distintas especificaciones de las funciones de utilidades de las alternativas permiten describir múltiples fenómenos asociados a la elección. Sin embargo, es importante reconocer que los supuestos subyacentes al logit imponen importantes restricciones a cómo se describe la lógica en que los agentes evalúan las alternativas y escogen entre ellas.

Para fijar ideas, resulta útil pensar qué restricciones impone asumir que las componentes no observables de la utilidad son todas independientes entre ellas. El supuesto de independencia obliga a imponer que cualquier relación entre las utilidades de dos alternativas debe necesariamente capturarse a través de variables observables. Del mismo modo, las utilidades que se derivan por dos alternativas en ocasiones de elección diferentes solo pueden describirse a través de elementos que se puedan observar a lo largo del tiempo. Para entender mejor cómo estas limitaciones se materializan en la formulación del modelo, se discutirán formalmente tres características del modelo logit: la existencia de patrones de sustitución proporcional, la incapacidad de capturar tanto heterogeneidad aleatoria en las preferencias como componentes dinámicas no observables.

##### Patrones de sustitución {-}

Los patrones de sustitución derivados de un modelo logit son bastante peculiares y, aunque desde un punto de vista econométrico puede resultar beneficioso, desde el punto de vista de la investigación de teorías de comportamiento suele ser considerado como bastante restrictivo. Se entenderá por patrones de sustitución a la forma en que cambia la probabilidad de elección de alguna alternativa cuando se modifica el atractivo de otra alternativa. Para entender la naturaleza de los patrones de sustitución del modelo logit es útil calcular el ratio de las probabilidades de elección de dos alternativas cualquiera $i$ y $j$.

$$\frac{P_{ni}}{P_{nj}} = e^{v_{ni} - v_{nj}}$$

Este ratio solo depende de las utilidades observables de las dos alternativas consideradas lo que indica que la probabilidad relativa de elegir la alternativa $i$ sobre la alternativa $j$ no depende de que otras alternativas existan ni de los atributos que ellas tengan. Por ejemplo, si se agrega una alternativa al conjunto de elección, el ratio de probabilidades de las alternativas existentes se mantendrá constante independiente de las características de la nueva alternativa. Se referirá a esta característica como *independencia de alternativas irrelevantes* o *IIA*.

Para ejemplificar, considérese una botillería que ofrece dos variedades de vino, uno blanco y otro tinto. Supóngase además que estas dos alternativas tienen la misma participación de
mercado, esto es la mitad de los clientes de la botillería compra vino blanco y la otra mitad compra vino tinto. En este caso, las utilidades sistemáticas debieran ser similares y, por tanto, el ratio de probabilidades de elección de vino blanco sobre vino tinto debiera acercarse a 1. Motivado por un
mayor margen de los vinos tintos, el administrador de la botillería decide incorporar una nueva variedad de vino tinto. Intuitivamente se esperaría que, como la nueva variedad de vino tinto es un sustituto más cercano al tinto existente, la participación de mercado de este debiera decrecer
más que la de vino blanco. Sin embargo, la propiedad de IIA impone que este ratio se mantiene constante. En otras palabras, la introducción de una nueva alternativa disminuirá la participación de todas la otras alternativas independiente de las similitudes que tengan. Esta última observación
puede corroborarse calculando la elasticidad de sustitución $E_{ix_{nj}}$ que determina como cambia la probabilidad de consumir la alternativa $i$ ante un cambio en un atributo $x_{nj}$ de la alternativa $j$. 

$$E_{ix_{nj}} = -\frac{\partial v_{nj}}{\partial x_{nj}}x_{nj} P_{nj}, \forall i \neq j$$
 
Esta expresión no depende de $i$, por lo que es constante para todas las alternativas de elección. Luego, si ocurre una mejora en los atributos de una alternativa, la probabilidad de elección de las demás disminuye en el mismo porcentaje independiente de la similitud entre alternativas. Se referirá a esta característica como *patrones de sustitución proporcionales*.

Una ventaja de los patrones de sustitución del modelo logit es que permite que los parámetros del modelo sean estimados consistentemente en base a un subconjunto de las alternativas. Esto es particularmente útil en ambientes de decisión de marketing donde típicamente se encuentran centenas de productos que potencialmente pueden constituir alternativas de elección en una situación de compra. De esta forma, para estimar un modelo logit se pueden seleccionar conjuntos
reducidos de alternativas que capturan los elementos esenciales de la elección e ignorar qué pasa con todas las otras alternativas.

##### Incapacidad de estimar componentes aleatorias {-}

La investigación de las diferencias entre las preferencias de los distintos clientes es un tema fundamental para el desarrollo de planes comerciales exitosos. Tradicionalmente se distinguen dos tipos de heterogeneidad de acuerdo a la capacidad de observación del analista. En un principio, se tiene el estudio de heterogeneidad observable que indica cómo las preferencias de los tomadores de decisiones varían de acuerdo a sus características medibles. Este tipo de heterogeneidad permite, por ejemplo, estudiar diferencias en las preferencias entre hombres y mujeres, por edad o por niveles de ingreso. Sin embargo, una proporción importante de las diferencias de las preferencias no es atribuible a características observables como las recién descritas. Otro ejemplo es que dos hermanos del mismo género, de edades similares, viviendo en el mismo hogar, pueden tener preferencias completamente diferentes respecto a sabores de yogur.

El resultado fundamental en esta sección indica que un modelo logit permite estudiar variaciones de preferencias asociadas a componentes observables, pero no a componentes no observables.
Para ilustrar este resultado, supóngase un tomador de decisión caracterizado por la siguiente función de utilidad:

$$u_{nit} = \alpha_i + \beta_np_{it} + \varepsilon_{nit}$$
 
 Es decir, la utilidad de cada alternativa tiene una componente base que es constante entre los tomadores de decisión y una penalización por precio $p_{it}$ al que se enfrenta el tomador de decisión. Al indexar $β_n$ por agente se está explícitamente permitiendo que algunos tomadores de decisión sean más sensibles al precio que otros. Supóngase que se postula que el coeficiente de precio viene dado por la siguiente ecuación de regresión.
 
 $$\beta_n = \lambda_0 + \lambda_1I_n + \mu_n$$
 Donde $\lambda_0$ captura la sensibilidad base al precio, $I_n$ el nivel de ingreso del agente $n$ y $\lambda_1$ el coeficiente que indica cómo dichos niveles de ingresos afectan la sensibilidad al precio. Por último, $\mu_n$ es un valor aleatorio que captura todas las otras componentes que modifican la sensibilidad al precio más allá del nivel base y los ingresos.
 
\begin{aligned}
u_{nit} &= \alpha_i + (\lambda_0 + \lambda_1 I_n + \mu_n)p_{it} + \varepsilon_{nit}\\
&= \alpha_i + \lambda_0 p_{it} + \lambda_1p_{it}I_n + \xi_{nit}
\end{aligned}
 
 
 Donde $\xi_{nit} = \mu_np_{it} + \varepsilon_{nit}$. De esta expresión debiera ser claro que la inclusión de heterogeneidad
observable puede ser capturada bajo un enfoque logit. En efecto, los parámetros $\alpha_i$, $\lambda_0$ y $\lambda_1$ dan cuenta respectivamente del nivel de utilidad base por alternativa, de la penalización por precio y de como dicha penalización se ve modificada por el nivel de ingresos. Lamentablemente, la
variación aleatoria $\mu_n$ no puede ser incluida, ya que su inclusión necesariamente implica que las componentes errores $\xi_{nit}$ no están idénticamente distribuidas. En efecto, se puede mostrar que $\mathbb{V}ar(\xi_{nit}, \xi_{njt}) = \mathbb{Var}(\mu_n)p^2_{it}$ que evidentemente varía entre alternativas. Más aún, también se puede mostrar que $\mathbb{Cov}(\xi_{nit}, \xi_{njt}) = \mathbb{Var}(\mu_n)p_{it}p_{jt} \neq 0$, violando también el supuesto de independencia.

 Es importante notar que la incapacidad de capturar aleatoriedad aplica también a componentes dinámicas. Esto es, al observar compras repetidas en el tiempo, el modelo logit no permite capturar que hay componentes no observables que varíen en el tiempo. Por ejemplo, no se puede incorporar que, debido a factores externos no observables, en algunos períodos algunas alternativas son más atractivas para todos los agentes decidiendo en dichos períodos. Al igual que en el ejemplo anterior, incluir estas variaciones viola los supuestos de distribuciones independientes e idénticamente distribuidas para las componentes no observables.
 
### Estimación

Para estimar el modelo, se necesita escribir la verosimilitud del problema. La componente fundamental para la construcción de la verosimilitud es la descripción de la probabilidad de
elección $P_{nit}$. Para el caso del modelo logit, como la expresión de la probabilidad de elección corresponde a una fórmula analítica cerrada, la construcción de la verosimilitud es directa. Si la componente determinística de la utilidad viene dada por $v_{nit}(x_{nit}, \theta)$ y si $y_{nit}$ es una variable que toma valor 1 si el tomador de decisión $n$ escoge alternativa $i$ en oportunidad $t$, entonces la verosimilitud viene dada por:

\begin{equation}
L(\theta) = \prod_n\prod_i\prod_t (P_{nit})^{y_{nit}} =  \prod_n\prod_i\prod_t \left(\frac{e^{v_{nit}(x_{nit},\theta)}}{\sum_j e^{v_{njt}(x_{njt},\theta)}}\right)^{y_{nit}}
(\#eq:likelihood)
\end{equation}

La que se puede maximizar directamente usando rutinas estándares de programación convexa. Computacionalmente, suele ser más conveniente trabajar con la log-verosimilitud en vez de la verosimilitud. Esto porque la multiplicación de probabilidades genera muy rápidamente valores que computacionalmente son indistinguibles de cero. Recuérdese que el valor de los valores óptimos son invariantes a transformaciones monótonas como la del logaritmo. 

\begin{equation}
\begin{aligned}
LL(\theta) &= \sum_n\sum_i\sum_t y_{nit} ln \left(\frac{e^{v_{nit}(x_{nit},\theta)}}{\sum_j e^{v_{njt}(x_{njt},\theta)}}\right)\\
&= \sum_n\sum_i\sum_t y_{nit}v_{nit}(x_{nit},\theta) - \sum_n\sum_i\sum_t ln \left(\sum_j e^{v_{njt}(x_{njt},\theta)}\right)
\end{aligned}
(\#eq:loglikelihood)
\end{equation}

Como se ha indicado, esta función objetivo puede ser ingresada directamente a cualquier rutina de optimización para encontrar los estimadores máximo verosímiles. Además, para muchas instancias prácticas, es conveniente contar con las derivadas de la log-verosimilitud, de modo de encontrar eficientemente direcciones de máximo ascenso o evaluar si el punto es estacionario o no. Afortunadamente, para la mayoría de las especificaciones del modelo logit, estas derivadas también son fáciles de obtener. Por ejemplo, si la componente sistemática de la utilidad viene dada por $v_{nit}(x_{nit}, \theta) = x'_{nit}\theta$ entonces

\begin{equation}
\frac{\partial LL(\theta)}{\partial \theta} = \sum_n\sum_i\sum_t \left(y_{nit} - \frac{e^{x'_{nit}\theta}}{\sum_j e^{x'_{njt}\theta}}\right)x_{nit}
(\#eq:gradient)
\end{equation}

Del mismo modo, se pueden calcular segundas derivadas que resultan útiles para el cálculo de errores estándares de los parámetros.

#### Evaluación del modelo {-}

Al igual que en otros modelos econométricos, una de las componentes fundamentales del análisis es la evaluación de la calidad del modelo. La variedad de métricas disponibles para la evaluación es muy amplia y la mayoría son transversales a cualquier modelo. Categorizaremos las herramientas de evaluación en tres grupos: bondad de ajuste, capacidad de pronóstico y test de hipótesis.

1. *BONDAD DE AJUSTE*: Las métricas de bondad de ajuste básicamente nos indican qué tan bien el modelo ajusta a la data. En el contexto de modelos de regresión, se suele analizar el estadístico $R^2$ que mide la proporción de la variabilidad de la variable dependiente que puede ser explicado por la variación de las variables independientes. En el contexto de modelos de elección discreta se basará la evaluación en el valor de la verosimilitud usando alguno o varios de los siguientes indicadores:

   - $\rho$ de McFadden. Este índice está en el rango [0,1] e informalmente, se suele interpretar como el coeficiente de determinación $(R^2)$ en el sentido que un valor cercano a 0 indica un mal ajuste y un valor cercano a 1 indica un buen ajuste. Sin embargo, es importante notar que no puede decirse que $\rho$ mida la variabilidad explicada por el modelo como
hace el coeficiente de determinación

    \begin{equation}
    \rho=1 - \frac{LL(\hat{\beta})}{LL(0)}
    (\#eq:rho)
    \end{equation}

  - Criterio de información de Akaike (AIC) y Bayesiano (BIC): Una de las limitaciones del $\rho$ de McFadden es que solo permite comparar modelos con el mismo número de parámetros. Los dos indicadores más usados para comparar modelos con distintos números de parámetros son AIC y BIC, en que se penaliza la verosimilitud por el número de parámetros para capturar el hecho de que al incluir nuevos parámetros la verosimilitud necesariamente crecerá. La diferencia entre AIC y BIC es que el primero tiene una penalización constante por número de parámetros mientras que la penalización del segundo depende de la cantidad de datos disponible. Si la log-verosimilitud de un modelo con n observaciones y k parámetros , entonces AIC y BIC vienen dados por: 
  
\begin{equation}
\begin{array}{cc}
AIC = -LL(\hat{\theta}) + 2k & BIC =-2LL(\hat{\theta}) + k\ln(n)
\end{array}
(\#eq:aicbic)
\end{equation}

1. *CAPACIDAD DE PRONÓSTICO*: Un modelo que explique muy bien la data puede correr el riesgo de sobreajustar. Esto es, que no permita describir el fenómeno para datos que no se usaron en el entrenamiento del modelo. Para medir la capacidad de pronóstico se suele dividir los datos en un subconjunto de entrenamiento y otro de prueba. Con esto, se comparan las realizaciones con lo pronosticado usando las estimaciones del subconjunto de entrenamiento. Supóngase que se está interesado en evaluar la capacidad de pronóstico de un indicador $f_{ni}$ que puede corresponder a las elecciones mismas, participaciones de mercado o cualquier otra. Si $\hat{f}_{ni}$ es el pronóstico del modelo, entonces se suele usar el mean
absolute error (MAE) o el mean absolute percentage error (MAPE) 

\begin{equation}
\begin{array}{cc}
MAE = \frac{1}{N} \sum_n \sum_i |f_{ni} - \hat{f}_{ni}| &MAPE = \frac{1}{N} \sum_n \sum_i \left| \frac{f_{ni} - \hat{f}_{ni}}{f_{ni}} \right|
\end{array}
(\#eq:maemape)
\end{equation}

3. *TEST DE HIPÓTESIS*: La evaluación de hipótesis también puede contribuir a diagnosticar un modelo. Por ejemplo, al agregar una variable explicativa, se podría evaluar si el coeficiente correspondiente es significativamente diferente de 0, lo que se puede hacer directamente a través de la construcción de intervalos de confianza o su estadístico $t$ equivalente (recuérdese que la varianza del estimador máximo verosímil puede obtenerse usando el inverso del Hessiano). En ocasiones también se estará interesado en testear hipótesis más complejas, para lo que se recurre a test de ratios de verosimilitud. Supóngase, por ejemplo, que se tiene un modelo en que los coeficientes asociados a display difieren por marca para incorporar la posibilidad de que algunas de ellas sean más efectivas en su comunicación en sala. El test de ratios de verosimilitud permite, por ejemplo, testear si estos coeficientes son iguales o si efectivamente difieren entre marcas. Si la hipótesis nula puede expresarse como $k$ restricciones sobre los parámetros, entonces se puede estimar un modelo A no restringido y otro B restringido y se calcula el estadístico $LR = 2(LLA − LLB)$, que se distribuye $\chi^2$
con k grados de libertad.

### Modelos de Panel: Persistencia y Dependencia Temporal

Hasta ahora se han discutido modelos de elección discreta asumiendo implícitamente que cada observación de elección es independiente de las demás. Sin embargo, cuando se dispone de datos de panel (observaciones repetidas del mismo individuo a lo largo del tiempo), es razonable esperar que las elecciones de un individuo en diferentes períodos estén relacionadas. En contextos de marketing, esta dependencia temporal puede manifestarse de diversas formas, siendo dos de las más relevantes la **persistencia de elección** (o lealtad) y la formación de **precios de referencia**.

#### Persistencia de Elección (Lealtad)

Uno de los fenómenos más documentados en el comportamiento de compra es la tendencia de los consumidores a repetir sus elecciones previas, lo que comúnmente se denomina lealtad de marca o inercia en el comportamiento. Esta persistencia puede originarse en múltiples factores:

- **Costos de cambio:** Tanto físicos (esfuerzo de probar algo nuevo) como psicológicos (aversión al riesgo)
- **Aprendizaje:** Experiencias positivas pasadas reducen la incertidumbre sobre el producto
- **Satisfacción acumulada:** La utilidad experimentada en compras previas afecta la percepción actual
- **Hábito:** Rutinas de compra que simplifican el proceso de decisión

Para capturar esta persistencia en un modelo logit, se introduce una variable de **lealtad latente** $z_{nit}$ que representa la propensión no observable del individuo $n$ a elegir la alternativa $i$ en el período $t$, basada en su historia de elecciones previas.

**Modelamiento de la Persistencia:**

La utilidad del individuo $n$ por la alternativa $i$ en el período $t$ se especifica como:

\begin{equation}
u_{nit} = \alpha_i + \beta x_{it} + \gamma z_{nit} + \varepsilon_{nit}
(\#eq:utilpersist)
\end{equation}

donde:

- $\alpha_i$ es la constante alternativa-específica
- $x_{it}$ son las covariables observables (precio, promoción, etc.)
- $\beta$ es el vector de coeficientes asociados a las variables observables
- $z_{nit}$ es la **lealtad latente** (no observable)
- $\gamma$ mide el efecto de la persistencia en la elección
- $\varepsilon_{nit}$ es el término de error i.i.d. valor extremo tipo I

**Construcción de la Variable de Lealtad:**

La variable de lealtad $z_{nit}$ se construye como un promedio ponderado exponencialmente de las elecciones pasadas del individuo. Sea $y_{nit}$ una variable indicadora que toma valor 1 si el individuo $n$ eligió la alternativa $i$ en el período $t$ y 0 en caso contrario. Entonces:

\begin{equation}
z_{nit} = \lambda z_{nit-1} + (1 - \lambda) y_{nit-1}
(\#eq:loyalty)
\end{equation}

donde $0 \leq \lambda \leq 1$ es un **parámetro de decaimiento** que determina qué tan rápido se desvanece el efecto de las elecciones pasadas.
Con $\lambda = 0$ solo importa la elección inmediatamente anterior ($z_{nit} = y_{nit-1}$) y con **$\lambda = 1$:**, todas las elecciones pasadas tienen el mismo peso (memoria perfecta).

Expandiendo recursivamente la ecuación \@ref(eq:loyalty):

\begin{aligned}
z_{nit} &= \lambda z_{nit-1} + (1-\lambda) y_{nit-1}\\
&= \lambda[\lambda z_{nit-2} + (1-\lambda)y_{nit-2}] + (1-\lambda)y_{nit-1}\\
&= \lambda^2 z_{nit-2} + \lambda(1-\lambda)y_{nit-2} + (1-\lambda)y_{nit-1}\\
&= \lambda^2[\lambda z_{nit-3} + (1-\lambda)y_{nit-3}] + \lambda(1-\lambda)y_{nit-2} + (1-\lambda)y_{nit-1}\\
&= \lambda^3 z_{nit-3} + \lambda^2(1-\lambda)y_{nit-3} + \lambda(1-\lambda)y_{nit-2} + (1-\lambda)y_{nit-1}\\
&= \vdots\\
&= (1-\lambda)y_{nit-1} + \lambda(1-\lambda)y_{nit-2} + \lambda^2(1-\lambda)y_{nit-3} + \cdots + \lambda^{t-2}(1-\lambda)y_{ni1}\\
&= (1-\lambda)\sum_{s=1}^{t-1} \lambda^{t-1-s} y_{nis}
\end{aligned}

Esta expresión muestra que $z_{nit}$ es un promedio ponderado de todas las elecciones pasadas, donde las elecciones más recientes reciben mayor peso exponencialmente decreciente.

**Inicialización:**

Para el primer período observado, se requiere una condición inicial. Las opciones comunes son:

- $z_{ni1} = 0$ para todas las alternativas
- $z_{ni1} = 1/J$ donde $J$ es el número de alternativas (distribución uniforme)
- $z_{ni1}$ basado en participación de mercado agregada

**Estimación:**

El parámetro $\lambda$ puede ser:

1. **Fijado a priori:** Por ejemplo, $\lambda = 0$ para considerar solo la elección inmediata anterior
2. **Estimado como parte del modelo:** Se incluye $\lambda$ como parámetro adicional a estimar, buscando en una grilla de valores $(0, 0.1, 0.2, ..., 0.9)$ o mediante búsqueda numérica
3. **Específico por alternativa:** $\lambda_i$ diferente para cada alternativa, permitiendo que algunas marcas generen más lealtad que otras

**Interpretación de $\gamma$:**

El coeficiente $\gamma$ mide la magnitud del efecto de la persistencia:

- **$\gamma > 0$:** Existe persistencia positiva - los consumidores tienden a repetir elecciones previas
- **$\gamma = 0$:** No hay efecto de persistencia - las elecciones son independientes en el tiempo
- **$\gamma < 0$:** Búsqueda de variedad - los consumidores tienden a cambiar de alternativa

En la mayoría de contextos de marketing, se espera $\gamma > 0$, aunque en categorías donde la variedad es valorada (helados, restaurantes) podría observarse $\gamma < 0$.

**Ejemplo Numérico:**

Supóngase un mercado de yogur con 3 marcas (A, B, C) y un consumidor que en los últimos 5 períodos eligió: A, A, B, A, ? (período actual). Con $\lambda = 0.5$:

Para la marca A:
\begin{aligned}
z_{A,t} &= (1-0.5)[1 \cdot 0.5^0 + 0 \cdot 0.5^1 + 1 \cdot 0.5^2 + 1 \cdot 0.5^3]\\
&= 0.5[1 + 0 + 0.25 + 0.125] = 0.6875
\end{aligned}

Para la marca B: $z_{B,t} = 0.5[0 + 1 \cdot 0.5^1 + 0 + 0] = 0.25$

Para la marca C: $z_{C,t} = 0$

Si $\gamma = 2$, entonces la marca A recibe un incremento de utilidad de $2 \times 0.6875 = 1.375$ debido a la lealtad acumulada.

#### Precios de Referencia

Otro aspecto fundamental del comportamiento de compra con datos de panel es la formación de **precios de referencia** (reference prices). Los consumidores no evalúan los precios en términos absolutos, sino que los comparan con un precio de referencia interno formado a partir de precios observados en el pasado. Esta noción está bien fundamentada tanto en teoría económica (teoría de prospectos) como en evidencia empírica de marketing.

**Modelamiento de Precios de Referencia:**

La utilidad se especifica incorporando tanto el efecto del precio actual como de la desviación respecto al precio de referencia:

\begin{equation}
u_{nit} = \alpha_i + \beta_1 P_{nit} - \beta_2(P_{nit} - RP_{nit}) + \delta x_{nit} + \varepsilon_{nit}
(\#eq:utilrefprice)
\end{equation}

donde:

- $P_{nit}$ es el precio actual de la alternativa $i$ para el individuo $n$ en período $t$
- $RP_{nit}$ es el **precio de referencia** (no observable) de la alternativa $i$
- $\beta_1$ captura el efecto del precio absoluto
- $\beta_2$ captura el efecto de pérdida/ganancia respecto al precio de referencia
- $x_{nit}$ son otras covariables

**Interpretación de Coeficientes:**

- **Precio absoluto ($\beta_1$):** Se espera $\beta_1 < 0$ - mayor precio reduce utilidad
- **Desviación de precio de referencia ($\beta_2$):** Se espera $\beta_2 > 0$
  - Si $P_{nit} > RP_{nit}$ (precio mayor que referencia): efecto negativo adicional - "pérdida percibida"
  - Si $P_{nit} < RP_{nit}$ (precio menor que referencia): efecto positivo adicional - "ganancia percibida"

La especificación captura que los consumidores son **más sensibles a desviaciones del precio de referencia** que al nivel de precio absoluto, consistente con teoría de prospectos que postula mayor sensibilidad a pérdidas que a ganancias.

**Construcción del Precio de Referencia:**

Similar a la lealtad, el precio de referencia se construye como promedio ponderado exponencialmente de precios pasados:

\begin{equation}
RP_{nit} = \lambda RP_{nit-1} + (1-\lambda) P_{nit-1}
(\#eq:refprice)
\end{equation}

donde $\lambda$ es el parámetro de persistencia del precio de referencia.

**Especificación asimétrica:**

La teoría de prospectos sugiere que las pérdidas (precios mayores que referencia) pesan más que las ganancias (precios menores). Esto motiva especificaciones asimétricas:

\begin{equation}
u_{nit} = \alpha_i + \beta_1 P_{nit} - \beta_2^+ \max(P_{nit} - RP_{nit}, 0) - \beta_2^- \max(RP_{nit} - P_{nit}, 0) + \delta x_{nit} + \varepsilon_{nit}
(\#eq:utilasym)
\end{equation}

donde $\beta_2^+$ captura el efecto de precios superiores a la referencia (pérdida) y $\beta_2^-$ el efecto de precios inferiores (ganancia). Típicamente se encuentra $\beta_2^+ > \beta_2^-$, confirmando aversión a pérdidas.

**Ejemplo Numérico:**

Considérese un producto con la siguiente historia de precios: \$10, \$12, \$9, \$11, ?.
Con $\lambda = 0.6$:

\begin{aligned}
RP_t &= 0.6 \cdot RP_{t-1} + 0.4 \cdot P_{t-1}\\
RP_2 &= 0.4 \cdot 10 = 4.0\\
RP_3 &= 0.6 \cdot 4.0 + 0.4 \cdot 12 = 7.2\\
RP_4 &= 0.6 \cdot 7.2 + 0.4 \cdot 9 = 7.92\\
RP_5 &= 0.6 \cdot 7.92 + 0.4 \cdot 11 = 9.152
\end{aligned}

Si en el período 5 el precio es \$13 y se tiene $\beta_1 = -0.5$ y $\beta_2 = 0.8$:

$$u_5 = \alpha + (-0.5)(13) - 0.8(13 - 9.152) + ... = \alpha - 6.5 - 3.08 + ... $$

El precio \$13 genera:

- Efecto directo: $-0.5 \times 13 = -6.5$
- Efecto de pérdida percibida: $-0.8 \times 3.848 = -3.08$
- **Efecto total:** $-9.58$ (más negativo que solo el efecto directo)

#### Combinación de Persistencia y Precios de Referencia

En la práctica, ambos fenómenos suelen coexistir. Un modelo integrado especificaría:

\begin{equation}
u_{nit} = \alpha_i + \beta_1 P_{nit} - \beta_2(P_{nit} - RP_{nit}) + \gamma z_{nit} + \delta x_{nit} + \varepsilon_{nit}
(\#eq:utilfull)
\end{equation}

donde tanto $z_{nit}$ como $RP_{nit}$ se construyen recursivamente usando los datos históricos del individuo:

\begin{aligned}
z_{nit} &= \lambda_z z_{nit-1} + (1-\lambda_z) y_{nit-1}\\
RP_{nit} &= \lambda_p RP_{nit-1} + (1-\lambda_p) P_{nit-1}
\end{aligned}

### Apéndice{-}

**Derivación probabilidad de elección modelo logit**

Por definición 

$$P_{nit} = Pr(\varepsilon_{njt}<v_{nit} - v_{njt} + \varepsilon_{nit}), \forall j \neq i$$
Fijando el valor de $\varepsilon_{nit}$, la probabilidad anterior no es más que una multiplicación de funciones de distribución de variables aleatorias valor extremo. Por lo tanto, se puede condicionar en $\varepsilon_{nit}$ y luego integrar respecto a los valores que puede tomar. Para simplificar la notación, sea $s=\varepsilon_{nit}$.


\begin{aligned}
P_{nit} &= \int_{-\infty}^{\infty} \left(\prod_{j\neq i}    e^{-e^{-(s + v_{ni} - v_{nj})}}\right) e^{-s} e^{-e^{-s}}ds\\
&= \int_{-\infty}^{\infty} \left(\prod_{j}   e^{-e^{-(s + v_{ni} - v_{nj})}}\right) e^{-s}ds\\
&= \int_{-\infty}^{\infty} exp\left(\sum_{j}  e^{-(v_{ni} - v_{nj})}\right) e^{-s}ds
\end{aligned}

Para resolver la integral, se puede recurrir a un cambio de variables $t = e^{−s}$ y $dt = e^{−s}ds$. Con esto:

\begin{aligned}
P_{nit} &= \int_{\infty}^{0} -e^{t\sum_{j}  e^{-(v_{ni} - v_{nj})}} dt\\
&= \frac{ e^{-(v_{ni} - v_{nj})}}{\sum_{j}  e^{-(v_{ni} - v_{nj})}}\mid^{\infty}_{0}\\
&= \frac{e^{v_{ni}}}{\sum_j e^{v_{nj}}}
\end{aligned}


## Probit

### Definición

Al introducir modelos de elección discreta, se postuló que los tomadores de decisiones disponían de una función de utilidad subyacente que se descomponía en una componente determinística y otra aleatoria. Más aún, se discutió que el modelo que describe la probabilidad de elegir cada una de las alternativas quedaba directamente determinado por la distribución que se asumiera para la componente aleatoria de la utilidad. Aunque una especificación de errores normales centrados en cero tiene una larga tradición en modelos econométricos, por simplicidad se optó por iniciar la discusión con modelos *logit* derivados de asumir que la componente aleatoria de la utilidad se distribuía valor extremo tipo I. En este capítulo se volverá al caso de componentes aleatorias normales que dan origen al modelo probit. Formalmente, un modelo *probit* resulta de los siguientes supuestos de comportamiento:

\begin{equation} 
  \begin{array}{cc}
  u_{ni} = v_{ni} + \varepsilon_{ni}, &\varepsilon_n \sim N(0,\Sigma)
  \end{array}  
  (\#eq:compo)
\end{equation} 

La normalidad de los errores provee bastante flexibilidad para acomodar una amplia variedad de estructuras de las preferencias. Como se verá en la discusión que sigue, un modelo con errores normales permite acomodar factores sistemáticos no observables en la utilidad. Una de las pocas limitaciones de un modelo probit viene de la normalidad de dichos factores. Por ejemplo, si se quiere incorporar el efecto que tiene el precio en la utilidad como una componente aleatoria, entonces las colas de la distribución normal implicarán una probabilidad positiva de que algunos clientes aumenten la utilidad de una alternativa si aumenta el precio de esta. Formalmente, el supuesto de la normalidad de la componente aleatoria de la utilidad implica que su función de densidad viene dada por:

\begin{equation} 
  \phi(\varepsilon_n) = \frac{1}{(2\pi)^{I/2}|\Sigma|^{1/2}}e^{-\frac{1}{2} \varepsilon'_n \Sigma^{-1}\varepsilon_n} 
  (\#eq:density)
\end{equation} 

Esta expresión no es más que la versión multivariada de la bien conocida densidad de la distribución $N(0, \sigma^2)$. La matriz $\Sigma$ corresponde a la matriz varianza-covarianza de los errores. Por tratarse de una distribución normal, la matriz $\Sigma$ es simétrica y de dimensión $I \times I$, donde $I$ es el número de alternativas disponibles para el tomador de decisión. Por ejemplo, si hay tres alternativas disponibles, la matriz $\Sigma$ tomaría la siguiente forma:

\begin{equation} 
  \Sigma = \begin{bmatrix} \sigma_{11} & \sigma_{12} & \sigma_{13}\\
 \cdot & \sigma_{22} & \sigma_{23}\\
 \cdot & \cdot & \sigma_{33}
\end{bmatrix} 
  (\#eq:matrix)
\end{equation} 

Los coeficientes en la diagonal dan cuenta de la variabilidad de la componente aleatoria de la utilidad. Así, por ejemplo, si $\sigma_{ii}$ tiene un valor alto indica que hay una fracción importante de la utilidad de la alternativa $i$ que no es capturada por el modelo de la componente sistemática. Los coeficientes fuera de la diagonal dan cuenta de la correlación de las componentes no observables de cada una de las alternativas. De este modo, si $\sigma_{ij}$ tiene un valor positivo alto indica que existe un elemento no observable importante que afecta simultáneamente las alternativas $i$ y $j$.

Como se vio en el desarrollo del modelo *logit*, una componente fundamental para estimar un modelo de elección discreta es la derivación de una expresión para la probabilidad de que cada agente elija cada alternativa en cada ocasión. Para el modelo probit, la probabilidad de que el individuo $n$ elija la alternativa $i$ viene dada por:

\begin{equation} 
  \begin{aligned}
    P_{ni} &= Pr (v_{ni} + \varepsilon_{ni} > v_{nj} + \varepsilon_{nj}), \forall j \neq i \\
    &= \int \mathbb{1}_{[v_{ni} + \varepsilon_{ni} > v_{nj} + \varepsilon_{nj}]}\phi(\varepsilon_n)d\varepsilon_n, \forall j \neq i
  \end{aligned}  
  (\#eq:modprobit)
\end{equation} 

Intuitivamente, simplemente se calcula el volumen bajo la densidad $\phi(\varepsilon_n)$ en la región en que los errores son tales que la alternativa $i$ es aquella que reporta mayor utilidad al individuo $n$. A diferencia del modelo logit, la integral sobre la densidad $\phi(\cdot)$ no tiene primitiva analítica y, por tanto, no se dispone de una fórmula cerrada para $P_{ni}$. Una aproximación estándar es usar simulación Monte Carlo. Para cada individuo $n$ y alternativa $i$, se genera un conjunto de $R$ vectores de errores $\{\varepsilon_n^{(r)}\}_{r=1}^R$ desde la distribución normal multivariada especificada. La probabilidad de elección se aproxima mediante:

\begin{equation}
\hat{P}_{ni}(\theta) = \frac{1}{R}\sum_{r=1}^R \mathbb{1}\left[v_{ni}(x_{ni},\theta) + \varepsilon_{ni}^{(r)} > v_{nj}(x_{nj},\theta) + \varepsilon_{nj}^{(r)}, \forall j \neq i\right]
(\#eq:simprob)
\end{equation}

donde $\mathbb{1}\{\cdot\}$ es la función indicadora. La log-verosimilitud simulada se construye como $\sum_n\sum_i y_{ni}\log\hat{P}_{ni}(\theta)$ y se maximiza numéricamente con respecto a $\theta$. A medida que $R \to \infty$, el estimador de máxima verosimilitud simulada converge al estimador de máxima verosimilitud verdadero.

### Patrones de substitución

Una de las grandes ventajas de un modelo *probit* es su flexibilidad para capturar una amplia variedad de patrones de comportamiento. En efecto, un modelo *probit* no impone restricciones en los patrones de sustitución más allá de la simetría propia de la distribución normal, lo que posibilita al analista explorar el esquema que mejor se ajusta a los datos. En este sentido, es útil compararlo con el modelo *logit* que, aunque provee una fórmula analítica cerrada para la probabilidad de cada elección, impone la propiedad de sustitución proporcional (o de independencia de alternativas irrelevantes). El modelo probit no tiene esta propiedad y, por tanto, el aumento de la probabilidad de elección de una alternativa puede tener impactos diferentes en las probabilidades de elección de las alternativas remanentes. Esto permitiría, por ejemplo, identificar pares de alternativas que son mejores sustitutos (complementos) más allá de las comunalidades que podrían existir en las componentes determinísticas de su utilidad. 

A continuación se discutirá cómo el modelo probit puede ser usado para representar algunas situaciones de elección discreta.

#### Variación aleatoria en preferencias

Una de las componentes más importantes en el diseño de un plan comercial exitoso es la identificación de cómo las preferencias de los potenciales clientes se distribuyen en la población. Identificando estas variaciones, se pueden encontrar las propuestas de valor que resulten más atractivas para cada grupo de clientes. En un modelo probit, se puede asumir que los parámetros que definen la componente determinística son heterogéneos en la población sin perder los supuestos básicos que definen el modelo. Por simplicidad, supóngase que la componente determinística de la utilidad es lineal:

\begin{equation} 
  \begin{array}{cc}
    u_{ni} = \beta'_{n} x_{ni} + \varepsilon_{ni}, & \varepsilon_n \sim N(0,\Sigma)
  \end{array}  
  (\#eq:cdeterminista)
\end{equation} 

Nótese que, a diferencia de los modelos anteriores, ahora se ha asumido que cada tomador de decisión $n$ tiene su propio conjunto de parámetros $\beta_n$ que describen sus preferencias por las alternativas disponibles. Para completar el modelo se necesita especificar una distribución de $\beta_n$ en la población. Para mantener la estructura del modelo se asumirá normalidad: $\beta_n \sim N(b, \sigma^2_\beta)$. Dado que la suma de dos variables aleatorias normales se distribuye normal, es fácil ver que el modelo es equivalente a:

\begin{equation} 
  \begin{array}{cc}
    u_{ni} = b'_{n} x_{ni} + \eta_{ni}, & \eta_n \sim (0,\hat{\Sigma})
  \end{array}  
  (\#eq:cdeterministaequi)
\end{equation} 

Las componentes de la matriz de varianza-covarianza resultante $\hat{\Sigma}$ pueden trazarse directamente a las componentes de la matriz $\Sigma$ original como lo indica el siguiente ejemplo:

**Ejemplo:** Considérese un modelo de elección con dos alternativas y un modelo lineal con una única variable para describir la componente sistemática de la utilidad. En este caso, las utilidades por cada alternativa vienen dadas por:

\begin{aligned}
u_{n1} &= \beta_n x_{n1} + \varepsilon_{n1}\\
u_{n2} &= \beta_n x_{n2} + \varepsilon_{n2}
\end{aligned}

donde $\varepsilon_{n1}$ y $\varepsilon_{n2}$ son términos independientes e idénticamente distribuidos con varianza $\sigma_\varepsilon$. Si se asume que el parámetro $\beta_n$ se distribuye normal con media $b$ y varianza $\sigma_\beta$, entonces se puede reescribir las utilidades como:

\begin{aligned}
u_{n1} &= b x_{n1} + \eta_{n1}\\
u_{n2} &= b x_{n2} + \eta_{n2}
\end{aligned}

donde $\eta_{n1}$ y $\eta_{n2}$ están normalmente distribuidas. Cada una tiene esperanza cero: $\mathbb{E}(\eta_{ni}) =\mathbb{E}(\beta_nx_{ni} + \varepsilon_{ni}) = 0$, varianza igual a $\mathbb{V}ar(\eta_{ni}) = \mathbb{V}ar(\beta_n x_{ni} + \varepsilon_{ni}) = x^2_{ni}\sigma_\beta + \sigma_\varepsilon$ y covarianzas $\mathbb{C}ov(\eta_{n1}, \eta_{n2}) = x_{n1}x_{n2}\sigma_\beta$. Así, la matriz de covarianza viene dada por:

\begin{aligned}
\Sigma &= \begin{bmatrix}x^2_{n1}\sigma_\beta + \sigma_\varepsilon & x_{n1}x_{n2}\sigma_\beta\\
x_{n1}x_{n2}\sigma_\beta & x^2_{n2}\sigma_\beta + \sigma_\varepsilon \end{bmatrix} \\
&= \sigma_\beta \begin{bmatrix}x^2_{n1} & x_{n1}x_{n2}\\
x_{n1}x_{n2} & x^2_{n2} \end{bmatrix} + \sigma_{\varepsilon} \begin{bmatrix}1 & 0\\
0 & 1\end{bmatrix}
\end{aligned}

El siguiente paso es estimar. Recordando que el comportamiento no es afectado por transformaciones multiplicativas de la utilidad, es necesario escalar esta matriz. Lo recomendable es fijar $\sigma_\varepsilon = 1$, obteniendo así:

$$Σ= \sigma_\beta \begin{bmatrix}x^2_{n1} & x_{n1}x_{n2}\\
x_{n1}x_{n2} & x^2_{n2} \end{bmatrix} + \begin{bmatrix}1 & 0\\
0 & 1\end{bmatrix}$$


#### Dependencia del tiempo

Se ha discutido que bajo un modelo *probit* se pueden estudiar relaciones no observables entre las alternativas de elección. En las bases disponibles para la función comercial, las observaciones suelen estar indexadas temporalmente generando estructuras de panel que permiten estudiar aspectos interesantes de los agentes. A continuación se discute cómo usar un modelo *probit* para explorar no solo la relación entre las utilidades de alternativas, sino que también, el comportamiento de las utilidades de las alternativas en el tiempo. 

Al igual que en la sección anterior, se busca encontrar patrones temporales en las componentes no observables de la utilidad, ya que las variaciones en la componente observable pueden ser fácilmente estudiadas incluyendo variables observables que describan la evolución temporal del sistema. Por ejemplo, si se cree que la utilidad de una de las alternativas es creciente en el tiempo, basta incluir el tiempo $t$ entre las variables independientes en la descripción de la utilidad de la alternativa. En general, se debería esperar que las utilidades estén correlacionadas tanto en el tiempo como entre las alternativas, ya que los factores que no son observados por el analista suelen ser persistentes en el tiempo. Eventualmente un modelo *probit* también podría ayudar a identificar shocks en que hay variaciones instantáneas (o de unos pocos períodos) en las utilidades de varias de las alternativas. 

Supóngase que se observa un panel de $N$ clientes que deciden respecto de $I$ alternativas en $T$ períodos y que la utilidad del producto que el agente $n$ deriva sobre la alternativa $i$ en el período $t$ viene dada por:

\begin{equation} 
  \begin{array}{cc}
    u_{ni} = v_{nit} + \varepsilon_{nit},  & [\varepsilon_{n11},...,\varepsilon_{nI1},\varepsilon_{n12}, ..., \varepsilon_{nI2},...,\varepsilon_{n1T},...,\varepsilon_{nIT}] \sim N(0,Σ)
  \end{array}  
  (\#eq:cdeterministaequi)
\end{equation} 

La matriz de covarianza \Sigma tiene dimensión $IT \times IT$ (como se verá, no todas las componentes son identificables y se deberá imponer ciertas restricciones). Para paneles típicos, $T$ es grande y genera matrices de varianza-covarianza muy grandes. Por ejemplo, si se tienen datos semanales de compras de 5 marcas por un período de 2 años, se enfrentará una matriz de varianza (sin normalizar) con 5 × 104 = 520 filas y 520 columnas, lo que generaría no solo un modelo difícil de estimar numéricamente sino que, también, difícil de interpretar. Así, para usar un modelo *probit* con dependencia en el tiempo, típicamente se agregará estructura al modelo. Por ejemplo, se puede restringir el análisis a grupos de períodos que podría ser el caso de las decisiones antes y después de una intervención en el sistema (e.g., antes y después del lanzamiento de una campaña publicitaria).

**Ejemplo:** Supóngase un caso de elección binaria. El error está compuesto por una componente sistemática específica del tomador de decisión y otra que es variable en el tiempo.


\begin{equation} 
  \varepsilon_{nt} = \eta_n + \mu_{nt}
  (\#eq:errorbinario)
\end{equation} 

Si se asume que $η_n$ está distribuida $N(0, σ)$ y $\mu_{nt}$ en $N(0, 1)$, entonces la varianza y covarianza son

  \begin{equation} 
  \mathbb{V}ar(\varepsilon_{nt}) =  \mathbb{V}ar(\eta_{n}+ \mu_{nt}) = \sigma + 1
    (\#eq:varbinaria)
  \end{equation} 
  
  \begin{equation} 
  \mathbb{C}ov(\varepsilon_{nt},\varepsilon_{ns}) =  \mathbb{E}((\eta_{n}+ \mu_{nt}) (\eta_{n}+ \mu_{ns})) = \sigma
    (\#eq:covbinaria)
  \end{equation} 

La matriz $\Sigma$, por lo tanto, es

\begin{equation} 
  Σ = \begin{bmatrix}\sigma +1 & \sigma & ... & \sigma\\
\sigma & \sigma+1 & ... & \sigma\\
\vdots & \vdots & \ddots & \vdots\\
\sigma & \sigma & \dots & \sigma +1
\end{bmatrix}
    (\#eq:matrizsum)
  \end{equation} 

### Identificación

Para estimar un modelo *probit*, junto con los parámetros de la componente sistemática de la utilidad, se necesita estimar los coeficientes de la matriz $\Sigma$. Por tratarse de una distribución normal, la matriz $\Sigma$ es simétrica, ya que sus varianzas generadas son conmutativas. Por tanto, se deben estimar $\frac{I(I+1)}{2}$ de sus componentes. Sin embargo, dicho problema no es identificable y se necesita imponer restricciones adicionales eliminando uan componente. La intuición detrás de esta falta de identificación resulta de asumir que las utilidades subyacentes que maximizan los individuos son monótonas y homotéticas. En otras palabras, se puede agregar un valor constante a las utilidades de cada una de las alternativas o escalarlas en cualquier proporción y la identidad de la alternativa de mayor utilidad no cambia. En general, si se tienen $I$ alternativas, solo se pueden identificar $\frac{I(I+1)}{2} - 1$ parámetros. A continuación se discutirán dos enfoques para generar restricciones que hagan el problema identificable.

#### Normalización de las funciones de utilidad

Motivados en las propiedades de la función de utilidad, este enfoque consiste en imponer directamente restricciones de escala y locación. Este enfoque es completamente general y permite además garantizar identificación con un procedimiento estándar que puede incluso automatizarse. Formalmente el proceso consiste en imponer dos restricciones:

1. FIJAR LOCACIÓN: Como el valor absoluto de las utilidades es irrelevante, se puede fijar arbitrariamente el punto de referencia sobre el cual se interpretarán las utilidades. De esta forma, se tomará la utilidad de una de las alternativas como referencia y se redefinirán las utilidades como las diferencias con respecto a la alternativa de referencia.

2. FIJAR ESCALA: Como la escala de las utilidades es irrelevante, se puede fijarla asignando un valor arbitrario a cualquiera de las componentes de la matriz de varianza covarianza. Típicamente se impondrá que la primera componente de la diagonal tome el valor 1.
 
**Ejemplo:** Considérese la normalización de una matriz $\Sigma$ resultante de un problema de elección discreto de 4 alternativas. 

\begin{equation} 
  \Sigma = \begin{bmatrix} \sigma_{11} & \sigma_{12} & \sigma_{13} & \sigma_{13}\\
 \cdot & \sigma_{22} & \sigma_{23} & \sigma_{24}\\
 \cdot & \cdot & \sigma_{33} & \sigma_{34}\\
 \cdot & \cdot & \cdot & \sigma_{44}
\end{bmatrix} 
  (\#eq:matrixcuatro)
\end{equation} 


El primer paso en la normalización es considerar diferencias de utilidades con respecto a una alternativa de referencia, la que por simplicidad se escogerá como la primera de la lista. Al fijar esta utilidad y tomar las diferencias, se ha reducido la dimensión del vector de errores, resultando en una matriz de varianza-covarianza $\hat{Σ} = \{\hat{σ}_{ij}\}^3_{i,j=1}$ cuyas componentes vienen dadas por:

\begin{aligned}
\hat{\sigma}_{22} &= \sigma_{22} + \sigma_{11} - 2\sigma_{12}\\
\hat{\sigma}_{33} &= \sigma_{33} + \sigma_{11} - 2\sigma_{13}\\
\hat{\sigma}_{44} &= \sigma_{44} + \sigma_{11} - 2\sigma_{14}\\
\hat{\sigma}_{23} &= \sigma_{23} + \sigma_{11} - \sigma_{12} - \sigma_{13}\\
\hat{\sigma}_{24} &= \sigma_{24} + \sigma_{11} - \sigma_{12} - \sigma_{14}\\
\hat{\sigma}_{34} &= \sigma_{34} + \sigma_{11} - \sigma_{13} - \sigma_{14}
\end{aligned}

El segundo paso en la normalización es fijar en 1 (o cualquier otro real positivo) una de las componentes de la diagonal de la matriz de varianza covarianza para precisar la escala de la función de utilidad. Por simplicidad se escoge la primera componente de la diagonal. Para hacerla 1 basta con dividir toda la matriz por dicha componente, resultando en una matriz de varianza-covarianza  $\hat{Σ} = \{\hat{σ}_{ij}\}^3_{i,j=1}$ cuyas componentes vienen dadas por:

\begin{aligned}
\hat{\sigma}_{33} &= \frac{\sigma_{33} + \sigma_{11} - 2\sigma_{13}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}\\
\hat{\sigma}_{44} &= \frac{\sigma_{44} + \sigma_{11} - 2\sigma_{14}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}\\
\hat{\sigma}_{23} &= \frac{\sigma_{23} + \sigma_{11} - \sigma_{12} - \sigma_{13}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}\\
\hat{\sigma}_{24} &= \frac{\sigma_{24} + \sigma_{11} - \sigma_{12} - \sigma_{14}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}\\
\hat{\sigma}_{34} &= \frac{\sigma_{34} + \sigma_{11} - \sigma_{13} - \sigma_{14}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}
\end{aligned}

La matriz resultante $\hat{Σ}$ es identificable. En ella es importante trazar sus componentes originales de la matriz sigma porque ayudan a darle interpretación a los resultados obtenidos en la estimación.

#### Incorporación de restricciones estructurales

Aunque completamente general, la normalización descrita en la sección anterior, muchas veces puede ser algo inconveniente en cuanto los parámetros estimados no tienen interpretación
directa. Un enfoque que permite interpretar directamente los parámetros se obtiene al imponer estructura sobre la matriz de varianza-covarianza a partir de supuestos de comportamiento. Por ejemplo, se puede imponer que las componentes aleatorias de algunos pares de alternativas no están correlacionadas o que algún grupo de alternativas tiene la misma variabilidad de la componente no observable. El cuadro 4.1 ejemplifica algunas de las estructuras de varianza-covarianza comúnmente usadas en la literatura.

Otros modelos usados en la literatura y que están implementados en aplicaciones comerciales incluyen estructuras de bandas, Huynh-Feldt, autoregresivo heterogéneo y simetría compuesta. Como en otros aspectos de la modelación, la elección de la estructura a elegir para la matriz de
varianza-covarianza dependerá de las hipótesis de comportamiento que se tengan a la mano y la dificultad numérica de estimar el modelo resultante. 


## Nested Logit

### Introducción

Como se ha discutido previamente, una de las limitaciones fundamentales del modelo logit estándar es la propiedad de independencia de alternativas irrelevantes (IIA), que implica patrones de sustitución proporcionales entre todas las alternativas. Esta restricción puede resultar poco realista en muchas situaciones prácticas de marketing donde algunas alternativas son sustitutos más cercanos entre sí que con otras. El modelo **Nested Logit** (o Logit Anidado) surge como una extensión del modelo logit estándar que permite relajar parcialmente la restricción de IIA al permitir que las alternativas se agrupen en conjuntos (o "nidos") donde la correlación entre alternativas dentro del mismo nido puede diferir de la correlación entre alternativas de nidos diferentes.

La idea fundamental del nested logit es reconocer que en muchos problemas de elección existe una estructura jerárquica natural. Los tomadores de decisión primero eligen entre categorías generales de alternativas (los nidos) y luego, dentro de la categoría seleccionada, eligen una alternativa específica. Esta estructura refleja de manera más realista muchos procesos de decisión en marketing.

Por ejemplo, se tiene el problema de elección de medio de transporte en una ciudad que ofrece las siguientes alternativas: auto particular, auto compartido (carpool), bus y tren. Intuitivamente, se esperaría que auto particular y auto compartido sean sustitutos más cercanos entre sí (ambos involucran viajar en auto) que cualquiera de ellos con respecto al bus o tren. Del mismo modo, bus y tren (ambos transporte público) serían sustitutos más cercanos entre sí. Un modelo logit estándar impondría que un incremento en el costo del bus afecta igualmente la probabilidad de elegir auto particular, auto compartido y tren, lo cual parece poco razonable. El nested logit permite capturar que el incremento en el costo del bus afectará más la probabilidad de elegir tren (mismo nido de transporte público) que la de elegir auto particular.

### Estructura del Modelo

#### Partición en Nidos

El modelo nested logit requiere una partición del conjunto de $J$ alternativas en $K$ subconjuntos exhaustivos y mutuamente excluyentes llamados **nidos**. Sea $B_k$ el conjunto de alternativas en el nido $k$, donde $k = 1, 2, ..., K$. La partición debe satisfacer:

1. $\bigcup_{k=1}^K B_k = \{1, 2, ..., J\}$ (exhaustividad)
2. $B_k \cap B_m = \emptyset$ para $k \neq m$ (exclusividad mutua)

Es importante destacar que la definición de los nidos debe basarse en consideraciones teóricas sobre qué alternativas son sustitutos más cercanos, no en criterios puramente estadísticos. La teoría económica, el conocimiento del mercado y la intuición sobre el comportamiento del consumidor deben guiar esta partición.

#### Especificación de la Utilidad

En el modelo nested logit, la utilidad que el individuo $n$ deriva de la alternativa $i$ en el nido $B_k$ se especifica como:

\begin{equation}
u_{ni} = v_{ni} + \varepsilon_{ni}
(\#eq:nestedutil)
\end{equation}

donde $v_{ni}$ es la componente sistemática (observable) de la utilidad y $\varepsilon_{ni}$ es la componente aleatoria. Si bien es común en la literatura descomponer el error $\varepsilon_{ni}$ en dos componentes —una idiosincrática a la alternativa y otra común a todas las alternativas del nido— esta descomposición no es necesaria para derivar el modelo. Como muestra Train (2009), la estructura de correlación del nested logit puede motivarse directamente asumiendo que el vector completo de errores sigue una distribución de valor extremo generalizada (GEV), sin necesidad de imponer una estructura aditiva específica en los términos de error. Esta formulación más general permite capturar la correlación intra-nido a través de los parámetros de la distribución GEV.

La característica distintiva del nested logit es la estructura de correlación de los errores. A diferencia del logit estándar donde todos los $\varepsilon_{ni}$ son independientes, en el nested logit se permite que los errores de alternativas dentro del mismo nido estén correlacionados, mientras que los errores entre alternativas de diferentes nidos permanecen independientes.

Formalmente, se asume que el vector de errores $\varepsilon_n = (\varepsilon_{n1}, ..., \varepsilon_{nJ})$ tiene una distribución de valor extremo con función de distribución acumulada:

\begin{equation}
F(\varepsilon_{n1}, ..., \varepsilon_{nJ}) = \exp\left[-\sum_{k=1}^K \left(\sum_{i \in B_k} e^{-\varepsilon_{ni}/\lambda_k}\right)^{\lambda_k}\right]
(\#eq:gevdist)
\end{equation}

donde $\lambda_k$ es un parámetro que gobierna el grado de correlación entre alternativas en el nido $k$, con $0 < \lambda_k \leq 1$:

- **$\lambda_k = 1$:** Las alternativas en el nido $k$ no están correlacionadas (caso del logit estándar)
- **$\lambda_k < 1$:** Las alternativas en el nido $k$ están positivamente correlacionadas; cuanto menor sea $\lambda_k$, mayor es la correlación
- **$\lambda_k \to 0$:** Correlación perfecta entre alternativas del nido $k$

La correlación entre dos alternativas $i$ y $j$ en el mismo nido $k$ viene dada por:

\begin{equation}
\text{Corr}(\varepsilon_{ni}, \varepsilon_{nj}) = 1 - \lambda_k^2, \quad \text{para } i, j \in B_k
(\#eq:corrwithin)
\end{equation}

Mientras que alternativas en nidos diferentes tienen correlación cero:

\begin{equation}
\text{Corr}(\varepsilon_{ni}, \varepsilon_{nj}) = 0, \quad \text{para } i \in B_k, j \in B_m, k \neq m
(\#eq:corrbetween)
\end{equation}

### Probabilidades de Elección

Una de las ventajas computacionales del modelo nested logit es que, a pesar de permitir correlación entre errores, aún se pueden derivar fórmulas cerradas para las probabilidades de elección.

#### Estructura Jerárquica de Decisión

El nested logit puede interpretarse como un proceso de decisión secuencial en dos etapas:

1. **Etapa 1 (elección de nido):** El individuo elige qué nido $B_k$ le proporciona mayor utilidad esperada
2. **Etapa 2 (elección dentro del nido):** Dado el nido seleccionado, el individuo elige la alternativa específica dentro de ese nido

#### Probabilidad Condicional (Etapa 2)

La probabilidad de que el individuo $n$ elija la alternativa $i$ dado que ha elegido el nido $B_k$ viene dada por:

\begin{equation}
P_{ni|B_k} = \frac{\exp(v_{ni}/\lambda_k)}{\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)}
(\#eq:condprob)
\end{equation}

Esta expresión tiene la forma de un modelo logit estándar, escalando las utilidades con $\lambda_k$.

#### Valor Inclusivo (Inclusive Value)

Un concepto fundamental en el nested logit es el **valor inclusivo** (o **log-suma**) del nido $B_k$, definido como:

\begin{equation}
IV_k = \ln\left(\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right)
(\#eq:inclusivevalue)
\end{equation}

El valor inclusivo $IV_k$ representa la utilidad esperada (antes de conocer los shocks aleatorios $\varepsilon_{nj}$) que el individuo obtiene del nido $k$. Es una medida del atractivo agregado de todas las alternativas en el nido, ajustada por el grado de correlación entre ellas.

**Interpretación Económica:** El valor inclusivo captura el "valor de la opción" que proporciona tener múltiples alternativas similares disponibles. Un valor inclusivo alto indica que el nido contiene alternativas atractivas para el individuo.

#### Probabilidad Marginal de Elegir el Nido (Etapa 1)

La probabilidad de elegir el nido $B_k$ viene dada por:

\begin{equation}
P_{nB_k} = \frac{\exp(\lambda_k \cdot IV_k)}{\sum_{m=1}^K \exp(\lambda_m \cdot IV_m)}
(\#eq:nestprob)
\end{equation}

Esta probabilidad tiene también forma logit, donde la "utilidad" del nido es el valor inclusivo escalado por $\lambda_k$.

#### Probabilidad No Condicional (Probabilidad Total)

Finalmente, la probabilidad de que el individuo $n$ elija la alternativa $i$ en el nido $B_k$ se obtiene multiplicando las probabilidades de las dos etapas:

\begin{equation}
P_{ni} = P_{ni|B_k} \cdot P_{nB_k} = \frac{\exp(v_{ni}/\lambda_k)}{\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)} \cdot \frac{\exp(\lambda_k \cdot IV_k)}{\sum_{m=1}^K \exp(\lambda_m \cdot IV_m)}
(\#eq:totalprob)
\end{equation}

Para reescribir esta expresión de forma más compacta, se procede de la siguiente manera. Recordando que $IV_k = \ln\left[\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right]$, se tiene que:

$$\exp(\lambda_k \cdot IV_k) = \exp\left(\lambda_k \cdot \ln\left[\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right]\right) = \left[\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right]^{\lambda_k}$$

Sustituyendo esta expresión en el numerador de la probabilidad total:

\begin{aligned}
P_{ni} &= \frac{\exp(v_{ni}/\lambda_k)}{\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)} \cdot \frac{\left[\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right]^{\lambda_k}}{\sum_{m=1}^K \left[\sum_{j \in B_m} \exp(v_{nj}/\lambda_m)\right]^{\lambda_m}}\\
&= \frac{\exp(v_{ni}/\lambda_k) \cdot \left[\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right]^{\lambda_k}}{\left[\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right] \cdot \sum_{m=1}^K \left[\sum_{j \in B_m} \exp(v_{nj}/\lambda_m)\right]^{\lambda_m}}\\
&= \frac{\exp(v_{ni}/\lambda_k) \cdot \left[\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right]^{\lambda_k - 1}}{\sum_{m=1}^K \left[\sum_{j \in B_m} \exp(v_{nj}/\lambda_m)\right]^{\lambda_m}}
\end{aligned}

Esto conduce a la forma compacta:

\begin{equation}
P_{ni} = \frac{\exp(v_{ni}/\lambda_k) \cdot [\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)]^{\lambda_k - 1}}{\sum_{m=1}^K [\sum_{j \in B_m} \exp(v_{nj}/\lambda_m)]^{\lambda_m}}
(\#eq:totalprobcompact)
\end{equation}

### Propiedades y Patrones de Sustitución

#### Relajación Parcial de IIA

Una propiedad importante del nested logit es que la restricción de IIA se mantiene **dentro de cada nido** pero no **entre nidos**. Específicamente:

**Dentro del mismo nido:** Para dos alternativas $i$ y $j$ en el mismo nido $B_k$:

\begin{equation}
\frac{P_{ni}}{P_{nj}} = \frac{\exp(v_{ni}/\lambda_k)}{\exp(v_{nj}/\lambda_k)} = \exp\left(\frac{v_{ni} - v_{nj}}{\lambda_k}\right)
(\#eq:ratiowithin)
\end{equation}

Este ratio es independiente de otras alternativas, manteniendo IIA dentro del nido.

**Entre diferentes nidos:** Para alternativas en nidos diferentes, el ratio de probabilidades sí depende de las características de otras alternativas a través de los valores inclusivos, permitiendo patrones de sustitución más realistas.

#### Elasticidades de Sustitución

Las elasticidades propias y cruzadas en un modelo nested logit revelan cómo los patrones de sustitución difieren entre alternativas del mismo nido versus alternativas de nidos diferentes.

**Elasticidad propia:** La elasticidad de $P_{ni}$ respecto a un atributo $x_{ni}$ de la misma alternativa es:

\begin{equation}
\eta_{ii} = \frac{\partial P_{ni}}{\partial x_{ni}} \cdot \frac{x_{ni}}{P_{ni}} = \frac{\beta}{\lambda_k} x_{ni} \left(1 - P_{ni} - \lambda_k P_{ni|B_k}(1 - P_{ni|B_k})\right)
(\#eq:elastown)
\end{equation}

donde $\beta$ es el coeficiente asociado a $x_{ni}$ en $v_{ni}$.

**Elasticidad cruzada dentro del nido:** Para alternativas $i$ y $j$ en el mismo nido $B_k$:

\begin{equation}
\eta_{ij} = \frac{\partial P_{ni}}{\partial x_{nj}} \cdot \frac{x_{nj}}{P_{ni}} = \frac{\beta}{\lambda_k} x_{nj} P_{nj|B_k}(1 + \lambda_k(1 - P_{nj|B_k}))
(\#eq:elastwithin)
\end{equation}

**Elasticidad cruzada entre nidos:** Para alternativas $i \in B_k$ y $j \in B_m$ con $k \neq m$:

\begin{equation}
\eta_{ij} = -\beta x_{nj} P_{nj}
(\#eq:elastbetween)
\end{equation}

Nótese que $\eta_{ij}$ (dentro del nido) depende de $\lambda_k$ y es típicamente mayor en magnitud que la elasticidad cruzada entre nidos, reflejando que alternativas dentro del mismo nido son mejores sustitutos.

### Ejemplo

En una situación de elección de tipo de vivienda en una ciudad hay cuatro alternativas: departamento pequeño (DP), departamento grande (DG), casa pequeña (CP) y casa grande (CG).

**Estructura de Nidos:** Se propone una estructura con dos nidos:

- Nido 1 (Departamentos): $B_1 = \{DP, DG\}$
- Nido 2 (Casas): $B_2 = \{CP, CG\}$

**Especificación de Utilidad:**

\begin{aligned}
v_{n,DP} &= \alpha_{DP} + \beta_1 \cdot precio_{DP} + \beta_2 \cdot distancia_{DP}\\
v_{n,DG} &= \alpha_{DG} + \beta_1 \cdot precio_{DG} + \beta_2 \cdot distancia_{DG}\\
v_{n,CP} &= \alpha_{CP} + \beta_1 \cdot precio_{CP} + \beta_2 \cdot distancia_{CP}\\
v_{n,CG} &= \alpha_{CG} + \beta_1 \cdot precio_{CG} + \beta_2 \cdot distancia_{CG}
\end{aligned}

donde $\alpha_i$ son constantes alternativa-específicas, $\beta_1 < 0$ captura el efecto del precio y $\beta_2 < 0$ el efecto de la distancia al centro.

**Resultados Hipotéticos:**

Supóngase que la estimación arroja $\lambda_1 = 0.6$ y $\lambda_2 = 0.7$. Esto implica:

- **Correlación en Nido 1 (Departamentos):** $1 - (0.6)^2 = 0.64$
- **Correlación en Nido 2 (Casas):** $1 - (0.7)^2 = 0.51$

Los departamentos presentan mayor correlación en sus componentes no observables que las casas, sugiriendo que hay factores no modelados (quizás preferencias por estilo de vida urbano, servicios comunes en edificios, etc.) que afectan similarmente la atractiva de ambos tipos de departamentos.

**Implicaciones para Sustitución:**

Si el precio del departamento grande aumenta, este incremento afectará más la probabilidad de elegir el departamento pequeño (mismo nido) que la probabilidad de elegir cualquiera de las casas. Formalmente, la elasticidad cruzada $\eta_{DP,DG}$ será mayor en magnitud que $\eta_{DP,CP}$ o $\eta_{DP,CG}$.

### Estimación

La estimación del modelo nested logit se realiza mediante **máxima verosimilitud**. Dada una muestra de $N$ individuos donde cada individuo $n$ elige una alternativa $i_n$ de su conjunto de elección, la función de log-verosimilitud viene dada por:

\begin{equation}
LL(\theta, \lambda) = \sum_{n=1}^N \ln P_{ni_n}(\theta, \lambda)
(\#eq:nestedll)
\end{equation}

donde $\theta$ representa todos los parámetros de las utilidades sistemáticas y $\lambda = (\lambda_1, ..., \lambda_K)$ son los parámetros de disimilitud de cada nido.

**Procedimiento de Estimación:**

1. Especificar la partición en nidos $\{B_1, ..., B_K\}$
2. Especificar las funciones de utilidad $v_{ni}$ para cada alternativa
3. Calcular valores inclusivos $IV_k$ para cada nido
4. Calcular probabilidades $P_{ni}$ usando la ecuación \@ref(eq:totalprob)
5. Maximizar la log-verosimilitud \@ref(eq:nestedll) con restricciones $0 < \lambda_k \leq 1$

**Test de Especificación:**

Un test natural es evaluar si $\lambda_k = 1$ para todos los nidos, lo que equivaldría al modelo logit estándar. Se puede usar un **test de razón de verosimilitud** comparando:

- Modelo restringido: Logit estándar (todos los $\lambda_k = 1$)
- Modelo no restringido: Nested logit con $\lambda_k$ estimados

El estadístico $LR = 2(LL_{nested} - LL_{logit})$ se distribuye asintóticamente como $\chi^2$ con $K$ grados de libertad bajo la hipótesis nula de que el logit estándar es adecuado.

### Extensiones: Nested Logit con Múltiples Niveles

El modelo nested logit puede extenderse a **estructuras jerárquicas de múltiples niveles**, donde los nidos pueden a su vez contener sub-nidos. Por ejemplo, en el contexto de elección de vehículos, se podría tener:

- **Nivel 1:** Tipo de combustión (gasolina vs. eléctrico)
- **Nivel 2:** Tamaño del vehículo (pequeño, mediano, grande)
- **Nivel 3:** Marca específica

En este caso, la decisión se modela como una secuencia de elecciones desde el nivel más alto (combustión) hasta el más específico (marca), con parámetros de disimilitud en cada nivel capturando la correlación entre alternativas dentro de cada sub-nido.

La probabilidad de elección en un nested logit de tres niveles sigue una estructura análoga:

\begin{equation}
P_{ni} = P_{ni|nido_3} \cdot P_{nido_3|nido_2} \cdot P_{nido_2}
(\#eq:threelevel)
\end{equation}

donde cada probabilidad condicional tiene forma logit con su respectivo parámetro de disimilitud.

## Mixed Logit

### Introducción y Motivación

Como se ha discutido anteriormente, el modelo logit estándar, aunque computacionalmente conveniente gracias a su forma cerrada, presenta limitaciones importantes que pueden restringir su aplicabilidad en contextos reales de marketing. El modelo **Mixed Logit** (también conocido como **Random Parameters Logit** o **Error Components Logit**) surgió como una generalización flexible del modelo logit estándar que permite superar las limitaciones de *Logit*. La idea fundamental es permitir que los parámetros de la función de utilidad varíen aleatoriamente en la población, capturando así heterogeneidad no observable en las preferencias.

**Intuición del Modelo:**

Supóngase que se está modelando la elección de medio de transporte (auto, bus, tren) y se sabe que la sensibilidad al tiempo de viaje varía sustancialmente entre individuos. Mientras que el logit estándar asumiría un único coeficiente de tiempo de viaje para toda la población, el mixed logit permite que este coeficiente siga una distribución en la población (por ejemplo, normal con cierta media y varianza), reflejando que algunos individuos son muy sensibles al tiempo mientras otros lo son menos.

### Especificación del Modelo

#### Función de Utilidad y Probabilidad de Elección

En un modelo mixed logit, la utilidad que el individuo $n$ deriva de la alternativa $i$ en la ocasión de elección $t$ viene dada por:

\begin{equation}
u_{nit} = \beta'_n x_{nit} + \varepsilon_{nit}
(\#eq:mixedutil)
\end{equation}

donde:

- $x_{nit}$ es un vector de atributos observables de la alternativa $i$ para el individuo $n$ en el período $t$
- $\beta_n$ es un vector de coeficientes **aleatorios** que varía entre individuos
- $\varepsilon_{nit}$ es un término de error i.i.d. valor extremo tipo I (como en el logit estándar)

La característica clave es que $\beta_n$ no es un parámetro fijo, sino una **variable aleatoria** que sigue una distribución de probabilidad $f(\beta | \theta)$, donde $\theta$ son los parámetros que describen esta distribución (típicamente media y varianza/covarianza).

**Especificación común:** Se suele asumir que $\beta_n \sim N(b, \Sigma_\beta)$, donde $b$ es el vector de medias poblacionales y $\Sigma_\beta$ es la matriz de varianzas-covarianzas.

Condicional en $\beta_n$, la probabilidad de que el individuo $n$ elija la alternativa $i$ es simplemente un logit estándar:

\begin{equation}
L_{nit}(\beta_n) = \frac{\exp(\beta'_n x_{nit})}{\sum_{j=1}^J \exp(\beta'_n x_{njt})}
(\#eq:condlogit)
\end{equation}

Sin embargo, como $\beta_n$ no es observable, la probabilidad **no condicional** de elección se obtiene integrando sobre la distribución de $\beta$:

\begin{equation}
P_{nit} = \int L_{nit}(\beta) f(\beta | \theta) d\beta = \int \frac{\exp(\beta' x_{nit})}{\sum_{j=1}^J \exp(\beta' x_{njt})} f(\beta | \theta) d\beta
(\#eq:mixedprob)
\end{equation}

Esta integral **no tiene solución cerrada** en general, lo que distingue fundamentalmente al mixed logit del logit estándar y requiere métodos de simulación para su estimación. La idea básica es aproximar la integral usando simulación de Monte Carlo:

1. **Extraer valores aleatorios:** Para cada individuo $n$, se extraen $R$ valores de $\beta$ de la distribución especificada $f(\beta|\theta)$: $\beta^{(1)}, \beta^{(2)}, ..., \beta^{(R)}$

2. **Calcular logit condicional:** Para cada extracción $r$, se calcula la probabilidad logit condicional:
   $$L_{nit}(\beta^{(r)}) = \frac{\exp(\beta^{(r)'} x_{nit})}{\sum_j \exp(\beta^{(r)'} x_{njt})}$$

3. **Promediar:** La probabilidad simulada es el promedio sobre las $R$ extracciones:
   \begin{equation}
   \tilde{P}_{nit} = \frac{1}{R} \sum_{r=1}^R L_{nit}(\beta^{(r)})
   (\#eq:simprob)
   \end{equation}

La probabilidad simulada $\tilde{P}_{nit}$ es un **estimador insesgado** de la verdadera probabilidad $P_{nit}$ y por la ley de los grandes números, $\tilde{P}_{nit} \to P_{nit}$ cuando $R \to \infty$.

La log-verosimilitud simulada viene dada por:

\begin{equation}
SLL(\theta) = \sum_{n=1}^N \sum_{t=1}^T \sum_{i=1}^J y_{nit} \ln(\tilde{P}_{nit})
(\#eq:simll)
\end{equation}

El **estimador de máxima verosimilitud simulada (MSLE)** maximiza esta función:

$$\hat{\theta}_{MSL} = \arg\max_\theta SLL(\theta)$$

**Propiedades asintóticas:**
- Si $R$ crece más rápido que $\sqrt{N}$, el MSLE es consistente, asintóticamente normal y asintóticamente eficiente
- En la práctica, valores de $R$ entre 100 y 500 suelen ser suficientes

La elección de la distribución $f(\beta|\theta)$ es crucial y debe basarse tanto en consideraciones teóricas como prácticas:

**Distribuciones Comunes:**

1. **Normal:** $\beta_k \sim N(b_k, \sigma^2_k)$
   - Permite valores positivos y negativos
   - Apropiada cuando no hay restricciones de signo (ej: efectos de marca)

2. **Log-Normal:** $\beta_k \sim LN(b_k, \sigma^2_k)$, es decir $\ln(\beta_k) \sim N(b_k, \sigma^2_k)$
   - Garantiza que $\beta_k > 0$ (útil para tiempo, costo)
   - **Limitación:** No permite valores negativos

3. **Normal Truncada:** Normal restringida a cierto rango
   - Útil cuando la teoría sugiere un signo pero se quiere flexibilidad
   - Ejemplo: coeficiente de precio debe ser negativo

4. **Uniforme:** $\beta_k \sim U[a_k, b_k]$
   - Útil cuando se conocen límites naturales
   - Menos común en aplicaciones de marketing

Es posible especificar correlaciones entre coeficientes aleatorios usando distribuciones multivariadas. Por ejemplo, con distribución normal multivariada:

$$\beta_n \sim N(b, \Sigma_\beta)$$

#### Descomposición de Parámetros

Es común especificar el modelo de manera que algunos parámetros sean fijos (iguales para todos los individuos) y otros sean aleatorios. Por ejemplo:

\begin{equation}
\beta_n = b + \eta_n
(\#eq:betadecomp)
\end{equation}

donde $b$ representa las preferencias medias de la población y $\eta_n \sim N(0, \Sigma_\beta)$ captura las desviaciones individuales respecto a estas preferencias medias.

Sustituyendo en la utilidad:

\begin{aligned}
u_{nit} &= (b + \eta_n)' x_{nit} + \varepsilon_{nit}\\
&= b' x_{nit} + \eta'_n x_{nit} + \varepsilon_{nit}\\
&= b' x_{nit} + \tilde{\varepsilon}_{nit}
\end{aligned}

donde $\tilde{\varepsilon}_{nit} = \eta'_n x_{nit} + \varepsilon_{nit}$ es la componente de error compuesta.

### Propiedades del Mixed Logit

El modelo mixed logit posee propiedades notables que lo hacen extremadamente flexible:

#### Aproximación Universal

**Resultado fundamental (McFadden y Train, 2000):** Cualquier modelo de utilidad aleatoria (RUM) puede ser aproximado arbitrariamente bien por un modelo mixed logit, siempre que se especifique apropiadamente la distribución de los coeficientes aleatorios.

Esto significa que el mixed logit puede aproximar patrones de sustitución arbitrarios, incluyendo aquellos del modelo probit multinomial, eliminando las restricciones del IIA cuando sea necesario.

#### Patrones de Sustitución Flexibles

A diferencia del logit estándar, el mixed logit permite patrones de sustitución no proporcionales. La elasticidad cruzada entre alternativas depende de:

- Sus características específicas
- La correlación entre sus utilidades inducida por los coeficientes aleatorios
- La distribución de preferencias en la población

**Ejemplo:** Si dos alternativas comparten muchos atributos que tienen coeficientes aleatorios correlacionados, serán sustitutos más cercanos que alternativas con atributos diferentes.

#### Captura de heterogeneidad no observable

El mixed logit permite modelar explícitamente que individuos con características observables idénticas pueden tener preferencias diferentes. La distribución $f(\beta|\theta)$ caracteriza cómo se distribuyen las preferencias en la población.

**Interpretación:**

- La **media** $b$ representa la preferencia promedio de la población
- La **desviación estándar** $\sigma_\beta$ captura el grado de heterogeneidad en preferencias
- Las **covarianzas** capturan relaciones sistemáticas entre preferencias (ej: quienes valoran más la velocidad también valoran más el confort)

#### Correlación Temporal y Entre Alternativas

Al observar decisiones repetidas del mismo individuo, el mixed logit permite correlación entre las utilidades a través del tiempo porque $\beta_n$ es constante para el individuo $n$ a lo largo de sus decisiones.

Si se observa al individuo $n$ en $T$ ocasiones y se define $y_{nit} = 1$ si elige alternativa $i$ en ocasión $t$ y 0 en caso contrario, la probabilidad condicional de la secuencia completa de elecciones es:

\begin{equation}
L_n(\beta_n) = \prod_{t=1}^T \prod_{i=1}^J L_{nit}(\beta_n)^{y_{nit}} = \prod_{t=1}^T \left[\frac{\exp(\beta'_n x_{nit})}{\sum_j \exp(\beta'_n x_{njt})}\right]^{y_{nit}}
(\#eq:seqprob)
\end{equation}

Y la probabilidad no condicional es:

\begin{equation}
P_n = \int L_n(\beta) f(\beta|\theta) d\beta
(\#eq:panelprob)
\end{equation}

Esta estructura captura naturalmente que las elecciones del mismo individuo están correlacionadas debido a sus preferencias subyacentes $\beta_n$.

### Disposición a Pagar (Willingness to Pay)

Un beneficio importante del mixed logit es que permite derivar la distribución de la **disposición a pagar (DAP)** por diferentes atributos.

Si la utilidad es lineal: $u_{nit} = \beta_{n,precio} \cdot precio_{it} + \beta_{n,atributo} \cdot atributo_{it} + ...$

La DAP por una unidad adicional del atributo es:

\begin{equation}
DAP_n = -\frac{\beta_{n,atributo}}{\beta_{n,precio}}
(\#eq:wtp)
\end{equation}

Como ambos $\beta_{n,atributo}$ y $\beta_{n,precio}$ son aleatorios, la DAP también tiene una distribución en la población. El mixed logit permite:

1. Estimar la **distribución de la DAP** en la población
2. Calcular estadísticos como la DAP media, mediana, percentiles
3. Identificar segmentos con alta/baja DAP

Si ambos coeficientes son normales, la DAP sigue una distribución de Cauchy (que puede tener momentos no definidos). Esto ha llevado a usar especificaciones alternativas como log-normal para el coeficiente de precio.

### Inferencia Individual: Conditional/Posterior Means

Una aplicación valiosa del mixed logit es la posibilidad de hacer **inferencia individual** sobre los parámetros $\beta_n$ de cada persona, incluso cuando estos no son directamente observables.

Usando el **Teorema de Bayes**, se puede calcular la distribución **posterior** de $\beta_n$ dado el historial de elecciones del individuo $n$:

\begin{equation}
h(\beta_n | y_n, \theta) = \frac{L_n(\beta_n) f(\beta_n | \theta)}{\int L_n(\beta) f(\beta | \theta) d\beta}
(\#eq:posterior)
\end{equation}

donde $y_n$ representa todas las elecciones observadas del individuo $n$.

La **media condicional** (o posterior) es:

\begin{equation}
\bar{\beta}_n = E[\beta_n | y_n, \theta] = \int \beta \cdot h(\beta | y_n, \theta) d\beta
(\#eq:condmean)
\end{equation}

Esta integral también se aproxima por simulación:

\begin{equation}
\tilde{\bar{\beta}}_n = \frac{\sum_{r=1}^R \beta^{(r)} L_n(\beta^{(r)})}{\sum_{r=1}^R L_n(\beta^{(r)})}
(\#eq:simcondmean)
\end{equation}

Tiene aplicaciones en:

- **Personalización:** Usar $\bar{\beta}_n$ para hacer recomendaciones personalizadas
- **Segmentación:** Agrupar individuos con $\bar{\beta}_n$ similares
- **Targeting:** Identificar individuos con alta probabilidad de responder a cierta oferta

### Ejemplo

Sea el caso de la elección de una marca de yogur (3 marcas: A, B, C) con datos de panel en el tiempo. Las variables que se disponen son:

- $precio_{nit}$: precio de marca $i$ para individuo $n$ en ocasión $t$
- $display_{nit}$: indicadora de display especial
- $marca_i$: indicadoras de marca (efectos fijos de marca)

La especificación del modelo corresponda a:

\begin{aligned}
u_{nit} &= \alpha_i + \beta_{n,precio} \cdot precio_{nit} + \beta_{display} \cdot display_{nit} + \varepsilon_{nit}\\
\beta_{n,precio} &\sim N(b_{precio}, \sigma^2_{precio})
\end{aligned}

En un caso hipotético, donde se estima que $b_{precio} = -2.5$ y $\sigma_{precio} = 1.0$:

- El consumidor promedio tiene sensibilidad al precio de -2.5
- Hay heterogeneidad sustancial: aprox. 68% de consumidores (equivalente a una desviación estándar) tienen sensibilidad entre -3.5 y -1.5
- Aproximadamente 1% de consumidores, calculado con la distribución normal acumulada para $b_{precio} = -2.5$, podrían tener sensibilidad positiva, ya que prefieren productos caros.

El DAP por un display se calcula como:

$$DAP_{display} = -\frac{\beta_{display}}{\beta_{n,precio}}$$

Si $\beta_{display} = 0.5$, la DAP media sería aproximadamente $0.5/2.5 = 0.20$ dólares.

<!--chapter:end:03-estructurales.Rmd-->

# Apéndices Técnicos

## Métodos de Estimación y Evaluación de modelos



<!--chapter:end:04-apéndice.Rmd-->

