% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Marketing Engineering},
  pdfauthor={Marcel Goic},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Marketing Engineering}
\author{Marcel Goic}
\date{2025-11-07}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{pruxf3logo}{%
\chapter*{Prólogo}\label{pruxf3logo}}
\addcontentsline{toc}{chapter}{Prólogo}

\begin{itemize}
\item ~
  \hypertarget{estimadoa-estudiante-tienes-en-tus-manos-el-primer-apunte-oficial-del-curso-de-ingenieruxeda-de-marketing-hecho-con-mucho-esfuerzo-por-varios-integrantes-de-los-distintos-equipos-docente-del-curso-a-lo-largo-de-los-auxf1os.-cabe-recordar-que-este-documento-estuxe1-en-constante-actualizaciuxf3n-y-mejora-por-lo-que-cualquier-sugerencia-correcciuxf3n-o-comentario-favor-de-comunicarse-al-correo-mktengnotesgmail.com.-uxe9xito-en-el-estudio}{%
  \section{\texorpdfstring{Estimado/a estudiante, tienes en tus manos el primer apunte oficial del curso de Ingeniería de Marketing, hecho con mucho esfuerzo por varios integrantes de los distintos equipos docente del curso a lo largo de los años. Cabe recordar que este documento está en constante actualización y mejora, por lo que cualquier sugerencia, corrección o comentario favor de comunicarse al correo \href{mailto:mktengnotes@gmail.com}{\nolinkurl{mktengnotes@gmail.com}}. ¡Éxito en el estudio!}{Estimado/a estudiante, tienes en tus manos el primer apunte oficial del curso de Ingeniería de Marketing, hecho con mucho esfuerzo por varios integrantes de los distintos equipos docente del curso a lo largo de los años. Cabe recordar que este documento está en constante actualización y mejora, por lo que cualquier sugerencia, corrección o comentario favor de comunicarse al correo mktengnotes@gmail.com. ¡Éxito en el estudio!}}\label{estimadoa-estudiante-tienes-en-tus-manos-el-primer-apunte-oficial-del-curso-de-ingenieruxeda-de-marketing-hecho-con-mucho-esfuerzo-por-varios-integrantes-de-los-distintos-equipos-docente-del-curso-a-lo-largo-de-los-auxf1os.-cabe-recordar-que-este-documento-estuxe1-en-constante-actualizaciuxf3n-y-mejora-por-lo-que-cualquier-sugerencia-correcciuxf3n-o-comentario-favor-de-comunicarse-al-correo-mktengnotesgmail.com.-uxe9xito-en-el-estudio}}
\end{itemize}

\hypertarget{modelos-de-regresiuxf3n}{%
\chapter{Modelos de Regresión}\label{modelos-de-regresiuxf3n}}

\hypertarget{conceptos-buxe1sicos-de-regresiuxf3n}{%
\section{Conceptos básicos de regresión}\label{conceptos-buxe1sicos-de-regresiuxf3n}}

Como bien ya se ha estudiado en otros cursos de la carrera de ingeniería
industrial, una \emph{regresión} es una técnica para calcular el valor
esperado de una variable condicional en la realización de otras. Por
ejemplo:

\begin{itemize}
\tightlist
\item
  ¿Cuál debería ser el precio de venta de una casa en la comuna de la
  Providencia, con 4 dormitorios, 170 \(m^2\) de superficie construida?
\item
  ¿Cuáles deberían ser las ventas de Leche semidescremada Nestlé en la
  última semana del mes de Abril si el precio es \$723?
\item
  ¿Cuál debería ser el número de clientes que ve un aviso publicitario
  si se despliega en 4 programas durante 3 semanas y el rating
  promedio de los programas es 8.7 puntos?
\end{itemize}

\hypertarget{notaciuxf3n}{%
\subsection{Notación}\label{notaciuxf3n}}

En general se denota con \(y\) al vector que representa todas las
variables dependientes en un único vector columna, mientras que \(X\)
representa la matriz que incluye todas las variables independientes
(esto incluye una columna de 1s si se desea incluir un intercepto).

Es importante notar que:

\begin{itemize}
\tightlist
\item
  Cada columna corresponde a una variable.
\item
  Cada fila corresponde a un caso.
\item
  Las dimensiones de las filas del vector \(y\) y la matriz \(X\) deben
  ser consistentes.
\item
  Todos los elementos de una misma fila deben tener los mismos
  índices.
\end{itemize}

Para estimar los parámetros de la recta de regresión, se utilizan
diferentes métodos, siendo uno de los más populares el método de Mínimos
Cuadrados Ordinarios (OLS).

\hypertarget{muxednimos-cuadrados-ordinarios-ols-y-supuestos}{%
\section{Mínimos Cuadrados Ordinarios (OLS) y supuestos}\label{muxednimos-cuadrados-ordinarios-ols-y-supuestos}}

OLS proporciona una estimación óptima de los parámetros de la recta de
regresión, al encontrar la recta que minimiza la suma de los cuadrados
de las diferencias entre los valores reales y los valores estimados de
la variable dependiente. Sin embargo, para que este método sea un
estimador adecuado de los parámetros, se deben cumplir ciertos
supuestos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Existe una \emph{relación lineal} entre la variable dependiente y las
  variables independientes. Debido a esto, la relación entre las
  variables se puede modelar mediante una recta. Sin este supuesto,
  OLS no es apropiado y se debe recurrir a otros métodos.
\item
  Los errores tienen una \textbf{distribución normal y tienen una media
  igual a cero}. Es decir, los errores son insesgados y distribuyen
  de forma simétrica alrededor del cero. Si los errores no siguen una
  distribución normal, los resultados de la regresión pueden no ser
  confiables.
\item
  Los errores tienen una \emph{varianza constante} (homocedasticidad). Esto
  significa que la varianza de los errores es la misma para todos los
  valores de las variables independientes. Si no se cumple este
  supuesto, los errores pueden estar influenciados por alguna variable
  independiente y los resultados pueden ser incorrectos.
\item
  Los errores son \emph{independientes entre sí}. Es decir, no están
  correlacionados con los errores de otra observación. Si los errores
  están correlacionados, la varianza de los coeficientes puede ser
  demasiado baja, lo que puede llevar a una sobreestimación de la
  significancia estadística.
\item
  No existe \emph{multicolinealidad} perfecta entre las variables
  independientes. La multicolinealidad perfecta se refiere a la
  existencia de una relación lineal exacta entre las variables
  independientes. Esto puede ocurrir cuando dos o más variables
  independientes están altamente correlacionadas. Si no se cumple este
  supuesto, los coeficientes estimados pueden no ser confiables y los
  resultados pueden ser incorrectos.
\end{enumerate}

En general, se utiliza OLS porque proporciona una estimación óptima de
los parámetros de la recta de regresión, es decir, los valores que mejor
se ajustan a los datos. El método OLS minimiza la suma de los cuadrados
de las diferencias entre los valores reales y los valores estimados de
la variable dependiente. Esto se logra al encontrar los valores de los
parámetros de la recta que minimizan esta suma de cuadrados.

\hypertarget{estimaciuxf3n}{%
\subsection{Estimación}\label{estimaciuxf3n}}

Supongamos que queremos estimar los parámetros
\(\beta_0, \beta_1, \ldots, \beta_n\) de la recta de regresión
\(Y = \beta_0 + \beta_1 x_1 + \cdots + \beta_n x_n + \epsilon\), donde
\(\epsilon\) es el término de error e \(Y\) es la variable dependiente.
Queremos encontrar los valores de los parámetros
\(\beta_0, \beta_1, \ldots, \beta_n\) que minimizan la suma de los
cuadrados de las diferencias entre los valores reales y los valores
estimados de \(Y\).

La idea detrás del método de Mínimos Cuadrados Ordinarios (OLS) es
minimizar la función de pérdida
\(S(\beta_0, \beta_1, \ldots, \beta_n) = \sum_{i=1}^N (Y_i - \beta_0 - \beta_1 x_{i1} - \cdots - \beta_n x_{in})^2\).
La solución de este problema de optimización se puede encontrar a través
del cálculo de las derivadas parciales de \(S\) con respecto a cada uno de
los parámetros \(\beta_j\), e igualar a cero. Esto nos lleva al siguiente
sistema de ecuaciones:

\[\hat{\beta}=(X^TX)^{-1}X^TY\]

donde \(X\) es la matriz de variables independientes, \(Y\) es el vector de
la variable dependiente y \(\hat{\beta}\) es el vector de estimadores de
mínimos cuadrados.

La solución de este sistema entrega los valores de los parámetros
\(\beta_0, \beta_1, \ldots, \beta_n\) que minimizan la función de pérdida
\(S(\beta_0, \beta_1, \ldots, \beta_n)\). Estos valores se conocen como
los estimadores de mínimos cuadrados de los parámetros de la recta de
regresión.

\hypertarget{propiedades}{%
\subsection{Propiedades}\label{propiedades}}

Si se cumplen los supuestos anteriormente mencionados, mínimos cuadrados
ordinarios cumple con las siguientes propiedades:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Insesgadez}: Los estimadores de mínimos cuadrados son insesgados,
  lo que significa que, en promedio, su valor esperado es igual al
  verdadero valor del parámetro que se está estimando.
\item
  \emph{Eficiencia}: Entre todos los estimadores insesgados y lineales, los
  estimadores de mínimos cuadrados tienen la menor varianza posible.
\item
  \emph{Linealidad}: Los estimadores de mínimos cuadrados son lineales en
  la variable de respuesta \(Y\).
\item
  \emph{Consistencia}: Con un tamaño de muestra lo suficientemente grande,
  los estimadores de mínimos cuadrados se acercan al verdadero valor
  del parámetro que se está estimando.
\item
  El estimador máximo verosímil, para el caso lineal con errores
  normales \emph{coincide con el estimador de mínimos cuadrados}.
\end{enumerate}

Según el teorema de Gauss-Markov, al cumplirse las propiedades de
*Insesgadez, **Eficiencia* y \emph{Linealidad}, los estimadores de OLS
son \emph{BLUE} (Best Linear Unbiased Estimators).

\hypertarget{estrategias-de-modelamiento}{%
\section{Estrategias de Modelamiento}\label{estrategias-de-modelamiento}}

\hypertarget{arte-vs.-procedimiento}{%
\subsection{Arte vs.~Procedimiento}\label{arte-vs.-procedimiento}}

El debate entre el arte y el procedimiento en el campo de la
modelización y análisis de datos se ha intensificado en los últimos años
con el auge de la inteligencia artificial y el aprendizaje automático.
Los defensores del arte argumentan que la experiencia y la intuición del
analista son esenciales para identificar patrones y relaciones complejas
en los datos que no son evidentes a simple vista. Por otro lado, los
defensores del procedimiento insisten en que la aplicación rigurosa de
algoritmos y técnicas estadísticas es la única manera de garantizar la
validez y precisión del modelo.

Es importante tener en cuenta que el uso exclusivo de uno u otro enfoque
puede llevar a resultados subóptimos. Por ejemplo, un modelo construido
únicamente a través del arte puede ser difícil de replicar o explicar a
otros, lo que limita su utilidad práctica. Por otro lado, un modelo
construido únicamente a través del procedimiento puede pasar por alto
aspectos importantes de los datos que son evidentes para un experto en
el campo.

En la práctica, los analistas suelen combinar ambos enfoques para
construir modelos efectivos y útiles. Un aspecto clave en este proceso
es la exploración exhaustiva de los datos y la definición de una lista
de modelos candidatos, que pueden incluir diferentes técnicas de
modelización y selección de variables. Luego, se pueden utilizar
diversas métricas de ajuste y predicción para evaluar la calidad de cada
modelo y seleccionar el que mejor se ajuste a los datos y sea capaz de
hacer predicciones precisas.

\hypertarget{aprendizajes-preliminares}{%
\subsection{Aprendizajes Preliminares}\label{aprendizajes-preliminares}}

En el ámbito del modelado estadístico, existen innumerables modelos de
regresión, lo que hace imposible determinar cuál es el mejor en términos
absolutos.

Una forma de abordar este problema es equilibrar la complejidad del
modelo con su capacidad explicativa. Esto significa que el modelo debe
ser lo suficientemente simple como para ser fácilmente interpretable,
pero lo suficientemente complejo como para capturar todas las relaciones
relevantes entre las variables.

Para seleccionar un modelo de regresión adecuado, es fundamental tener
conocimientos previos del negocio y realizar una exploración exhaustiva
de los datos antes de aplicar cualquier modelo. Esta exploración ex-ante
puede ayudar a identificar las variables más relevantes y las posibles
relaciones entre ellas. Es importante evaluar cómo se relacionan las
variables, qué variables tienen mayor dispersión y qué variables se
mantienen relativamente constantes.

Después de la exploración ex-ante, es necesario aplicar el modelo y
evaluar su rendimiento mediante la evaluación ex-post. Esto implica
evaluar el modelo en datos nuevos y comprobar si se comporta de manera
similar a cómo lo hizo en los datos de entrenamiento.

\emph{1. Elegir nivel de agregación}

Uno de los aspectos clave del análisis de datos es determinar el nivel
adecuado de agregación para realizar el análisis. Por ejemplo, se puede
analizar las ventas de un producto en un supermercado por hora, día,
semana, mes o año. También se puede considerar el análisis de ventas por
SKU (código de identificación), marca, cadena o sala.

Es importante tener en cuenta que el problema de gestión puede imponer
restricciones al nivel de agregación mínimo. Por ejemplo, si un gerente
de una cadena de supermercados necesita tomar decisiones en tiempo real
sobre la reposición de un producto, es posible que necesite datos a
nivel de hora o día. En este caso, analizar las ventas a nivel de semana
o mes no sería útil.

En el análisis de ventas, a menudo se enfrenta un trade-off entre la
sensibilidad al precio y la programación de reposición. Si el análisis
se realiza a nivel de SKU, se puede obtener una comprensión más
detallada de cómo el precio afecta a las ventas. Sin embargo, si el
análisis se realiza a nivel de cadena o sala, se puede obtener una mejor
comprensión de los patrones de reposición.

Agregar los datos a un nivel de agregación más alto puede ser más fácil,
ya que se requiere menos detalle y se puede tener una visión más
general. Sin embargo, puede llevar a una pérdida de precisión por
underfitting. Por ejemplo, si se analiza las ventas a nivel de mes, se
puede perder información valiosa sobre patrones diarios o semanales. Por
otro lado, si la cantidad de datos es limitada, es posible que se
necesite mantener un nivel de agregación más alto para obtener un modelo
preciso. En este caso, reducir el nivel de agregación puede significar
la pérdida de información importante y la reducción de la precisión del
modelo por overfitting.

\emph{2. Descomposición en múltiples regresiones:}

La descomposición en múltiples regresiones es una técnica que permite
abordar problemas complejos y de alta dimensionalidad mediante la
partición del problema en componentes más pequeños y manejables. Este
enfoque puede adoptar diversas formas, incluyendo la descomposición por
índices y la descomposición por componentes latentes.

\begin{itemize}
\item
  \emph{Descomposición por índices:} Aunque en general es preferible
  utilizar una única regresión para analizar las relaciones entre las
  variables, en ciertas situaciones, como en casos de complejidad
  computacional elevada o cuando se abordan problemas con múltiples
  niveles de jerarquía, la descomposición por índices puede ser una
  solución adecuada. Esta técnica implica dividir el conjunto de datos
  en subconjuntos según algún criterio y ajustar modelos de regresión
  separados para cada subconjunto.
\item
  \emph{Regresión lineal y modelos más complejos:} La regresión lineal es
  un enfoque simple y fácil de estimar que puede ser suficiente en
  muchos casos. Sin embargo, en situaciones donde las relaciones entre
  las variables no son lineales o donde se requiere una mayor
  flexibilidad en el modelado, se pueden justificar modelos más
  complejos, como regresiones polinómicas, regresiones no paramétricas
  o modelos de regresión con variables categóricas.
\item
  \emph{Descomposición por componentes latentes:} En ciertos casos, la
  variable dependiente puede descomponerse de manera natural en
  componentes latentes, lo que facilita la interpretación de los
  resultados y la identificación de relaciones subyacentes entre las
  variables. Un ejemplo típico es la descomposición de las ventas en
  el número de compras y el número de unidades por compra. Al analizar
  estos componentes por separado, se puede obtener una comprensión más
  detallada de los factores que influyen en las ventas.
\item
  \emph{Caso del cero inflado (zero inflated):} En algunas situaciones, se
  pueden observar una gran cantidad de ceros en los datos, lo que
  indica una distribución inflada en cero. En estos casos, se puede
  utilizar un modelo de regresión de ceros inflados que distingue
  entre dos procesos distintos: la incidencia de compra (probabilidad
  de que ocurra una compra) y el monto de compra (valor de la compra,
  condicional a que se haya realizado una compra). Este enfoque
  permite analizar de manera más efectiva los factores que afectan
  tanto la propensión a comprar como la cantidad gastada en las
  compras.
\end{itemize}

\emph{3. Transformación de Variables}

La transformación de variables es una técnica utilizada para mejorar la
interpretación y el ajuste del modelo. Esta técnica consiste en aplicar
funciones matemáticas a las variables con el objetivo de modificar su
distribución y hacer que el modelo sea más interpretable y
significativo.

Un ejemplo común de transformación de variables es el modelo doble log,
en el cual se aplican logaritmos a las variables dependientes e
independientes para transformar la relación no lineal en una relación
lineal. Esta técnica puede ser útil cuando se analizan datos que siguen
una distribución log-normal o cuando se busca interpretar los
coeficientes de manera logarítmica.

Es importante tener en cuenta que, aunque la transformación de variables
puede mejorar la bondad del ajuste y la precisión de las predicciones,
no siempre es necesario aplicarla. En algunos casos, las variables ya
están en una forma adecuada para el modelo y cualquier transformación
adicional podría reducir la interpretabilidad del modelo. Por lo tanto,
es importante tener una comprensión sólida de los datos y del problema a
resolver antes de aplicar cualquier transformación de variables.

\begin{longtable}[]{@{}llll@{}}
\toprule
\emph{Modelo} & \emph{Variable dependiente} & \emph{Variable independiente} & \emph{Interpretación} \\
\midrule
\endhead
Nivel-nivel & \(Y\) & \(X\) & \(\Delta Y = \beta_1 \Delta X\) \\
Nivel-log & \(Y\) & \(\log(X)\) & \(\Delta Y = \dfrac{\beta_1}{100}\% \Delta X\) \\
Log-nivel & \(\log(Y)\) & \(X\) & \(\%\Delta Y = (100\beta_1)\Delta X\) \\
Log-log & \(\log(Y)\) & \(\log(X)\) & \(\%\Delta Y = \beta_1 \%\Delta X\) \\
\bottomrule
\end{longtable}

\emph{4. Selección de Variables}

En el campo de la regresión, existen diferentes enfoques para la
selección de variables, incluyendo métodos automáticos y manuales. Uno
de los métodos automáticos más utilizados es la regresión paso a paso
(stepwise regression), que implica la iterativa agregación o eliminación
de variables en función de algún criterio de bondad de ajuste.

En el enfoque forward de la regresión paso a paso, las variables se van
agregando al modelo una por una, comenzando con la variable que
proporciona el mejor ajuste según el criterio establecido. En cada
etapa, se evalúa si agregar una nueva variable mejora significativamente
el ajuste del modelo.

Por otro lado, en el enfoque backward de la regresión paso a paso, todas
las variables se incluyen inicialmente en el modelo y se van eliminando
una por una, comenzando con la variable que menos contribuye al ajuste
según el criterio establecido. En cada etapa, se evalúa si eliminar una
variable mejora significativamente el ajuste del modelo.

Otro enfoque de selección de variables es la penalización de uso de
parámetros no nulos al momento de minimizar la función de error. Dentro
de este enfoque se encuentra la regresión Ridge y LASSO (Least Absolute
Shrinkage and Selection Operator)

\[\text{Ridge: }\min_{β} \sum_{i}(y_i - \beta_0 - \sum_{j}\beta_{j}x_{ij})^2 + λ\sum_{j}\beta_{j}^2\]
\[\text{LASSO: }\min_{β}\sum_{i}(y_i - \beta_0 - \sum_{j}\beta_{j}x_{ij})^2 + λ\sum_{j}|\beta_{j}|\]

Aunque estos enfoques automáticos de selección de variables pueden ser
convenientes y ahorrar tiempo, es importante tener en cuenta algunas
limitaciones. En primer lugar, las implementaciones automáticas de
selección de variables no exploran todas las posibles combinaciones de
variables, lo que significa que podrían pasar por alto combinaciones
óptimas que un enfoque manual más exhaustivo podría descubrir.

Además, los resultados de la selección automática de variables pueden
generar conjuntos de variables poco intuitivos y difíciles de
interpretar. A veces, el algoritmo puede seleccionar variables que
tienen una relación estadística con la variable de respuesta, pero
carecen de una interpretación causal o intuitiva en el contexto del
problema.

Una alternativa es utilizar una mixtura entre métodos automáticos y
manuales, eligiendo aquellas variables que mejoran el modelo en ajuste y
que igualmente tienen un sentido interpretativo para la resolución de la
pregunta a responder.

\emph{5. Selección de Índices}

La selección de índices en el análisis de regresión es un proceso
discrecional que puede influir significativamente en la interpretación y
el rendimiento de los modelos. Para abordar este problema de manera
efectiva, se pueden seguir algunas pautas generales que ayuden a
identificar y justificar la inclusión de índices en el análisis.

Condiciones para Indexar un Parámetro Es recomendable considerar la
inclusión de un índice en un modelo de regresión si se cumplen las
siguientes tres condiciones:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  Relevancia para el problema de gestión: El índice debe ser
  importante para abordar el problema de gestión en cuestión,
  proporcionando una distinción significativa entre diferentes
  aspectos del problema.
\item
  Diferencias en el comportamiento de la variable dependiente: La
  variable dependiente debe mostrar comportamientos distintos para
  cada índice, lo que sugiere que la desagregación aporta información
  adicional útil.
\item
  Suficiencia de datos: Deben estar disponibles suficientes datos para
  estimar de manera confiable los parámetros desagregados. La falta de
  datos puede conducir a estimaciones poco fiables y a un mayor riesgo
  de sobreajuste.
\item
  Índices y Variables Binarias: En el análisis de regresión, los
  índices pueden representarse mediante variables binarias, también
  conocidas como variables dummy. Estas variables toman el valor de 1
  cuando se cumple una condición específica (por ejemplo, si un
  producto pertenece a una categoría determinada) y 0 en caso
  contrario. Aunque la representación de índices mediante variables
  binarias es matemáticamente equivalente, la notación de índices
  suele ser más compacta y se prefiere en la mayoría de los casos.
\end{enumerate}

\emph{6. Uso de Jerarquías}

Una jerarquía aparece cuando un parámetro del modelo aparece como una
función de otros parámetros, el uso de esta técnica es útil para
detectar posibles efectos de interacción entre las variables
predictoras, de esta forma se pueden escribir modelos más parsinomios
(es decir, modelos más sencillos y con menor cantidad de parámetros).
Sin embargo, es importante tener en cuenta que la inclusión de
jerarquías entre variables debe estar basada en una teoría clara o una
justificación empírica, y no simplemente probando diferentes
combinaciones de variables.

\hypertarget{evaluaciuxf3n-de-modelos}{%
\section{Evaluación de modelos}\label{evaluaciuxf3n-de-modelos}}

La evaluación de modelos estadísticos es un tema amplio que involucra la
aplicación de los mismos principios y técnicas básicas a un gran grupo
de modelos. En la práctica, la evaluación de modelos se utiliza para
determinar la calidad y utilidad de los modelos estadísticos, es decir,
para determinar si un modelo se ajusta adecuadamente a los datos y si es
útil para hacer predicciones o inferencias sobre la población de
interés.

Es importante destacar que la evaluación de modelos estadísticos no es
un proceso estático y que puede requerir ajustes y modificaciones a
medida que se adquiere más información o se amplía el alcance del
modelo. Por lo tanto, es fundamental seguir actualizando y refinando los
modelos para asegurar su calidad y utilidad en la toma de decisiones
basadas en datos.

En la evaluación de modelos estadísticos, se utilizan diversas técnicas
que se verán a continuación.

\hypertarget{quuxe9-buscamos-en-un-modelo}{%
\subsection{¿Qué buscamos en un modelo?}\label{quuxe9-buscamos-en-un-modelo}}

Lo deseable en un modelo es que cualitativamente puedan contar una buena
historia, es decir, proporcionar información útil para poder tomar
decisiones que vayan en línea de lo que se busca estimar. Por otra
parte, se espera que cuantitativamente el modelo escogido ajuste bien a
los datos utilizados como insumo para la calibración, de tal manera que
reduzca el error de predicción y pueda generar un pronóstico creíble a
partir de lo observado.

Con esto en mente, queremos un criterio bien definido para comparar
modelos y determinar si un modelo dado es suficientemente bueno.

\hypertarget{ajuste-por-muxe9tricas-generales}{%
\subsection{Ajuste por métricas generales}\label{ajuste-por-muxe9tricas-generales}}

Las siguientes métricas de ajuste se basan en reducir los errores de
predicción de los modelos, teniendo como fin cuantificar qué tanto error
tiene un modelo al predecir un conjunto de datos dado: 1. Coeficiente de
determinación o \(R^2\): Indica la cantidad de variación en la variable
dependiente que puede ser explicada por las variable independientes en
un modelo. Se define como:

\[ R^2 = \frac{\sum_{i=1}^n (\hat{y}i - \bar{y})^2}{\sum{i=1}^n (y_i - \bar{y})^2} \]

Donde \(\hat{y_i}\) son los valores predichos por el modelo, \(\bar{y}\) es
la media de los valores observados \(y_i\) y \(n\) es el número de
observaciones.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  MAE (Mean Average Error):Calcula la diferencia promedio entre las
  predicciones del modelo y los valores reales observados en los
  datos.
\end{enumerate}

\[MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y_i}|\]

La función valor absoluto (\(|x|\)) se utiliza para asegurar que el error
siempre sea positivo.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  MAPE (Mean Absolute Percentage Error): Se expresa en porcentaje y se
  calcula como el promedio de los valores absolutos de los errores
  porcentuales de cada observación.
\end{enumerate}

\[MAPE = \frac{1}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|\cdot 100\%\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  RMSE (Root Mean Squared Error): Es una medida de la diferencia entre
  los valores predichos y los valores reales en un conjunto de datos.
  La fórmula del RMSE es:
\end{enumerate}

\[ RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2} \]

\hypertarget{ajuste-basado-en-la-probabilidad}{%
\subsection{Ajuste basado en la probabilidad}\label{ajuste-basado-en-la-probabilidad}}

También es posible darle una interpretación probabilística al ajuste, es
decir, elegir aquellos parámetros que más se asemejen a la distribución
de probabilidad que generan los datos del modelo, para ello nos basamos
en la función de verosimilitud.

La fórmula general de la función de verosimilitud para un conjunto de
\(n\) observaciones independientes y con distribución conjunta
\(f(x_1, x_2, ..., x_n; θ)\) es:

\[L(\theta | x_1, x_2, ..., x_n) = f(x_1, x_2, ..., x_n; \theta) = \prod_{i=1}^{n} f(x_i;\theta)\]

donde \(θ\) es el vector de parámetros desconocidos que se quieren estimar
y \(f(x_i; θ)\) es la densidad de probabilidad (o función de masa de
probabilidad) de la variable aleatoria \(x_i\) para un valor de \(θ\).

Es común aplicar logaritmo a la función de verosimilitud, pues de esta
forma se facilitan los cálculos manteniendo sus propiedades (dado que el
logaritmo es una función monótona y creciente):

\[\ell(\theta | x) = \sum_{i=1}^{n} \log(f(x_i|\theta))\]

Las siguientes métricas se basan en la log-verosimilitud para evaluar el
nivel de ajuste:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Razón de verosimilitud (o pseudo \(R^2\)): Esta métrica es utilzada
  cuando la variable de resultado es nominal u ordinal, de modo que el
  coeficiente de determinación no se puede aplicar como una medida de
  bondad de ajuste. Se define como:
\end{enumerate}

\[\rho = 1 - \frac{\ell(\hat{\beta})}{\ell(0)} \text{(Asumiendo que $\beta=0$ es un modelo nulo razonable)}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Criterio de Información de Akaike (AIC): Basado en la teoría de
  información, es una medida de la calidad del modelo que penaliza
  aquellos que son más complejos, lo que ayuda a prevenir el
  sobreajuste de los datos.
\end{enumerate}

\[AIC = -2\ell({\hat{\beta}}) + 2k\]

Con \(k\) el número de variables del modelo.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Criterio de Información Bayesiano (BIC): Este criterio penaliza la
  complejidad del modelo de manera más fuerte que el AIC, en función
  del número de parámetros del modelo y del tamaño de la muestra de
  datos. El BIC es más efectivo que el AIC para prevenir el
  sobreajuste del modelo, lo que significa que es más probable que
  seleccione un modelo más simple y generalizable.
\end{enumerate}

\[BIC = -2\ell(\hat{\beta}) + klog(n)\]

Con \(n\) el número de observaciones en el set de datos.

\hypertarget{errores-dentro-y-fuera-de-la-muestra}{%
\subsection{Errores dentro y fuera de la muestra}\label{errores-dentro-y-fuera-de-la-muestra}}

En general, se busca contruir modelos que sean generalizables a otros
datos fuera de aquellos que se utilizan para su construcción, para ello
se suele dividir el conjunto de datos en un set de \emph{calibración} y otro
de \emph{validación} para evaluar su capacidad de predicción.

En general, uno de los problemas que puede traer la excesiva
complejización de un modelo es la poca adaptabilidad a nuevos conjuntos
de datos, esto se conoce como sobreajuste (o overfitting), lo cual puede
ser detectado al comparar los errores de predicción entre el set de
calibración y validación:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/fitting.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/fitting} 

}

\caption{Error de calibración vs predicción}\label{fig:my-fig1}
\end{figure}

\hypertarget{divisiuxf3n-de-datos}{%
\subsection{División de datos}\label{divisiuxf3n-de-datos}}

La división de los datos en conjuntos de calibración y validación
depende de la estructura de los mismos. Por lo general se utiliza el 80\%
de los datos en calibración y el 20\% en validación. Si la estructura de
datos lo permite, podemos realizar crossvalidación ejecutamos múltiples
validaciones sobre diferentes muestras de prueba.

\hypertarget{validaciuxf3n-cruzada}{%
\subsection{Validación cruzada}\label{validaciuxf3n-cruzada}}

Algunos modelos, en especial en el mundo del Machine learning, requieren
la calibración de sus hiperparámetros para una mejor predicción. Para
ello existen múltiples técnicas, donde una de las más populares es la
validación cruzada (cross validation).

El método de validación cruzada comienza con la división del conjunto en
\(k\) subconjuntos (folds), dónde \(k-1\) servirán para calibrar el modelo,
mientras que el conjunto restante se utilizará como validación. Este
proceso se repite cambiando el conjunto de validación por cada uno de
los folds, buscando los hiperparámetros que optimizan el rendimiento
para cada una de las combinaciones. Finalmente, el valor de los
hiperparámetros será la media de sus valores para cada fold.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/cv.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/cv} 

}

\caption{Ejemplo de validación cruzada}\label{fig:my-fig2}
\end{figure}

\hypertarget{test-de-hipuxf3tesis}{%
\subsection{Test de hipótesis}\label{test-de-hipuxf3tesis}}

Además de la evaluación del ajuste del modelo a partir de métricas, es
posible hacer inferencias estadísticas sobre el modelo completo:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pruebas de bondad de ajuste: Este tipo de tests intentan responder
  la pregunta de si el modelo es lo suficientemente bueno para confiar
  en su rendimiento. Una de las pruebas más utilizadas es el test de
  \(\chi ^2\) de Pearson. Se busca testear la siguiente hipótesis nula:
\end{enumerate}

\(H_0: \text{El modelo describe correctamente los datos observados}\)

Para ello se separan los datos en \(k\) posible categorías y se construye
el estadístico \(\chi^2\)

\[\chi^2 = \sum_{i = 1}^{K} \frac{(y_i - \hat{y_i})^2}{\hat{y_i}}\]

Se rechaza la hipótesis nula si \(\chi^2 > \chi^{2}_{K-1, α}\).

Donde \(\mathbb{P}(\chi^2 > \chi^{2}_{K-1, α}) = α\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Comparación de modelos anidados: Supongamos que tenemos dos modelos
  A y B, diremos que el modelo B está anidado en el modelo A si el
  modelo B puede derivarse imponiendo algunas restricciones sobre los
  parámetros de A.
\end{enumerate}

En el contexto de regresión, por ejemplo un modelo \(y=a+bx\) está anidado
en otro modelo \(y=a+bx+cz\), solo basta con imponer que \(c=0\).

Para evaluar si vale la pena agregar más complejidad al modelo se
utiliza la prueba de Likelihood Ratio. De esta forma se puede determinar
si la mejora del rendimiento de un modelo en comparación al modelo
anidado se justifica en relación a la cantidad de nuevos parámetros.

La prueba de verosimilitud se basa en computar el estadístico del ratio:

\[LR = 2(LL_A - LL_B)\]

Supongamos que existen \(k\) nuevos parámetros que se agregan en el modelo
A.

Si \(LR > \chi^2(0.05, k)\), entonces el modelo A es mejor que el modelo B
(es decir, la adición de parámetros marca una diferencia
estadísticamente significativa al rendimiento del modelo.)

\hypertarget{usos-y-limitaciones-del-anuxe1lisis-de-regresiuxf3n}{%
\section{Usos y limitaciones del análisis de regresión}\label{usos-y-limitaciones-del-anuxe1lisis-de-regresiuxf3n}}

Una vez que se construye y se estima un modelo, el siguiente paso es
interpretar sus resultados. Es posible enfocarse en el \emph{aprendizaje}
sobre los parámetros retornados del modelo y cómo estos explican el
fenómeno a estudiar, como también es posible realizar un \emph{pronóstico} a
futuro del desempeño de las variables a predecir.

\hypertarget{aprendizaje-de-los-paruxe1metros}{%
\subsection{Aprendizaje de los parámetros}\label{aprendizaje-de-los-paruxe1metros}}

En general, la principal fuente de aprendizaje que provee un modelo de
regresión son los coeficientes calculados, los cuales entregan
información sobre el efecto de las variables independientes sobre lo que
se desea estudiar.

Dentro de las preguntas más importantes a responder se encuentran:

\begin{itemize}
\tightlist
\item
  ¿Poseen las variables del modelo el signo esperado?
\item
  ¿Son estadísticamente significativos?
\item
  ¿Es relevante la magnitud de su efecto?
\end{itemize}

Para responder a estas preguntas se hace necesario el uso de heramientas
estadsticas tales como \emph{t-test} para evaluaciones individuales o
\emph{F-test} para la evaluación de un conjunto de regresores.

\hypertarget{interpretaciuxf3n-de-los-coeficientes}{%
\subsection{Interpretación de los coeficientes}\label{interpretaciuxf3n-de-los-coeficientes}}

Supongamos un modelo lineal simple definido por \(y = 12 + 1.5x\), es de
toda lógica pensar que el efecto de \(x\) sobre \(y\) al incrementar en una
unidad es, en promedio, de \(1.5\). Sin embargo, esta afirmación sería
correcta \emph{sólo} en el caso de que se tengan buenas razones para creer
que \(x\) tiene un \emph{efecto causal} en \(y\).

Es importante recordar que los modelos de regresión solo indican la
correlación entre las variables dependientes con las independientes,
pero no necesariamente una relación causal entre ambas. Dentro de los
fenómenos que pueden explicar la correlación sin causalidad entre
variables, se encuentran los siguientes:

\begin{itemize}
\tightlist
\item
  Causalidad inversa: \(y\) causa \(x\)
\item
  Simultaneidad: \(y\) causa \(x\) y \(x\) causa \(y\)
\item
  Tercera variable: \(z\) causa \(x\) e \(y\)
\end{itemize}

Para averiguar qué es lo que hace que una variable independiente tenga
un efecto sobre la variable dependiente, se suele recurrir a un método
llamado \emph{análisis de mediación}, el cual consiste en la investigación
para examinar la relación entre una variable independiente y una
variable dependiente a través de una variable intermedia, conocida como
mediador. La mediación se produce cuando la relación entre la variable
independiente y la variable dependiente se explica por completo o
parcialmente por la influencia del mediador.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/Simple\_Mediation\_Model.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/Simple_Mediation_Model} 

}

\caption{Modelo de mediación}\label{fig:my-fig3}
\end{figure}

Es importante no confundir el análisis de mediación con un efecto de
tercera variable. Por ejemplo, si \(z\) causa \(x\) y a la vez \(z\) causa
\(y\), entonces estamos bajo un escenario de tercera variable. Sin
embargo, si \(x\) causa \(z\) y \(z\) causa \(y\), es posible afirmar que \(z\) es
una variable mediadora entre \(x\) e \(y\).

\hypertarget{pronuxf3sticos}{%
\subsection{Pronósticos}\label{pronuxf3sticos}}

La principal razón de realizar buenas predicciones con los modelos
construidos es la toma de decisiones mediante la evaluación de
resultados en diversos escenarios posibles. Bajo el enfoque de regresión
lineal, el pronóstico está dado por la esperanza del valor de la
variable dependiente, es decir \(\mathbb{E}[Y]\).

En el caso mas sencillo, el pronóstico está dado por
\(\mathbb{E}[Y] = \beta X\), si dentro del desarrollo del modelo se
decidiera utilizar una transformación funcional en el modelo, la
expresión del pronóstico cambiará. Por ejemplo, para el caso de una
regresión log-lineal, el término de error no desaparece del pronóstico,
debido a que se está calculando la esperanza de una función de una
variable aleatoria, luego el resultado que se obtiene es
\(\mathbb{E}[Y] = exp(\beta X + \frac{1}{2}S_ϵ^2)\), con \(S_{ϵ}^2\) la
varianza muestral de \(ϵ\).

\hypertarget{errores-de-pronuxf3stico}{%
\subsection{Errores de pronóstico}\label{errores-de-pronuxf3stico}}

El error de pronóstico contiene dos componentes: errores residuales
(debido a la dispersión de los datos) y errores de muestra. Se puede
escribir de la siguiente manera:

\[\text{sef}(x_0) = s\sqrt{x_0^T(X^TX)^{-1}x_0 + 1}\]

La variabilidad en los prónosticos dependerá de las variables
explicativas del modelo y de la muestra utilizada para estimar la forma
funcional de la variable dependiente. Esta variabilidad debe ser
considerada en la evaluación de escenarios al momento de tomar una
decisión.

\hypertarget{principios-generales-de-pronuxf3stico}{%
\subsection{Principios generales de pronóstico}\label{principios-generales-de-pronuxf3stico}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Incluir todas las variables que se esperan que contribuyan al
  pronóstico: A diferencia del enfoque anterior, no se está buscando
  el entendimiento de los parámetros sino predecir.
\item
  Evaluar si algunas variables pueden ser agregadas para crear
  índices: Puede suceder que varias variables capturan un mísmo
  fenómeno, y por ende causar ruido en la predicción. Para evitar
  esto, se puede construir una variable que las agrupe a todas en una
  sola componente.
\item
  Para variables importantes agregar interacciones: Puede que exista
  un efecto conjunto no observado.
\item
  Evaluar la inclusión de variables explicativas basadas en su signo
  esperado y significancia estadística:
\item
  Significativa y signo esperado: Mantener en el modelo.
\item
  No significativa y signo esperado: Mantener en el modelo.
\item
  Significativa y signo contrario: Puede causar ruido en el
  pronóstico, por lo que se debe quitar del modelo.
\item
  No significativa y signo contrario: Es posible que algo esté pasando
  con esa variable, es importante considerar trabajar con mas datos
  y/o variables.
\end{enumerate}

\hypertarget{limitaciones-de-los-modelos-de-regresiuxf3n}{%
\subsection{Limitaciones de los modelos de regresión}\label{limitaciones-de-los-modelos-de-regresiuxf3n}}

Debido a su simpleza, los modelos de regresión poseen ciertas
limitaciones provocadas por la muestra de datos utilizadas, las
variables escogidas para el modelo o por la naturaleza del método de
estimación de mínimos cuadrados. Algunos de los problemas más frecuentes
que se encuentran al trabajar con modelos de regresión son los
siguientes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Colinealidad}: Es la condición cuando uno o más regresores están
  correlacionados entre sí, dependiendo del grado de la misma se debe
  proceder de manera distinta. Si la correlación entre regresores es
  baja, no existe problema. Si la correlación es alta, se debe
  considerar eliminar una o más variables redundantes, reducir el
  número de variables en el modelo o transformar las variables para
  reducir su correlación. Finalmente, si existe \textbf{colinealidad
  perfecta} la matriz de regresores \(X\) no es invertible y el modelo
  no puede ser calculado.
\item
  Es posible requerir de \emph{causalidad} para afirmar que existe un
  efecto entre variables. Para determinar un efecto causal se pueden
  realizar experimentos, proponer modelos estructurales o utilizar
  variables instrumentales.
\item
  \emph{Heteroscedasticidad}: Es la correlación entre los términos de error
  y las variables del modelo. En otras palabras, la
  heteroscedasticidad significa que la dispersión de los errores en
  los datos es diferente para diferentes valores de las variables
  independientes. El estimador sigue siendo insesgado, pero se torna
  estadísticamente ineficiente. Para coregir heteroscedasticidad se
  utiliza mínimos cuadrados generalizados, ponderando según la
  magnitud del error de cada observación.
\item
  \emph{Autocorrelación}: Los errores estan correlacionados entre sí. Al
  igual que en el caso anterior el estimador sigue siendo insesgado,
  pero se torna estadísticamente ineficiente. Para enfrentar este
  fenómeno se recurre al uso de series de tiempo.
\end{enumerate}

\hypertarget{modelos-lineales-generalizados}{%
\subsection{Modelos lineales generalizados}\label{modelos-lineales-generalizados}}

Muchas veces los modelos lineales son muy restrictivos, para ello se
utilizan modelos lineales generalizados, es decir, mantiene la
linealidad en los parámetros, pero la respuesta del modelo puede tener
una forma funcional distinta.

Dentro de la familia de modelos generalizados se encuentran:

\begin{itemize}
\tightlist
\item
  Regresión de Poisson (La variable dependiente es positiva y
  discreta)
\item
  Regresión logística (Se busca predecir número de sucesos de un total
  de intentos)
\item
  Mínimos cuadrados generalizados
\end{itemize}

\hypertarget{alternativas-de-machine-learning-para-la-regresiuxf3n}{%
\section{Alternativas de Machine Learning para la regresión}\label{alternativas-de-machine-learning-para-la-regresiuxf3n}}

\hypertarget{quuxe9-es-machine-learning}{%
\subsection{¿Qué es Machine Learning?}\label{quuxe9-es-machine-learning}}

El concepto de Machine Learning se ha vuelto muy popular últimamente,
obteniendo mucha atención y usos en una gran cantidad de tareas, pero ¿A
qué nos referimos cuando hablamos de modelos de machine learning?

En terminos sencillos, el aprendizaje automático, o machine learning en
inglés, es una rama de la inteligencia artificial que se centra en el
desarrollo de algoritmos y modelos que permiten a las computadoras
aprender patrones y realizar tareas específicas sin ser programadas
explícitamente. En lugar de seguir instrucciones detalladas, los
sistemas de aprendizaje automático utilizan datos para mejorar su
rendimiento en una tarea particular a lo largo del tiempo. Este enfoque
permite a las máquinas adaptarse y mejorar su desempeño a medida que se
exponen a más información.

\hypertarget{la-regresiuxf3n-cuenta-como-un-modelo-de-ml}{%
\subsection{¿La regresión cuenta como un modelo de ML?}\label{la-regresiuxf3n-cuenta-como-un-modelo-de-ml}}

Si bien la regresión utiliza datos para aprender a partir de ellos, no
se suele considerar completamente un modelo de aprendizaje automático.
El hecho de tener que seleccionar las variables adecuadas, aplicar
transformaciones funcionales y tener que verificar el cumplimiento de
supuestos estadísticos hace que la regresión sea menos automático que lo
que normalmente se entiende como ML.

Un acercamiento más próximo a un modelo de ML se da al utilizar técnicas
de selección automática de variables como Ridge o LASSO. De todas
formas, los límites son difusos, en este curso se entenderá como ML a
cualquier modelo que pueda aprender automáticamente sobre el conjunto de
variables predictivas y sus formas funcionales.

\hypertarget{multivariate-adaptive-regression-splines-mars}{%
\subsection{Multivariate Adaptive Regression Splines (MARS)}\label{multivariate-adaptive-regression-splines-mars}}

MARS extiende OLS generando para cada variable independiente \(x\) una
función bisagra (hinge)
\(h(x, a) = \{ \max\{0, x-a\}, \max\{0, a-x\} \}\). De esta forma, un
modelo MARS genera una aproximación lineal por tramos.

Por ejemplo:

\[\text{OLS: }y = \beta_0 + \beta_1 x\]
\[\text{MARS: }y = \gamma_0 + \gamma_1 \max\{0, x-a\} + \gamma_2 \max\{0, a-x\}\]

Además, MARS puede incluir multiplicaciones entre dos o más funciones
bisagras para diferentes predictores, de tal manera que captura la
interacción entre estos.

Inicialmente, MARS busca el único punto en el rango de \(x\) donde dos
relaciones lineales diferentes entre \(y\) y \(x\) logran un error más
pequeño, este punto se convierte en el primer corte (knot) \(a\) del
modelo. Este procedimiento continúa hasta que se encuentren los demás
puntos de corte. Para evitar el sobreajuste, MARS elimina términos que
provoquen una pequeña contribución a la mejora del ajuste.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/mars.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/mars} 

}

\caption{Regresión MARS para distinto número de bisagras}\label{fig:mars}
\end{figure}

\hypertarget{k-nearest-neighbors-regression-knn}{%
\subsection{K Nearest Neighbors Regression (KNN)}\label{k-nearest-neighbors-regression-knn}}

En la regresión con KNN, el objetivo es predecir un valor numérico para
una variable dependiente basándose en los valores de las variables
independientes. A diferencia de la regresión lineal, que ajusta una
línea o superficie a los datos, KNN no realiza una aproximación
paramétrica. En cambio, hace predicciones basándose en la similitud
entre los puntos de datos.

Hay una serie de parámetros que deben ajustarse en KNN. Para decidir qué
funciona mejor, la práctica común es decidir basándose en el error de
predicción:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Vecinos más cercanos (Neighbors): \(k\) representa el número de
  vecinos más cercanos que se tomarán en cuenta para hacer una
  predicción. Se calcula la distancia entre el punto a predecir y los
  demás puntos del conjunto de entrenamiento.
\item
  Pesos (Weights): Para predecir el valor de la variable dependiente
  para un nuevo punto, se promedian los valores de la variable
  dependiente de los \(k\) vecinos más cercanos. Uno de los parámetros
  del modelo es el peso que se le da a los vecinos más cercanos.
\item
  Distancia: La medida de distancia más comúnmente utilizada en KNN es
  la distancia euclidiana, pero otras medidas también pueden ser
  empleadas según el tipo de datos y el problema específico
  (Manhattan, Coseno, Mahalanobis, etc.)
\end{enumerate}

\hypertarget{regression-trees}{%
\subsection{Regression trees}\label{regression-trees}}

Los arboles de regresión solo tienen sentido cuando el problema tiene
múltiples regresores, el objetivo es dividir el espacio de regresores en
subconjuntos y luego utilizar un modelo simple (constante) dentro de
cada región. Las particiones son secuenciales mediante divisiones
binarias generando una estructura de árbol.

El modelo busca cada valor distinto de cada variable de entrada para
encontrar el predictor y dividir el valor que divide los datos en dos.
regiones \(R_1\) y \(R_2\), con valores medios \(c_1\) y \(c_2\) para minimizar
la suma de los errores al cuadrado

\[\min SSE = \min \left\{ \sum_{i \in R_1}(y_i - c_1)^2 + \sum_{i \in R_2} (y_i - c_2)^2 \right\}\]

Es común agregar hiperparámetros de penalización para evitar el
sobreajuste.

\emph{Ejemplo:} Sea \(y = f(x_1, x_2)\). Los valores de \(x_1\) y \(x_2\) se pueden
representar en el plano mientras que los valores de \(y\) se representan
con colores (cuanto más grandes, más oscuros)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/tree1.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.4\linewidth]{images/tree1} 

}

\caption{Región de ejemplo}\label{fig:ej1}
\end{figure}

Luego, un arbol que representa la separación en regiones según \(x_1\) y
\(x_2\) es:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/tree2.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.2\linewidth]{images/tree2} 

}

\caption{Árbol de ejemplo}\label{fig:ej2}
\end{figure}

\hypertarget{bagging-y-random-forests}{%
\subsection{Bagging y Random forests}\label{bagging-y-random-forests}}

Un problema de los árboles de regresión es que son sensibles a pequeñas
variaciones en los datos. En general para solucionar este problema se
crean varios árboles y se promedian los resultados obtenidos, a esto se
le llama bosque aleatorio (random forest).

Para la construcción de este conjunto de arboles de regresión se hace
uso de una técnica llamada Bagging (*Bootstrap **Agg*regation), la
cual sigue los siguientes pasos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Bootstrap Sampling:} Se generan múltiples conjuntos de datos de
  entrenamiento mediante un muestreo con reemplazo, al que se conoce
  como bootstrap. Al hacerlo, algunos datos se pueden repetir en un
  conjunto de datos, mientras que otros pueden no aparecer en
  absoluto.
\item
  \emph{Construcción de árboles de regresión:} Se construyen múltiples
  árboles de decisión, generalmente utilizando el conjunto de datos de
  entrenamiento generado en cada iteración del bootstrap. Cada árbol
  se entrena de manera independiente y puede llegar a sobreajustarse a
  ciertos patrones del conjunto de datos de entrenamiento.
\item
  \emph{Promediar resultados:} Para hacer predicciones en un nuevo dato, se
  utiliza cada árbol de decisión para realizar una predicción,
  promediando los valores de cada árbol.
\end{enumerate}

La combinación de múltiples árboles entrenados de esta manera ayuda a
reducir la varianza y mejora la capacidad de generalización del modelo.
Además, el Random Forest introduce aleatoriedad adicional al seleccionar
un subconjunto aleatorio de características para dividir en cada nodo de
los árboles, lo que agrega más diversidad al conjunto de árboles.

\hypertarget{modelos-probabiluxedsticos}{%
\chapter{Modelos probabilísticos}\label{modelos-probabiluxedsticos}}

\hypertarget{introducciuxf3n}{%
\section{Introducción}\label{introducciuxf3n}}

Usualmente, y en el contexto de Marketing, interesa estudiar el
comportamiento de las personas, para realizar acciones estratégicas en
función de los aprendizajes adquiridos. Así, se pueden definir dos tipos
de enfoques a usar según distintos supuestos en el comportamiento de los
agentes (tomadores de decisiones):

\begin{itemize}
\item
  \emph{Enfoque Estructural}: Este enfoque asume que los los agentes se
  comportan de manera racional, tomando decisiones de modo de
  maximizar sus utilidades. Usualmente aparece cuando hay
  disponibilidad de largos volúmenes de datos.
\item
  \emph{Modelos Probabilísticos}: Este enfoque asume que los agentes se
  comportan en base a decisiones aleatorias. Usualmente aparece cuando
  se tiene información reducida y/o agregada respecto al
  comportamiento de los agentes en estudio.
\end{itemize}

En esta unidad, se estudiará el enfoque probabilístico.

\textbf{Metodología}

La metodología consiste en:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Determinar el problema de decisión a estudiar y la información
  requerida.
\item
  Identificar el comportamiento observable de interés a nivel
  individual.
\item
  Seleccionar la distribución de probabilidad que caracterice el
  comportamiento individual. Se consideran los parámetros de esta
  distribución, como características latentes a nivel individual.
\item
  Escoger la distribución que caracterice cómo las características
  latentes están distribuidas en la población. Se le llama
  distribución mixta o heterogénea. Típicamente, se denota con
  \(g(\theta)\).
\item
  Derivar la distribución agregada, o distribución observable, del
  comportamiento de interés.

  \[
  \begin{array}{cc}
  f(x) = \int f(x \mid \theta)\, g(\theta)\, d\theta & \text{, para el caso continuo.} \\
  p(x) = \sum_{i}f(x \mid \theta)\, \Pr(\theta = \theta_{i}) & \text{, para el caso discreto.}
  \end{array}
  \]
\item
  Estimar los parámetros del modelo (de la distribución mixta),
  mediante el ajuste de la distribución agregada a los datos
  observados.
\item
  Usar los resultados para tomar una decisión sobre el problema de
  marketing en cuestión.
\end{enumerate}

El enfoque de modelos probabilísticos permite abordar una gran cantidad
de problemas asociados al marketing, entre los cuales se considerarán:

\begin{itemize}
\item
  \emph{Duración}: Situaciones ligadas a la duración de una determinada
  conducta de un cliente, como por ejemplo el tiempo de permanencia en
  una compañía y el tiempo de adopción de un cierto producto
  innovador.
\item
  \emph{Conteo}: Situaciones ligadas al estudio de llegadas de clientes y
  contabilización de una determinada conducta, como por ejemplo el
  número de visitas a un portal web y la cantidad de productos
  comprados en una tienda de retail.
\item
  \emph{Elección}: Situaciones asociadas a las decisiones de elección de un
  determinado cliente, como por ejemplo el número de clientes que
  eligen responder una campaña publicitaria y la elección de cambiar o
  no de canal de televisión.
\end{itemize}

\hypertarget{modelos-de-duraciuxf3n}{%
\section{Modelos de Duración}\label{modelos-de-duraciuxf3n}}

En años recientes, las mejoras en las tecnologías de información han
dado como resultado un aumento en la disponibilidad de data acerca de
los individuos en determinadas situaciones de consumo. Esta tendencia se
relaciona íntimamente con el creciente deseo de los gerentes de
marketing respecto a utilizar esta data disponible para aprender de
manera exhaustiva sobre el comportamiento de los clientes. Muchos
analistas tratan de describir y predecir el comportamiento de los
consumidores usando variables observables, como lo son variables
transaccionales (monto gastado, tienda donde se adquirió un determinado
producto, fecha de la compra, etc.), como así también variables que
caracterizan a los individuos (edad, nivel socio-económico, estado
civil, etc.). A partir de esta información es posible aplicar modelos de
regresión lineal o árboles de decisión, con el objetivo de poder
proyectar comportamientos, o bien rebatir hipótesis que previamente se
tenían respecto a un escenario determinado.

En este capítulo, se considera un enfoque distinto al anterior, en el
cual las decisiones de los individuos se desprenden de un comportamiento
\textbf{aleatorio}, en que las decisiones no dependen únicamente de variables
descriptivas del modelo, sino que también provienen del resultado de un
proceso estocástico no observable que opera intrínsecamente en los
individuos. Es decir, la asunción que el comportamiento se desprende de
una distribución de probabilidades que puede variar dependiendo del
modelo a estimar y de la complejidad del mismo. Alternativamente, se
puede considerar el enfoque racionalista que contempla a los individios
que siempre actúan racionalmente, lo que, de acuerdo a la experiencia
empírica, no se cumple siempre.

\textbf{Ejemplo 1}: Supongamos que un cliente hizo 2 compras el año pasado de
nuestro producto. ¿Esto implica inmediatamente que el consumidor
mantendrá ese patrón y este año volverá a ese nivel de consumo? ¿O
existe alguna posibilidad de que el cliente incremente o disminuya su
consumo? ¿Cuál es el proceso que hay detrás?

En lo que sigue, se considera 3 tipos de modelos de duración a estimar:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Modelos de duración en tiempo discreto.}
\item
  \textbf{Modelos de duración en tiempo continuo sin dependencia en la
  duración.}
\item
  \textbf{Modelos de duración en tiempo continuo con dependencia en la
  duración.}
\end{enumerate}

\hypertarget{modelos-de-duraciuxf3n-de-tiempo-discreto}{%
\subsection{Modelos de duración de tiempo discreto}\label{modelos-de-duraciuxf3n-de-tiempo-discreto}}

Como ejemplo, se tiene el siguiente escenario: a través de una propuesta
de valor atractiva, una empresa consigue un cliente. ¿Durante cuántos
periodos estará afiliado a la compañía?

Se considera que cada periodo se puede cuantificar en términos discretos
(días, semanas, meses, años). Algunos ejemplos a considerar:

\begin{itemize}
\item
  Un usuario descarga una aplicación para su teléfono inteligente.
  ¿Por cuántos meses la utilizará?
\item
  Adquirimos un cliente en un banco. ¿Durante cuántos años permanecerá
  como cliente?
\item
  Un cliente se suscribe a un plan telefónico o de internet. ¿Por
  cuántos periodos se mantendrá suscrito?
\end{itemize}

\hypertarget{modelo-geomuxe9trico-desplazado}{%
\subsubsection*{Modelo Geométrico Desplazado}\label{modelo-geomuxe9trico-desplazado}}
\addcontentsline{toc}{subsubsection}{Modelo Geométrico Desplazado}

Como ejemplo, se asume que se tiene una cartera de clientes que van
abandonando la relación comercial para \textbf{nunca más retomarla} en
cualquier periodo definido. Al final de cada periodo, un cliente decide
de manera aleatoria si continúa afiliado. De acuerdo a un proceso de
Bernoulli, hay una probabilidad \(\theta\) de cancelar la relación
comercial con la empresa y con el complemento \(1-\theta\) decide su
permanencia.

Para cada individuo, se asume que la probabilidad con la que decide no
cambia en el tiempo. Como primer acercamiento, se asume que dicha
probabilidad es igual e idénticamente distribuida (iid). Sea T la
variable aleatoria relativa a la duración de la relación comercial entre
el cliente y la compañía, es decir la variable que describe el instante
en el cual esta relación se acaba. De acuerdo a la descripción anterior,
la variable aleatoria T sigue una distribución Geométrica Desplazada
(sG) con parámetro \(\theta\), es decir, el comportamiento de los
individuos puede ser descrito formalmente de acuerdo a la siguiente
relación:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Probabilidad de que un individuo cualquiera abandone la relación
  comercial exactamente en el periodo t:

  \[P(T=t| \theta) = \theta (1 - \theta)^{t-1}\]
\item
  Probabilidad de que un individuo cualquiera abandone la relación
  comercial en un periodo posterior al periodo t:

  \[P(T>t \;|\; \theta) = (1 - \theta)^{t}\]
\end{enumerate}

No es muy difícil aplicar un modelamiento a partir de lo anterior para
intentar dilucidar de qué forma se debería comportar un determinado
grupo de individuos a partir de la data transaccional que se tiene.

\textbf{Ejemplo:} Se considera una cohorte inicial de 1000 clientes (indexado
por el número 0). Se toma el supuesto de que, año a año, un determinado
número de clientes se retira del negocio por razones que se desconocen a
priori, pero que provienen de un proceso estocástico en el que cada
cliente en forma independiente toma la decisión de permanecer o
abandonar a partir del lanzamiento de una moneda (Bernoulli). Esto es,
con probabilidad \(\theta\) abandona y con probabilidad \(1 - \theta\)
permanece en la compañía. La data histórica se presenta a continuación:

\begin{longtable}[]{@{}cccc@{}}
\toprule
Año & \# de Clientes & \% de Permanencia & \% de Retención \\
\midrule
\endhead
0 & 1000 & 100\% & - \\
1 & 631 & 63\% & 63\% \\
2 & 468 & 47\% & 74\% \\
3 & 382 & 38\% & 82\% \\
4 & 326 & 33\% & 85\% \\
5 & 289 & 29\% & 89\% \\
6 & 262 & 26\% & 91\% \\
7 & 241 & 24\% & 92\% \\
\bottomrule
\end{longtable}

Donde el \% de Retención como el porcentaje de clientes que se mantuvo en
la relación comercial respecto al periodo anterior.

Sin embargo, aún no se desconoce el valor de \(\theta\) (es un parámetro
poblacional). Dicho valor se estima mediante el método de máxima
verosimilitud, que busca encontrar el valor del parámetro óptimo de
acuerdo a los datos observados y asumiendo independencia entre las
muestras:

\begin{itemize}
\tightlist
\item
  Densidad de probabilidades conjunta:
\end{itemize}

\[f(x_1,x_2,...,x_n|\theta) = f(x_1|\theta) \cdot f(x_2|\theta) \cdot ... \cdot f(x_n|\theta)\]

\begin{itemize}
\tightlist
\item
  Función de verosimilitud:
\end{itemize}

\[
\begin{aligned}
L(\theta)  &= \left\{\prod_{t=1}^{\tau=7} P(T=t \mid \theta)^{\,n_t}\right\}\; P(T>\tau \mid \theta)^{\,n_{\tau}} \\  &= \left\{\prod_{t=1}^{\tau=7} \big[\theta(1-\theta)^{t-1}\big]^{\,n_t}\right\}\; \big[(1-\theta)^{\tau}\big]^{\,n_{\tau}}
\end{aligned}
\] Notar que \(n_\tau\) es el número de clientes activos después del
máximo tiempo observable \(\tau\), \(n_t\) es el número de abandonos (si hay
369 abandonos, se multiplica 369 veces), y \(x_i\) el año. A partir de
esto y de la data disponible, las contribuciones a la verosimilitud son
las siguientes (asumiendo como modelo de comportamiento la distribución
geométrica desplazada)

\begin{longtable}[]{@{}llll@{}}
\toprule
Año & \# de Clientes & \# de Abandonos & Pr \\
\midrule
\endhead
0 & 1000 & - & - \\
1 & 631 & 369 & \(P(T=1\|\theta) = \theta^{369}\) \\
2 & 468 & 163 & \(P(T=2\|\theta) = ((1 - \theta)^{(2-1)} \cdot \theta)^{163}\) \\
3 & 382 & 86 & \(P(T=3\|\theta) = ((1 - \theta)^{(3-1)} \cdot \theta)^{86}\) \\
4 & 326 & 56 & \(P(T=4\|\theta) = ((1 - \theta)^{(4-1)} \cdot \theta)^{56}\) \\
5 & 289 & 37 & \(P(T=5\|\theta) = ((1 - \theta)^{(5-1)} \cdot \theta)^{37}\) \\
6 & 262 & 27 & \(P(T=6\|\theta) = ((1 - \theta)^{(6-1)} \cdot \theta)^{27}\) \\
7 & 241 & 21 & \(P(T=7\|\theta) = ((1 - \theta)^{(7-1)} \cdot \theta)^{21}\) \\
\textgreater7 & - & - & \(P(T>7\|\theta) = ((1-\theta)^7)^{241}\) \\
\bottomrule
\end{longtable}

Dado que maximizar un producto es complicado, se aplica logaritmo a lo
anterior, de modo de construir la función de log verosimilitud:

\begin{itemize}
\tightlist
\item
  Función de log verosimilitud:
\end{itemize}

\[
\begin{aligned}
\hat{\ell}(\theta)  &= \sum_{t=1}^{\tau} n_t \,\ln P(T=t \mid \theta)\;+\; n_{\tau}\,\ln P(T>\tau \mid \theta) \\  &= \sum_{t=1}^{\tau} n_t \big[\ln \theta + (t-1)\ln(1-\theta)\big]\;+\;n_{\tau}\,\tau\ln(1-\theta) \end{aligned}
\] Con lo anterior, es sencillo maximizar la función de log
verosimilitud para un \(\theta\) desconocido utilizando un paquete
estadístico como R, con lo que se tiene:

\[
\begin{aligned}
\hat{\theta} &= 0, 226027 \\
\hat{l} &= -1794,62
\end{aligned}
\quad \label{eq:homogeneo}
\]El modelo presentado, si bien permite tomar medidas de gestión a
partir de un modelo sencillo, es poco realista, pues se asume que la
población posee igual probabilidad de abandono.

Una manera de incluir mayor complejidad al modelo y hacerlo más robusto,
se asume que la población no es homogénea, sino que existen segmentos de
individuos quienes al ser agrupados, presentan un comportamiento similar
(heterogéneo). La forma más sencilla de modelar esto es asumiendo que la
población presenta 2 patrones de comportamiento o 2 segmentos. Para un
segmento de individuos, la decisión de abandonar o permanecer se
identifica a partir de un parámetro \(\theta_1\) (del mismo modo que en el
caso anterior) y, para el otro segmento, la decisión se determina a
partir de un parámetro \(\theta_2\) distinto de \(\theta_1\).

Formalmente, las relaciones que describen de mejor manera esto son las
siguientes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Probabilidad de que un individuo cualquiera abandone la relación
  comercial exactamente en el periodo \(t\) en una población con 2
  segmentos:
\end{enumerate}

\[P(T=t|\theta_1, \theta_2, \pi)= \theta_1 (1-\theta_1)^{t-1} \pi + \theta_2(1-\theta_2)^{t-1}(1-\pi)\]
2. Probabilidad de que un individuo cualquiera abandone la relación
comercial en un periodo posterior al periodo \(t\) en una población con 2
segmentos:

\[P(T>t|\theta_1, \theta_2, \pi)= (1-\theta_1)^{t} \pi + (1-\theta_2)^{t}(1-\pi)\]

En el modelo anterior, \(\pi\) representa el porcentaje de la población
que pertenece al segmento 1, de tal forma que su complemento \(1-\pi\)
representa el porcentaje de la población que pertenece al segmento 2.
Cabe mencionar que se puede expandir a más segmentos, siempre que
sepamos su proporción \(\pi\).

\hypertarget{modelo-beta-geomuxe9trico-desplazado}{%
\subsubsection*{Modelo Beta Geométrico desplazado}\label{modelo-beta-geomuxe9trico-desplazado}}
\addcontentsline{toc}{subsubsection}{Modelo Beta Geométrico desplazado}

Los modelos anteriores funcionan bien cuando la población se comporta de
manera distinta entre clases latentes, y similar al interior de cada
clase latente. Sin embargo, puede ser mucho más realista e interesante
asumir que existe una heterogeneidad continua en la población, es decir,
que existe un número infinito de segmentos (o al menos tendiente a
infinito) de manera de capturar todas las preferencias individuales de
cada miembro de la población considerada.

Para estos propósitos, ya no asumiremos que la probabilidad de abandono
\(\theta\) sigue una distribución discreta de Bernoulli (éxito-fracaso),
sino que asumiremos que el parámetro proviene de una distribución
continua \(\text{Beta}\) de parámetros \(\alpha\) y \(\beta\).

Por tanto, es posible calcular las probabilidades antes presentadas en
forma análoga, aplicando el enfoque antes mencionado (probabilidades
totales):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Probabilidad de que un individuo cualquiera abandone la relación
  comercial exactamente en el periodo t:

  \[P(T=t|\alpha,\beta) = \int_0^1 P(T=t|\theta)B(\theta|\alpha,\beta)d\theta\]

  Donde:
\end{enumerate}

\[B(\theta|\alpha,\beta) = \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}\]

\[B(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}\]
2. Probabilidad de que un individuo cualquiera abandone la relación
comercial en un periodo posterior al periodo t:

\[P(T>t|\alpha,\beta) = \int_0^1 (T>t|\theta)B(\theta|\alpha,\beta)d\theta\]
Al desarrollar la primera integral antes mencionada, y reconociendo las
relaciones de la distribución \emph{Beta}, se tiene que:

\[
\begin{aligned} P(T = t \mid \alpha, \beta) &= \int_0^1 \left( \theta(1-\theta)^{t-1} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) d\theta \\ &= \frac{1}{B(\alpha, \beta)} \int_0^1 (\theta \cdot \theta^{\alpha-1}) \cdot ((1-\theta)^{t-1} \cdot (1-\theta)^{\beta-1}) d\theta \\ &= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha} (1-\theta)^{t+\beta-2} d\theta \\ &= \frac{B(\alpha+1, t+\beta-1)}{B(\alpha, \beta)} \end{aligned}
\]

Notar que se usa indistintamente el \(B(\alpha,\beta)\) para hacer alusión
tanto a la \textbf{función} como a la \textbf{distribución Beta}. Bajo ninguna
circunstancia dichos objetos son iguales.

El desarrollo de la segunda integral es:

\[
\begin{aligned}
P(T > t \mid \alpha, \beta) &= \int_0^1 (1-\theta)^{t} \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) d\theta \\
&= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha-1} \cdot ((1-\theta)^{t} \cdot (1-\theta)^{\beta-1}) d\theta \\
&= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha-1} (1-\theta)^{t+\beta-1} d\theta \\
&= \frac{B(\alpha, t+\beta)}{B(\alpha, \beta)}
\end{aligned}
\]

\textbf{Ejemplo:} Considerando la misma situación que se presentó en el
ejemplo anterior (clientes que año a año abandonan la relación
comercial), pero ahora asumiendo que existe un comportamiento
heterogéneo en la población, es posible reconocer que existe una
recursividad en la fórmula del cálculo de la probabilidad de abandono en
cada período:

\[
\begin{aligned}
\text{Caso Base (t=1):}& \\
P(T=1 \mid \alpha, \beta) &= \frac{B(\alpha+1, \beta)}{B(\alpha, \beta)} \\
&= \frac{\frac{\Gamma(\alpha+1)\Gamma(\beta)}{\Gamma(\alpha+1+\beta)}}{\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}} \\
&= \frac{\Gamma(\alpha+1)}{\Gamma(\alpha)} \cdot \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha+\beta+1)} \\
&= \frac{\alpha\Gamma(\alpha)}{\Gamma(\alpha)} \cdot \frac{\Gamma(\alpha+\beta)}{(\alpha+\beta)\Gamma(\alpha+\beta)} \\
&= \frac{\alpha}{\alpha+\beta} \\
\\
\text{Paso Recursivo (t > 1):}& \\
\frac{P(T=t \mid \alpha, \beta)}{P(T=t-1 \mid \alpha, \beta)} &= \frac{B(\alpha+1, t+\beta-1)}{B(\alpha+1, t+\beta-2)} \\
&= \frac{\frac{\Gamma(\alpha+1)\Gamma(t+\beta-1)}{\Gamma(\alpha+t+\beta)}}{\frac{\Gamma(\alpha+1)\Gamma(t+\beta-2)}{\Gamma(\alpha+t+\beta-1)}} \\
&= \frac{\Gamma(t+\beta-1)}{\Gamma(t+\beta-2)} \cdot \frac{\Gamma(\alpha+t+\beta-1)}{\Gamma(\alpha+t+\beta)} \\
&= \frac{(t+\beta-2)\Gamma(t+\beta-2)}{\Gamma(t+\beta-2)} \cdot \frac{\Gamma(\alpha+t+\beta-1)}{(\alpha+t+\beta-1)\Gamma(\alpha+t+\beta-1)} \\
&= \frac{\beta+t-2}{\alpha+\beta+t-1} \\
&= P(T=t-1 \mid \alpha, \beta) \frac{\beta+t-2}{\alpha+\beta+t-1}
\end{aligned}
\]

Modelo que al ser evaluado, da el siguiente resultado:

\[
\begin{array}{c}
\hat{\alpha} = 0,7041\\
\hat{\beta}= 1,1820\\
\hat{l} = -1680,27
\end{array}
\quad \label{eq:heterogeneo}
\]

Notar que existe una notoria diferencia en cuanto al valor de la log
verosimilitud obtenida por el modelo \eqref{eq:heterogeneo} respecto al
modelo \eqref{eq:homogeneo}. Si bien esto indica una mejora del modelo,
es necesario realizar la comparación en base a métricas de evaluación
mas precisas (AIC, BIC, etc.)

\hypertarget{modelos-de-duraciuxf3n-en-tiempo-continuo-sin-dependencia-en-la-duraciuxf3n}{%
\subsection{Modelos de duración en tiempo continuo sin dependencia en la duración}\label{modelos-de-duraciuxf3n-en-tiempo-continuo-sin-dependencia-en-la-duraciuxf3n}}

Para algunos modelos, medir el tiempo como si fueran períodos discretos
puede ser un buena aproximación de acuerdo a los objetivos del análisis
que se desea llevar a cabo.

En otros casos, puede ser en cambio más útil considerar el tiempo como
una variable continua, debido a que podría interesar medir la ocurrencia
de un suceso de manera más exacta. Algunos casos relativos a este
enfoque son:

\begin{itemize}
\item
  Tiempos de respuesta a una campaña promocional de marketing directo.
\item
  Tiempo entre visitas a nuestro website.
\item
  Tiempos entre llamadas en un call center.
\item
  Tiempos de operación en la industria de servicios.
\end{itemize}

Al igual que en el caso de los modelos en tiempo discreto, lo que
interesa estudiar es poder implementar un modelo que tenga una forma
funcional flexible para ser trabajada y modificada fácilmente, que logre
ajustar a la data histórica que se tiene y proyectar el comportamiento
futuro de los clientes, es decir, que sea un buen modelo predictivo para
tomar acciones en función de aquello.

\hypertarget{modelo-exponencial}{%
\subsubsection*{Modelo Exponencial}\label{modelo-exponencial}}
\addcontentsline{toc}{subsubsection}{Modelo Exponencial}

Se puede medir el tiempo que pasa desde que se lanza un producto hasta
que el consumidor decide adquirirlo. Existen muchos factores externos
que determinan esta decisión: exposición a publicidad, número de visitas
a la tienda, llamadas recibidas por call center, entre otras. Nuevamente
se asume que el comportamiento es aleatorio, es decir, que los
consumidores deciden el momento en el cuál van a consumir a partir de
una distribución de probabilidades.

Esto puede verse con una distribución exponencial, con la variable
aleatoria \(t\) definida como el tiempo en que un cliente va a consumir el
producto por primera vez. Se asume que esta variable está
exponencialmente distribuida con una tasa \(\lambda\). De esta forma, se
tiene que el comportamiento de los consumidores puede verse como:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Probabilidad de que ocurra en \(t\) o antes:

  \[P(T \leq t) = 1 - e^{-\lambda t}\]
\item
  Probabilidad de que ocurra después de \(t\):

  \[
  P(T > t) = e^{-\lambda t}
  \]
\end{enumerate}

Por tanto, su función de verosimilitud para un tiempo continuo
corresponde a:

\[
\begin{aligned}
L(\theta) &= \prod_{i \in A} f(t_i | \theta) \prod_{i \notin A} (1 - P(T \leq t)) \\
&= \prod_{i \in A} (\theta e^{-\theta t_i}) \prod_{i \notin A} (e^{-\theta \tau_i})
\end{aligned}
\]

Acá \(f(t_i \mid \theta)\) es la función de densidad, es decir, la
derivada de la función de probabilidad acumulada \(P(T \leq t)\). El
índice \(i\) corresponde a cada cliente y \(A\) es el conjunto de clientes
que adquiere un producto o servicio. El parámetro \(\tau\), al igual que
en el modelo de duración discreta, corresponde al tiempo máximo
observado.

Ahora bien, esto inmediatamente deja en evidencia una limitante a este
modelo: para un \(t\) muy grande, todos los consumidores van a tener un
caso de éxito (Recordar que \(\text{lim } e^{-t} = 0\)), lo cual no es una
situación del todo realista. Es necesario, en consecuencia, imponer que
existe una fracción de clientes dentro de la muestra considerada que
nunca probará el producto (caso de éxito) y, así, es posible solucionar
la limitante encontrada (2 clases latentes).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Segmento que prueba: Tamaño \(\pi\):

  \[
  \begin{array}{c}
  \lambda = \theta\\
  \Rightarrow P(T \leq t) = 1 - e^{-\theta t}
  \end{array}
  \]
\item
  Segmento que no prueba: Tamaño (\(1-\pi\)):

  \[
  \begin{array}{c}
  \lambda = 0\\
  \Rightarrow P(T \leq t) = 0
  \end{array}
  \]
\end{enumerate}

Luego, la probabilidad total será:

\[
\begin{array}{c}
P(T \leq t) = P(T \leq t | \text{Prueba}) P(\text{Prueba}) + P(T \leq t | \text{No Prueba}) P(\text{No Prueba}) \\
= 1 - e^{-\theta t}\pi
\end{array}
\]

Es importante notar que si bien el modelo describe probabilidades en
tiempo continuo, la data aún se presenta y obtiene en tiempo discreto.
Incorporando esto, es posible construir la función de log verosimilitud
calculando las probabilidades de adopción del producto entre los límites
del intervalo temporal definido por el periodo de medición, es decir:

\[P(t_0 \leq T \leq t_1) = F(t_1) - F(t_0)\] Cconsiderando n periodos
discretos para el cálculo, la log-verosimilitud es:

\[LL(\pi,\theta|\text{data}) = N_1 ln[P(1\leq T \leq 2)] + ... + (N_{panel} - \sum_{i=1}^{n}N_i)ln[P(T>n)]\]
Adicionalmente, es de interés calcular los valores predichos por el
modelo, de modo de realizar predicciones futuras. \(F(t)\) representa la
probabilidad que un cliente escogido aleatoriamente pruebe el producto
en \(t\), tal que \(t=0\) corresponde al instante de lanzamiento del
producto. La estimación del futuro se puede hacer a través de la
esperanza:

\[\mathbb{E}[T(t)] = N_{\text{panel }} \cdot \hat{F}(t) \]

Antes de avanzar, es importante aclarar la distinción de un modelo \emph{sin
dependencia en la duración}. Esto se puede explicar con la propiedad
fundamental de la distribución exponencial:

\textbf{Propiedad fundamental:} La distribución exponencial no tiene memoria,
es decir, poseer información de que un elemento ha sobrevivido un tiempo
's' hasta este momento no modifica la probabilidad de que sobreviva un
periodo \(t\) más. Es decir la probabilidad de que ocurra un suceso no
depende del tiempo en que aún no ha ocurrido. Se puede demostrar
matemáticamente:

\[P(T > s + t|T>s) = \frac{P(T> s+t)}{P(T> s)} = \frac{1-P(T \leq s+t)}{1-P(T \leq s)}= \frac{e^{-\lambda(s+t)}}{e^{-\lambda s}} = e^{-\lambda t}\]

\hypertarget{modelo-gamma-exponencial}{%
\subsubsection{Modelo Gamma Exponencial}\label{modelo-gamma-exponencial}}

Análogamente al caso de duración discreta, hay casos en que el
comportamiento de la población heterogéneo. Esto busca complejizar la
suposición que antes se hizo al considerar un grupo de clientes que
nunca consume. Por tanto, el modelo con heterogeneidad no observada
ahora considerará que la tasa de prueba \(\lambda\) se distribuye \emph{Gamma}
en la población:

\[g(\lambda) = \frac{\alpha^r \lambda^{r-1} e^{-\alpha \lambda}}{\Gamma(r)}\]Donde
\(r\) es un parámetro de forma mide la morfología. Con \(r=1\) se reduce a
una exponencial y, a medida que crece, su la forma se vuelve más
simétrica y similar a una normal. Por otro lado, \(\alpha\) es un
parámetro de escala que estira la distribución a medida que crece, o la
comprime en la medida que decrece.

Al incorporar la heterogeneidad mencionada, la probabilidad que un
cliente adquiera un producto antes de un tiempo \(t\) es la siguiente:

\[ 
\begin{aligned} P(T\leq t) &= \int_{0}^{\infty} P(T \leq t|\lambda) g(\lambda)d \lambda \\ &= \int_{0}^{\infty} (1 - e^{-\lambda t}) \left( \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} \right) d\lambda \\ &= \int_{0}^{\infty} \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} d\lambda - \int_{0}^{\infty} e^{-\lambda t} \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} d\lambda \\ &= 1 - \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \frac{\lambda^{r-1} e^{-\lambda(\alpha+t)} \Gamma(r) (\alpha + t)^r}{\Gamma(r) (\alpha + t)^r} d\lambda \\ &= 1 - \frac{\alpha^r}{\Gamma(r)} \frac{\Gamma(r)}{(\alpha+t)^r} \\ &= 1 - \left(\frac{\alpha}{\alpha + t}\right)^r \end{aligned} \]

Donde en el cuarto paso se agregó un 1 en forma de
\(\frac{\Gamma(r) (\alpha + t)^r}{\Gamma(r) (\alpha + t)^r}\) para obtener
una función de acumulación de dominio completo para la distribución
gamma (lo que al integrarlo da 1).

\hypertarget{modelos-de-duraciuxf3n-en-tiempo-continuo-con-dependencia-en-la-duraciuxf3n}{%
\subsection{Modelos de duración en tiempo continuo con dependencia en la duración}\label{modelos-de-duraciuxf3n-en-tiempo-continuo-con-dependencia-en-la-duraciuxf3n}}

Otra de las grandes limitantes del modelo \emph{Exponencial} es que posee
pérdida de memoria. En algunas aplicacioens se requiere incorporar esta
distinción, es decir, la probabilidad de que un evento ocurra dado que
hasta este momento no ha ocurrido. Esto último se conoce como \emph{tasa de
riesgo} o \emph{hazard rate}:

\[h(t) = \frac{f(t)}{1 - F(t)}\]

Donde

\[
\begin{aligned}
f(t) &= \frac{d}{dt} F(t) \\
&= -c\lambda t^{c-1} e^{-\lambda t^c}
\end{aligned}
\]

Gráficamente, la tasa de riesgo se comporta de la siguiente manera:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/tasa\_riesgo.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/tasa_riesgo} 

}

\caption{Ejemplos de tasas de riesgo}\label{fig:my-fig}
\end{figure}

\FloatBarrier

En el primer caso, la intuición es que si una persona no ha respondido a
un e-mail, cada vez es menos probable que lo responda, pues en general
las personas tienden a ignorar los correos con una antigüedad superior a
un par de días. En la llegada de un bus - si bien en ramos pasados se ha
modelado con una exponencial - se asume que a medida que más se demora
en llegar al paradero, cada vez la espera debe ser menor, pues tarde o
temprano este deberá llegar. Con respecto al divorcio, es más probable
que en el caso de haber, este no ocurra inmediatamente y, con menor
probabilidad, ocurrirá en las etapas tardías de la vida del matrimonio.
Con respecto a la falla del disco duro, este tiene un comportamiento no
lineal (cuadrático). Sus mayores posibilidades de fallar se dan al
principio y al final de su vida útil esperada.

A partir de la tasa de riesgo, se puede definir unívocamente la
distribución de una variable aleatoria no negativa a través de la
siguiente integral:

\[F(t) = 1 - exp \left( -\int_{0}^{t} h(u)du \right)\]Este concepto será
útil para definir los modelos de duración en tiempo continuo en que la
duración sí es un factor relevante

\hypertarget{modelo-weibull}{%
\subsubsection*{Modelo Weibull}\label{modelo-weibull}}
\addcontentsline{toc}{subsubsection}{Modelo Weibull}

A pesar de las generalizaciones de las funciones de tasas de riesgo para
generar modelos de tiempo de ocurrencia, el foco será puesto en la
distribución Weibull, debido a que es fácil de trabajar y entrega una
fórmula cerrada muy similar a la de la distribución exponencial. Se
tiene que, para la misma variable aleatoria \(T\) que se definió en la
sección anterior, la probabilidad de ocurrencia de que un cliente pruebe
nuestro producto en un tiempo inferior a t será:

\[F(t) = P(T \leq t) = 1 - e^{-\lambda t ^c}\] Y la tasa de riesgo
asociada a esta distribución:

\[h(t) = c \lambda t ^{c-1}\]El primer parámetro \(\lambda\) que compone
la fórmula es un parámetro de escala, mientras que el parámetro c es el
parámetro de forma. Es importante notar que para \(c=1\), la distribución
se convierte en la distribución exponencial, por lo que se puede decir
que la distribución Weibull es una generalización de la exponencial.
Notar que para \(c=1\), la tasa de riesgo es constante, lo que es
consistente con la propiedad de pérdida de memoria de la distribución
exponencial.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/tasa\_riesgo\_c.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/tasa_riesgo_c} 

}

\caption{Ejemplos de tasas de riesgo para distintos valores de c}\label{fig:riesgoc}
\end{figure}

\FloatBarrier

En la distribución de Weibull generalizada la propiedad de pérdida de
memoria no aplica como en el caso de la exponencial, es decir, la
probabilidad de ocurrencia varía a medida que pasa el tiempo:

\[P(T > s + t|T>s) = \frac{P(T> s+t)}{P(T> s)} = \frac{1-P(T \leq s+t)}{1-P(T \leq s)}= \frac{e^{-\lambda(s+t)^c}}{e^{-\lambda s^c}} \]

\hypertarget{modelo-gamma-weibull}{%
\subsubsection*{Modelo Gamma Weibull}\label{modelo-gamma-weibull}}
\addcontentsline{toc}{subsubsection}{Modelo Gamma Weibull}

Una de las propiedades interesantes de la distribución Weibull, es que
es sencillo introducir heterogeneidad sobre los parámetros y, de esa
forma, capturar los distintos posibles comportamientos de la población.

Al igual que en el modelo Gamma-Exponencial, asumiremos que el parámetro
de escala \(\alpha\) está distribuido \(\text{Gamma}(\alpha,r)\) en la
población. La probabilidad de ocurrencia del consumo de los clientes se
puede modelar a través de la

\[
\begin{aligned} P(T \leq t \mid \alpha,r, c) &= \int_{0}^{\infty} \frac{(1 - e^{-\lambda t^c}) \alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda \\ &= \int_{0}^{\infty} \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda - \int_{0}^{\infty} \frac{e^{-\lambda t^c} \alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda \\ &= 1 - \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{r-1}e^{-\lambda(\alpha + t^c)} d\lambda \\ &= 1 - \frac{\alpha^r}{\Gamma(r)} \frac{\Gamma(r)}{(\alpha + t^c)^r} \\ &= 1 - \left(\frac{\alpha}{\alpha + t^c}\right)^r \end{aligned}
\]

Si \(c=1\), se recupera el modelo de duración Gamma-Exponencial.

\hypertarget{modelos-de-conteo}{%
\section{Modelos de Conteo}\label{modelos-de-conteo}}

Permiten modelar cuántas veces los consumidores incurrirán en un
comportamiento determinado en un período de tiempo (ejemplo: problema de
exposición publicitaria).

Algunas medidas de efectividad son:

\begin{itemize}
\item
  \textbf{Alcance:} Proporción de la población expuesta al evento al menos
  una vez durante el período: \(1 − P(X_t = 0)\).
\item
  \textbf{Frecuencia promedio:} número promedio de exposiciones en el
  período entre aquellos que han experimentado el evento (por ejemplo,
  ver la valla publicitaria). \[\frac{\mathbb{E}(X_t)}{1-P(X_t =0)}\]
\item
  \textbf{Puntos de rating brutos (GRPs):} número promedio de exposiciones
  por cada 100 personas.
\end{itemize}

\[100 \cdot \mathbb{E}(X_t)\]

El fenómeno que se quiere estudiar es el número de veces que cada
individuo ve la valla publicitaria. Para ello, se define el modelo
individual \emph{Poisson}.

\[
P(N_t=m|\lambda) = \frac{(\lambda t)^m e^{-\lambda t}}{m!} \quad \label{eq:poisson}
\]

lo cual corresponde a la probabilidad de que el número de exposiciones
sea \(m\) en un intervalo de largo \(t\).

Su verosimilitud corresponde a:

\[
\begin{aligned}
L(\lambda) &= \prod_{m} P(N_t = m | \lambda)^{n_m} \\
&= \prod_{m} \left( \frac{(\lambda t)^m e^{-\lambda t}}{m!} \right)^{n_m}
\end{aligned}
\]

Mientras que su log verosimilitud es:

\[
\begin{aligned}
LL(\lambda) &= \sum_{m} n_m \ln \left( P(N_t = m | \lambda) \right) \\
&= \sum_{m} n_m \ln \left( \frac{(\lambda t)^m e^{-\lambda t}}{m!} \right)
\end{aligned}
\]

Donde \(m\) corresponde al número de ocurrencias de un suceso (cuántas
personas han visto un determinado número de anuncios), \(n_m\) es el
número de casos en donde hubieron \(m\) ocurrencias de un suceso (cuántas
veces un usuario ha visto un anuncio) y no se utiliza cuando las
observaciones están desagregadas (datos en los cuales cada fila del
conjunto de datos corresponde a una observación única y específica).
Cuando el tiempo es unitario, el modelo se simplifica a \(t = 1\).

Al igual que en los modelos anteriores, es posible incluir
heterogeneidad asumiendo que el parámetro \(\lambda\) no es el mismo para
todos. Para el caso en donde existe una mezcla finita y hay dos
segmentos, las tasas de eventos de la población pueden ser \(\lambda_1\) o
\(\lambda_2\), con una probabilidad \(\pi\) de pertenecer al primer
segmento. El modelo de probabilidad queda representado por:

\[
P(N_t = m | \lambda_1, \lambda_2, \pi) = \left( \frac{(\lambda_1 t)^m e^{-\lambda_1 t}}{m!} \right) \pi + \left( \frac{(\lambda_2 t)^m e^{-\lambda_2 t}}{m!} \right) (1-\pi) \quad (\#eq-mfp)
\]

Para los modelos de heterogeneidad continua, \(\lambda\) distribuye de
acuerdo a una determinada distribución. Suponiendo que dicha
distribución es \emph{Gamma}.

\[
g(\lambda|\alpha, r) = \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} \quad \label{eq:gamma}
\]

Usando el modelo individual en \eqref{eq:poisson} y la distribución en
\eqref{eq:gamma}, se puede estimar la probabilidad de un número de
exposiciones, conocido como modelo \textbf{Gamma Poisson (NBD):}

\[
\begin{aligned}
P(N_t = m \mid r, \alpha) &= \int_{0}^{\infty} P(N_t = m|\lambda) g(\lambda)d\lambda \\
&= \int_{0}^{\infty} \frac{(\lambda t)^m e^{-\lambda t}}{m!} \cdot \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)}d\lambda \\
&= \frac{t^m \alpha^r}{m! \Gamma(r)} \int_{0}^{\infty} \lambda^m \lambda^{r-1} e^{-\lambda t} e^{-\alpha \lambda} d\lambda \\
&= \frac{t^m \alpha^r}{m! \Gamma(r)} \int_{0}^{\infty} \lambda^{(r+m)-1} e^{-\lambda(\alpha+t)} d\lambda \\
&= \frac{t^m \alpha^r}{m! \Gamma(r)} \cdot \frac{\Gamma(r+m)}{(\alpha+t)^{r+m}} \\
&= \frac{\alpha^r}{(\alpha+t)^r} \cdot \frac{t^m}{(\alpha+t)^m} \cdot \frac{\Gamma(r+m)}{\Gamma(r)m!} \\
&= \left( \frac{\alpha}{\alpha+t}\right)^r \left( \frac{t}{\alpha + t}\right)^m \frac{\Gamma(r+m)}{\Gamma(r)m!}
\end{aligned}
\quad \label{eq:gammita}
\]

\hypertarget{modelos-de-elecciuxf3n-binaria-binomial}{%
\section{Modelos de Elección Binaria binomial}\label{modelos-de-elecciuxf3n-binaria-binomial}}

Permiten modelar la probabilidad de que los individuos elijan un
determinado comportamiento, dado que tienen varias opciones para elegir.
Es aplicable en una situación de compras en un supermercado, exposición
a varios anuncios, las variadas formas de uso de un producto, etc.

Consideremos como variable de interés la probabilidad de que un
individuo perteneciente a un segmento responda positivamente a una
campaña de marketing. En el enfoque tradicional, se realiza una
segmentación de clientes en grupos homogéneos, se envía mensajes a
muestras aleatorias de cada segmento y se implementa un campaña en
segmentos con tasa de respuesta (TR) sobre cierto corte, por ejemplo,
\(TR > \frac{\text{Costo de envío}}{\text{Margen unitario}}\).

Sin embargo, es posible incorporar un enfoque de modelos probabilísticos
para abordar el problema. Si se considera la probabilidad de responder
de manera positiva que tiene un segmento \(s\), en particular \(p_s\), es
posible interpretar de manera sencilla la cantidad de respuestas
obtenidas. Recordando que la suma de experimentos de \(\text{Bernoulli}\)
corresponde a una variable aleatoria Binomial, es posible interpretar
\(X_s\) como la cantidad de respuestas obtenidas de un total de \(m_s\)
enviadas. Luego:

\[
\begin{aligned}
P(X_s = x_s|m_s,p_s) &= \binom{m_s}{x_s} p_s^{x_s}(1-p_s)^{m_s-x_s} 
\end{aligned}
\quad \label{eq:bin}\]

donde \(m_s\) es la población del segmento \(s\) y \(p_s\) es la probabilidad
de respuesta del segmento \(s\).

Se tiene que la verosimilitud es expresada como:

\[
\begin{aligned}
L(\theta) &= \prod_{s=1}^{S} P(X_s = x_s | m_s, \theta) \\
&= \prod_{s=1}^{S} \binom{m_s}{x_s} \theta^{x_s} (1-\theta)^{m_s - x_s}
\end{aligned}
\quad (\#eq:verosimilitud:bin)
\]

Mientras que su log verosimilitud es:

\[
\begin{aligned}
LL(\theta) &= \sum_{s=1}^{S} \ln \left( P(X_s = x_s | m_s, \theta) \right) \\
&= \sum_{s=1}^{S} \ln \left( \binom{m_s}{x_s} \theta^{x_s} (1-\theta)^{m_s - x_s} \right) \\
&= \sum_{s=1}^{S} \left[ \ln\binom{m_s}{x_s} + \ln(\theta^{x_s}) + \ln((1-\theta)^{m_s - x_s}) \right] \\
&= \sum_{s=1}^{S} \left[ \ln\binom{m_s}{x_s} + x_s \ln(\theta) + (m_s - x_s) \ln(1-\theta) \right]
\end{aligned}
\quad (\#eq:logverosimilitud:bin)
\]

Con respecto a la heterogeneidad, en el caso de una mezcla finita en
donde la probabilidad de éxito en cada uno de los intentos es distinta
de acuerdo a dos segmentos identificables, la probabilidad adopta el
valor de \(\theta_1\) y \(\theta_2\), donde \(\pi\) corresponde a la
probabilidad de pertencer al primer segmento. El modelo de probabilidad
queda representado por:

\[P(X_s = x_s | m_s, \theta_1, \theta_2, \pi) = \binom{m_s}{x_s} \left[ \theta_1^{x_s}(1-\theta_1)^{m_s-x_s}\pi + \theta_2^{x_s}(1-\theta_2)^{m_s-x_s}(1-\pi) \right] \quad (\#eq:mezcla:b)\]

En el caso de mezcla infinita, la heterogeneidad no observable se extrae
aprovechando la distribución \(B(\alpha,\beta)\):

\[
\begin{aligned}
P(X_s = x_s \mid \alpha, \beta) &= \int_{0}^{1} P(X_s = x_s|m_s,\theta_s) g(\theta_s|\alpha,\beta)d\theta_s \\
&= \int_{0}^{1} \binom{m_s}{x_s} \theta_s^{x_s}(1-\theta_s)^{m_s-x_s} \frac{\theta_s^{\alpha-1}(1-\theta_s)^{\beta -1}}{B(\alpha,\beta)}d\theta_s \\
&= \frac{\binom{m_s}{x_s}}{B(\alpha,\beta)} \int_{0}^{1} \theta_s^{x_s+\alpha-1}(1-\theta_s)^{m_s-x_s+\beta-1} d\theta_s \\
&= \binom{m_s}{x_s} \frac{B(\alpha + x_s, \beta + m_s - x_s)}{B(\alpha,\beta)}
\end{aligned}
\quad \label{eq:beta-binomial}
\]

\hypertarget{heterogeneidad-observable}{%
\section{Heterogeneidad observable}\label{heterogeneidad-observable}}

Se ha expuesto modelos que intentan explicar y predecir el tiempo en que
los individuos realizarán una determinada acción (e.g: proponer la
probabilidad de fuga de un cliente), considerando que el comportamiento
de los agentes se debe netamente a factores aleatorios.

En esta sección se incorporará heterogeneidad observable a un modelo de
duración en tiempo continuo sin dependencia en la duración. Entendemos
por heterogeneidad observable, aquellos factores observables (que están
en los datos) intrínsecos a los individuos que los hacen distintos,
tales como sexo, edad, nivel socioeconómico, género, entre otras.

\hypertarget{modelos-de-duraciuxf3n-en-tiempo-discreto}{%
\subsection{Modelos de duración en tiempo discreto}\label{modelos-de-duraciuxf3n-en-tiempo-discreto}}

Sea \(T_i\) la variable aleatoria que describe el instante en que el
individuo \(i\) termina su relación comercial. Se modelará dicha variable
con una distribución Geométrica Desplazada de parámetro \(\theta_i\), que
es la probabilidad de abandono para el individuo \(i\).

\[\mathbb{P}(T_i=t_i|\theta_i) = \theta_i(1-\theta_i)^{t_i-1}\]

Dado que se cuenta con información a nivel individual, es posible
estimar un parámetro de abandono para cada persona.

Sea \(x_i\) el vector que contiene las variables explicativas del
individuo \(i\). Se modela la probabilidad de abandono \(\theta_i\)
utilizando una transformación logística para asegurar que el resultado
se mantenga entre 0 y 1:

\[\theta_i = \frac{\exp(\beta_0 + \beta'x_i)}{1 + \exp(\beta_0 + \beta'x_i)} = \frac{1}{1 + \exp(-(\beta_0 + \beta'x_i))}\]

Donde \(\beta\) corresponde al vector de coeficientes asociados a las
variables explicativas. La inclusión de esta función permite capturar el
efecto de las covariables sin restringir el signo de los coeficientes.

En el caso donde la probabilidad de abandono depende de las
características de cada individuo (heterogeneidad observable), la
probabilidad de que el individuo \(i\) abandone en el tiempo \(t_i\) es:

\[
\begin{aligned}
\mathbb{P}(T_i = t_i|\beta_0, \beta) &= \theta_i (1 - \theta_i)^{t_i-1} \\
\text{donde } \theta_i &= \frac{1}{1 + \exp(-(\beta_0 + \beta'x_i))}
\end{aligned}
\]

Con lo cual, para un panel de \(N\) individuos, donde algunos abandonan en
el período \(t_i\) y otros permanecen activos (censurados a la derecha),
la log-verosimilitud del problema resulta:

\[
\begin{aligned}
LL(\beta_0, \beta) &= \sum_{i \in \text{abandono}} \ln(\mathbb{P}(T_i = t_i|\beta_0, \beta)) + \sum_{i \in \text{activos}} \ln(\mathbb{P}(T_i > t_i|\beta_0, \beta)) \\
&= \sum_{i \in \text{abandono}} \left[ \ln(\theta_i) + (t_i-1)\ln(1-\theta_i) \right] + \sum_{i \in \text{activos}} t_i \ln(1-\theta_i)
\end{aligned}
\]

Para introducir heterogeneidad no observable en el modelo y así mezclar
ambos efectos, es análogo al desarrollo de la integral del Modelo
Beta-Geométrico desplazado. Se modelan los parámetros \(\alpha_i\) y
\(\beta_i\) de la distribución Beta de la siguiente forma para asegurar
que sean positivos:

\[\alpha_i = \exp(a'x_i) \quad \text{y} \quad \beta_i = \exp(b'x_i)\]

La obtención de la expresión de probabilidad con heterogeneidad mixta es
análoga a la obtención de la probabilidad con heterogeneidad no
observable, salvo que la interpretación de los coeficientes \(\alpha_i\) y
\(\beta_i\) son distintas.

Finalmente, la función de log-verosimilitud para el modelo mixto
resulta, con \(\theta_{params} = (a, b)\):

\[
\begin{aligned}
LL(\theta_{params}) &= \sum_{i \in \text{abandono}} \ln(\mathbb{P}(T_i = t_i|a, b)) + \sum_{i \in \text{activos}} \ln(\mathbb{P}(T_i > t_i|a, b)) \\
&= \sum_{i \in \text{abandono}} \ln\left(\frac{B(\alpha_i+1, t_i+\beta_i-1)}{B(\alpha_i, \beta_i)}\right) + \sum_{i \in \text{activos}} \ln\left(\frac{B(\alpha_i, \beta_i+t_i)}{B(\alpha_i, \beta_i)}\right)
\end{aligned}
\]

\hypertarget{modelos-de-duraciuxf3n-en-tiempo-continuo-sin-dependencia-de-la-duraciuxf3n}{%
\subsection{Modelos de duración en tiempo continuo sin dependencia de la duración}\label{modelos-de-duraciuxf3n-en-tiempo-continuo-sin-dependencia-de-la-duraciuxf3n}}

Sea \(T_i\) la variable aleatoria que describe el instante en que el
individuo \(i\) realiza una determinada acción. Se modelará dicha variable
aleatoria con una distribución exponencial de parámetro \(\lambda_i\):

\[\mathbb{P}(T_i<t_i|\lambda_i) = 1-e^{-\lambda_it_i}\]Cabe destacar
que, dada la naturaleza de los datos, el comportamiento descrito se
realizará de manera desagregada (dependencia de \(i\) en el parámetro), es
decir, dado que existe información individual para cada individuo, es
posible estimar el parámetro de cada uno de éstos (no así en los casos
agregados vistos anteriormente).

Sea \(x_i\) el vector que contiene las variables explicativas pertinentes
del individuo \(i\). Se modela la tasa de llegada de \(i\) de la siguiente
manera:

\[\lambda_i = exp(\beta_0 + \beta'x_i) = \lambda_0 exp(\beta'x_i)\]
Donde \(\beta\) corresponde al vector de coeficientes asociados a las
variables explicativas en cuestión.

La inclusión de la exponencial se debe a que, por razones de
convergencia e interpretación, la tasa de respuesta individual debe ser
positiva. De esta forma, se puede capturar el efecto marginal de las
variables demográficas sin restricción de signos. Así, el modelo no
tendrá problemas si hay valores de \(\beta\) negativos.

En el caso con tasa homogénea (la misma para toda la población), la
probabilidad que un individuo \(i\) realice un evento determinado antes
del tiempo \(t_i\), incluyendo su información observable, es:

\[
\begin{aligned}
\mathbb{P}(T_i < t_i|\beta,\lambda_0) &= 1 - e^{-\lambda_it_i}\\
&= 1 - e^{-\lambda_0 \exp(\beta'x_i)t_i}
\end{aligned}
\]

Con lo cual (considerando instantes de tiempo \(t_i^-\) y \(t_i^+\) para
discretizar el tiempo, un panel de \(N\) individuos y un vector de
parámetros \(\theta = (\beta,\lambda_0)\)), la log verosimilitud del
problema resulta:

\[
\begin{aligned}
LL(\theta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- < T_i < t_i^+|\beta,\lambda_0)) \\
&= \sum_{i=1}^{N} \ln((\mathbb{P}(T_i < t_i^+|\beta,\lambda_0)) - \mathbb{P}(T_i < t_i^-|\beta,\lambda_0)) \\
&=  \sum_{i=1}^{N} \ln \left((1 - e^{-\lambda_0 \exp(\beta'x_i)t_i^+}) - (1 - e^{-\lambda_0 \exp(\beta'x_i)t_i^-}) \right)\\
&= \sum_{i=1}^{N} \ln (e^{-\lambda_0 \exp(\beta'x_i)t_i^-} - e^{-\lambda_0 \exp(\beta'x_i)t_i^+})
\end{aligned}
\]

Para introducir heterogeneidad no observable en el modelo, se dejará el
parámetro \(\lambda_0\) distribuyendo de manera continua en la población
según una ley \(\Gamma(\alpha,r)\) pues, de esta forma, es posible mezclar
tanto la heterogeneidad no observable, como la observable. El desarrollo
de la integral es análogo al caso con heterogeneidad no observable, con
la diferencia de que se multiplica la constante \(exp(\beta' x_i)\) a la
variable del tiempo \(t\) .

Finalmente, la función de log verosimilitud resulta, con
\(\theta = (\beta,\alpha,r)\):

\[
\begin{aligned}
LL(\theta) &= \sum_{i=1}^{N} \ln(\mathbb{P} (t_i^-<T_i<t_i^+|\alpha,r,\beta))\\
&= \sum_{i=1}^{N} \ln \left(\left(\frac{\alpha}{ \alpha + \exp(\beta'x_i)t_i^-}\right)^r - \left(\frac{\alpha}{ \alpha + \exp(\beta'x_i)t_i^+}\right)^r\right)
\end{aligned}
\]

\hypertarget{modelos-de-duraciuxf3n-en-tiempo-continuo-con-dependencia-de-la-duraciuxf3n}{%
\subsection{Modelos de duración en tiempo continuo con dependencia de la duración}\label{modelos-de-duraciuxf3n-en-tiempo-continuo-con-dependencia-de-la-duraciuxf3n}}

Cuando el tiempo en que ocurre un determinado suceso posee dependencia
en la duración, el procedimiento es análogo que en el caso sin dicha
dependencia, pero considerando que \(T_i\) distribuye según una ley
Weibull.

\[\mathbb{P}(T_i < t_i|\lambda_i,c) = 1 - e^{-\lambda_it_i^c}\]

En el caso con tasa homogénea (la misma para toda la población), la
probabilidad que un individuo \(i\) realice un evento determinado antes
del tiempo \(t_i\), incluyendo su información observable, es:

\[
\begin{aligned}
\mathbb{P}(T_i < t_i|\beta,\lambda_0,c) &= 1 - e^{-\lambda_i t_i}\\
&= 1 - e^{-\lambda_0 \exp(\beta'x_i) t_i^c}
\end{aligned}
\]

Por lo que, la función de log verosimilitud toma la siguiente forma:

\[
\begin{aligned}
LL(\theta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- < T_i < t_i^+|\beta,\lambda_0,c)) \\
&= \sum_{i=1}^{N} \ln((\mathbb{P}(T_i < t_i^+|\beta,\lambda_0,c)) - \mathbb{P}(T_i < t_i^-|\beta,\lambda_0,c)) \\
&=  \sum_{i=1}^{N} \ln \left((1 - e^{-\lambda_0 \exp(\beta'x_i)(t_i^+)^c}) - (1 - e^{-\lambda_0 \exp(\beta'x_i)(t_i^-)^c}) \right)\\
&= \sum_{i=1}^{N} \ln (e^{-\lambda_0 \exp(\beta'x_i)(t_i^-)^c} - e^{-\lambda_0 \exp(\beta'x_i)(t_i^+)^c})
\end{aligned}
\]

De manera análoga al caso anterior, se puede introducir adicionalmente
heterogeneidad no observable mediante el parámetro \(\lambda_0\) según una
distribución \(\Gamma(\alpha,r)\). Dando como conocido este resultado, la
log-verosimilitud queda descrita como:

\[
\begin{aligned}
LL(\theta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- < T_i < t_i^+|\beta,\lambda_0,r,c)) \\
&= \sum_{i=1}^{N} \ln \left( \left(\frac{\alpha}{\alpha + \exp(\beta'x_i)(t_i^-)^c}\right)^r - \left(\frac{\alpha}{\alpha + \exp(\beta'x_i)(t_i^+)^c}\right)^r \right)
\end{aligned}
\]

\hypertarget{modelos-de-conteo-1}{%
\subsection{Modelos de Conteo}\label{modelos-de-conteo-1}}

Sea \(Y_i\) la variable aleatoria que describe el número de veces que el
individuo \(i\) incurre en un determinado comportamiento durante un
período de tiempo. Se modelará dicha variable con una distribución
\textbf{Poisson} de parámetro \(\lambda_i\), que representa la tasa de
ocurrencia para el individuo \(i\).

\[\mathbb{P}(Y_i=y_i|\lambda_i) = \frac{\lambda_i^{y_i} e^{-\lambda_i}}{y_i!}\]

Para incorporar heterogeneidad observable, se modela la tasa individual
\(\lambda_i\) como una función de un vector \(x_i\) que contiene las
variables explicativas del individuo:

\[\lambda_i = \exp(\beta_0 + \beta'x_i) = \lambda_0 \exp(\beta'x_i)\]

Donde \(\beta\) es el vector de coeficientes y \(\lambda_0 = \exp(\beta_0)\)
es la tasa base. La probabilidad de que el individuo \(i\) realice el
evento \(y_i\) veces es:

\[
\mathbb{P}(Y_i = y_i|\beta_0, \beta) = \frac{(\lambda_0 \exp(\beta'x_i))^{y_i} \exp(-\lambda_0 \exp(\beta'x_i))}{y_i!}
\]

La función de log-verosimilitud para estimar los parámetros \(\beta_0\) y
\(\beta\) a partir de los datos de \(N\) individuos es la suma de las
log-probabilidades individuales:

\[
\begin{aligned}
LL(\beta_0, \beta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(Y_i=y_i|\beta_0, \beta)) \\
&= \sum_{i=1}^{N} \left[ y_i \ln(\lambda_i) - \lambda_i - \ln(y_i!) \right] \\
&= \sum_{i=1}^{N} \left[ y_i (\beta_0 + \beta'x_i) - \exp(\beta_0 + \beta'x_i) - \ln(y_i!) \right]
\end{aligned}
\]

Para introducir heterogeneidad no observable y mezclarla con la
observable, se asume que la tasa base \(\lambda_0\)no es fija para toda la
población, sino que sigue una distribución Gamma con parámetros de forma
\(r\) y de escala \(\alpha\).

\[g(\lambda_0|r, \alpha) = \frac{\alpha^r \lambda_0^{r-1}e^{-\alpha\lambda_0}}{\Gamma(r)}\]

El desarrollo de la integral para obtener la probabilidad marginal es
análogo al caso NBD (Distribución Binomial Negativa) sin covariables. El
resultado es la distribución de probabilidad para un modelo de Regresión
Binomial Negativa:

\[
\mathbb{P} (Y_i = y_i|r, \alpha, \beta) = \frac{\Gamma(r+y_i)}{\Gamma(r)y_i!} \left(\frac{\alpha}{\alpha + \exp(\beta'x_i)}\right)^r \left(\frac{\exp(\beta'x_i)}{\alpha + \exp(\beta'x_i)}\right)^{y_i}
\]

Finalmente, la función de \textbf{log-verosimilitud} para el modelo mixto
(Regresión NBD) que estima los parámetros \((r, \alpha, \beta)\) es: \[
LL(r, \alpha, \beta) = \sum_{i=1}^{N} \ln(\mathbb{P}(Y_i = y_i|r, \alpha, \beta))
\]

\hypertarget{modelos-de-elecciuxf3n-binaria-binomial-1}{%
\subsection{Modelos de Elección Binaria binomial}\label{modelos-de-elecciuxf3n-binaria-binomial-1}}

Sea \(X_i\) la variable aleatoria que describe el número de ``éxitos'' (ej.
respuestas a una campaña, compras) en \(m_i\) intentos para un individuo o
segmento \(i\). Se modelará dicha variable con una distribución con
parámetros \(m_i\) y \(\theta_i\), donde \(\theta_i\) es la probabilidad de
éxito para el individuo \(i\).

\[\mathbb{P}(X_i=x_i|m_i, \theta_i) = \binom{m_i}{x_i} \theta_i^{x_i}(1-\theta_i)^{m_i-x_i}\]

Para incorporar heterogeneidad observable, se modela la probabilidad de
éxito individual \(\theta_i\) como una función de un vector de covariables
\(x_i\). Al igual que en el modelo de duración discreta, se utiliza una
transformación logística para asegurar que \(\theta_i\) se mantenga en el
intervalo \((0,1)\):

\[\theta_i = \frac{\exp(\beta_0 + \beta'x_i)}{1 + \exp(\beta_0 + \beta'x_i)} = \frac{1}{1 + \exp(-(\beta_0 + \beta'x_i))}\]

Donde \(\beta\) es el vector de coeficientes que captura el efecto de las
características observables.

La función de log verosimilitud para estimar los parámetros \(\beta_0\) y
\(\beta\) a partir de los datos de \(N\) individuos o segmentos es la suma
de las log-probabilidades binomiales individuales:

\[
\begin{aligned}
LL(\beta_0, \beta) &= \sum_{i=1}^{N} \ln(\mathbb{P}(X_i=x_i|\beta_0, \beta)) \\
&= \sum_{i=1}^{N} \left[ \ln\binom{m_i}{x_i} + x_i \ln(\theta_i) + (m_i - x_i) \ln(1-\theta_i) \right]
\end{aligned}
\]

Para introducir heterogeneidad no observable y mezclarla con la
observable, se asume que la probabilidad de éxito \(\theta_i\) no es fija,
sino que sigue una distribución Beta. Para incorporar las covariables,
se modelan los parámetros \(\alpha_i\) y \(\beta_i\) de la distribución Beta
como una función de las características \(x_i\):

\[\alpha_i = \exp(a'x_i) \quad \text{y} \quad \beta_i = \exp(b'x_i)\]

La probabilidad marginal de observar \(x_i\) éxitos en \(m_i\) intentos para
el individuo \(i\) se obtiene a través de la integral análoga al caso sin
covariables:

\[
\mathbb{P} (X_i = x_i|a, b) = \binom{m_i}{x_i} \frac{B(\alpha_i + x_i, \beta_i + m_i - x_i)}{B(\alpha_i,\beta_i)}
\]

Finalmente, la función de log verosimilitud para el modelo mixto
(Regresión Beta Binomial) que estima los parámetros \((a, b)\) es: \[
LL(a, b) = \sum_{i=1}^{N} \ln \left( \binom{m_i}{x_i} \frac{B(\alpha_i + x_i, \beta_i + m_i - x_i)}{B(\alpha_i,\beta_i)} \right)
\]

\hypertarget{esperanzas-condicionales}{%
\section{Esperanzas Condicionales}\label{esperanzas-condicionales}}

Primero, es fundamental establecer el valor esperado de las
distribuciones que se usaron para modelar la heterogeneidad no
observable. A continuación, se muestra el desarrollo para obtener la
esperanza de las distribuciones Gamma y Beta.

\begin{itemize}
\item
  \textbf{Esperanza de la distribución Gamma}

  Para la distribución Gamma, con parámetro de forma \(r\) y de tasa
  \(\alpha\), que se utiliza para modelar tasas de ocurrencia (ej.
  \(\lambda\)), su función de densidad de probabilidad es:
  \[g(\lambda|r,\alpha) = \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha\lambda}\]
  La esperanza de una variable aleatoria \(\lambda\) que sigue esta
  distribución es: \[
  \mathbb{E}[\lambda] = \frac{r}{\alpha}
  \]Este resultado se obtiene a partir de la definición de valor
  esperado para una variable continua: \[
  \begin{aligned}
  \mathbb{E}[\lambda] &= \int_{0}^{\infty} \lambda \cdot g(\lambda|r,\alpha) d\lambda \\
  &= \int_{0}^{\infty} \lambda \cdot \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha\lambda} d\lambda \\
  &= \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{r} e^{-\alpha\lambda} d\lambda \\
  &= \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{(r+1)-1} e^{-\alpha\lambda} d\lambda \\
  \end{aligned}
  \] Reconociendo que la integral
  \(\int_{0}^{\infty} x^{k-1}e^{-\theta x}dx = \frac{\Gamma(k)}{\theta^k}\),
  con \(k=r+1\) y \(\theta=\alpha\): \[
  \begin{aligned}
  \mathbb{E}[\lambda] &= \frac{\alpha^r}{\Gamma(r)} \left[ \frac{\Gamma(r+1)}{\alpha^{r+1}} \right] \\
  &= \frac{\alpha^r}{\Gamma(r)} \cdot \frac{r\Gamma(r)}{\alpha^r \cdot \alpha} \\
  &= \frac{r}{\alpha}
  \end{aligned}
  \]
\item
  \textbf{Esperanza de la distribución Beta}

  Para la distribución Beta con parámetros \(\alpha\) y \(\beta\) que se
  utilizan para modelar probabilidades (ej. \(\theta\)), su función de
  densidad de probabilidad es:
  \[g(\theta|\alpha,\beta) = \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}\]
  El desarrollo para obtener esta esperanza es el siguiente: \[
  \begin{aligned}
  \mathbb{E}[\theta] &= \int_{0}^{1} \theta \cdot g(\theta|\alpha,\beta) d\theta \\
  &= \int_{0}^{1} \theta \cdot \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)} d\theta \\
  &= \frac{1}{B(\alpha,\beta)} \int_{0}^{1} \theta^{\alpha}(1-\theta)^{\beta-1} d\theta \\
  &= \frac{1}{B(\alpha,\beta)} \int_{0}^{1} \theta^{(\alpha+1)-1}(1-\theta)^{\beta-1} d\theta \\
  \end{aligned}
  \] Reconociendo que la integral
  \(\int_{0}^{1} x^{a-1}(1-x)^{b-1}dx = B(a,b)\), con \(a=\alpha+1\) y
  \(b=\beta\): \[
  \begin{aligned}
  \mathbb{E}[\theta] &= \frac{1}{B(\alpha,\beta)} \left[ B(\alpha+1, \beta) \right] \\
  &= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \cdot \frac{\Gamma(\alpha+1)\Gamma(\beta)}{\Gamma(\alpha+1+\beta)} \\
  &= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)} \cdot \frac{\alpha\Gamma(\alpha)}{(\alpha+\beta)\Gamma(\alpha+\beta)} \\
  &= \frac{\alpha}{\alpha+\beta}
  \end{aligned}
  \]
\end{itemize}

\hypertarget{modelo-de-tiempo-discreto-combinado-con-beta}{%
\subsection{Modelo de Tiempo Discreto (Combinado con Beta)}\label{modelo-de-tiempo-discreto-combinado-con-beta}}

Para el modelo de duración en tiempo discreto, una pregunta válida es
cuál es la probabilidad de abandono esperada para un cliente
determinado, dado su historial con la empresa. Intuitivamente, esta
probabilidad debería estar entre la tasa de abandono promedio de la
población y el comportamiento observado de ese cliente.

Recordando que la distribución del parámetro \(\theta\) (la probabilidad
de abandono), condicionada a los datos observados de un cliente, se
obtiene por el Teorema de Bayes:

\[ 
\begin{aligned}
g(\theta|\text{datos}) &= \frac{\mathbb{P}(\text{datos}|\theta)g(\theta)}{\int \mathbb{P}(\text{datos}|\theta)g(\theta)d\theta}
\end{aligned}
\quad \label{eq:thetabayes} \]

donde \(g(\theta)\) es la distribución a priori del parámetro (Beta) y
\(\mathbb{P}(\text{datos}|\theta)\) es la verosimilitud del comportamiento
observado (Geométrica). Para el modelo Beta-Geométrico, la distribución
posterior de \(\theta\) también es una distribución Beta con parámetros
actualizados.

Para el Modelo de Tiempo Discreto (Beta), la esperanza condicional
\(E[\theta|t]\) representa la probabilidad de abandono esperada para un
cliente, la cual se actualiza y ajusta en función de su tiempo de
permanencia observado \(t\).

El cálculo de esta esperanza se basa en el Teorema de Bayes, que
actualiza el conocimiento previo sobre el parámetro \(\theta\) a la luz de
los datos observados:

\[ g(\theta|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\theta) \cdot g(\theta)}{\int \mathbb{P}(\text{datos} \mid \theta) \cdot g(\theta) d\theta} \]

El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:

\begin{itemize}
\item
  \textbf{Distribución a Priori}: Se asume que la heterogeneidad en la
  probabilidad de abandono \(\theta\) en la población sigue una
  distribución \textbf{Beta}:
  \[ g(\theta|\alpha, \beta) \sim \text{Beta}(\alpha, \beta) \]
\item
  \textbf{Función de Verosimilitud}: El comportamiento de abandono
  individual se modela con una distribución Geométrica Desplazada, que
  indica la probabilidad de que el evento ocurra exactamente en el
  período \(t\): \[ \mathbb{P}(T=t|\theta) = \theta(1-\theta)^{t-1} \]
\end{itemize}

Con respecto a la Ley de Probabilidades Totales, ya se ha calculado en
anterioridad para el Modelo Beta Geométrico-Desplazado. A continuación,
se muestra el desarrollo: \[
\begin{aligned}
g(\theta|T=t) &= \frac{\mathbb{P}(T=t|\theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(T=t|\theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&= \frac{ \left( \theta(1-\theta)^{t-1} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \frac{B(\alpha+1, \beta+t-1)}{B(\alpha, \beta)} } \\
&= \frac{\theta^{\alpha}(1-\theta)^{\beta+t-2}}{B(\alpha+1, \beta+t-1)}
\end{aligned}
\]

La expresión resultante es la función de densidad de una distribución
Beta, con los parámetros actualizados.
\[g(\theta|T=t) \sim \text{Beta}(\alpha+1, \beta+t-1)\]

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
\[ \mathbb{E}(\theta|T=t) = \frac{\alpha+1}{\alpha+\beta+t} \]

Esta expresión representa la probabilidad de abandono esperada y
actualizada para un cliente que ha permanecido exactamente \(t\) períodos.
El resultado combina la información previa sobre la población (contenida
en \(\alpha\) y \(\beta\)) con la observación específica del cliente (su
duración \(t\)).

De forma análoga, para un cliente que sigue activo después de \(t\)
períodos (observación censurada):

\begin{itemize}
\tightlist
\item
  \textbf{Función de Verosimilitud}: La probabilidad de que el evento aún
  no haya ocurrido es la función de supervivencia:
  \[ \mathbb{P}(T>t|\theta) = (1-\theta)^{t} \]
\end{itemize}

Obteniendo la distribución posterior: \[
\begin{aligned}
g(\theta|T > t) &= \frac{\mathbb{P}(T > t|\theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(T > t|\theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&= \frac{ \left( (1-\theta)^{t} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \frac{B(\alpha, \beta+t)}{B(\alpha, \beta)} } \\
&= \frac{\theta^{\alpha-1}(1-\theta)^{\beta+t-1}}{B(\alpha, \beta+t)}
\end{aligned}
\]

La expresión resultante es la función de densidad de otra distribución
Beta, con los parámetros actualizados.
\[g(\theta|T>t) \sim \text{Beta}(\alpha, \beta+t)\]

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
\[ \mathbb{E}(\theta|T>t) = \frac{\alpha}{\alpha+\beta+t} \]

Se podría replantear una regla de decisión y, por ejemplo, dirigir una
campaña de retención a los clientes aún activos después de \(t\) períodos
si su probabilidad de abandono esperada supera cierto umbral:

\[\mathbb{E} (\theta|T > t) = \frac{\alpha}{\alpha + \beta + t} > \frac{\text{Costo de Retención}}{\text{Valor del Cliente}}\]

\[
\mathbb{E}(\theta \mid T>t) = \frac{\alpha}{\alpha + \beta + t} (\#eq:esp:discrete)
\]

\hypertarget{modelo-de-tiempo-continuo-combinado-con-gamma}{%
\subsection{Modelo de Tiempo Continuo (Combinado con Gamma)}\label{modelo-de-tiempo-continuo-combinado-con-gamma}}

Para el modelo de duración en tiempo continuo, una pregunta válida es
cuál es la tasa de eventos esperada para un cliente determinado, dado su
historial. Intuitivamente, esta tasa debería estar entre la tasa
promedio de la población y el comportamiento observado de ese cliente.

Recordando que la distribución del parámetro \(\lambda\) (la tasa de
eventos), condicionada a los datos observados de un cliente, se obtiene
por el Teorema de Bayes:

\[ 
\begin{aligned}
g(\lambda|\text{datos}) &= \frac{\mathbb{P}(\text{datos}|\lambda)g(\lambda)}{\int \mathbb{P}(\text{datos}|\lambda)g(\lambda)d\lambda}
\end{aligned}
\quad \label{eq:thetabayes} 
\]

La esperanza condicional \(E[\lambda|t]\) representa la tasa de ocurrencia
esperada para un cliente, la cual se actualiza y ajusta en función del
tiempo transcurrido \(t\).

El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:

\begin{itemize}
\item
  \textbf{Distribución a Priori}: Se asume que la heterogeneidad en la tasa
  de eventos \(\lambda\) en la población sigue una distribución
  \textbf{Gamma}: \[ g(\lambda|r, \alpha) \sim \text{Gamma}(r, \alpha) \]
\item
  \textbf{Función de Verosimilitud}: El comportamiento del tiempo hasta el
  evento se modela con una distribución Exponencial, que indica la
  probabilidad (densidad) de que el evento ocurra exactamente en el
  instante \(t\):
  \[ \mathbb{P}(T=t|\lambda) = f(t|\lambda) = \lambda e^{-\lambda t} \]
\end{itemize}

Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Gamma-Exponencial. A continuación, se muestra el
desarrollo de la distribución posterior: \[
\begin{aligned}
g(\lambda|T=t) &= \frac{\mathbb{P}(T=t|\lambda) \cdot g(\lambda|r, \alpha)}{\int_0^\infty \mathbb{P}(T=t|\lambda) \cdot g(\lambda|r, \alpha) d\lambda} \\
&= \frac{ \left( \lambda t e^{-\lambda t} \right) \left( \frac{\alpha^r \lambda^{r-1} e^{-\alpha\lambda}}{\Gamma(r)} \right) }{\left(\frac{rt}{\alpha + t} \right) \left(\frac{1}{\alpha + t} \right)^r} \\
&= \frac{(\alpha+t)^{r+1}}{\Gamma(r+1)}\lambda^{r}e^{-\lambda(\alpha+t)}
\end{aligned}
\]

La expresión resultante es la función de densidad de una distribución
Gamma, con los parámetros actualizados.
\[g(\lambda|T=t) \sim \text{Gamma}(r+1, \alpha+t)\]

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
\[ \mathbb{E}(\lambda|T=t) = \frac{r+1}{\alpha+t} \]

\hypertarget{modelo-de-conteo-combinado-con-gamma}{%
\subsection{Modelo de Conteo (Combinado con Gamma)}\label{modelo-de-conteo-combinado-con-gamma}}

Para el modelo de conteo, una pregunta válida es cuál es la tasa de
eventos esperada para un cliente determinado, dado su historial de
eventos en un período de tiempo \(t\).

Recordando que la distribución del parámetro \(\lambda\) (la tasa de
eventos), condicionada a los datos observados de un cliente, se obtiene
por el Teorema de Bayes:

\[
\begin{aligned}
g(\lambda|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\lambda)g(\lambda)}{\int \mathbb{P}(\text{datos}|\lambda)g(\lambda)d\lambda}
\end{aligned}
\quad \label{eq:thetabayes} \]

El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:

\begin{itemize}
\item
  \textbf{Distribución a Priori}: Se asume que la heterogeneidad en la tasa
  de eventos \(\lambda\) en la población sigue una distribución
  \textbf{Gamma}: \[ g(\lambda|r, \alpha) \sim \text{Gamma}(r, \alpha) \]
\item
  \textbf{Función de Verosimilitud}: El comportamiento de conteo de eventos
  se modela con una distribución \textbf{Poisson}, que indica la
  probabilidad de que ocurran exactamente \(y\) eventos en un período de
  duración \(t\):
  \[ \mathbb{P}(Y_t=y|\lambda,t) = \frac{(\lambda t)^y e^{-\lambda t}}{y!} \]
\end{itemize}

Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Gamma-Poisson (NBD). A continuación, se muestra el
desarrollo de la distribución posterior: \[
\begin{aligned}
g(\lambda|Y_t=y) &= \frac{\mathbb{P}(Y_t=y|\lambda, t) \cdot g(\lambda|r, \alpha)}{\int_0^\infty \mathbb{P}(Y_t=y|\lambda, t) \cdot g(\lambda|r, \alpha) d\lambda} \\
&= \frac{ \left( \frac{(\lambda t)^y e^{-\lambda t}}{y!} \right) \left( \frac{\alpha^r \lambda^{r-1} e^{-\alpha\lambda}}{\Gamma(r)} \right) }{ \frac{\Gamma(r+y)}{\Gamma(r)y!} \left(\frac{\alpha}{\alpha+t}\right)^r \left(\frac{t}{\alpha+t}\right)^{y} } \\
&= \frac{(\alpha+t)^{r+y}}{\Gamma(r+y)}\lambda^{r+y-1}e^{-\lambda(\alpha+t)}
\end{aligned}
\]

La expresión resultante es la función de densidad de una distribución
Gamma, con los parámetros actualizados.
\[g(\lambda|Y_t=y) \sim \text{Gamma}(r+y, \alpha+t)\]

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
\[ \mathbb{E}(\lambda|Y_t=y) = \frac{r+y}{\alpha+t} \]

\hypertarget{modelo-de-elecciuxf3n-binaria-binomial-combinado-con-beta}{%
\subsection{Modelo de Elección Binaria binomial (Combinado con Beta)}\label{modelo-de-elecciuxf3n-binaria-binomial-combinado-con-beta}}

Recordando que la distribución del parámetro \(\theta\) (la probabilidad
de éxito), condicionada a los datos observados, se obtiene por el
Teorema de Bayes:

\[
\begin{aligned}
g(\theta|\text{datos}) &= \frac{\mathbb{P}(\text{datos}|\theta)g(\theta)}{\int \mathbb{P}(\text{datos}|\theta)g(\theta)d\theta}
\end{aligned}
\quad \label{eq:thetabayes} \]

El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:

\begin{itemize}
\item
  \textbf{Distribución a Priori}: Se asume que la heterogeneidad en la
  probabilidad de éxito \(\theta\) en la población sigue una
  distribución \textbf{Beta}:
  \[ g(\theta|\alpha, \beta) \sim \text{Beta}(\alpha, \beta) \]
\item
  \textbf{Función de Verosimilitud}: El comportamiento de elección se
  modela con una distribución Binomial, que indica la probabilidad de
  obtener exactamente \(x\) éxitos en \(m\) intentos:
  \[ \mathbb{P}(X=x|m, \theta) = \binom{m}{x} \theta^x (1-\theta)^{m-x} \]
\end{itemize}

Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Beta-Binomial. A continuación, se muestra el
desarrollo de la distribución posterior: \[
\begin{aligned}
g(\theta|X=x) &= \frac{\mathbb{P}(X=x|m, \theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(X=x|m, \theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&= \frac{ \left( \binom{m}{x} \theta^x (1-\theta)^{m-x} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \binom{m}{x} \frac{B(\alpha+x, \beta+m-x)}{B(\alpha, \beta)} } \\
&= \frac{\theta^{\alpha+x-1}(1-\theta)^{\beta+m-x-1}}{B(\alpha+x, \beta+m-x)}
\end{aligned}
\]

La expresión resultante es la función de densidad de una distribución
Beta, con los parámetros actualizados.
\[g(\theta|X=x) \sim \text{Beta}(\alpha+x, \beta+m-x)\]

De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
\[ \mathbb{E}(\theta|X=x) = \frac{\alpha+x}{\alpha+\beta+m} \]

En el modelo de elección en donde la \(P(X_s = x_s)\) quedaba definida en
\eqref{eq:bin}. Una pregunta válida que se puede hacer es cuál es la tasa
de respuesta de un segmento \(s\) determinado. Intuitivamente debería
estar entre la tasa de respuesta esperada de la población y la
observada, es decir,

\[ 
\begin{aligned}
\mathbb{E}(\theta_s|m_s,x_s)=\gamma \frac{\alpha}{\alpha+\beta} + (1-\gamma) \frac{x_s}{m_s}
\end{aligned}
\quad \label{eq:tasa} 
\]

Esta última igualdad se encuentra al hacer el reemplazo
\(\gamma = \frac{\alpha + \beta}{\alpha + \beta + m_s}\), la cual coincide
con \eqref{eq:thetabayes}. Se podría replantear la regla de decisión y
enviar catálogos a los segmentos \(s\) tales que

\[\mathbb{E} (\theta_s|x_s) =\frac{\alpha + x_s}{\alpha + \beta + m_s} > \frac{\text{costo de envío}}{\text{margen unitario}}\]

\[ 
\begin{aligned}
\mathbb{E}(\theta_s \mid x_s) &= \frac{\alpha + x_s}{\alpha + \beta + m_s}
\end{aligned}
\quad \label{eq:esp} \]

\hypertarget{modelos-estructurales}{%
\chapter{Modelos Estructurales}\label{modelos-estructurales}}

\hypertarget{introducciuxf3n-a-modelos-estructurales}{%
\section{Introducción a Modelos Estructurales}\label{introducciuxf3n-a-modelos-estructurales}}

\hypertarget{introducciuxf3n-1}{%
\subsection{Introducción}\label{introducciuxf3n-1}}

En esencia, un modelo econométrico estructural es aquel que deriva relaciones estimables estadísticamente a partir de supuestos bien definidos de comportamiento de los agentes que deciden respecto a las cantidades observables. En contraposición a los modelos estructurales están los modelos de forma reducida donde los modelos simplemente describen la variabilidad de alguna medida de interés en base a un conjunto de variables observables exógenas.

La disciplina económica suele llamar modelos estructurales a los resultantes de asumir que los consumidores maximizan una utilidad subyacente y que las firmas maximizan su rentabilidad esperada. Desde el marketing, se considera también en la definición aquellos que postulan hipótesis alternativas de comportamiento incluyendo así una variedad de teorías de comportamiento que nutren la disciplina tales como teoría de prospectos, contabilidad mental, elección sobre conjuntos de consideración, etc. Como se discutirá más adelante, no existe un modelo estructural puro y la línea que los separa de los modelos de forma reducida es ciertamente difusa.

Se incluirá en la discusión de modelos estructurales a cualquiera que considere alguna historia de comportamiento que permita añadir interpretabilidad a los parámetros del modelo.

\textbf{Ejemplo 1:} Supongamos que un analista busca estudiar cómo el precio en la región \(i (p_i)\) se ve afectado por la presencia o no de competencia. Si además de los precios se observa la cantidad de clientes en la región \((POP_i)\), el ingreso per cápita en la región \((INC_i)\) y una indicatriz \(CMP_i\) que toma el valor 1 si en la región correspondiente presenta competencia (0 en caso contrario).

Entonces, un modelo de forma reducida sencillo para estudiar el problema viene dado por:

\[p_i = \beta_0+ \beta_1POP_i + \beta_2INC_i + \beta_3CMP_i + \varepsilon_i\]
Bajo este enfoque, se pueden usar técnicas de regresión tradicionales para estimar \(β_3\) que en principio indicaría el impacto de la competencia en el nivel de precios. Sin embargo, la presencia de competencia en un determinado mercado depende también del nivel de precios. Si los precios en una región son altos, la rentabilidad esperada por entrar también es alta motivando a potenciales competidores a participar. En consecuencia, un modelo como el planteado podría subestimar
el efecto de la competencia.

Un modelo estructural buscaría derivar relaciones estimables a partir de supuestos básicos del comportamiento de la firma. Por ejemplo, se podría asumir que cada firma decide conjuntamente la entrada/salida de un mercado y los precios a cobrar de modo de maximizar la rentabilidad esperada.

\textbf{Ejemplo 2:} Supongamos que se busca describir la productividad de los miembros de la fuerza de venta medida como número de unidades vendidas \(q\).

\[q=f(X,\beta)+\varepsilon\]

La especificación del término de error \(\varepsilon\) puede por sí solo permitir dar una interpretación estructural a los estimadores. Si simplemente se asume un error normalmente distribuido, entonces corresponderá simplemente a un ruido blanco y la regresión simplemente indicará a través de los parámetros \(\beta\) cómo las variables \(X\) en promedio afectan las ventas \(q\). Por el contrario, si se asume que el término \(\varepsilon\) considera además del ruido una componente no observable positiva asociada a la brecha de productividad de los miembros menos eficientes de la fuerza de venta, entonces la regresión describirá la frontera eficiente de ventas. Esto puede hacerse por ejemplo especificando que \(\varepsilon = \epsilon - \xi\) donde \(\epsilon\) está normalmente distribuida centrada en cero, pero \(\xi\) proviene de una normal truncada en los números positivos (este enfoque se le suele llamar de regresión estocástica de frontera).

El gran desafío de la aplicación de modelos econométricos a problemas comerciales es enriquecer el conocimiento respecto a cómo se comportan los agentes relevantes del negocio, para así tomar decisiones más consistentes y más rentables. Desde este punto de vista, se apunta a modelos que describan la lógica que determina el comportamiento de los clientes y firmas más allá de simples correlaciones estadísticas entre las variables observables. En general, son varias las ventajas de usar modelos estructurales por sobre modelos de forma reducida:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{La capacidad de contar una mejor historia del comportamiento de los agentes}. Esto se expresa por la capacidad de interpretación directa de los parámetros del modelo. Mientras los parámetros asociados a enfoques de regresión tradicionales típicamente indican la magnitud en que en promedio varía alguna magnitud de interés ante variaciones de otra, los parámetros de un modelo estructural indican entre otros la valoración relativa de un atributo en la función de utilidad, los precios de referencia de un producto o la aversión al riesgo de un tomador de decisión. La provisión de una historia de comportamiento más completa no se deriva exclusivamente de la interpretación directa de los parámetros del modelo sino que también de la capacidad de derivar métricas complementarias tales como elasticidades y excedentes de consumidores. Más aún, se puede proyectar el comportamiento para calcular probabilidades y frecuencias de compra, participaciones de mercado, etc.
\item
  La generación de estimaciones consistentes con las expectativas de los analistas. Frecuentemente, al analizar los datos se quiere dejar la mayor libertad posible al modelo \emph{para dejar que la data hable}. Este enfoque puede tener valor y ser recomendable en estudios exploratorios, pero para tomar decisiones se necesitan estimaciones robustas y usar tanta información como sea posible. Las teorías usadas para derivar modelos econométricos estructurales suelen estar soportadas tanto por estudios experimentales como por amplia evidencia empírica en múltiples dominios. Por lo tanto, al incorporar teoría se está implícitamente usando información que ha demostrado consistentemente su validez.
\end{enumerate}

\textbf{Ejemplo 3:} Supongamos que se quiere proponer un modelo que describa la participación de mercado de las distintas marcas en una industria. Si se usa un enfoque de regresión en que simplemente se disponen los shares al lado izquierdo y una forma funcional flexible al lado derecho, el modelo resultante podría predecir participaciones fuera del rango {[}0,1{]}, que difícilmente pueden justificarse. Por el contrario si se adscribe al axioma de elección de Luce (1959) que indica que la probabilidad de elección en un determinado conjunto depende del ratio entre una medida de atracción de la alternativa con respecto al atractivo total del conjunto, se fuerza a que las participaciones siempre estén en el rango deseado.

\textbf{Ejemplo 4:} La teoría económica predice que en general, las cantidades demandadas decrecen ante aumentos en su precio. Sin embargo, en muchas situaciones prácticas la disponibilidad de datos al nivel de agregación requerido es limitada dificultando la estimación de esta relación inversa entre precio y demanda. En estas situaciones no es raro que un modelo flexible prediga que la demanda crece en función del precio. Agregar estructura permite limitar la búsqueda solo entre aquellos modelos que son consistentes con la premisa de que las demandas decrecen en el precio.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \emph{Evaluación de impacto de modificación de políticas}. Una de las herramientas fundamentales de la función comercial es la generación de planes comerciales que buscan proponer un diseño del conjunto producto, plaza, precio y promoción que genere el mayor valor para el cliente y la captura del mayor excedente por parte de la firma. El rol de los modelos econométricos es estudiar el impacto que tendrían distintas estrategias en el comportamiento del consumidor. En esencia, un plan de marketing propone un cambio en las reglas del juego que han generado la data que se observa y por tanto se necesita apuntar a estimar los elementos más básicos del comportamiento que se mantendrán invariantes ante modificación de productos, precios, canales de distribución, etc. En este grupo se tienen valoraciones por atributos de productos, costo de transporte, aversión al riesgo, entre otros, que no pueden ser estimados a menos que se derive el modelo a partir de teorías individuales de comportamiento. En otras palabras, la derivación de modelos de demanda a partir de teorías de comportamiento permite evaluar contrafactuales que apoyan el diseño de propuestas de valor efectivas.
\end{enumerate}

La necesidad de evaluar contrafactuales usando elementos fundamentales que no se vean afectados por cambios en los sistemas fue inicialmente discutida por Robert Lucas (1976) en la famosa crítica que lleva su nombre. En el contexto de la predicción de efectos macroeconómicos, Lucas postuló que cualquier cambio en las políticas variaría sistemáticamente la estructura de los modelos y por tanto se debe apuntar a describir parámetros profundos que gobiernan el comportamiento individual.

\textbf{Ejemplo 5:} Considere un retailer que vende múltiples productos a través de dos canales, las salas de venta tradicionales y un sitio web con despacho directo. El retailer está evaluando la posibilidad de reasignar el conjunto de productos que vende a través de cada canal para aumentar la rentabilidad del negocio. Para apoyar esta decisión, parece evidente que el simple análisis de las ventas de cada producto en cada canal no ayudará a predecir cómo dichos productos se venderían en el otro canal o cómo se afectaría la venta si un producto deja de venderse en algunos de los canales. Para hacer este ejercicio necesariamente se deberá investigar primitivas más fundamentales del comportamiento como preferencias intrínsecas por canal para cada categoría y patrones de sustitución entre las alternativas disponibles dentro del canal y con respecto al otro canal.

\textbf{Ejemplo 6:} En muchas industrias como la de vestuario de moda o de artículos tecnológicos, hay una alta variabilidad de la oferta con constantes entradas y salidas de diferentes versiones de los productos dificultando la proyección del desempeño de cada variante en el tiempo. Mientras el surtido de producto varía con frecuencia, hay parámetros de la demanda que pueden perdurar por varias temporadas tales como la elasticidad al precio, crecimiento de la categoría, factores estacionales y de sustitución/complementariedad de atributos. Un enfoque estructural apunta precisamente a la estimación de estos parámetros estables.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \emph{Testear aplicabilidad de teoría}. Al usar un enfoque estructural, se fuerza a pensar detalladamente respecto al problema y explicitar cada uno de los supuestos de comportamiento. Las especificaciones alternativas de modelos de forma reducida simplemente corresponden a formas funcionales diferentes y por tanto no son informativas respecto a la lógica en que deciden los agentes. Por otra parte, dos modelos estructurales diferentes provienen de supuestos de comportamiento diferentes y por tanto cuando uno de ellos ajusta mejor a la data indica que hay una teoría de comportamiento que es más plausible que la otra en el dominio de aplicación del modelo. Así, los modelos estructurales no solo se nutren de teoría sino que también ayudan a su desarrollo.
\end{enumerate}

Las ventajas antes descritas no implican que siempre deban preferirse modelos estructurales por sobre los de forma reducida. Como se ha descrito, los modelos de forma reducida suelen proveer suficiente flexibilidad para dejar que sea la data la que hable, lo que puede ser particularmente útil en análisis exploratorios del caso bajo estudio. Además, muchas veces la inclusión de más estructura en el modelo implica rutinas de estimación más sofisticadas siendo con frecuencia altamente intensivas computacionalmente.

Es importante destacar que no existe un modelo puramente estructural. Todo modelo requiere en algún momento suponer alguna forma funcional flexible sin fundamento teórico sólido. Por ejemplo, se puede asumir que los consumidores al elegir un producto están maximizando una utilidad subyacente, pero ¿cómo describir dicha función de utilidad? ¿Qué variables explicativas usar y cuál forma funcional escoger? Ciertamente la especificidad de las teorías disponibles no alcanza a responder a estas preguntas y se debe por lo tanto escoger en base a la intuición y empíricamente entre aquellas que generen mejor ajuste y/o capacidad de pronóstico. De esta forma, un buen modelo debe balancear adecuadamente el uso de la teoría con la simpleza y flexibilidad del modelo.

Para ser convincente, un modelo estructural debe al menos (i) entregar suficiente flexibilidad para aprender de la data, (ii) derivar las ecuaciones de comportamiento de supuestos razonables respecto de los agentes involucrados y (iii) incorporar explícitamente en la descripción la naturaleza no experimental de la data.

\textbf{Observación:} En la discusión se ha hecho la distinción entre modelos probabilísticos y modelos estructurales. Aunque los modelos probabilísticos proveen una historia de comportamiento de los agentes, los supuestos básicos usados para derivarlos no se sustentan en ninguna teoría de comportamiento. Por ejemplo, en modelos de duración en tiempo discreto se suele suponer que los clientes dejan de estar activos con cierta probabilidad. Más que una teoría de comportamiento esto es simplemente una descripción probabilística de un fenómeno. En determinadas situaciones, especialmente en casos en que no se dispone de una descripción rica del ambiente en que los agentes toman sus decisiones, se conforma con esta descripción agregada del comportamiento. El enfoque estructural sobre el que se ahondará en esta parte resulta particularmente útil cuando se tiene suficiente información para investigar las motivaciones profundas de las elecciones. Al definir un modelo estructural, tanto las teorías de comportamiento como la descripción probabilística del sistema son fuentes válidas de estructura. Sin embargo, se considerará como modelo econométrico estructural a aquellos que se nutren de ambas fuentes.

\hypertarget{modelos-estructurales-en-marketing}{%
\subsection{Modelos Estructurales en Marketing}\label{modelos-estructurales-en-marketing}}

El desarrollo de modelos estructurales se ha gestado en varias áreas del conocimiento tales como economía, transportes, logística, finanzas y marketing. Entre estas áreas, la del marketing se ha constituido en un terreno particularmente fértil para el desarrollo y adopción del enfoque estructural. Se identifican al menos cuatro motivos por los cuales la adición de estructura en los modelos econométricos es particularmente útil para el análisis de problemas comerciales:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Disponibilidad de datos}. Gran parte de los datos que registran las compañías dan cuenta de las interacciones entre clientes y firma como son ocasiones de compra, visitas a sitios web corporativos o llamadas a los centros de llamadas. De esta forma, un conjunto importante de los datos disponibles dentro de las organizaciones son informativos respecto a procesos claves de la función comercial. Así, los requerimientos de datos impuestos por los modelos estructurales están inmediatamente satisfechos por procesos operacionales.
\item
  \emph{Atractivo de la evaluación de la intervención de sistemas}. En la función comercial, casi por definición se busca perturbar los sistemas para mejorar la oferta de valor cambiando precios, proponiendo nuevos diseños de productos, redefiniendo la cadena logística, etc. De esta forma se necesita disponer de modelos que describan la reacción de los consumidores ante dichos cambios del ambiente competitivo lo que, de acuerdo a la crítica de Lucas, solo puede hacerse con un modelo estructural.
\item
  \emph{Importancia de heterogeneidad}. En marketing se busca hacer inferencia desagregada a nivel de cliente o segmento para poder diseñar versiones especializadas del marketing mix que sean atractivas para segmentos específicos de clientes. Como los modelos estructurales requieren especificar los supuestos de comportamiento a nivel individual, la generación de estimaciones desagregadas suele derivarse directamente.
\item
  \emph{Pragmatismo en la aceptación de teorías}. Como se ha argumentado, una de las ventajas de los modelos estructurales es que permiten testear si una determinada teoría de comportamiento aplica a una situación. A diferencia de otras disciplinas, en marketing hay una tradición de revisión continua de las fuerzas que moldean el comportamiento de las personas y por tanto el enfoque de modelos estructurales entrega una herramienta alternativa a la verificación experimental de nuevas teorías.
\end{enumerate}

\hypertarget{taxonomuxeda-de-modelos-estructurales}{%
\subsection{Taxonomía de Modelos Estructurales}\label{taxonomuxeda-de-modelos-estructurales}}

Metodológicamente, es útil generar una clasificación de los tipos de modelos estructurales existentes en la literatura. Como se ha consignado, uno de los costos de la inclusión de teoría en modelos econométricos es la mayor complejidad en las rutinas de estimación. Es esta complejidad la que dificulta la generación de un mecanismo único que permita estimar modelos generales y por tanto se ve forzado a usar metodologías específicas dependiendo de la naturaleza del problema. En la discusión se basará la clasificación en la evaluación de cuatro factores.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Nivel de agregación de la Data}. Hemos propuesto que un modelo estructural debe basarse en una descripción detallada de los supuestos de los tomadores de decisión a nivel individual. Por lo tanto la disponibilidad de data a nivel individual como la decisión de compra de cada uno de los individuos de un panel de consumidores, nos habilita para, imponiendo las restricciones de identificación necesaria, estimar los parámetros de comportamiento de manera mas o menos directa. Sin embargo, en ciertas situaciones solo se dispone de información agregada, como participaciones de mercado o datos agregados de venta. En estos casos, la identificación de parámetros de comportamiento requiere además de una descripción del mecanismo mediante el cual se agregan las decisiones individuales. Este mecanismo típicamente considera la especificación de un modelo de heterogeneidad describiendo como se distribuyen los parámetros entre los clientes la que se integra sobre la población para generar las métricas agregadas. Esto es precisamente lo propuesto por el método BLP (a partir de
  Berry, Levinsohn y Pakes quienes primero propusieron el método en 1995) que describe un método que basado en un modelo logit permite estimar ofertas y demandas de un modelo oligopólico con información agregada. Por simplicidad, en esta versión nos concentraremos en modelos estimables directamente sobre data desagregada a nivel individual.
\item
  \emph{Temporalidad de las Decisiones}. Dependiendo de la amplitud temporal considerada por los agentes al evaluar las alternativas de decisión distinguiremos entre problemas estáticos y dinámicos. Básicamente, si consideramos que las acciones que observamos resultan de una evaluación completa del horizonte, entonces hablaremos de problemas dinámicos. En caso contrarios diremos que el problema es estático. La distinción es importante desde un punto de vista metodológico. Si el tomador de decisiones basa sus decisiones exclusivamente
  mirando el pasado, entonces estas decisiones pueden caracterizarse directamente mediante condiciones de optimidad sencillas. Por el contrario, si el tomador de decisión además evalúa las repercusiones (inciertas) que sus acciones de hoy podrían tener en su bienestar futuro, entonces necesitamos caracterizar las políticas optimas a través de ecuaciones de Bellman que incorporen explícitamente la naturaleza multiperiodo del problema. En este caso, para encontrar la política óptima del problema se requiere usar técnicas como programación dinámica estocástica o control óptimo aumentando de manera importante la complejidad computacional de la estimación.
\item
  \emph{Naturaleza de las Variables de Decisión}. Si las variables sobre las que deciden los agentes son continuas (gasto, montos de inversión, unidades compradas, etc.), hablaremos de un
  modelo de decisión continuo. Si las variables sobre las que deciden los agentes son discretos (si visita o no visita la tienda, si elige la marca A o marca B, etc.), hablaremos de un modelo de decisión discreto. La distinción es relevante en cuanto las soluciones de un problema de decisión continua puede caracterizarse directamente mediante condiciones de KarushKuhn-Tucker mientras que las soluciones de un problema de decisión discreta requieren una enumeración del valor de las alternativas.
\item
  \emph{Identidad de los Agentes}. Los modelos estructurales pueden usarse para estudiar tanto el comportamiento de los clientes o de las otras firmas en el mercado. El área que estudia el comportamiento de las firmas ha tenido una gran desarrollo en los últimos años y se conoce como Organización Industrial Empírica. En esta versión, concentraremos la discusión en el estudio de los clientes por dos motivos principales: la disponibilidad de data de comportamiento de cliente y la simpleza de las nociones de equilibrio requeridas para describir a los clientes. Mientras cada cliente suele tener poco poder de mercado por si mismo, las acciones de marketing de las firmas competidoras típicamente pueden modificar de manera importante las condiciones del mercado. Así, la descripción de las decisiones de las firmas conlleva desafíos metodológicos importantes como la inclusión de nociones sofisticadas de equilibrio para internalizar que las decisiones de las firmas resultan tanto de mirar las respuestas esperadas de los clientes como las reacciones estratégicas de los competidores.
\end{enumerate}

Metodológicamente es útil también distinguir los métodos de estimación de los modelos. La literatura reconoce dos grandes enfoques para estimar modelos estructurales como los aquí presentados: Método de los Momentos Generalizados (GMM) y Método de la Máxima Verosimilitud. Dada su eficiencia estadística (en el sentido que usa toda la información disponibles), en esta primera versión usaremos solo el método de la máxima verosimilitud. En lo que sigue nos enfocaremos la discusión al estudio del comportamiento de clientes, en problemas estáticos (o con dinámica limitada a la incorporación del pasado) y con data desagregada. Partiremos describiendo brevemente modelos de decisión continuos para luego iniciar una discusión más extensa en modelos de decisión discreta que tienen una tradición más larga en marketing.

\hypertarget{logit}{%
\section{Logit}\label{logit}}

\hypertarget{modelos-de-elecciuxf3n-discreta}{%
\subsection{Modelos de Elección Discreta}\label{modelos-de-elecciuxf3n-discreta}}

Un modelo de elección discreta consiste básicamente en situaciones en que la naturaleza de las variables de decisión a las que se enfrenta el tomador de decisión son discretas. Para ilustrar la intuición de la diferencia con respecto a modelos de decisión continua es útil pensar que mientras
estos últimos buscan describir decisiones de el cuanto, los modelos de elección discreta se concentran en el cuál. La distinción además relevante desde un punto de vista metodológico. A diferencia de los modelos de elección continua en que la optimidad de la elección queda bien descrita por
condiciones de primer orden, al enfrentar decisiones discretas caracterizaremos la optimidad por enumeración. Ejemplos típicos en que la decisión a evaluar es de naturaleza discreta incluye la elección de una marca por sobre otra en la góndola de un supermercado, la decisión de visitar o no a una tienda, la elección del color de una prenda de vestir, de un canal de venta y la elección de las firmas respecto a entrar o no entrar a un mercado.

Para que un problema de elección discreta este bien definido necesitamos además de variables de decisión discretas, que el conjunto de alternativas presente las siguientes tres características:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{EXHAUSTIVAS}: El conjunto sobre el que los tomadores de decisión eligen deben incluir todas las alternativas posibles. En otras palabras, cualquiera sea la decisión observada, debe
  estar incluida en el conjunto de elección. Esta condición es poco restrictiva ya que siempre es posible incluir en el set de alternativas la posibilidad ``ninguna de las anteriores'' o similar que por definición incluya toda las otras posibilidades no consideradas en conjunto. Sin embargo, esta estrategia debe usarse con precaución. Por ejemplo, al estudiar la elección de marca en una categoría en que observamos que los clientes no siempre compran alguna
  de las marcas disponibles podríamos incluir la alternativa de no compra en el conjunto de elección. Si la proporción de no compras es alta en nuestra muestra, la inclusión de la alternativa de no compra podría limitar la habilidad del modelo de aprender respecto a como los clientes eligen entre marcas. En este caso, podría convenir concentrarse en la elección de la marca condicional en haber hecho una compra en la categoría.
\item
  \emph{MUTUAMENTE EXCLUYENTES:} El conjunto de decisión debe definirse de modo que en cada ocasión el tomador de decisión seleccione solo una de las alternativas disponibles. Esto es,
  la elección de una alternativa implica necesariamente la no elección de cualquiera de las alternativas restante. Aunque aparentemente restrictiva, la definición de conjunto de elección puede acomodarse para generar conjuntos mutuamente excluyente. Por ejemplo, consideremos un modelo para describir la elección de los clientes entre la \emph{tienda física tradicional} o la \emph{tienda virtual}. Si simplemente una alternativa de elección por cada canal, entonces excluimos
  la posibilidad que un mismo cliente más de un canal en un mismo periodo. Para incorporar esta posibilidad debiéramos redefinir las alternativas agregando la opción de \emph{tienda tradicional y virtual}.
\item
  \emph{FINITAS}: El conjunto debe contener un conjunto finito de alternativas. Esta condición es importante por dos motivos técnicos. Primero, un conjunto finito facilita la evaluación de la optimidad de las decisiones y segundo, facilita la definición de probabilidades de elección. Existen situaciones que la decisión teóricamente permite infinitas posibilidades, pero que en la practica se concentran en un numero reducido de alternativas y por tanto quedan bien representadas por un modelo de elección discreta. Por ejemplo, podemos usar el número de cajas de cereal compradas por los clientes en cada visita al supermercado. Aunque teóricamente los clientes siempre podrían comprar una unidad adicional, el problema queda bien descrito considerando solo las alternativas de 0,1,2,3 o más de 3 cajas.
\end{enumerate}

El comportamiento observado de los agentes es que alternativa eligieron en cada oportunidad y por tanto los modelos de elección discreta se enfocan en describir la probabilidad de elección de cada alternativa. Aunque frecuentemente nos encontraremos con situaciones en que solo observamos una decisión por agente, a continuación describiremos el caso de panel en que observamos múltiples agentes tomando decisiones en múltiples períodos.

Un modelo estructural para describir la probabilidad de elegir cada alternativa necesita especificar el mecanismo que usan los agentes para decidir entre las alternativas. Partiremos asumiendo que en cada oportunidad de compra \(t\), el tomador de decisión \(n\) elige la alternativa \(i\) que le reporta mayor utilidad \(u_{nit}\). Aunque el tomador de decisión necesariamente necesita conocer la utilidad que deriva de cada una de las alternativas, desde la perspectiva del analista solo observamos algunas características del ambiente de decisión y del tomador de decisión a partir de las cuales podemos intentar aproximar la utilidad del tomador de decisión a través de una función \(v_{nit}(x_{nit}, θ)\) donde \(x_{nit}\) son las características observables del problema y θ el vector de parámetros que buscamos estimar y que describen la relación de dichas características con la utilidad.

\textbf{Ejemplo:} Supongamos que queremos describir la elección del medio de pago que usan los usuarios de una tienda determinado, el que permite pagar en efectivo o con alguna tarjeta bancaria. El analista observa 3 variables que intuye pueden ser relevantes en la elección del medio de pago: el género del cliente (\(F_n = 1\) si cliente es de género femenino), su nivel de ingresos \((I_n)\) y el monto de la transacción \((M_{nt})\). Son precisamente estas características las que estarían incluidas en la matriz que hemos llamado \(x_{nit}\). A partir de esta información pueden plantearse múltiples modelos para describir \(v_{nit}\) (asumiremos que \(i = 0\) corresponde al caso de pago con efectivo mientras que \(i = 1\) al de pago con tarjeta).

\begin{itemize}
\tightlist
\item
  \emph{Modelo Lineal Homogéneo}: Aquí, la utilidad para ambas alternativas crece linealmente con las variables observables. En este caso, los parámetros son los mismos para todos los tomadores de decisión y por tanto el vector de parámetros viene dado por \(θ = (α_0, α_1, β, γ, δ)\)
\end{itemize}

\[v_{nit} = \alpha_i + \beta F_n + \gamma I_n + \delta M_{nt}\]

\begin{itemize}
\tightlist
\item
  \emph{Modelo Lineal Heterogéneo:} Aquí, la utilidad para ambas alternativas también crecen linealmente con las variables observables, pero ahora los parámetros varían por alternativa y por agente y por tanto el vector de parámetros viene dado por \(\theta = ( \{ \alpha_{1n} \} _{n=1}^{N}, \beta_0,\beta_1,\gamma_0,\gamma_1,\{ \delta_n \}_{n=1}^{N} )\)
\end{itemize}

\[v_{nit} = \alpha_{in} + \beta_i F_n + \gamma_i I_n + \delta_n M_{nt}\]

La definición que los interceptos dependen del cliente n simplemente nos indica que cada cliente tiene una preferencia intrínseca por cada medio de pago. Del mismo modo, estamos
imponiendo que la influencia que tiene el monto en el atractivo que tiene cada alternativa depende del cliente. Por ejemplo, mientras para algunos clientes el monto de la transacción puede jugar un rol importante en la decisión del medio de pago, para otros este efecto podría no ser relevante. Por último, la dependencia de la alternativa en los parámetros asociados a género e ingreso podrían usarse para por ejemplo situaciones en que el nivel de ingreso afecta el atractivo de un medio de pago pero no del otro (la intuición para el género es análoga).

Por supuesto, también podemos postular modelos no lineales u otras especificaciones de la heterogeneidad. Por ejemplo que la influencia del ingreso varíe por medio de pago, pero que
el efecto del género sea constante entre las alternativas. Descubrir la especificación que mejor describe el problema es precisamente la tarea del analista.

\textbf{Observación:} En el ejemplo hemos introducido brevemente el concepto de heterogeneidad. Sin embargo, para facilitar la exposición de los temas básicos, en primera instancia nos concentraremos en modelos sin heterogeneidad. En marketing los modelos que incluyen heterogeneidad en las preferencias son tan importantes que postergaremos su discusión en una capitulo separado.

En la práctica, aún en situaciones en que observamos con detalle el ambiente de decisión, no podremos describir con exactitud todas las factores que gobiernan el comportamiento de los agentes. Por lo tanto, definiremos \(\varepsilon _{nit}\) como el error (aditivo) que cometemos al aproximar \(u_{nit}\) a
través de \(v_{nit}\).

\[u_{nit} = v_{nit} + \varepsilon_{nit}\]
Así, descomponemos la utilidad de cada alternativa en una componente sistemática (u observable o explicable) \(v_{nit}\) y en una componente aleatoria (o no observable o inexplicable) \(\varepsilon_{nit}\). Como veremos, la tarea de modelamiento del problema involucra tanto la especificación de la componente sistemática como de la aleatoria.

La componente básica para estimar estadísticamente un modelo de elección discreta es la especificación de la probabilidad de elección de cada alternativa. Sea \(P_{nit}\) la probabilidad que el agente \(n\) escoja la alternativa \(i\) en la oportunidad de compra \(t\). El supuesto de maximización de utilidades
implica que \(P_{nit}\) puede escribirse como:

\begin{aligned}
P_{nit} &= Pr(u_{nit}>u_{njt},\forall j \neq i)\\
&= Pr(v_{nit} + \varepsilon_{nit} >v_{njt} + \varepsilon_{njt} ,\forall j \neq i)\\
&= \int \textbf{1} (\varepsilon_{njt} - \varepsilon_{nit} > v_{nit} - v_{njt}) f(\varepsilon_{nt}) d \varepsilon_{nt}
\end{aligned}

donde \(\textbf{1}(\cdot)\) toma el valor 1 si se cumple el argumento y el valor 0 en caso contrario. En esta expresión, \(\varepsilon_{nt} = (\varepsilon_{n1t},\varepsilon_{n2t}, ...,\varepsilon_{nIt})\) es el vector de las componentes aleatorias de la elección del agente \(n\) en la oportunidad \(t\) y \(f(·)\) la función de densidad que describe su comportamiento
probabilístico. La elección de la distribución de la componente aleatoria es importante en cuanto impone restricciones a los patrones de comportamientos que pueden ser capturados por el modelo. Concentraremos nuestra atención en los casos en que \(\varepsilon_{nit}\) se distribuye valor extremo que da origen al modelo \emph{logit} y normal que da origen al modelo \emph{probit}.

\hypertarget{modelo-logit}{%
\subsection{Modelo Logit}\label{modelo-logit}}

El modelo logit resulta de asumir que cada \(\varepsilon_{nit}\) es independientemente distribuido de acuerdo a una distribución gumbel o de valor extremo tipo I.

\begin{equation} 
  \begin{array}{cc}
  F(\varepsilon_{nit}) = e^{-e^{-\varepsilon_{nit}}}
   &f(\varepsilon_{nit}) = e^{-\varepsilon_{nit}}e^{-e^{-\varepsilon_{nit}}}
   \end{array}
  \label{eq:logituno}
\end{equation}

Aplicando esta definición, podemos demostrar que la probabilidad de elección en un modelo logit corresponde a una fórmula cerrada sencilla (para el detalle de la derivación ver \protect\hyperlink{apuxe9ndice}{apéndice}):

\begin{aligned}
P_{nit} &= \int Pr(\varepsilon_{njt} < v_{nit} - v_{njt} + \varepsilon_{nit}, \forall j \neq i | \varepsilon_{nit}) f(\varepsilon_{nit})d\varepsilon_{nit}\\
&= \int \left(\prod_{j \neq i} e^{-e^{-(v_{nit} - v_{njt} + \varepsilon_{nit})}}\right) e^{-\varepsilon_{nit}}e^{-e^{-\varepsilon_{nit}}}d \varepsilon_{nit} \\
&= \frac{e^{v_{nit}}}{\sum_j e^{v_{njt}}}
\end{aligned}

En algunos libros de texto se justifica esta expresión simplemente como una regresión logística, esto es una transformación lineal para normalizar la utilidad de modo de interpretarla directamente como una probabilidad de elección en el rango {[}0,1{]}. Aunque válido, resulta útil entender que
en efecto dicha expresión puede derivarse a partir de supuestos de maximización de utilidades.

Para ganar algo de intuición respecto a la expresión de la probabilidad de elección, es útil graficarla con respecto a la utilidad derivada por cada alternativa. Por ejemplo, supongamos que tenemos una decisión binaria que por ejemplo corresponde a decisión de comprar o no comprar un producto. En este caso, la probabilidad de comprar el producto crece \emph{sigmoidalmente} con la utilidad derivada de la compra. Esto es, al graficar la probabilidad de compra con respecto a la
utilidad derivada obtenemos una curva S como muestra la Figura 1. En la figura, hemos agregado también la curva de la probabilidad de elección en el caso en que en vez de asumir que el error se distribuye valor extremo como demanda el modelo logit, asumimos que el error está normalmente
distribuido como tradicionalmente hacemos en otros modelos econométricos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"images/probabilidad\_eleccion.png"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/probabilidad_eleccion} 

}

\caption{Probabilidad de elección}\label{fig:probelec}
\end{figure}

\FloatBarrier

La disposición de una fórmula cerrada para la probabilidad de elección facilita el cálculo de múltiples métricas asociadas que permiten complementar el análisis. Supongamos que la utilidad de una alternativa viene dada por \(v_{nit} = v(x_{nit}, θ)\), entonces podemos calcular:

\begin{itemize}
\tightlist
\item
  Como varía la probabilidad de elegir la alternativa \(i\) al variar alguna componente de la utilidad de la misma alternativa.
\end{itemize}

\[\frac{dP_{nit}}{dx_{nit}}  = \frac{\partial v_{nit}}{\partial x_{nit}} \cdot P_{nit}(1- P_{nit})\]

\begin{itemize}
\tightlist
\item
  Como varía la probabilidad de elegir la alternativa \(i\) al variar alguna componente de la utilidad otra alternativa.
\end{itemize}

\[\frac{dP_{nit}}{dx_{njt}}  = \frac{\partial v_{njt}}{\partial x_{njt}} \cdot P_{nit}\cdot P_{njt}\]

\begin{itemize}
\tightlist
\item
  Elasticidad de la probabilidad de elegir la alternativa \(i\) con respecto alguna componente de la utilidad de la misma alternativa.
\end{itemize}

\[e_{ix_{nit}} = \frac{\partial P_{nit}}{\partial x_{nit}}  \cdot \frac{x_{nit}}{P_{nit}}= \frac{\partial v_{nit}}{\partial x_{nit}} x_{nit} (1- P_{nit})\]

\begin{itemize}
\tightlist
\item
  Elasticidad de la probabilidad de elegir la alternativa \(i\) con respecto alguna componente de la utilidad otra alternativa.
\end{itemize}

\[e_{ix_{njt}} = \frac{\partial P_{nit}}{\partial x_{njt}}  \cdot \frac{x_{njt}}{P_{nit}}= \frac{\partial v_{njt}}{\partial x_{njt}} x_{njt} P_{njt}\]

Recuerden que unas de las motivaciones para el uso de modelos estructurales es la posibilidad de analizar contrafactuales, esto es ver que pasaría con el mercado si hay cambio en alguna
variable de control interesante. Por ejemplo que pasa con las participaciones de mercado si sube el precio de una alternativa, si se aumenta la frecuencia publicitaria, etc. Las métricas recién presentadas permiten precisamente hacer dichas evaluaciones de manera directa.

\hypertarget{propiedades-del-modelo-logit}{%
\subsubsection{Propiedades del modelo Logit}\label{propiedades-del-modelo-logit}}

El modelo logit es bastante flexible para acomodar una amplia variedad de situaciones. En efecto, distintas especificaciones de las funciones de utilidades de las alternativas permiten describir múltiples fenómenos asociados a la elección. Sin embargo, es importante reconocer que los supuestos subyacentes al logit imponen importantes restricciones a como describimos la lógica en que los agentes evalúan las alternativas y escogen entre ellas.

Para fijar ideas, resulta útil pensar qué restricciones impone asumir que las componentes no observables de la utilidad son todas independientes entre ellas. El supuesto de independencia
nos obliga a imponer que cualquier relación entre las utilidades de dos alternativas debe necesariamente capturarse a través de variables observables. Del mismo modo, las utilidades que derivamos por dos alternativas en ocasiones de elección diferentes solo pueden describirse a través de elementos que podamos observar a lo largo del tiempo. Para entender mejor como estas limitaciones se materializan en la formulación del modelo, discutiremos formalmente tres características del modelo logit: la existencia de patrones de substitución proporcional, la incapacidad de capturar tanto heterogeneidad aleatoria en las preferencias como componentes dinámicas no observables.

\hypertarget{patrones-de-sustituciuxf3n}{%
\paragraph*{Patrones de sustitución}\label{patrones-de-sustituciuxf3n}}
\addcontentsline{toc}{paragraph}{Patrones de sustitución}

Los patrones de substitución derivados de un modelo logit son bastante peculiares y aunque desde un punto de vista econométrico puede resultar beneficioso, desde el punto de vista de la investigación de teorías de comportamiento suele ser considerado como bastante restrictivo. Entenderemos por patrones de substitución a la forma en que cambia la probabilidad de elección de alguna alternativa cuando se modifica el atractivo de otra alternativa. Para entender la naturaleza de los patrones de substitución del modelo logit es util calcular el ratio de las probabilidades de elección de dos alternativas cualquiera \(i\) y \(j\).

\[\frac{P_{ni}}{P_{nj}} = e^{v_{ni} - v_{nj}}\]

Este ratio solo depende de las utilidades observables de las dos alternativas consideradas lo que indica que la probabilidad relativa de elegir la alternativa \(i\) sobre la alternativa \(j\) no depende de que otras alternativas existan ni de los atributos que ellas tengan. Por ejemplo, si agregamos una alternativa al conjunto de elección, el ratio de probabilidades de las alternativas existentes se mantendrá constante independiente de las características de la nueva alternativa. Nos referiremos a esta característica como \emph{independencia de alternativas irrelevantes} o \emph{IIA}.

Para ejemplificar consideremos una botillería que ofrece dos variedades de vino, uno blanco y otro tinto. Supongamos ademas que estas dos alternativas tienen la misma participación de
mercado, esto es la mitad de los clientes de la botillería compra vino blanco y la otra mitad compra vino tinto. En este caso, las utilidades sistemáticas debieran ser similares y por tanto el ratio de probabilidades de elección de vino blanco sobre vino tinto debiera acercarse a 1. Motivado por un
mayor margen de los vinos tintos, el administrador de la botillería decide incorporar una nueva variedad de vino tinto. Intuitivamente esperaríamos que, como la nueva variedad de vino tinto es un sustituto más cercano al tinto existente, la participación de mercado de este debiera decrecer
más que la de vino blanco. Sin embargo la propiedad de IIA impone que este ratio se mantiene constante. En otras palabras, la introducción de una nueva alternativa disminuirá la participación de todas la otras alternativas independiente de las similitudes que tengan. Esta última observación
puede corroborarse calculando la elasticidad de sustitución Eiznj que determina como cambia la probabilidad de consumir la alternativa \(i\) ante un cambio en un atributo \(z_{nj}\) de la alternativa \(j\).

\[E_{ix_{nj}} = -\frac{\partial v_{nj}}{\partial x_{nj}}x_{nj} P_{nj}, \forall i \neq j\]

Notamos en esta expresión que la expresión no depende de \(i\) por lo que es constante para todas las alternativas de elección. Luego, si ocurre una mejora en los atributos de una alternativa la probabilidad de elección de las demás disminuye en el mismo porcentaje independiente de la similitud entre alternativas. Nos referiremos a esta característica como \emph{patrones de sustitución proporcionales}.

Una ventaja de los patrones de substitución del modelo logit es que permite que los parámetros del modelo sean estimados consistentemente en base a un subconjunto de las alternativas. Esto es particularmente útil en ambientes de decisión de marketing donde típicamente nos encontramos con centenas de productos que potencialmente pueden constituir alternativas de elección en una situación de compra. De esta forma, para estimar un modelo logit podemos seleccionar conjuntos
reducidos de alternativas que capturan los elementos esenciales de la elección e ignorar que pasa con todas las otras alternativas.

\hypertarget{incapacidad-de-estimar-componentes-aleatorias}{%
\paragraph*{Incapacidad de estimar componentes aleatorias}\label{incapacidad-de-estimar-componentes-aleatorias}}
\addcontentsline{toc}{paragraph}{Incapacidad de estimar componentes aleatorias}

La investigación de las diferencias entre las preferencias de los distintos clientes es un tema fundamental para el desarrollo de planes comerciales exitosos. Tradicionalmente distinguimos dos tipos de heterogeneidad de acuerdo a la capacidad de observación del analista. Por un lado tenemos el estudio de heterogeneidad observable que indica como las preferencias de los tomadores de decisiones varían de acuerdo a sus características medibles. Este tipo de heterogeneidad
nos permite por ejemplo estudiar diferencias en las preferencias entre hombres y mujeres, por edad o por niveles de ingreso. Sin embargo una proporción importante de las diferencias de las preferencias no es atribuible a características observables como las recién descritas. Por ejemplo, dos hermanos del mismo género de edades similares viviendo en el mismo hogar pueden tener preferencias completamente diferentes respecto a sabores de yogur.

El resultado fundamental en esta sección indica que un modelo logit permite estudiar variaciones de preferencias asociadas a componentes observables, pero no a componentes no observables.
Para ilustrar este resultado, supongamos un tomadores de decisión caracterizados por la siguiente función de utilidad:

\[u_{nit} = \alpha_i + \beta_np_{it} + \varepsilon_{nit}\]

Es decir, la utilidad de cada alternativa tiene una componente base que es constante entre los tomadores de decisión y una penalización por precio \(p_{it}\) al que se enfrenta el tomador de decisión. Al indexar \(β_n\) por agente estamos explícitamente permitiendo que algunos tomadores decisión sean más sensibles al precio que otros. Supongamos que postulamos que el coeficiente precio viene dado por la siguiente ecuación de regresión.

\[\beta_n = \lambda_0 + \lambda_1I_n + \mu_n\]
Donde \(λ_0\) captura la sensibilidad base al precio, \(I_n\) el nivel de ingreso del agente \(n\) y \(λ_1\) el coeficiente que indica como dichos niveles de ingresos afectan la sensibilidad al precio. Por último \(\mu_n\) es un valor aleatorio que captura todas las otras componentes que modifican la sensibilidad al precio más allá del nivel base y los ingresos.

\begin{aligned}
u_{nit} &= \alpha_i + (\lambda_0 + \lambda_1 I_n + \mu_n)p_{it} + \varepsilon_{nit}\\
&= \alpha_i + \lambda_0 p_{it} + \lambda_1p_{it}I_n + \xi_{nit}
\end{aligned}

Donde \(\xi_{nit} = \mu_np_{it} + \varepsilon_{nit}\). De esta expresión debiera ser claro que la inclusión de heterogeneidad
observable puede ser capturada bajo un enfoque logit. En efecto, los parámetros \(α_i\), \(λ_0\) y \(λ_1\) dan cuenta respectivamente del nivel de utilidad base por alternativa, de la penalización por precio y de como dicha penalización se ve modificada por el nivel de ingresos. Lamentablemente, la
variación aleatoria µn no puede ser incluida ya que su inclusión necesariamente implica que las componentes errores \(\xi_{nit}\) no están idénticamente distribuidas. En efecto, se puede mostrar que \(\mathbb{V}ar(\xi_{nit}, \xi_{njt}) = \mathbb{V}ar(\mu_n)p^2_{it}\) que evidentemente varía entre alternativas. Más aún, también se puede mostrar que \$\mathbb{C}ov(\xi\emph{\{nit\}, \xi}\{njt\}) = \mathbb{V}ar(\mu\emph{n)p}\{it\}p\_\{jt\} \neq 0 \$violando también el supuesto de independencia.

Es importante notar que la incapacidad de capturar aleatoriedad aplica también a componentes dinámicas. Esto es, al observar compras repetidas en el tiempo, el modelo logit no permite capturar que hay componentes no observables que varíen en el tiempo. Por ejemplo no podemos incorporar que, debido a factores externos no observables, en algunos periodos algunas alternativas son más atractivas para todos los agentes decidiendo en dichos periodos. Al igual que en el ejemplo anterior, incluir estas variaciones viola los supuestos de distribuciones independientes e idénticamente distribuidas para las componentes no observables.

\hypertarget{estimaciuxf3n-1}{%
\subsection{Estimación}\label{estimaciuxf3n-1}}

Para estimar el modelo, necesitamos escribir la verosimilitud del problema. La componente fundamental para la construcción de la verosimilitud es la descripción de la probabilidad de
elección \(P_{nit}\). Para el caso del modelo logit, como la expresión de la probabilidad de elección corresponde a una fórmula analítica cerrada, la construcción de la verosimilitud es directa. Si la componente determinística de la utilidad viene dada por \(v_{nit}(x_{nit}, θ)\) y si \(y_{nit}\) es una variable que toma valor 1 si el tomador de decisión \(n\) escoge alternativa \(i\) en oportunidad \(t\), entonces la verosimilitud viene dada por:

\[L(\theta) = \prod_n\prod_i\prod_t (P_{nit})^{y_{nit}} =  \prod_n\prod_i\prod_t \left(\frac{e^{v_{nit}(x_{nit},\theta)}}{\sum_j e^{v_{njt}(x_{njt},\theta)}}\right)^{y_{nit}} \]
La que podemos maximizar directamente usando rutinas estándares de programación convexa. Computacionalmente, suele ser más conveniente trabajar con la log-verosimilitud en vez de la verosimilitud. Esto porque la multiplicación de probabilidades genera muy rápidamente valores que computacionalmente son indistinguibles de cero. Recordar que el valor de los valores óptimos son invariantes a transformaciones monótonas como la del logaritmo.

\begin{aligned}
LL(\theta) &= \sum_n\sum_i\sum_t y_{nit} ln \left(\frac{e^{v_{nit}(x_{nit},\theta)}}{\sum_j e^{v_{njt}(x_{njt},\theta)}}\right)\\
&= \sum_n\sum_i\sum_t y_{nit}v_{nit}(x_{nit},\theta) - \sum_n\sum_i\sum_t ln \left(\sum_j e^{v_{njt}(x_{njt},\theta)}\right)
\end{aligned}

Como hemos indicado, esta función objetivo puede ser ingresada directamente a cualquier rutina de optimización para encontrar los estimadores máximo verosímiles. Para muchas instancias prácticas, es conveniente contar además con las derivadas de la log-verosimilitud de modo de encontrar eficientemente direcciones de máximo ascenso o evaluar si el punto es estacionario o no. Afortunadamente, para la mayoría de las especificaciones del modelo logit, estas derivadas también son fáciles de obtener. Por ejemplo, si la componente sistemática de la utilidad viene dada por \(v_{nit}(x_{nit}, θ) = x'_{nit}θ\) entonces

\[\frac{\partial LL(\theta)}{\partial \theta} = \sum_n\sum_i\sum_t \left(y_{nit} - \frac{e^{x'_{nit}θ}}{\sum_j e^{x'_{njt}θ}}\right)x_{nit}\]

Del mismo modo, podemos calcular segundas derivadas que resultan útiles para el cálculo de errores estándares de los parámetros.

\hypertarget{evaluaciuxf3n-del-modelo}{%
\subsubsection*{Evaluación del modelo}\label{evaluaciuxf3n-del-modelo}}
\addcontentsline{toc}{subsubsection}{Evaluación del modelo}

Al igual que en otros modelos econométricos, una de las componentes fundamentales del análisis es la evaluación de la calidad del modelo. La variedad de métricas disponibles para la evaluación es muy amplia y la mayoría son transversales a cualquier modelo. Categorizaremos las herramientas de evaluación en tres grupos: bondad de ajuste, capacidad de pronóstico y test de hipótesis.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{BONDAD DE AJUSTE}: Las métricas de bondad de ajuste básicamente nos indican que tan bien el modelo ajusta a la data. En el contexto de modelos de regresión, solemos analizar el estadístico \(R^2\) que mide la proporción de la variabilidad de la variable dependiente que puede ser explicado por la variación de las variables independientes. En el contexto de modelos de elección discreta basaremos la evaluación en el valor de la verosimilitud usando alguno o varios de los siguientes indicadores:
\end{enumerate}

\begin{itemize}
\item
  \(\rho\) de McFadden. Este índice está en el rango {[}0,1{]} e informalmente, se suele interpretar como el coeficiente de determinación \((R^2)\) en el sentido que un valor cercano a 0 indica un mal ajuste y un valor cercano a 1 indica un buen ajuste. Sin embargo, es importante notar que no puede decirse que \(\rho\) mida la variabilidad explicada por el modelo como
  hace el coeficiente de determinación

  \[\rho=1 - \frac{LL(\hat{\beta})}{LL(0)}\]
\item
  Criterio de información de Akaike(AIC) y Bayesiano (BIC): Uno de las limitaciones del ρ de McFadden es que solo permite comparar modelos con el mismo numero de parámetros. Los dos indicadores más usados para comparar modelos con distintos números de parámetros son AIC y BIC en que se penaliza la verosimilitud por el número de parámetros para capturar el hecho que al incluir nuevos parámetros la verosimilitud necesariamente crecerá. La diferencia entre AIC y BIC es que el primero tiene una penalización constante por numero de parámetros mientras que la penalización del segundo depende de la cantidad de data disponible. Si la log verosimilitud de un modelo con n observaciones y k parámetros es LL entonces AIC y BIC vienen dados por:
\end{itemize}

\begin{array}{cc}
AIC = -LL(\hat{\theta} + 2k) & BIC =-2LL(\hat{\theta} + kln(n))
\end{array}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \emph{CAPACIDAD DE PRONÓSTICO}: Un modelo que explique muy bien la data puede correr el riesgo de sobre ajustar. Esto es que no permita describir el fenómeno más allá de los datos
  con que se calibran. Para medir la capacidad de pronóstico se suele dividir la data en un subconjunto de calibración en que estimamos el modelo y otro de validación en que comparamos las realizaciones con lo pronosticado usando las estimaciones del subconjunto de calibración. Supongamos que estamos interesados en evaluar la capacidad de pronostico de un indicador \(f_{ni}\) que puede corresponder a las elecciones mismas, participaciones de mercado o cualquier otra. Si \(\hat{f}_{ni}\) es el pronostico del modelo entonces solemos usar el mean
  absolute error (MAE) o el mean absolute percentage error (MAPE)
\end{enumerate}

\begin{array}{cc}
MAE = \frac{1}{N} \sum_n \sum_i |f_{ni} - \hat{f}_{ni}| &MAPE = \frac{1}{N} \sum_n \sum_i \left| \frac{f_{ni} - \hat{f}_{ni}}{f_{ni}} \right|
\end{array}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \emph{TEST DE HIPÓTESIS}: La evaluación de hipótesis, también puede contribuir a diagnosticar un modelo. Por ejemplo, al agregar una variable explicativa, nos gustaría evaluar si el coeficiente correspondiente es significativamente diferente de 0, lo que podemos hacer directamente a través de la construcción de intervalos de confianza o su estadístico \(t\) equivalente (recordar que la varianza de del estimador máximo verosímil puede obtenerse usando el inverso del Hessiano). En ocasiones también estaremos interesados en testear hipótesis más complejas para lo que recurrimos a test de ratios de verosimilitud. Supongamos por ejemplo que tenemos un modelo en que los coeficientes asociado a display difieren por marca para incorporar la posibilidad que algunas de ellas sean más efectivas en su comunicación en sala. El test de ratios de verosimilitud nos permite por ejemplo testear si estos coeficientes son iguales o si efectivamente difieren entre marcas. Si la hipótesis nula puede expresarse como \(k\) restricciones sobre los parámetros, entonces podemos estimar un modelo A no restringido y otro B restringido y calculamos el estadístico \(LR = 2(LLA − LLB)\), que se distribuye \(\chi^2\)
  con k grados de libertad.
\end{enumerate}

\hypertarget{modelos-de-panel-persistencia-y-dependencia-temporal}{%
\subsection{Modelos de Panel: Persistencia y Dependencia Temporal}\label{modelos-de-panel-persistencia-y-dependencia-temporal}}

Hasta ahora hemos discutido modelos de elección discreta asumiendo implícitamente que cada observación de elección es independiente de las demás. Sin embargo, cuando disponemos de datos de panel (observaciones repetidas del mismo individuo a lo largo del tiempo), es razonable esperar que las elecciones de un individuo en diferentes períodos estén relacionadas. En contextos de marketing, esta dependencia temporal puede manifestarse de diversas formas, siendo dos de las más relevantes la \textbf{persistencia de elección} (o lealtad) y la formación de \textbf{precios de referencia}.

\hypertarget{persistencia-de-elecciuxf3n-lealtad}{%
\subsubsection{Persistencia de Elección (Lealtad)}\label{persistencia-de-elecciuxf3n-lealtad}}

Uno de los fenómenos más documentados en el comportamiento de compra es la tendencia de los consumidores a repetir sus elecciones previas, lo que comúnmente se denomina lealtad de marca o inercia en el comportamiento. Esta persistencia puede originarse en múltiples factores:

\begin{itemize}
\tightlist
\item
  \textbf{Costos de cambio:} Tanto físicos (esfuerzo de probar algo nuevo) como psicológicos (aversión al riesgo)
\item
  \textbf{Aprendizaje:} Experiencias positivas pasadas reducen la incertidumbre sobre el producto
\item
  \textbf{Satisfacción acumulada:} La utilidad experimentada en compras previas afecta la percepción actual
\item
  \textbf{Hábito:} Rutinas de compra que simplifican el proceso de decisión
\end{itemize}

Para capturar esta persistencia en un modelo logit, se introduce una variable de \textbf{lealtad latente} \(z_{nit}\) que representa la propensión no observable del individuo \(n\) a elegir la alternativa \(i\) en el período \(t\), basada en su historia de elecciones previas.

\textbf{Modelamiento de la Persistencia:}

La utilidad del individuo \(n\) por la alternativa \(i\) en el período \(t\) se especifica como:

\begin{equation}
u_{nit} = \alpha_i + \beta x_{it} + \gamma z_{nit} + \varepsilon_{nit}
\label{eq:utilpersist}
\end{equation}

donde:
- \(\alpha_i\) es la constante alternativa-específica
- \(x_{it}\) son las covariables observables (precio, promoción, etc.)
- \(\beta\) es el vector de coeficientes asociados a las variables observables
- \(z_{nit}\) es la \textbf{lealtad latente} (no observable)
- \(\gamma\) mide el efecto de la persistencia en la elección
- \(\varepsilon_{nit}\) es el término de error i.i.d. valor extremo tipo I

\textbf{Construcción de la Variable de Lealtad:}

La variable de lealtad \(z_{nit}\) se construye como un promedio ponderado exponencialmente de las elecciones pasadas del individuo. Sea \(y_{nit}\) una variable indicadora que toma valor 1 si el individuo \(n\) eligió la alternativa \(i\) en el período \(t\) y 0 en caso contrario. Entonces:

\begin{equation}
z_{nit} = \lambda z_{nit-1} + (1 - \lambda) y_{nit-1}
\label{eq:loyalty}
\end{equation}

donde \(0 \leq \lambda \leq 1\) es un \textbf{parámetro de decaimiento} que determina qué tan rápido se desvanece el efecto de las elecciones pasadas.

\textbf{Interpretación del Parámetro \(\lambda\):}

\begin{itemize}
\tightlist
\item
  \textbf{\(\lambda = 0\):} Solo importa la elección inmediatamente anterior (\(z_{nit} = y_{nit-1}\))
\item
  \textbf{\(\lambda\) cercano a 1:} La historia completa de elecciones tiene peso significativo
\item
  \textbf{\(\lambda = 1\):} Todas las elecciones pasadas tienen el mismo peso (memoria perfecta)
\end{itemize}

Expandiendo recursivamente la ecuación \eqref{eq:loyalty}:

\begin{aligned}
z_{nit} &= \lambda z_{nit-1} + (1-\lambda) y_{nit-1}\\
&= \lambda[\lambda z_{nit-2} + (1-\lambda)y_{nit-2}] + (1-\lambda)y_{nit-1}\\
&= (1-\lambda)\sum_{s=1}^{t-1} \lambda^{t-1-s} y_{nis}
\end{aligned}

Esta expresión muestra que \(z_{nit}\) es un promedio ponderado de todas las elecciones pasadas, donde las elecciones más recientes reciben mayor peso.

\textbf{Inicialización:}

Para el primer período observado, se requiere una condición inicial. Las opciones comunes son:
- \(z_{ni1} = 0\) para todas las alternativas
- \(z_{ni1} = 1/J\) donde \(J\) es el número de alternativas (distribución uniforme)
- \(z_{ni1}\) basado en participación de mercado agregada

\textbf{Estimación:}

El parámetro \(\lambda\) puede ser:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Fijado a priori:} Por ejemplo, \(\lambda = 0\) para considerar solo la elección inmediata anterior
\item
  \textbf{Estimado como parte del modelo:} Se incluye \(\lambda\) como parámetro adicional a estimar, buscando en una grilla de valores \((0, 0.1, 0.2, ..., 0.9)\) o mediante búsqueda numérica
\item
  \textbf{Específico por alternativa:} \(\lambda_i\) diferente para cada alternativa, permitiendo que algunas marcas generen más lealtad que otras
\end{enumerate}

\textbf{Interpretación de \(\gamma\):}

El coeficiente \(\gamma\) mide la magnitud del efecto de la persistencia:
- \textbf{\(\gamma > 0\):} Existe persistencia positiva - los consumidores tienden a repetir elecciones previas
- \textbf{\(\gamma = 0\):} No hay efecto de persistencia - las elecciones son independientes en el tiempo
- \textbf{\(\gamma < 0\):} Búsqueda de variedad - los consumidores tienden a cambiar de alternativa

En la mayoría de contextos de marketing, se espera \(\gamma > 0\), aunque en categorías donde la variedad es valorada (helados, restaurantes) podría observarse \(\gamma < 0\).

\textbf{Ejemplo Numérico:}

Supongamos un mercado de yogur con 3 marcas (A, B, C) y un consumidor que en los últimos 5 períodos eligió: A, A, B, A, ? (período actual). Con \(\lambda = 0.5\):

Para la marca A:

\begin{aligned}
z_{A,t} &= (1-0.5)[1 \cdot 0.5^0 + 0 \cdot 0.5^1 + 1 \cdot 0.5^2 + 1 \cdot 0.5^3]\\
&= 0.5[1 + 0 + 0.25 + 0.125] = 0.6875
\end{aligned}

Para la marca B: \(z_{B,t} = 0.5[0 + 1 \cdot 0.5^1 + 0 + 0] = 0.25\)

Para la marca C: \(z_{C,t} = 0\)

Si \(\gamma = 2\), entonces la marca A recibe un incremento de utilidad de \(2 \times 0.6875 = 1.375\) debido a la lealtad acumulada.

\hypertarget{precios-de-referencia}{%
\subsubsection{Precios de Referencia}\label{precios-de-referencia}}

Otro aspecto fundamental del comportamiento de compra con datos de panel es la formación de \textbf{precios de referencia} (reference prices). Los consumidores no evalúan los precios en términos absolutos, sino que los comparan con un precio de referencia interno formado a partir de precios observados en el pasado. Esta noción está bien fundamentada tanto en teoría económica (teoría de prospectos) como en evidencia empírica de marketing.

\textbf{Modelamiento de Precios de Referencia:}

La utilidad se especifica incorporando tanto el efecto del precio actual como de la desviación respecto al precio de referencia:

\begin{equation}
u_{nit} = \alpha_i + \beta_1 P_{nit} - \beta_2(P_{nit} - RP_{nit}) + \delta x_{nit} + \varepsilon_{nit}
\label{eq:utilrefprice}
\end{equation}

donde:
- \(P_{nit}\) es el precio actual de la alternativa \(i\) para el individuo \(n\) en período \(t\)
- \(RP_{nit}\) es el \textbf{precio de referencia} (no observable) de la alternativa \(i\)
- \(\beta_1\) captura el efecto del precio absoluto
- \(\beta_2\) captura el efecto de pérdida/ganancia respecto al precio de referencia
- \(x_{nit}\) son otras covariables

\textbf{Interpretación de Coeficientes:}

\begin{itemize}
\tightlist
\item
  \textbf{Precio absoluto (\(\beta_1\)):} Se espera \(\beta_1 < 0\) - mayor precio reduce utilidad
\item
  \textbf{Desviación de precio de referencia (\(\beta_2\)):} Se espera \(\beta_2 > 0\)

  \begin{itemize}
  \tightlist
  \item
    Si \(P_{nit} > RP_{nit}\) (precio mayor que referencia): efecto negativo adicional - ``pérdida percibida''
  \item
    Si \(P_{nit} < RP_{nit}\) (precio menor que referencia): efecto positivo adicional - ``ganancia percibida''
  \end{itemize}
\end{itemize}

La especificación captura que los consumidores son \textbf{más sensibles a desviaciones del precio de referencia} que al nivel de precio absoluto, consistente con teoría de prospectos que postula mayor sensibilidad a pérdidas que a ganancias.

\textbf{Construcción del Precio de Referencia:}

Similar a la lealtad, el precio de referencia se construye como promedio ponderado exponencialmente de precios pasados:

\begin{equation}
RP_{nit} = \lambda RP_{nit-1} + (1-\lambda) P_{nit-1}
\label{eq:refprice}
\end{equation}

donde \(\lambda\) es el parámetro de persistencia del precio de referencia.

\textbf{Especificaciones Alternativas:}

Existen múltiples formas de construir el precio de referencia:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Promedio móvil simple:} \(RP_{nit} = \frac{1}{k}\sum_{s=t-k}^{t-1} P_{nis}\) (últimos \(k\) períodos)
\item
  \textbf{Promedio ponderado exponencial:} Ecuación \eqref{eq:refprice}
\item
  \textbf{Precio mínimo observado:} \(RP_{nit} = \min_{s<t} P_{nis}\) (precio más bajo visto)
\item
  \textbf{Combinación de precio esperado y mínimo:} \(RP_{nit} = \omega \cdot E[P_{it}] + (1-\omega) \cdot \min_{s<t} P_{nis}\)
\item
  \textbf{Específico por fuente:} Separar precios de referencia internos (memoria) vs.~externos (precios de competidores)
\end{enumerate}

La elección de la especificación debe basarse en el contexto del mercado y puede evaluarse empíricamente comparando ajuste del modelo.

\textbf{Especificaciones Asimétricas:}

La teoría de prospectos sugiere que las pérdidas (precios mayores que referencia) pesan más que las ganancias (precios menores). Esto motiva especificaciones asimétricas:

\begin{equation}
u_{nit} = \alpha_i + \beta_1 P_{nit} - \beta_2^+ \max(P_{nit} - RP_{nit}, 0) - \beta_2^- \max(RP_{nit} - P_{nit}, 0) + \delta x_{nit} + \varepsilon_{nit}
\label{eq:utilasym}
\end{equation}

donde \(\beta_2^+\) captura el efecto de precios superiores a la referencia (pérdida) y \(\beta_2^-\) el efecto de precios inferiores (ganancia). Típicamente se encuentra \(\beta_2^+ > \beta_2^-\), confirmando aversión a pérdidas.

\textbf{Ejemplo Numérico:}

Considérese un producto con la siguiente historia de precios: \$10, \$12, \$9, \$11, ?.
Con \(\lambda = 0.6\):

\begin{aligned}
RP_t &= 0.6 \cdot RP_{t-1} + 0.4 \cdot P_{t-1}\\
RP_2 &= 0.4 \cdot 10 = 4.0\\
RP_3 &= 0.6 \cdot 4.0 + 0.4 \cdot 12 = 7.2\\
RP_4 &= 0.6 \cdot 7.2 + 0.4 \cdot 9 = 7.92\\
RP_5 &= 0.6 \cdot 7.92 + 0.4 \cdot 11 = 9.152
\end{aligned}

Si en el período 5 el precio es \$13 y tenemos \(\beta_1 = -0.5\) y \(\beta_2 = 0.8\):

\[u_5 = \alpha + (-0.5)(13) - 0.8(13 - 9.152) + ... = \alpha - 6.5 - 3.08 + ... \]

El precio \$13 genera:
- Efecto directo: \(-0.5 \times 13 = -6.5\)
- Efecto de pérdida percibida: \(-0.8 \times 3.848 = -3.08\)
- \textbf{Efecto total:} \(-9.58\) (más negativo que solo el efecto directo)

\hypertarget{combinaciuxf3n-de-persistencia-y-precios-de-referencia}{%
\subsubsection{Combinación de Persistencia y Precios de Referencia}\label{combinaciuxf3n-de-persistencia-y-precios-de-referencia}}

En la práctica, ambos fenómenos suelen coexistir. Un modelo integrado especificaría:

\begin{equation}
u_{nit} = \alpha_i + \beta_1 P_{nit} - \beta_2(P_{nit} - RP_{nit}) + \gamma z_{nit} + \delta x_{nit} + \varepsilon_{nit}
\label{eq:utilfull}
\end{equation}

donde tanto \(z_{nit}\) como \(RP_{nit}\) se construyen recursivamente usando los datos históricos del individuo:

\begin{aligned}
z_{nit} &= \lambda_z z_{nit-1} + (1-\lambda_z) y_{nit-1}\\
RP_{nit} &= \lambda_p RP_{nit-1} + (1-\lambda_p) P_{nit-1}
\end{aligned}

\textbf{Estimación Conjunta:}

Los parámetros \(\lambda_z\) y \(\lambda_p\) pueden:
- Fijarse a valores específicos (ej: 0.5 para ambos)
- Estimarse mediante búsqueda en grilla
- Ser específicos por alternativa o categoría

La estimación se realiza por máxima verosimilitud, maximizando:

\begin{equation}
LL(\theta) = \sum_{n=1}^N \sum_{t=1}^T \sum_{i=1}^J y_{nit} \ln P_{nit}(\theta)
\label{eq:llpanel}
\end{equation}

donde \(P_{nit}(\theta)\) incluye los efectos de persistencia y precios de referencia.

\textbf{Consideraciones de Identificación:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Colinealidad:} \(z_{nit}\) y las constantes de alternativa pueden estar correlacionadas si hay mucha persistencia. Puede ser necesario fijar algunas constantes o normalizar.
\item
  \textbf{Períodos iniciales:} Las primeras observaciones de cada individuo requieren condiciones iniciales para \(z_{ni1}\) y \(RP_{ni1}\). Se pueden:

  \begin{itemize}
  \tightlist
  \item
    Fijar en valores neutrales
  \item
    Tratarlas como parámetros adicionales
  \item
    Excluir primeras observaciones del likelihood
  \end{itemize}
\item
  \textbf{Endogeneidad:} Si las firmas ajustan precios anticipando lealtad, puede haber endogeneidad. Instrumentos o modelos estructurales de oferta y demanda pueden ser necesarios.
\end{enumerate}

\hypertarget{implicaciones-para-marketing}{%
\subsubsection{Implicaciones para Marketing}\label{implicaciones-para-marketing}}

Los modelos de panel con persistencia y precios de referencia tienen implicaciones prácticas importantes:

\textbf{1. Valoración de Lealtad:}
El parámetro \(\gamma\) permite cuantificar el valor de construir lealtad. Una marca con alta lealtad acumulada puede sostener precios mayores o requiere menos promoción.

\textbf{2. Estrategias de Precio Dinámico:}
Entender cómo se forman los precios de referencia permite diseñar trayectorias de precio óptimas. Descuentos temporales pueden generar ganancias percibidas sin reducir permanentemente el precio de referencia si \(\lambda\) es alto.

\textbf{3. Efectos de Promociones:}
Las promociones no solo afectan ventas en el período actual sino que:
- Pueden generar lealtad (\(z_{nit}\) aumenta si se compra)
- Reducen el precio de referencia futuro (efecto negativo en períodos post-promoción)

\textbf{4. Segmentación:}
Individuos difieren en \(\lambda_z\) y \(\lambda_p\). Algunos son más sensibles a historia reciente, otros mantienen memoria más larga. Identificar estos segmentos permite targeting diferenciado.

\textbf{5. Evaluación de Campañas:}
Al evaluar el impacto de una campaña de marketing, se debe considerar tanto el efecto inmediato como el efecto persistente a través de lealtad acumulada.

\hypertarget{apuxe9ndice}{%
\subsection*{Apéndice}\label{apuxe9ndice}}
\addcontentsline{toc}{subsection}{Apéndice}

\textbf{Derivación probabilidad de elección modelo logit}

Por definición

\[P_{nit} = Pr(\varepsilon_{njt}<v_{nit} - v_{njt} + \varepsilon_{nit}), \forall j \neq i\]
Fijando el valor de \(\varepsilon_{nit}\), la probabilidad anterior no es más que una multiplicación de funciones distribución de variables aleatorias valor extremo. Por lo tanto podemos condicionar en \(\varepsilon_{nit}\) y luego integrar respecto a los valores que puede tomar. Para simplificar la notación, sea \(s=\varepsilon_{nit}\)

\begin{aligned}
P_{nit} &= \int_{-\infty}^{\infty} \left(\prod_{j\neq i}    e^{-e^{-(s + v_{ni} - v_{nj})}}\right) e^{-s} e^{-e^{-s}}ds\\
&= \int_{-\infty}^{\infty} \left(\prod_{j}   e^{-e^{-(s + v_{ni} - v_{nj})}}\right) e^{-s}ds\\
&= \int_{-\infty}^{\infty} exp\left(\sum_{j}  e^{-(v_{ni} - v_{nj})}\right) e^{-s}ds
\end{aligned}

Para resolver la integral podemos recurrir a un cambio de variables \(t = e^{−s}\) y \(dt = e^{−s}ds\). Con esto

\begin{aligned}
P_{nit} &= \int_{\infty}^{0} -e^{t\sum_{j}  e^{-(v_{ni} - v_{nj})}} dt\\
&= \frac{ e^{-(v_{ni} - v_{nj})}}{\sum_{j}  e^{-(v_{ni} - v_{nj})}}\mid^{\infty}_{0}\\
&= \frac{e^{v_{ni}}}{\sum_j e^{v_{nj}}}
\end{aligned}

\hypertarget{probit}{%
\section{Probit}\label{probit}}

\hypertarget{definiciuxf3n}{%
\subsection{Definición}\label{definiciuxf3n}}

Al introducir modelos de elección discreta, postulamos que los tomadores de decisiones disponían de una función de utilidad subyacente que descomponíamos en una componente determinística y otra aleatoria. Más aún, discutimos que el modelo que describe la probabilidad de elegir cada una de las alternativas quedaba directamente determinada por la distribución que asumiéramos para la componente aleatoria de la utilidad. Aunque una especificación de errores normales
centrados en cero tiene una larga tradición en modelos econométricos, por simplicidad optamos iniciar la discusión con modelos \emph{logit} derivados de asumir que la componente aleatoria de la utilidad se distribuía valor extremo tipo I. En este capitulo volveremos al caso de componentes
aleatorias normales que dan origen al modelo probit. Formalmente, un modelo \emph{probit} resulta de los siguientes supuestos de comportamiento:

\begin{equation} 
  \begin{array}{cc}
  u_{ni} = v_{ni} + \varepsilon_{ni} &\varepsilon_n \sim N(0,Σ)
  \end{array}  
  \label{eq:compo}
\end{equation}

La normalidad de los errores provee bastante flexibilidad para acomodar una amplia variedad de estructuras de las preferencias. Como veremos en la discusión que sigue, un modelo con errores normales permite acomodar factores sistemáticos no observables en la utilidad. Una de las pocas limitaciones de un modelo probit viene de la normalidad dichos factores. Por ejemplo, si queremos incorporar el efecto que tiene el precio en la utilidad como una componente aleatoria, entonces las colas de la distribución normal implicara una probabilidad positiva de que algunos clientes aumenten la utilidad de una alternativa si aumenta el precio de esta. Formalmente, el supuesto de la normalidad de la componente aleatoria de la utilidad implica que su función de densidad viene dada por:

\begin{equation} 
  \phi(\varepsilon_n) = \frac{1}{(2\pi)^{I/2}|Σ|^{1/2}}e^{-\frac{1}{2} \varepsilon'_n Σ^{-1}\varepsilon_n} 
  \label{eq:density}
\end{equation}

Esta expresión no es más que la versión multivariada de la bien conocida densidad de la distribución \(N(0, \sigma^2)\). La matriz Σ corresponde a la matriz varianza-covarianza de los errores. Por tratarse de una distribución normal, la matriz Σ es simétrica y de dimensión I × I, donde I es el número de alternativas disponibles para el tomador de decisión. Por ejemplo, si hay tres alternativas disponibles, la matriz Σ tomaría la siguiente forma:

\begin{equation} 
  Σ = \begin{bmatrix} \sigma_{11} & \sigma_{12} & \sigma_{13}\\
 \cdot & \sigma_{22} & \sigma_{23}\\
 \cdot & \cdot & \sigma_{33}
\end{bmatrix} 
  \label{eq:matrix}
\end{equation}

Los coeficientes en la diagonal dan cuenta de la variabilidad de la componente aleatoria de la utilidad. Así por ejemplo, si \(σ_{ii}\) tiene un valor alto indica que hay una fracción importante de la utilidad de la alternativa \(i\) que no es capturada por el modelo de la componente sistemática. Los
coeficientes fuera de la diagonal dan cuenta de la correlación de las componentes no observables de cada una de las alternativas. De este modo, si \(σ_{ij}\) tiene un valor positivo alto indica que existe un elemento no observable importante que afecta simultáneamente las alternativas \(i\) y \(j\).

Como vimos en el desarrollo del modelo \emph{logit}, una componente fundamental para estimar un modelo de elección discreta es la derivación de una expresión para la probabilidad que cada agente elija cada alternativa en cada ocasión. Para el modelo probit, la probabilidad que el individuo \(n\) elija la alternativa \(i\) viene dada por:

\begin{equation} 
  \begin{aligned}
    P_{ni} &= Pr (v_{ni} + \varepsilon_{ni} > v_{nj} + \varepsilon_{nj}), \forall j \neq i \\
    &= \int \textbf{1} (v_{ni} + \varepsilon_{ni} > v_{nj} + \varepsilon_{nj})\phi(\varepsilon_n)d\varepsilon_n , \forall j \neq i
  \end{aligned}  
  \label{eq:modprobit}
\end{equation}

Intuitivamente, simplemente calculamos el volumen bajo la densidad \(\phi(\varepsilon_n)\) en la región en que los errores son tales que la alternativa \(i\) es aquella que reporta mayor utilidad al individuo \(n\). A diferencia del modelo logit, la integral sobre la densidad \(\phi(\cdot)\) no tiene primitiva analítica y por tanto no disponemos de una formula cerrada para \(P_{ni}\).

\hypertarget{patrones-de-substituciuxf3n}{%
\subsection{Patrones de substitución}\label{patrones-de-substituciuxf3n}}

Una de las grandes ventajas de un modelo \emph{probit} es su flexibilidad para capturar una amplia variedad de patrones de comportamiento. En efecto, un modelo \emph{probit} no impone restricciones en los patrones de substitución más allá de la simetría propia de la distribución normal lo que posibilita al analista explorar el esquema que mejor se ajusta a la data. En este sentido, es útil compararlo con el modelo \emph{logit} que, aunque provee una fórmula analítica cerrada para la probabilidad de cada elección, impone la propiedad de substitución proporcional (o de independencia de alternativas irrelevantes). El modelo probit no tiene esta propiedad y por tanto el aumento de la probabilidad de elección de una alternativa puede tener impactos diferentes en las probabilidades de elección de las alternativas remanentes. Esto permitiría por ejemplo identificar pares de alternativas que son mejores substitutos (complementos) más allá de las comonalidades que podrían existir en las componentes determinísticas de su utilidad.

A continuación discutiremos como el modelo probit puede ser usado para representar algunas situaciones de elección discreta.

\hypertarget{variaciuxf3n-aleatorias-en-preferencias}{%
\subsubsection{Variación aleatorias en preferencias}\label{variaciuxf3n-aleatorias-en-preferencias}}

Una de las componentes más importantes en el diseño de un plan comercial exitoso es la identificación de como las preferencias de los potenciales clientes se distribuyen en la población. Identificando estas variaciones, podemos encontrar las propuestas de valor que resulten más atractivas para cada grupo de clientes. En un modelo probit, podemos asumir que los parámetros que definen la componente determinística son heterogéneos en la población sin perder los supuestos básicos que definen el modelo. Por simplicidad, supongamos que la componente determinística de la utilidad es lineal:

\begin{equation} 
  \begin{array}{cc}
    u_{ni} = \beta'_{n} x_{ni} + \varepsilon_{ni} & \varepsilon_n \sim N(0,Σ)
  \end{array}  
  \label{eq:cdeterminista}
\end{equation}

Notar que a diferencia de los modelos anteriores, ahora hemos asumido que cada tomador de decisión \(n\) tiene su propio set de parámetros \(β_n\) que describen sus preferencias por las alternativas disponibles. Para completar el modelo necesitamos especificar una distribución de \(β_n\) en la población. Para mantener la estructura del modelo asumiremos normalidad: \(β_n ∼ N(b, σ^2_β)\). Dado que la suma de dos variables aleatorias normales se distribuye normal, es fácil ver que el modelo es
equivalente a

\begin{equation} 
  \begin{array}{cc}
    u_{ni} = b'_{n} x_{ni} + \eta_{ni} & \eta_n \sim N(0,\hat{Σ})
  \end{array}  
  \label{eq:cdeterministaequi}
\end{equation}

Las componentes de la matriz de varianza-covarianza resultante \(\hat{Σ}\) pueden trazarse directamente a las componentes de la matriz Σ original como lo indica el siguiente ejemplo:

\textbf{Ejemplo:} Consideremos un modelo de elección con dos alternativas y un modelo lineal con una única variable para describir la componente sistemática de la utilidad. En este caso, las utilidades por cada alternativa vienen dadas por:

\begin{aligned}
u_{n1} &= \beta_n x_{n1} + \varepsilon_{n1}\\
u_{n2} &= \beta_n x_{n2} + \varepsilon_{n2}
\end{aligned}

donde \(\varepsilon_{n1}\) y \(\varepsilon_{n2}\) son términos independientes e idénticamente distribuidos con varianza \(σ_\varepsilon\). Si asumimos que el parámetro \(β_n\) se distribuye normal con media \(b\) y varianza \(σ_β\), entonces podemos re-escribir las utilidades como:

\begin{aligned}
u_{n1} &= b x_{n1} + \eta_{n1}\\
u_{n2} &= b x_{n2} + \eta_{n2}
\end{aligned}

donde \(\eta_{n1}\) y \(\eta_{n2}\) están normalmente distribuidas. Cada una tiene esperanza cero: \(\mathbb{E}(\eta_{ni}) =\mathbb{E}(β_nx_{ni} + ε_{ni}) = 0\), varianza igual a \(\mathbb{V}ar(\eta_{ni}) = \mathbb{V}ar(β_n x_{ni} + ε_{ni}) = x^2_{ni}σ_β + σ_ε\) y covarianzas \(\mathbb{C}ov(\eta_{n1}, \eta_{n2}) = x_{n1}x_{n2}σ_β\). Así, la matriz de covarianza viene dada por:

\begin{aligned}
Σ &= \begin{bmatrix}x^2_{n1}σ_β + σ_ε & x_{n1}x_{n2}σ_β\\
x_{n1}x_{n2}σ_β & x^2_{n2}σ_β + σ_ε \end{bmatrix} \\
&= \sigma_\beta \begin{bmatrix}x^2_{n1} & x_{n1}x_{n2}\\
x_{n1}x_{n2} & x^2_{n2} \end{bmatrix} + \sigma_{\varepsilon} \begin{bmatrix}1 & 0\\
0 & 1\end{bmatrix}
\end{aligned}

El siguiente paso es estimar. Recordando que el comportamiento no es afectado por transformaciones multiplicativas de la utilidad, es necesario escalar esta matriz. Lo recomendable es fijar \(σ_ε = 1\), obteniendo así

\[Σ= \sigma_\beta \begin{bmatrix}x^2_{n1} & x_{n1}x_{n2}\\
x_{n1}x_{n2} & x^2_{n2} \end{bmatrix} + \begin{bmatrix}1 & 0\\
0 & 1\end{bmatrix}\]

\hypertarget{dependencia-del-tiempo}{%
\subsubsection{Dependencia del tiempo}\label{dependencia-del-tiempo}}

Se ha discutido que bajo un modelo \emph{probit} se pueden estudiar relaciones no observables entre las alternativas de elección. En las bases disponibles para la función comercial, las observaciones suelen estar indexadas temporalmente generando estructuras de panel que permiten estudiar aspectos interesantes de los agentes. A continuación se discute cómo usar un modelo \emph{probit} para explorar no solo la relación entre las utilidades de alternativas sino también el comportamiento de las utilidades de las alternativas en el tiempo. Al igual que en la sección anterior, se busca
encontrar patrones temporales en las componentes no observables de la utilidad, ya que las variaciones en la componente observable pueden ser fácilmente estudiadas incluyendo variables observables que describan la evolución temporal del sistema. Por ejemplo, si se cree que la utilidad
de una de las alternativas es creciente en el tiempo, basta incluir el tiempo \(t\) entre las variables independientes en la descripción de la utilidad de la alternativa. En general, se debería esperar que las utilidades estén correlacionadas tanto en el tiempo como entre las alternativas ya que los
factores que no son observados por el analista suelen ser persistentes en el tiempo. Eventualmente un modelo \emph{probit} también podría ayudar a identificar shocks en que hay variaciones instantáneas (o de unos pocos periodos) en las utilidades de varias de las alternativas.

Supóngase que se observa un panel de \(N\) clientes que deciden respecto de \(I\) alternativas en \(T\) períodos y que la utilidad del producto que el agente \(n\) deriva sobre la alternativa \(i\) en el período \(t\) viene dada por:

\begin{equation} 
  \begin{array}{cc}
    u_{ni} = v_{nit} + \varepsilon_{nit}  & [\varepsilon_{n11},...,\varepsilon_{nI1},\varepsilon_{n12}, ..., \varepsilon_{nI2},...,\varepsilon_{n1T},...,\varepsilon_{nIT}] \sim N(0,Σ)
  \end{array}  
  \label{eq:cdeterministaequi}
\end{equation}

La matriz de covarianza Σ tiene dimensión \(IT ×IT\) (como se verá, no todas las componentes son identificables y se deberá imponer ciertas restricciones). Para paneles típicos, \(T\) es grande y generan matrices de varianza covarianza muy grandes. Por ejemplo, si se tienen datos semanales de compras de 5 marcas por un período de 2 años, se
enfrentará una matriz de varianza (sin normalizar) con 5 × 104 = 520 filas y 520 columnas, lo que generaría no solo un modelo difícil de estimar numéricamente sino también difícil de interpretar. Así, para usar un modelo \emph{probit} con dependencia en el tiempo, típicamente
se agregará estructura al modelo. Por ejemplo, se puede restringir el análisis a grupos de períodos que podría ser el caso de las decisiones antes y después de una intervención en el sistema (e.g.~antes y después del lanzamiento de una campaña publicitaria).

\textbf{Ejemplo:} Supóngase un caso de elección binaria, el error está compuesto por una componente sistemática específica del tomador de decisión, y otra que es variable en el tiempo.

\begin{equation} 
  \varepsilon_{nt} = \eta_n + \mu_{nt}
  \label{eq:errorbinario}
\end{equation}

Si asumimos que \(η_n\) está distribuida \(N(0, σ)\) y \(\mu_{nt}\) en \(N(0, 1)\), entonces la varianza y covarianza son

\begin{equation} 
  \mathbb{V}ar(\varepsilon_{nt}) =  \mathbb{V}ar(\eta_{n}+ \mu_{nt}) = \sigma + 1
    \label{eq:varbinaria}
  \end{equation}

\begin{equation} 
  \mathbb{C}ov(\varepsilon_{nt},\varepsilon_{ns}) =  \mathbb{E}((\eta_{n}+ \mu_{nt}) (\eta_{n}+ \mu_{ns})) = \sigma
    \label{eq:covbinaria}
  \end{equation}

La matriz Σ, por lo tanto, es

\begin{equation} 
  Σ = \begin{bmatrix}\sigma +1 & \sigma & ... & \sigma\\
\sigma & \sigma+1 & ... & \sigma\\
\vdots & \vdots & \ddots & \vdots\\
\sigma & \sigma & \dots & \sigma +1
\end{bmatrix}
    \label{eq:matrizsum}
  \end{equation}

\hypertarget{identificaciuxf3n}{%
\subsection{Identificación}\label{identificaciuxf3n}}

Para estimar un modelo \emph{probit}, junto con los parámetros de la componente sistemática de la utilidad se necesita estimar los coeficientes de la matriz Σ. Por tratarse de una distribución normal, la matriz Σ es simétrica y por tanto en principio se deben estimar \(\frac{I(I+1)}{2}\) de sus componentes. Sin
embargo, dicho problema no es identificable y se necesita imponer restricciones adicionales. La intuición detrás de esta falta de identificación resulta de asumir que las utilidades subyacentes que maximizan los individuos son monótonas y homotéticas. En otras palabras, se puede agregar un valor constante a las utilidades de cada una de las alternativas o escalarlas en cualquier proporción y la identidad de la alternativa de mayor utilidad no cambia. En general, si se tienen \(I\) alternativas, solo se pueden identificar \(\frac{I(I+1)}{2} -1\) parámetros. A continuación se discutirán dos enfoques para generar restricciones que hagan el problema identificable.

\hypertarget{normalizaciuxf3n-de-las-funciones-de-utilidad}{%
\subsubsection{Normalización de las funciones de utilidad}\label{normalizaciuxf3n-de-las-funciones-de-utilidad}}

Motivados en las propiedades de la función de utilidad, este enfoque consiste en imponer directamente restricciones de escala y locación. Este enfoque es completamente general y permite además garantizar identificación con un procedimiento estándar que puede incluso automatizarse. Formalmente el proceso consiste en imponer dos restricciones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  FIJAR LOCACIÓN: Como el valor absoluto de las utilidades es irrelevante, se puede fijar arbitrariamente el punto de referencia sobre el cual se interpretarán las utilidades. De esta forma, se tomará la utilidad de una de las alternativas como referencia y se redefinirán las utilidades como las diferencias con respecto a la alternativa de referencia.
\item
  FIJAR ESCALA: Como la escala de las utilidades es irrelevante, se puede fijarla asignando un valor arbitrario a cualquiera de las componentes de la matriz de varianza covarianza. Típicamente se impondrá que la primera componente de la diagonal tome el valor 1.
\end{enumerate}

\textbf{Ejemplo:} Considérese la normalización de una matriz Σ resultante de un problema de elección discreto de 4 alternativas.

\begin{equation} 
  Σ = \begin{bmatrix} \sigma_{11} & \sigma_{12} & \sigma_{13} & \sigma_{13}\\
 \cdot & \sigma_{22} & \sigma_{23} & \sigma_{24}\\
 \cdot & \cdot & \sigma_{33} & \sigma_{34}\\
 \cdot & \cdot & \cdot & \sigma_{44}
\end{bmatrix} 
  \label{eq:matrixcuatro}
\end{equation}

El primer paso en la normalización es considerar diferencias de utilidades con respecto a una alternativa de referencia, la que por simplicidad escogeremos como la primera de la lista. Al fijar esta utilidad y tomar las diferencias, hemos reducido la dimensión del vector errores, resultando en una matriz de varianza-covarianza \(\hat{Σ} = \{\hat{σ}_{ij}\}^3_{i,j=1}\) cuyas componentes vienen dadas por:

\begin{aligned}
\hat{\sigma}_{22} &= \sigma_{22} + \sigma_{11} - 2\sigma_{12}\\
\hat{\sigma}_{33} &= \sigma_{33} + \sigma_{11} - 2\sigma_{13}\\
\hat{\sigma}_{44} &= \sigma_{44} + \sigma_{11} - 2\sigma_{14}\\
\hat{\sigma}_{23} &= \sigma_{23} + \sigma_{11} - \sigma_{12} - \sigma_{13}\\
\hat{\sigma}_{24} &= \sigma_{24} + \sigma_{11} - \sigma_{12} - \sigma_{14}\\
\hat{\sigma}_{34} &= \sigma_{34} + \sigma_{11} - \sigma_{13} - \sigma_{14}
\end{aligned}

El segundo paso en la normalización es fijar en 1 (o cualquier otro real positivo) una de las componentes de la diagonal de la matriz de varianza covarianza para precisar la escala de la función de utilidad. Por simplicidad se escoge la primera componente de la diagonal. Para hacerla 1 basta con dividir toda la matriz por dicha componente, resultando en una matriz de varianza-covarianza \(\hat{Σ} = \{\hat{σ}_{ij}\}^3_{i,j=1}\) cuyas componentes vienen dadas por:

\begin{aligned}
\hat{\sigma}_{33} &= \frac{\sigma_{33} + \sigma_{11} - 2\sigma_{13}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}\\
\hat{\sigma}_{44} &= \frac{\sigma_{44} + \sigma_{11} - 2\sigma_{14}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}\\
\hat{\sigma}_{23} &= \frac{\sigma_{23} + \sigma_{11} - \sigma_{12} - \sigma_{13}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}\\
\hat{\sigma}_{24} &= \frac{\sigma_{24} + \sigma_{11} - \sigma_{12} - \sigma_{14}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}\\
\hat{\sigma}_{34} &= \frac{\sigma_{34} + \sigma_{11} - \sigma_{13} - \sigma_{14}}{\sigma_{22} + \sigma_{11} - 2\sigma_{12}}
\end{aligned}

La matriz resultante \(\hat{Σ}\) es identificable. En ella es importante trazar sus componentes originales de la matriz sigma porque ayudan a darle interpretación a los resultados obtenidos en la estimación.

\hypertarget{incorporaciuxf3n-de-restricciones-estructurales}{%
\subsubsection{Incorporación de restricciones estructurales}\label{incorporaciuxf3n-de-restricciones-estructurales}}

Aunque completamente general, la normalización descrita en la sección anterior, muchas veces puede ser algo inconveniente en cuanto los parámetros estimados no tienen interpretación
directa. Un enfoque que permite interpretar directamente los parámetros se obtiene al imponer estructura sobre la matriz de varianza-covarianza a partir de supuestos de comportamiento. Por ejemplo, se puede imponer que las componentes aleatorias de algunos pares de alternativas no están correlacionadas o que algún grupo de alternativas tiene la misma variabilidad de la componente no observable. El cuadro 4.1 ejemplifica algunas de las estructuras de varianza-covarianza comúnmente usadas en la literatura.

Otros modelos usados en la literatura y que están implementados en aplicaciones comerciales incluyen estructuras de bandas, Huynh-Feldt, autoregresivo heterogéneo y simetría compuesta. Como en otros aspectos de la modelación, la elección de la estructura a elegir para la matriz de
varianza-covarianza dependerá de las hipótesis de comportamiento que se tengan a la mano y la dificultad numérica de estimar el modelo resultante.

\hypertarget{nested-logit}{%
\section{Nested Logit}\label{nested-logit}}

\hypertarget{introducciuxf3n-2}{%
\subsection{Introducción}\label{introducciuxf3n-2}}

Como se ha discutido previamente, una de las limitaciones fundamentales del modelo logit estándar es la propiedad de independencia de alternativas irrelevantes (IIA), que implica patrones de sustitución proporcionales entre todas las alternativas. Esta restricción puede resultar poco realista en muchas situaciones prácticas de marketing donde algunas alternativas son sustitutos más cercanos entre sí que con otras. El modelo \textbf{Nested Logit} (o Logit Anidado) surge como una extensión del modelo logit estándar que permite relajar parcialmente la restricción de IIA al permitir que las alternativas se agrupen en conjuntos (o ``nidos'') donde la correlación entre alternativas dentro del mismo nido puede diferir de la correlación entre alternativas de nidos diferentes.

La idea fundamental del nested logit es reconocer que en muchos problemas de elección existe una estructura jerárquica natural. Los tomadores de decisión primero eligen entre categorías generales de alternativas (los nidos) y luego, dentro de la categoría seleccionada, eligen una alternativa específica. Esta estructura refleja de manera más realista muchos procesos de decisión en marketing.

\textbf{Ejemplo Motivador:}

Considérese el problema de elección de medio de transporte en una ciudad que ofrece las siguientes alternativas: auto particular, auto compartido (carpool), bus y tren. Intuitivamente, se esperaría que auto particular y auto compartido sean sustitutos más cercanos entre sí (ambos involucran viajar en auto) que cualquiera de ellos con respecto al bus o tren. Del mismo modo, bus y tren (ambos transporte público) serían sustitutos más cercanos entre sí. Un modelo logit estándar impondría que un incremento en el costo del bus afecta igualmente la probabilidad de elegir auto particular, auto compartido y tren, lo cual parece poco razonable. El nested logit permite capturar que el incremento en el costo del bus afectará más la probabilidad de elegir tren (mismo nido de transporte público) que la de elegir auto particular.

\hypertarget{estructura-del-modelo}{%
\subsection{Estructura del Modelo}\label{estructura-del-modelo}}

\hypertarget{particiuxf3n-en-nidos}{%
\subsubsection{Partición en Nidos}\label{particiuxf3n-en-nidos}}

El modelo nested logit requiere una partición del conjunto de \(J\) alternativas en \(K\) subconjuntos exhaustivos y mutuamente excluyentes llamados \textbf{nidos}. Sea \(B_k\) el conjunto de alternativas en el nido \(k\), donde \(k = 1, 2, ..., K\). La partición debe satisfacer:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\bigcup_{k=1}^K B_k = \{1, 2, ..., J\}\) (exhaustividad)
\item
  \(B_k \cap B_m = \emptyset\) para \(k \neq m\) (exclusividad mutua)
\end{enumerate}

Es importante destacar que la definición de los nidos debe basarse en consideraciones teóricas sobre qué alternativas son sustitutos más cercanos, no en criterios puramente estadísticos. La teoría económica, el conocimiento del mercado y la intuición sobre el comportamiento del consumidor deben guiar esta partición.

\hypertarget{especificaciuxf3n-de-la-utilidad}{%
\subsubsection{Especificación de la Utilidad}\label{especificaciuxf3n-de-la-utilidad}}

En el modelo nested logit, la utilidad que el individuo \(n\) deriva de la alternativa \(i\) en el nido \(B_k\) se especifica como:

\begin{equation}
u_{ni} = v_{ni} + \varepsilon_{ni}
\label{eq:nestedutil}
\end{equation}

donde \(v_{ni}\) es la componente sistemática (observable) de la utilidad y \(\varepsilon_{ni}\) es la componente aleatoria.

La característica distintiva del nested logit es la estructura de correlación de los errores. A diferencia del logit estándar donde todos los \(\varepsilon_{ni}\) son independientes, en el nested logit se permite que los errores de alternativas dentro del mismo nido estén correlacionados, mientras que los errores entre alternativas de diferentes nidos permanecen independientes.

Formalmente, se asume que el vector de errores \(\varepsilon_n = (\varepsilon_{n1}, ..., \varepsilon_{nJ})\) tiene una distribución \textbf{Generalizada de Valor Extremo} (GEV) con función de distribución acumulada:

\begin{equation}
F(\varepsilon_{n1}, ..., \varepsilon_{nJ}) = \exp\left[-\sum_{k=1}^K \left(\sum_{i \in B_k} e^{-\varepsilon_{ni}/\lambda_k}\right)^{\lambda_k}\right]
\label{eq:gevdist}
\end{equation}

donde \(\lambda_k\) es un parámetro que gobierna el grado de correlación entre alternativas en el nido \(k\), con \(0 < \lambda_k \leq 1\).

\hypertarget{interpretaciuxf3n-de-los-paruxe1metros-de-disimilitud}{%
\subsubsection{Interpretación de los Parámetros de Disimilitud}\label{interpretaciuxf3n-de-los-paruxe1metros-de-disimilitud}}

Los parámetros \(\lambda_k\) (a veces llamados parámetros de disimilitud o parámetros de escala) tienen interpretaciones importantes:

\begin{itemize}
\tightlist
\item
  \textbf{\(\lambda_k = 1\):} Las alternativas en el nido \(k\) no están correlacionadas (caso del logit estándar)
\item
  \textbf{\(\lambda_k < 1\):} Las alternativas en el nido \(k\) están positivamente correlacionadas; cuanto menor sea \(\lambda_k\), mayor es la correlación
\item
  \textbf{\(\lambda_k \to 0\):} Correlación perfecta entre alternativas del nido \(k\)
\end{itemize}

La correlación entre dos alternativas \(i\) y \(j\) en el mismo nido \(k\) viene dada por:

\begin{equation}
\text{Corr}(\varepsilon_{ni}, \varepsilon_{nj}) = 1 - \lambda_k^2 \quad \text{para } i, j \in B_k
\label{eq:corrwithin}
\end{equation}

Mientras que alternativas en nidos diferentes tienen correlación cero:

\begin{equation}
\text{Corr}(\varepsilon_{ni}, \varepsilon_{nj}) = 0 \quad \text{para } i \in B_k, j \in B_m, k \neq m
\label{eq:corrbetween}
\end{equation}

\hypertarget{probabilidades-de-elecciuxf3n}{%
\subsection{Probabilidades de Elección}\label{probabilidades-de-elecciuxf3n}}

Una de las ventajas computacionales del modelo nested logit es que, a pesar de permitir correlación entre errores, aún se pueden derivar fórmulas cerradas para las probabilidades de elección.

\hypertarget{estructura-jeruxe1rquica-de-decisiuxf3n}{%
\subsubsection{Estructura Jerárquica de Decisión}\label{estructura-jeruxe1rquica-de-decisiuxf3n}}

El nested logit puede interpretarse como un proceso de decisión secuencial en dos etapas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Etapa 1 (elección de nido):} El individuo elige qué nido \(B_k\) le proporciona mayor utilidad esperada
\item
  \textbf{Etapa 2 (elección dentro del nido):} Dado el nido seleccionado, el individuo elige la alternativa específica dentro de ese nido
\end{enumerate}

\hypertarget{probabilidad-condicional-etapa-2}{%
\subsubsection{Probabilidad Condicional (Etapa 2)}\label{probabilidad-condicional-etapa-2}}

La probabilidad de que el individuo \(n\) elija la alternativa \(i\) dado que ha elegido el nido \(B_k\) viene dada por:

\begin{equation}
P_{ni|B_k} = \frac{\exp(v_{ni}/\lambda_k)}{\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)}
\label{eq:condprob}
\end{equation}

Esta expresión tiene la forma de un modelo logit estándar pero con las utilidades escaladas por \(\lambda_k\). Nótese que cuando \(\lambda_k = 1\), se recupera la fórmula del logit estándar.

\hypertarget{valor-inclusivo-inclusive-value}{%
\subsubsection{Valor Inclusivo (Inclusive Value)}\label{valor-inclusivo-inclusive-value}}

Un concepto fundamental en el nested logit es el \textbf{valor inclusivo} (o \textbf{log-suma}) del nido \(B_k\), definido como:

\begin{equation}
IV_k = \ln\left(\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)\right)
\label{eq:inclusivevalue}
\end{equation}

El valor inclusivo \(IV_k\) representa la utilidad esperada (antes de conocer los shocks aleatorios \(\varepsilon_{nj}\)) que el individuo obtiene del nido \(k\). Es una medida del atractivo agregado de todas las alternativas en el nido, ajustada por el grado de correlación entre ellas.

\textbf{Interpretación Económica:} El valor inclusivo captura el ``valor de la opción'' que proporciona tener múltiples alternativas similares disponibles. Un valor inclusivo alto indica que el nido contiene alternativas atractivas para el individuo.

\hypertarget{probabilidad-marginal-de-elegir-el-nido-etapa-1}{%
\subsubsection{Probabilidad Marginal de Elegir el Nido (Etapa 1)}\label{probabilidad-marginal-de-elegir-el-nido-etapa-1}}

La probabilidad de elegir el nido \(B_k\) viene dada por:

\begin{equation}
P_{nB_k} = \frac{\exp(\lambda_k \cdot IV_k)}{\sum_{m=1}^K \exp(\lambda_m \cdot IV_m)}
\label{eq:nestprob}
\end{equation}

Esta probabilidad tiene también forma logit, donde la ``utilidad'' del nido es el valor inclusivo escalado por \(\lambda_k\).

\hypertarget{probabilidad-no-condicional-probabilidad-total}{%
\subsubsection{Probabilidad No Condicional (Probabilidad Total)}\label{probabilidad-no-condicional-probabilidad-total}}

Finalmente, la probabilidad de que el individuo \(n\) elija la alternativa \(i\) en el nido \(B_k\) se obtiene multiplicando las probabilidades de las dos etapas:

\begin{equation}
P_{ni} = P_{ni|B_k} \cdot P_{nB_k} = \frac{\exp(v_{ni}/\lambda_k)}{\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)} \cdot \frac{\exp(\lambda_k \cdot IV_k)}{\sum_{m=1}^K \exp(\lambda_m \cdot IV_m)}
\label{eq:totalprob}
\end{equation}

Esta expresión se puede reescribir de forma más compacta como:

\begin{equation}
P_{ni} = \frac{\exp(v_{ni}/\lambda_k) \cdot [\sum_{j \in B_k} \exp(v_{nj}/\lambda_k)]^{\lambda_k - 1}}{\sum_{m=1}^K [\sum_{j \in B_m} \exp(v_{nj}/\lambda_m)]^{\lambda_m}}
\label{eq:totalprobcompact}
\end{equation}

\hypertarget{propiedades-y-patrones-de-sustituciuxf3n}{%
\subsection{Propiedades y Patrones de Sustitución}\label{propiedades-y-patrones-de-sustituciuxf3n}}

\hypertarget{relajaciuxf3n-parcial-de-iia}{%
\subsubsection{Relajación Parcial de IIA}\label{relajaciuxf3n-parcial-de-iia}}

Una propiedad importante del nested logit es que la restricción de IIA se mantiene \textbf{dentro de cada nido} pero no \textbf{entre nidos}. Específicamente:

\textbf{Dentro del mismo nido:} Para dos alternativas \(i\) y \(j\) en el mismo nido \(B_k\):

\begin{equation}
\frac{P_{ni}}{P_{nj}} = \frac{\exp(v_{ni}/\lambda_k)}{\exp(v_{nj}/\lambda_k)} = \exp\left(\frac{v_{ni} - v_{nj}}{\lambda_k}\right)
\label{eq:ratiowithin}
\end{equation}

Este ratio es independiente de otras alternativas, manteniendo IIA dentro del nido.

\textbf{Entre diferentes nidos:} Para alternativas en nidos diferentes, el ratio de probabilidades sí depende de las características de otras alternativas a través de los valores inclusivos, permitiendo patrones de sustitución más realistas.

\hypertarget{elasticidades-de-sustituciuxf3n}{%
\subsubsection{Elasticidades de Sustitución}\label{elasticidades-de-sustituciuxf3n}}

Las elasticidades propias y cruzadas en un modelo nested logit revelan cómo los patrones de sustitución difieren entre alternativas del mismo nido versus alternativas de nidos diferentes.

\textbf{Elasticidad propia:} La elasticidad de \(P_{ni}\) respecto a un atributo \(x_{ni}\) de la misma alternativa es:

\begin{equation}
\eta_{ii} = \frac{\partial P_{ni}}{\partial x_{ni}} \cdot \frac{x_{ni}}{P_{ni}} = \frac{\beta}{\lambda_k} x_{ni} \left(1 - P_{ni} - \lambda_k P_{ni|B_k}(1 - P_{ni|B_k})\right)
\label{eq:elastown}
\end{equation}

donde \(\beta\) es el coeficiente asociado a \(x_{ni}\) en \(v_{ni}\).

\textbf{Elasticidad cruzada dentro del nido:} Para alternativas \(i\) y \(j\) en el mismo nido \(B_k\):

\begin{equation}
\eta_{ij} = \frac{\partial P_{ni}}{\partial x_{nj}} \cdot \frac{x_{nj}}{P_{ni}} = \frac{\beta}{\lambda_k} x_{nj} P_{nj|B_k}(1 + \lambda_k(1 - P_{nj|B_k}))
\label{eq:elastwithin}
\end{equation}

\textbf{Elasticidad cruzada entre nidos:} Para alternativas \(i \in B_k\) y \(j \in B_m\) con \(k \neq m\):

\begin{equation}
\eta_{ij} = -\beta x_{nj} P_{nj}
\label{eq:elastbetween}
\end{equation}

Nótese que \(\eta_{ij}\) (dentro del nido) depende de \(\lambda_k\) y es típicamente mayor en magnitud que la elasticidad cruzada entre nidos, reflejando que alternativas dentro del mismo nido son mejores sustitutos.

\hypertarget{ejemplo-ilustrativo}{%
\subsection{Ejemplo Ilustrativo}\label{ejemplo-ilustrativo}}

\textbf{Contexto:} Elección de tipo de vivienda en una ciudad con cuatro alternativas: departamento pequeño (DP), departamento grande (DG), casa pequeña (CP) y casa grande (CG).

\textbf{Estructura de Nidos:} Se propone una estructura con dos nidos:
- Nido 1 (Departamentos): \(B_1 = \{DP, DG\}\)
- Nido 2 (Casas): \(B_2 = \{CP, CG\}\)

\textbf{Especificación de Utilidad:}

\begin{aligned}
v_{n,DP} &= \alpha_{DP} + \beta_1 \cdot precio_{DP} + \beta_2 \cdot distancia_{DP}\\
v_{n,DG} &= \alpha_{DG} + \beta_1 \cdot precio_{DG} + \beta_2 \cdot distancia_{DG}\\
v_{n,CP} &= \alpha_{CP} + \beta_1 \cdot precio_{CP} + \beta_2 \cdot distancia_{CP}\\
v_{n,CG} &= \alpha_{CG} + \beta_1 \cdot precio_{CG} + \beta_2 \cdot distancia_{CG}
\end{aligned}

donde \(\alpha_i\) son constantes alternativa-específicas, \(\beta_1 < 0\) captura el efecto del precio y \(\beta_2 < 0\) el efecto de la distancia al centro.

\textbf{Resultados Hipotéticos:}

Supóngase que la estimación arroja \(\lambda_1 = 0.6\) y \(\lambda_2 = 0.7\). Esto implica:

\begin{itemize}
\tightlist
\item
  \textbf{Correlación en Nido 1 (Departamentos):} \(1 - (0.6)^2 = 0.64\)
\item
  \textbf{Correlación en Nido 2 (Casas):} \(1 - (0.7)^2 = 0.51\)
\end{itemize}

Los departamentos presentan mayor correlación en sus componentes no observables que las casas, sugiriendo que hay factores no modelados (quizás preferencias por estilo de vida urbano, servicios comunes en edificios, etc.) que afectan similarmente la atractiva de ambos tipos de departamentos.

\textbf{Implicaciones para Sustitución:}

Si el precio del departamento grande aumenta, este incremento afectará más la probabilidad de elegir el departamento pequeño (mismo nido) que la probabilidad de elegir cualquiera de las casas. Formalmente, la elasticidad cruzada \(\eta_{DP,DG}\) será mayor en magnitud que \(\eta_{DP,CP}\) o \(\eta_{DP,CG}\).

\hypertarget{estimaciuxf3n-2}{%
\subsection{Estimación}\label{estimaciuxf3n-2}}

La estimación del modelo nested logit se realiza mediante \textbf{máxima verosimilitud}. Dada una muestra de \(N\) individuos donde cada individuo \(n\) elige una alternativa \(i_n\) de su conjunto de elección, la función de log-verosimilitud viene dada por:

\begin{equation}
LL(\theta, \lambda) = \sum_{n=1}^N \ln P_{ni_n}(\theta, \lambda)
\label{eq:nestedll}
\end{equation}

donde \(\theta\) representa todos los parámetros de las utilidades sistemáticas y \(\lambda = (\lambda_1, ..., \lambda_K)\) son los parámetros de disimilitud de cada nido.

\textbf{Restricciones en la Estimación:}

Para garantizar que el modelo sea consistente con la teoría de maximización de utilidad aleatoria (RUM), los parámetros \(\lambda_k\) deben satisfacer:

\begin{equation}
0 < \lambda_k \leq 1 \quad \forall k
\label{eq:lambdaconstraint}
\end{equation}

Valores de \(\lambda_k > 1\) o \(\lambda_k < 0\) violarían los axiomas de elección racional y producirían probabilidades que no derivarían de ninguna distribución de utilidad subyacente. En la práctica, se imponen estas restricciones durante la optimización usando métodos de optimización restringida o reparametrizando como \(\lambda_k = \exp(\gamma_k)/(1 + \exp(\gamma_k))\) donde \(\gamma_k\) es el parámetro a estimar sin restricciones.

\textbf{Procedimiento de Estimación:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Especificar la partición en nidos \(\{B_1, ..., B_K\}\)
\item
  Especificar las funciones de utilidad \(v_{ni}\) para cada alternativa
\item
  Calcular valores inclusivos \(IV_k\) para cada nido
\item
  Calcular probabilidades \(P_{ni}\) usando la ecuación \eqref{eq:totalprob}
\item
  Maximizar la log-verosimilitud \eqref{eq:nestedll} con restricciones \(0 < \lambda_k \leq 1\)
\end{enumerate}

\textbf{Test de Especificación:}

Un test natural es evaluar si \(\lambda_k = 1\) para todos los nidos, lo que equivaldría al modelo logit estándar. Se puede usar un \textbf{test de razón de verosimilitud} comparando:

\begin{itemize}
\tightlist
\item
  Modelo restringido: Logit estándar (todos los \(\lambda_k = 1\))
\item
  Modelo no restringido: Nested logit con \(\lambda_k\) estimados
\end{itemize}

El estadístico \(LR = 2(LL_{nested} - LL_{logit})\) se distribuye asintóticamente como \(\chi^2\) con \(K\) grados de libertad bajo la hipótesis nula de que el logit estándar es adecuado.

\hypertarget{extensiones-nested-logit-con-muxfaltiples-niveles}{%
\subsection{Extensiones: Nested Logit con Múltiples Niveles}\label{extensiones-nested-logit-con-muxfaltiples-niveles}}

El modelo nested logit puede extenderse a \textbf{estructuras jerárquicas de múltiples niveles}, donde los nidos pueden a su vez contener sub-nidos. Por ejemplo, en el contexto de elección de vehículos, se podría tener:

\begin{itemize}
\tightlist
\item
  \textbf{Nivel 1:} Tipo de combustión (gasolina vs.~eléctrico)
\item
  \textbf{Nivel 2:} Tamaño del vehículo (pequeño, mediano, grande)
\item
  \textbf{Nivel 3:} Marca específica
\end{itemize}

En este caso, la decisión se modela como una secuencia de elecciones desde el nivel más alto (combustión) hasta el más específico (marca), con parámetros de disimilitud en cada nivel capturando la correlación entre alternativas dentro de cada sub-nido.

La probabilidad de elección en un nested logit de tres niveles sigue una estructura análoga:

\begin{equation}
P_{ni} = P_{ni|nido_3} \cdot P_{nido_3|nido_2} \cdot P_{nido_2}
\label{eq:threelevel}
\end{equation}

donde cada probabilidad condicional tiene forma logit con su respectivo parámetro de disimilitud.

\hypertarget{ventajas-y-limitaciones}{%
\subsection{Ventajas y Limitaciones}\label{ventajas-y-limitaciones}}

\textbf{Ventajas:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Fórmula cerrada:} A diferencia del probit, el nested logit mantiene expresiones analíticas para las probabilidades, facilitando la estimación y el cálculo de elasticidades
\item
  \textbf{Patrones de sustitución más realistas:} Permite que alternativas similares sean mejores sustitutos, relajando parcialmente IIA
\item
  \textbf{Interpretación intuitiva:} La estructura de nidos refleja cómo los consumidores categorizan naturalmente las alternativas
\item
  \textbf{Eficiencia computacional:} Menos demandante que probit multinomial o mixed logit para conjuntos grandes de alternativas
\item
  \textbf{Valores inclusivos:} Proporciona medidas útiles del atractivo de categorías de productos
\end{enumerate}

\textbf{Limitaciones:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Definición de nidos:} Requiere especificación a priori de la estructura de nidos, que puede no ser obvia. Diferentes estructuras pueden producir resultados diferentes
\item
  \textbf{IIA dentro de nidos:} Mantiene la restricción de IIA para alternativas dentro del mismo nido
\item
  \textbf{Restricciones en correlación:} Solo permite un patrón específico de correlación (alta dentro de nidos, cero entre nidos). No captura correlaciones arbitrarias
\item
  \textbf{Restricción de un nido por alternativa:} Cada alternativa debe pertenecer a exactamente un nido, aunque en realidad las alternativas pueden compartir similitudes en múltiples dimensiones
\item
  \textbf{Sensibilidad a la normalización:} Los resultados pueden ser sensibles a qué nido se usa como referencia en la normalización
\end{enumerate}

\hypertarget{aplicaciones-en-marketing}{%
\subsection{Aplicaciones en Marketing}\label{aplicaciones-en-marketing}}

El modelo nested logit ha sido ampliamente aplicado en diversos contextos de marketing:

\textbf{1. Categorización de Productos:}

En mercados con muchas marcas y variantes, el nested logit permite modelar cómo los consumidores primero eligen categorías (ej: smartphones vs.~teléfonos básicos) y luego marcas específicas dentro de la categoría.

\textbf{2. Análisis de Canales:}

Se puede modelar la elección jerárquica de primero seleccionar canal (online vs.~tienda física) y luego marca específica dentro del canal, capturando que productos dentro del mismo canal comparten características no observables.

\textbf{3. Elección de Portafolio de Servicios:}

En servicios financieros o telecomunicaciones, los consumidores pueden primero decidir el tipo de servicio (básico, premium) y luego el proveedor específico, estructura que se acomoda naturalmente en nested logit.

\textbf{4. Diseño de Surtido:}

Los valores inclusivos proporcionan métricas útiles para evaluar el impacto de agregar o eliminar productos en el atractivo de categorías completas, apoyando decisiones de gestión de categorías.

\textbf{5. Valoración de Variedad:}

El modelo permite cuantificar cuánto valor deriva el consumidor de tener múltiples opciones dentro de una categoría (capturado en el valor inclusivo), información valiosa para decisiones de proliferación de líneas de producto.

\hypertarget{relaciuxf3n-con-otros-modelos}{%
\subsection{Relación con Otros Modelos}\label{relaciuxf3n-con-otros-modelos}}

El modelo nested logit ocupa una posición intermedia en el espectro de modelos de elección discreta:

\begin{itemize}
\tightlist
\item
  \textbf{Logit Estándar:} Caso especial cuando todos los \(\lambda_k = 1\) (sin correlación)
\item
  \textbf{Probit Multinomial:} Más flexible en patrones de correlación pero sin fórmula cerrada
\item
  \textbf{Mixed Logit:} Más flexible aún, permite heterogeneidad en coeficientes, pero requiere simulación
\end{itemize}

El nested logit proporciona un balance entre flexibilidad y tratabilidad: es más flexible que el logit estándar pero más parsimonioso y computacionalmente simple que el mixed logit o el probit multinomial. Para conjuntos de elección donde existe una estructura jerárquica clara y no se requiere capturar heterogeneidad no observable en coeficientes, el nested logit suele ser la opción preferida.

\hypertarget{mixed-logit}{%
\section{Mixed Logit}\label{mixed-logit}}

\hypertarget{introducciuxf3n-y-motivaciuxf3n}{%
\subsection{Introducción y Motivación}\label{introducciuxf3n-y-motivaciuxf3n}}

Como hemos discutido anteriormente, el modelo logit estándar, aunque computacionalmente conveniente gracias a su forma cerrada, presenta limitaciones importantes que pueden restringir su aplicabilidad en contextos reales de marketing. Recordemos las principales limitaciones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Patrones de sustitución proporcionales (IIA)}: La propiedad de independencia de alternativas irrelevantes implica que el ratio de probabilidades entre dos alternativas es independiente de las características de otras alternativas en el conjunto de elección.
\item
  \textbf{Incapacidad de capturar heterogeneidad no observable}: El modelo logit estándar no puede incorporar variación aleatoria en las preferencias más allá de las características observables de los individuos.
\item
  \textbf{Restricciones en correlación temporal y entre alternativas}: El supuesto de errores independientes e idénticamente distribuidos (i.i.d.) impide modelar correlaciones entre utilidades de diferentes alternativas o períodos.
\end{enumerate}

El modelo \textbf{Mixed Logit} (también conocido como \textbf{Random Parameters Logit} o \textbf{Error Components Logit}) surgió como una generalización flexible del modelo logit estándar que permite superar estas limitaciones. La idea fundamental es permitir que los parámetros de la función de utilidad varíen aleatoriamente en la población, capturando así heterogeneidad no observable en las preferencias.

\textbf{Intuición del Modelo:}

Supóngase que se está modelando la elección de medio de transporte (auto, bus, tren) y se sabe que la sensibilidad al tiempo de viaje varía sustancialmente entre individuos. Mientras que el logit estándar asumiría un único coeficiente de tiempo de viaje para toda la población, el mixed logit permite que este coeficiente siga una distribución en la población (por ejemplo, normal con cierta media y varianza), reflejando que algunos individuos son muy sensibles al tiempo mientras otros lo son menos.

\hypertarget{especificaciuxf3n-del-modelo}{%
\subsection{Especificación del Modelo}\label{especificaciuxf3n-del-modelo}}

\hypertarget{funciuxf3n-de-utilidad-y-probabilidad-de-elecciuxf3n}{%
\subsubsection{Función de Utilidad y Probabilidad de Elección}\label{funciuxf3n-de-utilidad-y-probabilidad-de-elecciuxf3n}}

En un modelo mixed logit, la utilidad que el individuo \(n\) deriva de la alternativa \(i\) en la ocasión de elección \(t\) viene dada por:

\begin{equation}
u_{nit} = \beta'_n x_{nit} + \varepsilon_{nit}
\label{eq:mixedutil}
\end{equation}

donde:

\begin{itemize}
\tightlist
\item
  \(x_{nit}\) es un vector de atributos observables de la alternativa \(i\) para el individuo \(n\) en el período \(t\)
\item
  \(\beta_n\) es un vector de coeficientes \textbf{aleatorios} que varía entre individuos
\item
  \(\varepsilon_{nit}\) es un término de error i.i.d. valor extremo tipo I (como en el logit estándar)
\end{itemize}

La característica clave es que \(\beta_n\) no es un parámetro fijo, sino una \textbf{variable aleatoria} que sigue una distribución de probabilidad \(f(\beta | \theta)\), donde \(\theta\) son los parámetros que describen esta distribución (típicamente media y varianza/covarianza).

\textbf{Especificación común:} Se suele asumir que \(\beta_n \sim N(b, \Sigma_\beta)\), donde \(b\) es el vector de medias poblacionales y \(\Sigma_\beta\) es la matriz de varianzas-covarianzas.

Condicional en \(\beta_n\), la probabilidad de que el individuo \(n\) elija la alternativa \(i\) es simplemente un logit estándar:

\begin{equation}
L_{nit}(\beta_n) = \frac{\exp(\beta'_n x_{nit})}{\sum_{j=1}^J \exp(\beta'_n x_{njt})}
\label{eq:condlogit}
\end{equation}

Sin embargo, como \(\beta_n\) no es observable, la probabilidad \textbf{no condicional} de elección se obtiene integrando sobre la distribución de \(\beta\):

\begin{equation}
P_{nit} = \int L_{nit}(\beta) f(\beta | \theta) d\beta = \int \frac{\exp(\beta' x_{nit})}{\sum_{j=1}^J \exp(\beta' x_{njt})} f(\beta | \theta) d\beta
\label{eq:mixedprob}
\end{equation}

Esta integral \textbf{no tiene solución cerrada} en general, lo que distingue fundamentalmente al mixed logit del logit estándar y requiere métodos de simulación para su estimación.

\hypertarget{descomposiciuxf3n-de-paruxe1metros}{%
\subsubsection{Descomposición de Parámetros}\label{descomposiciuxf3n-de-paruxe1metros}}

Es común especificar el modelo de manera que algunos parámetros sean fijos (iguales para todos los individuos) y otros sean aleatorios. Por ejemplo:

\begin{equation}
\beta_n = b + \eta_n
\label{eq:betadecomp}
\end{equation}

donde \(b\) representa las preferencias medias de la población y \(\eta_n \sim N(0, \Sigma_\beta)\) captura las desviaciones individuales respecto a estas preferencias medias.

Sustituyendo en la utilidad:

\begin{aligned}
u_{nit} &= (b + \eta_n)' x_{nit} + \varepsilon_{nit}\\
&= b' x_{nit} + \eta'_n x_{nit} + \varepsilon_{nit}\\
&= b' x_{nit} + \tilde{\varepsilon}_{nit}
\end{aligned}

donde \(\tilde{\varepsilon}_{nit} = \eta'_n x_{nit} + \varepsilon_{nit}\) es la componente de error compuesta.

\hypertarget{propiedades-del-mixed-logit}{%
\subsection{Propiedades del Mixed Logit}\label{propiedades-del-mixed-logit}}

El modelo mixed logit posee propiedades notables que lo hacen extremadamente flexible:

\hypertarget{aproximaciuxf3n-universal}{%
\subsubsection{Aproximación Universal}\label{aproximaciuxf3n-universal}}

\textbf{Resultado fundamental (McFadden y Train, 2000):} Cualquier modelo de utilidad aleatoria (RUM) puede ser aproximado arbitrariamente bien por un modelo mixed logit, siempre que se especifique apropiadamente la distribución de los coeficientes aleatorios.

Esto significa que el mixed logit puede aproximar patrones de sustitución arbitrarios, incluyendo aquellos del modelo probit multinomial, eliminando las restricciones del IIA cuando sea necesario.

\hypertarget{patrones-de-sustituciuxf3n-flexibles}{%
\subsubsection{Patrones de Sustitución Flexibles}\label{patrones-de-sustituciuxf3n-flexibles}}

A diferencia del logit estándar, el mixed logit permite patrones de sustitución no proporcionales. La elasticidad cruzada entre alternativas depende de:

\begin{itemize}
\tightlist
\item
  Sus características específicas
\item
  La correlación entre sus utilidades inducida por los coeficientes aleatorios
\item
  La distribución de preferencias en la población
\end{itemize}

\textbf{Ejemplo:} Si dos alternativas comparten muchos atributos que tienen coeficientes aleatorios correlacionados, serán sustitutos más cercanos que alternativas con atributos diferentes.

\hypertarget{captura-de-heterogeneidad-no-observable}{%
\subsubsection{Captura de Heterogeneidad No Observable}\label{captura-de-heterogeneidad-no-observable}}

El mixed logit permite modelar explícitamente que individuos con características observables idénticas pueden tener preferencias diferentes. La distribución \(f(\beta|\theta)\) caracteriza cómo se distribuyen las preferencias en la población.

\textbf{Interpretación:}
- La \textbf{media} \(b\) representa la preferencia promedio de la población
- La \textbf{desviación estándar} \(\sigma_\beta\) captura el grado de heterogeneidad en preferencias
- Las \textbf{covarianzas} capturan relaciones sistemáticas entre preferencias (ej: quienes valoran más la velocidad también valoran más el confort)

\hypertarget{correlaciuxf3n-temporal-y-entre-alternativas}{%
\subsubsection{Correlación Temporal y Entre Alternativas}\label{correlaciuxf3n-temporal-y-entre-alternativas}}

Al observar decisiones repetidas del mismo individuo, el mixed logit permite correlación entre las utilidades a través del tiempo porque \(\beta_n\) es constante para el individuo \(n\) a lo largo de sus decisiones.

Si se observa al individuo \(n\) en \(T\) ocasiones y se define \(y_{nit} = 1\) si elige alternativa \(i\) en ocasión \(t\) y 0 en caso contrario, la probabilidad condicional de la secuencia completa de elecciones es:

\begin{equation}
L_n(\beta_n) = \prod_{t=1}^T \prod_{i=1}^J L_{nit}(\beta_n)^{y_{nit}} = \prod_{t=1}^T \left[\frac{\exp(\beta'_n x_{nit})}{\sum_j \exp(\beta'_n x_{njt})}\right]^{y_{nit}}
\label{eq:seqprob}
\end{equation}

Y la probabilidad no condicional es:

\begin{equation}
P_n = \int L_n(\beta) f(\beta|\theta) d\beta
\label{eq:panelprob}
\end{equation}

Esta estructura captura naturalmente que las elecciones del mismo individuo están correlacionadas debido a sus preferencias subyacentes \(\beta_n\).

\hypertarget{estimaciuxf3n-por-simulaciuxf3n}{%
\subsection{Estimación por Simulación}\label{estimaciuxf3n-por-simulaciuxf3n}}

Dado que la integral en \eqref{eq:mixedprob} no tiene solución analítica, debemos recurrir a \textbf{métodos de simulación} para estimar el modelo.

\hypertarget{simulaciuxf3n-de-la-probabilidad-de-elecciuxf3n}{%
\subsubsection{Simulación de la Probabilidad de Elección}\label{simulaciuxf3n-de-la-probabilidad-de-elecciuxf3n}}

La idea básica es aproximar la integral usando simulación de Monte Carlo:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Extraer valores aleatorios:} Para cada individuo \(n\), se extraen \(R\) valores de \(\beta\) de la distribución especificada \(f(\beta|\theta)\): \(\beta^{(1)}, \beta^{(2)}, ..., \beta^{(R)}\)
\item
  \textbf{Calcular logit condicional:} Para cada extracción \(r\), se calcula la probabilidad logit condicional:
  \[L_{nit}(\beta^{(r)}) = \frac{\exp(\beta^{(r)'} x_{nit})}{\sum_j \exp(\beta^{(r)'} x_{njt})}\]
\item
  \textbf{Promediar:} La probabilidad simulada es el promedio sobre las \(R\) extracciones:
  \begin{equation}
  \tilde{P}_{nit} = \frac{1}{R} \sum_{r=1}^R L_{nit}(\beta^{(r)})
  \label{eq:simprob}
  \end{equation}
\end{enumerate}

La probabilidad simulada \(\tilde{P}_{nit}\) es un \textbf{estimador insesgado} de la verdadera probabilidad \(P_{nit}\) y por la ley de los grandes números, \(\tilde{P}_{nit} \to P_{nit}\) cuando \(R \to \infty\).

\hypertarget{estimador-de-muxe1xima-verosimilitud-simulada}{%
\subsubsection{Estimador de Máxima Verosimilitud Simulada}\label{estimador-de-muxe1xima-verosimilitud-simulada}}

La log-verosimilitud simulada viene dada por:

\begin{equation}
SLL(\theta) = \sum_{n=1}^N \sum_{t=1}^T \sum_{i=1}^J y_{nit} \ln(\tilde{P}_{nit})
\label{eq:simll}
\end{equation}

El \textbf{estimador de máxima verosimilitud simulada (MSLE)} maximiza esta función:

\[\hat{\theta}_{MSL} = \arg\max_\theta SLL(\theta)\]

\textbf{Propiedades asintóticas:}
- Si \(R\) crece más rápido que \(\sqrt{N}\), el MSLE es consistente, asintóticamente normal y asintóticamente eficiente
- En la práctica, valores de \(R\) entre 100 y 500 suelen ser suficientes

\hypertarget{secuencias-quasi-aleatorias-halton-draws}{%
\subsubsection{Secuencias Quasi-Aleatorias (Halton Draws)}\label{secuencias-quasi-aleatorias-halton-draws}}

Para mejorar la eficiencia de la simulación, es común usar \textbf{secuencias de Halton} en lugar de extracciones puramente aleatorias. Las secuencias de Halton cubren el espacio de probabilidad de manera más uniforme, permitiendo alcanzar la misma precisión con menos extracciones.

Con secuencias de Halton, a menudo \(R = 50\) o incluso \(R = 100\) son suficientes para obtener estimaciones precisas, reduciendo significativamente el tiempo computacional.

\hypertarget{especificaciuxf3n-de-distribuciones}{%
\subsection{Especificación de Distribuciones}\label{especificaciuxf3n-de-distribuciones}}

La elección de la distribución \(f(\beta|\theta)\) es crucial y debe basarse tanto en consideraciones teóricas como prácticas:

\hypertarget{distribuciones-comunes}{%
\subsubsection{Distribuciones Comunes}\label{distribuciones-comunes}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Normal:} \(\beta_k \sim N(b_k, \sigma^2_k)\)

  \begin{itemize}
  \tightlist
  \item
    Permite valores positivos y negativos
  \item
    Apropiada cuando no hay restricciones de signo (ej: efectos de marca)
  \item
    \textbf{Limitación:} Puede dar coeficientes con signo ``incorrecto'' (ej: coeficiente de precio positivo)
  \end{itemize}
\item
  \textbf{Log-Normal:} \(\beta_k \sim LN(b_k, \sigma^2_k)\), es decir \(\ln(\beta_k) \sim N(b_k, \sigma^2_k)\)

  \begin{itemize}
  \tightlist
  \item
    Garantiza que \(\beta_k > 0\) (útil para tiempo, costo)
  \item
    \textbf{Limitación:} No permite valores negativos
  \end{itemize}
\item
  \textbf{Normal Truncada:} Normal restringida a cierto rango

  \begin{itemize}
  \tightlist
  \item
    Útil cuando la teoría sugiere un signo pero se quiere flexibilidad
  \item
    Ejemplo: coeficiente de precio debe ser negativo
  \end{itemize}
\item
  \textbf{Uniforme:} \(\beta_k \sim U[a_k, b_k]\)

  \begin{itemize}
  \tightlist
  \item
    Útil cuando se conocen límites naturales
  \item
    Menos común en aplicaciones de marketing
  \end{itemize}
\item
  \textbf{Triangular, Johnson's \(S_B\), etc.}

  \begin{itemize}
  \tightlist
  \item
    Formas más flexibles para casos especiales
  \end{itemize}
\end{enumerate}

\hypertarget{correlaciuxf3n-entre-coeficientes}{%
\subsubsection{Correlación entre Coeficientes}\label{correlaciuxf3n-entre-coeficientes}}

Es posible especificar correlaciones entre coeficientes aleatorios usando distribuciones multivariadas. Por ejemplo, con distribución normal multivariada:

\[\beta_n \sim N(b, \Sigma_\beta)\]

donde \(\Sigma_\beta\) es la matriz de varianzas-covarianzas que captura cómo varían conjuntamente las preferencias.

\textbf{Ejemplo:} En modelos de transporte, individuos que valoran más el tiempo también tienden a ser más sensibles al costo (correlación negativa entre coeficientes de tiempo y costo).

\hypertarget{disposiciuxf3n-a-pagar-willingness-to-pay}{%
\subsection{Disposición a Pagar (Willingness to Pay)}\label{disposiciuxf3n-a-pagar-willingness-to-pay}}

Un beneficio importante del mixed logit es que permite derivar la distribución de la \textbf{disposición a pagar (DAP)} por diferentes atributos.

Si la utilidad es lineal: \(u_{nit} = \beta_{n,precio} \cdot precio_{it} + \beta_{n,atributo} \cdot atributo_{it} + ...\)

La DAP por una unidad adicional del atributo es:

\begin{equation}
DAP_n = -\frac{\beta_{n,atributo}}{\beta_{n,precio}}
\label{eq:wtp}
\end{equation}

Como ambos \(\beta_{n,atributo}\) y \(\beta_{n,precio}\) son aleatorios, la DAP también tiene una distribución en la población. El mixed logit permite:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Estimar la \textbf{distribución de la DAP} en la población
\item
  Calcular estadísticos como la DAP media, mediana, percentiles
\item
  Identificar segmentos con alta/baja DAP
\end{enumerate}

\textbf{Consideración:} Si ambos coeficientes son normales, la DAP sigue una distribución de Cauchy (que puede tener momentos no definidos). Esto ha llevado a usar especificaciones alternativas como log-normal para el coeficiente de precio.

\hypertarget{aplicaciones-en-marketing-1}{%
\subsection{Aplicaciones en Marketing}\label{aplicaciones-en-marketing-1}}

El modelo mixed logit ha sido ampliamente aplicado en diversos contextos de marketing:

\hypertarget{diseuxf1o-de-nuevos-productos}{%
\subsubsection{Diseño de Nuevos Productos}\label{diseuxf1o-de-nuevos-productos}}

\textbf{Objetivo:} Identificar qué combinación de atributos maximiza la adopción/ventas.

\begin{itemize}
\tightlist
\item
  Estimar distribución de preferencias por atributos
\item
  Simular participación de mercado para diferentes configuraciones
\item
  Identificar segmentos objetivo y estrategias de diferenciación
\end{itemize}

\textbf{Ejemplo:} Diseño de smartphones considerando precio, tamaño de pantalla, capacidad de batería, calidad de cámara.

\hypertarget{estrategias-de-precio}{%
\subsubsection{Estrategias de Precio}\label{estrategias-de-precio}}

\textbf{Objetivo:} Determinar precios óptimos considerando heterogeneidad en sensibilidad al precio.

\begin{itemize}
\tightlist
\item
  Estimar distribución de sensibilidad al precio en la población
\item
  Evaluar impacto de cambios de precio en participación de mercado
\item
  Diseñar estrategias de precio discriminatorio
\end{itemize}

\hypertarget{valoraciuxf3n-de-marca}{%
\subsubsection{Valoración de Marca}\label{valoraciuxf3n-de-marca}}

\textbf{Objetivo:} Cuantificar el valor de marca (``brand equity'').

\begin{itemize}
\tightlist
\item
  Incluir indicadoras de marca con coeficientes aleatorios
\item
  La distribución de estos coeficientes revela heterogeneidad en lealtad de marca
\item
  Calcular disposición a pagar por marca
\end{itemize}

\hypertarget{anuxe1lisis-de-conjoint}{%
\subsubsection{Análisis de Conjoint}\label{anuxe1lisis-de-conjoint}}

El mixed logit es el método preferido en análisis conjoint moderno (Choice-Based Conjoint):

\begin{itemize}
\tightlist
\item
  Permite heterogeneidad realista en preferencias
\item
  Supera limitaciones del IIA en conjuntos de elección complejos
\item
  Facilita segmentación basada en preferencias estimadas
\end{itemize}

\hypertarget{anuxe1lisis-de-canales-de-distribuciuxf3n}{%
\subsubsection{Análisis de Canales de Distribución}\label{anuxe1lisis-de-canales-de-distribuciuxf3n}}

\textbf{Objetivo:} Entender preferencias por canal (online vs.~tienda física).

\begin{itemize}
\tightlist
\item
  Modelar elección de canal como función de características de canal y producto
\item
  Identificar qué productos/consumidores prefieren qué canales
\item
  Optimizar estrategia omnicanal
\end{itemize}

\hypertarget{inferencia-individual-conditionalposterior-means}{%
\subsection{Inferencia Individual: Conditional/Posterior Means}\label{inferencia-individual-conditionalposterior-means}}

Una aplicación valiosa del mixed logit es la posibilidad de hacer \textbf{inferencia individual} sobre los parámetros \(\beta_n\) de cada persona, incluso cuando estos no son directamente observables.

Usando el \textbf{Teorema de Bayes}, se puede calcular la distribución \textbf{posterior} de \(\beta_n\) dado el historial de elecciones del individuo \(n\):

\begin{equation}
h(\beta_n | y_n, \theta) = \frac{L_n(\beta_n) f(\beta_n | \theta)}{\int L_n(\beta) f(\beta | \theta) d\beta}
\label{eq:posterior}
\end{equation}

donde \(y_n\) representa todas las elecciones observadas del individuo \(n\).

La \textbf{media condicional} (o posterior) es:

\begin{equation}
\bar{\beta}_n = E[\beta_n | y_n, \theta] = \int \beta \cdot h(\beta | y_n, \theta) d\beta
\label{eq:condmean}
\end{equation}

Esta integral también se aproxima por simulación:

\begin{equation}
\tilde{\bar{\beta}}_n = \frac{\sum_{r=1}^R \beta^{(r)} L_n(\beta^{(r)})}{\sum_{r=1}^R L_n(\beta^{(r)})}
\label{eq:simcondmean}
\end{equation}

\textbf{Aplicaciones:}
- \textbf{Personalización:} Usar \(\bar{\beta}_n\) para hacer recomendaciones personalizadas
- \textbf{Segmentación:} Agrupar individuos con \(\bar{\beta}_n\) similares
- \textbf{Targeting:} Identificar individuos con alta probabilidad de responder a cierta oferta

\hypertarget{ejemplo-ilustrativo-1}{%
\subsection{Ejemplo Ilustrativo}\label{ejemplo-ilustrativo-1}}

\textbf{Contexto:} Elección de marca de yogur (3 marcas: A, B, C) con datos de panel.

\textbf{Variables:}
- \(precio_{nit}\): precio de marca \(i\) para individuo \(n\) en ocasión \(t\)
- \(display_{nit}\): indicadora de display especial
- \(marca_i\): indicadoras de marca (efectos fijos de marca)

\textbf{Especificación:}

\begin{aligned}
u_{nit} &= \alpha_i + \beta_{n,precio} \cdot precio_{nit} + \beta_{display} \cdot display_{nit} + \varepsilon_{nit}\\
\beta_{n,precio} &\sim N(b_{precio}, \sigma^2_{precio})
\end{aligned}

\textbf{Interpretación de resultados:}

Si estimamos \(b_{precio} = -2.5\) y \(\sigma_{precio} = 1.0\):

\begin{itemize}
\tightlist
\item
  El consumidor promedio tiene sensibilidad al precio de -2.5
\item
  Hay heterogeneidad sustancial: aprox. 68\% de consumidores (equivalente a una desviación estándar) tienen sensibilidad entre -3.5 y -1.5
\item
  Aproximadamente 1\% de consumidores podrían tener sensibilidad positiva (preferir productos caros)
\end{itemize}

\textbf{DAP por display:}

\[DAP_{display} = -\frac{\beta_{display}}{\beta_{n,precio}}\]

Si \(\beta_{display} = 0.5\), la DAP media sería aproximadamente \(0.5/2.5 = 0.20\) dólares.

\hypertarget{apuxe9ndices-tuxe9cnicos}{%
\chapter{Apéndices Técnicos}\label{apuxe9ndices-tuxe9cnicos}}

\hypertarget{muxe9todos-de-estimaciuxf3n-y-evaluaciuxf3n-de-modelos}{%
\section{Métodos de Estimación y Evaluación de modelos}\label{muxe9todos-de-estimaciuxf3n-y-evaluaciuxf3n-de-modelos}}

\end{document}
