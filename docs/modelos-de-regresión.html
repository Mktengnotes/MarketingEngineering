<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 1 Modelos de Regresión | Marketing Engineering</title>
  <meta name="description" content="Capítulo 1 Modelos de Regresión | Marketing Engineering" />
  <meta name="generator" content="bookdown 0.37 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 1 Modelos de Regresión | Marketing Engineering" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Capítulo 1 Modelos de Regresión | Marketing Engineering" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 1 Modelos de Regresión | Marketing Engineering" />
  
  <meta name="twitter:description" content="Capítulo 1 Modelos de Regresión | Marketing Engineering" />
  

<meta name="author" content="Marcel Goic" />


<meta name="date" content="2023-12-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="modelos-probabilisticos.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Marketing Engineering</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prólogo</a></li>
<li class="chapter" data-level="1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html"><i class="fa fa-check"></i><b>1</b> Modelos de Regresión</a>
<ul>
<li class="chapter" data-level="1.1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#conceptos-básicos-de-regresión"><i class="fa fa-check"></i><b>1.1</b> Conceptos básicos de regresión</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#notación"><i class="fa fa-check"></i><b>1.1.1</b> Notación</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#mínimos-cuadrados-ordinarios-ols-y-supuestos"><i class="fa fa-check"></i><b>1.2</b> Mínimos Cuadrados Ordinarios (OLS) y supuestos</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#estimación"><i class="fa fa-check"></i><b>1.2.1</b> Estimación</a></li>
<li class="chapter" data-level="1.2.2" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#propiedades"><i class="fa fa-check"></i><b>1.2.2</b> Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#estrategias-de-modelamiento"><i class="fa fa-check"></i><b>1.3</b> Estrategias de Modelamiento</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#arte-vs.-procedimiento"><i class="fa fa-check"></i><b>1.3.1</b> Arte vs. Procedimiento</a></li>
<li class="chapter" data-level="1.3.2" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#aprendizajes-preliminares"><i class="fa fa-check"></i><b>1.3.2</b> Aprendizajes Preliminares</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#evaluación-de-modelos"><i class="fa fa-check"></i><b>1.4</b> Evaluación de modelos</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#qué-buscamos-en-un-modelo"><i class="fa fa-check"></i><b>1.4.1</b> ¿Qué buscamos en un modelo?</a></li>
<li class="chapter" data-level="1.4.2" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#ajuste-por-métricas-generales"><i class="fa fa-check"></i><b>1.4.2</b> Ajuste por métricas generales</a></li>
<li class="chapter" data-level="1.4.3" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#ajuste-basado-en-la-probabilidad"><i class="fa fa-check"></i><b>1.4.3</b> Ajuste basado en la probabilidad</a></li>
<li class="chapter" data-level="1.4.4" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#errores-dentro-y-fuera-de-la-muestra"><i class="fa fa-check"></i><b>1.4.4</b> Errores dentro y fuera de la muestra</a></li>
<li class="chapter" data-level="1.4.5" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#división-de-datos"><i class="fa fa-check"></i><b>1.4.5</b> División de datos</a></li>
<li class="chapter" data-level="1.4.6" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#validación-cruzada"><i class="fa fa-check"></i><b>1.4.6</b> Validación cruzada</a></li>
<li class="chapter" data-level="1.4.7" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#test-de-hipótesis"><i class="fa fa-check"></i><b>1.4.7</b> Test de hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#usos-y-limitaciones-del-análisis-de-regresión"><i class="fa fa-check"></i><b>1.5</b> Usos y limitaciones del análisis de regresión</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#aprendizaje-de-los-parámetros"><i class="fa fa-check"></i><b>1.5.1</b> Aprendizaje de los parámetros</a></li>
<li class="chapter" data-level="1.5.2" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#interpretación-de-los-coeficientes"><i class="fa fa-check"></i><b>1.5.2</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="1.5.3" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#pronósticos"><i class="fa fa-check"></i><b>1.5.3</b> Pronósticos</a></li>
<li class="chapter" data-level="1.5.4" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#errores-de-pronóstico"><i class="fa fa-check"></i><b>1.5.4</b> Errores de pronóstico</a></li>
<li class="chapter" data-level="1.5.5" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#principios-generales-de-pronóstico"><i class="fa fa-check"></i><b>1.5.5</b> Principios generales de pronóstico</a></li>
<li class="chapter" data-level="1.5.6" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#limitaciones-de-los-modelos-de-regresión"><i class="fa fa-check"></i><b>1.5.6</b> Limitaciones de los modelos de regresión</a></li>
<li class="chapter" data-level="1.5.7" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#modelos-lineales-generalizados"><i class="fa fa-check"></i><b>1.5.7</b> Modelos lineales generalizados</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#alternativas-de-machine-learning-para-la-regresión"><i class="fa fa-check"></i><b>1.6</b> Alternativas de Machine Learning para la regresión</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#qué-es-machine-learning"><i class="fa fa-check"></i><b>1.6.1</b> ¿Qué es Machine Learning?</a></li>
<li class="chapter" data-level="1.6.2" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#la-regresión-cuenta-como-un-modelo-de-ml"><i class="fa fa-check"></i><b>1.6.2</b> ¿La regresión cuenta como un modelo de ML?</a></li>
<li class="chapter" data-level="1.6.3" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#multivariate-adaptive-regression-splines-mars"><i class="fa fa-check"></i><b>1.6.3</b> Multivariate Adaptive Regression Splines (MARS)</a></li>
<li class="chapter" data-level="1.6.4" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#k-nearest-neighbors-regression-knn"><i class="fa fa-check"></i><b>1.6.4</b> K Nearest Neighbors Regression (KNN)</a></li>
<li class="chapter" data-level="1.6.5" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#regression-trees"><i class="fa fa-check"></i><b>1.6.5</b> Regression trees</a></li>
<li class="chapter" data-level="1.6.6" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#bagging-y-random-forests"><i class="fa fa-check"></i><b>1.6.6</b> Bagging y Random forests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html"><i class="fa fa-check"></i><b>2</b> Modelos Probabilisticos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#introducción"><i class="fa fa-check"></i><b>2.1</b> Introducción</a></li>
<li class="chapter" data-level="2.2" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelos-de-duración"><i class="fa fa-check"></i><b>2.2</b> Modelos de Duración</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelos-de-duración-de-tiempo-discreto"><i class="fa fa-check"></i><b>2.2.1</b> Modelos de duración de tiempo discreto</a></li>
<li class="chapter" data-level="2.2.2" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelos-de-duración-en-tiempo-continuo-sin-dependencia-en-la-duración"><i class="fa fa-check"></i><b>2.2.2</b> Modelos de duración en tiempo continuo sin dependencia en la duración</a></li>
<li class="chapter" data-level="2.2.3" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelos-de-duración-en-tiempo-continuo-con-dependencia-en-la-duración"><i class="fa fa-check"></i><b>2.2.3</b> Modelos de duración en tiempo continuo con dependencia en la duración</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelos-de-conteo"><i class="fa fa-check"></i><b>2.3</b> Modelos de Conteo</a></li>
<li class="chapter" data-level="2.4" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelos-de-elección"><i class="fa fa-check"></i><b>2.4</b> Modelos de Elección</a></li>
<li class="chapter" data-level="2.5" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#esperanzas-condicionales"><i class="fa fa-check"></i><b>2.5</b> Esperanzas Condicionales</a></li>
<li class="chapter" data-level="2.6" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#variables-explicativas"><i class="fa fa-check"></i><b>2.6</b> Variables explicativas</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#variables-explicativas-en-modelos-de-duración-en-tiempo-continuo-sin-dependencia-de-la-duración"><i class="fa fa-check"></i><b>2.6.1</b> Variables explicativas en modelos de duración en tiempo continuo sin dependencia de la duración</a></li>
<li class="chapter" data-level="2.6.2" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#variables-explicativas-en-modelos-de-duración-en-tiempo-continuo-con-dependencia-de-la-duración"><i class="fa fa-check"></i><b>2.6.2</b> Variables explicativas en modelos de duración en tiempo continuo con dependencia de la duración</a></li>
<li class="chapter" data-level="2.6.3" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#caso-modelo-de-conteo-khakichinos.com"><i class="fa fa-check"></i><b>2.6.3</b> Caso Modelo de Conteo: KhakiChinos.com</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelos-integrados"><i class="fa fa-check"></i><b>2.7</b> Modelos Integrados</a></li>
<li class="chapter" data-level="2.8" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#customer-lifetime-value-caso-contractual"><i class="fa fa-check"></i><b>2.8</b> Customer Lifetime Value: Caso Contractual</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelo-contractual-a-tiempo-discreto"><i class="fa fa-check"></i><b>2.8.1</b> Modelo contractual a tiempo discreto</a></li>
<li class="chapter" data-level="2.8.2" data-path="modelos-probabilisticos.html"><a href="modelos-probabilisticos.html#modelo-contractual-a-tiempo-continuo"><i class="fa fa-check"></i><b>2.8.2</b> Modelo contractual a tiempo continuo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html"><i class="fa fa-check"></i><b>3</b> Modelos Estructurales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#introducción-a-modelos-estructurales"><i class="fa fa-check"></i><b>3.1</b> Introducción a Modelos Estructurales</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#introducción-1"><i class="fa fa-check"></i><b>3.1.1</b> Introducción</a></li>
<li class="chapter" data-level="3.1.2" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#modelos-estructurales-en-marketing"><i class="fa fa-check"></i><b>3.1.2</b> Modelos Estructurales en Marketing</a></li>
<li class="chapter" data-level="3.1.3" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#taxonomía-de-modelos-estrucuturales"><i class="fa fa-check"></i><b>3.1.3</b> Taxonomía de Modelos Estrucuturales</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#logit"><i class="fa fa-check"></i><b>3.2</b> Logit</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#modelos-de-elección-discreta"><i class="fa fa-check"></i><b>3.2.1</b> Modelos de Elección Discreta</a></li>
<li class="chapter" data-level="3.2.2" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#modelo-logit"><i class="fa fa-check"></i><b>3.2.2</b> Modelo Logit</a></li>
<li class="chapter" data-level="3.2.3" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#estimación-1"><i class="fa fa-check"></i><b>3.2.3</b> Estimación</a></li>
<li class="chapter" data-level="" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#apéndice"><i class="fa fa-check"></i>Apéndice</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#probit"><i class="fa fa-check"></i><b>3.3</b> Probit</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#definición"><i class="fa fa-check"></i><b>3.3.1</b> Definición</a></li>
<li class="chapter" data-level="3.3.2" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#patrones-de-substitución"><i class="fa fa-check"></i><b>3.3.2</b> Patrones de substitución</a></li>
<li class="chapter" data-level="3.3.3" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#identificación"><i class="fa fa-check"></i><b>3.3.3</b> Identificación</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#mixed-logit"><i class="fa fa-check"></i><b>3.4</b> <em>Mixed Logit</em></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="apéndices-técnicos.html"><a href="apéndices-técnicos.html"><i class="fa fa-check"></i><b>4</b> Apéndices Técnicos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="apéndices-técnicos.html"><a href="apéndices-técnicos.html#métodos-de-estimación-y-evaluación-de-modelos"><i class="fa fa-check"></i><b>4.1</b> Métodos de Estimación y Evaluación de modelos</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Marketing Engineering</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelos-de-regresión" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Capítulo 1</span> Modelos de Regresión<a href="modelos-de-regresión.html#modelos-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="conceptos-básicos-de-regresión" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Conceptos básicos de regresión<a href="modelos-de-regresión.html#conceptos-básicos-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Como bien ya se ha estudiado en otros cursos de la carrera de ingeniería industrial, una <strong>regresión</strong> es una técnica para calcular el valor esperado de una variable condicional en la realización de otras.</p>
<p>Por ejemplo: - ¿Cuál debería ser el precio de venta de una casa en la comuna de la Providencia, con 4 dormitorios, 170m2 de superficie construida? -¿Cuáles deberían ser las ventas de Leche semidescremada Nestlé en la última semana del mes de Abril si el precio es $723? - ¿Cuál debería ser el número de clientes que ve un aviso publicitario si se despliega en 4 programas durante 3 semanas y el rating promedio de los programas es 8.7 puntos?</p>
<div id="notación" class="section level3 hasAnchor" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Notación<a href="modelos-de-regresión.html#notación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En general se denota con <span class="math inline">\(y\)</span> al vector que representa todas las variables dependientes en un único vector columna, mientras que <span class="math inline">\(X\)</span> representa la matriz que incluye todas las variables independientes (esto incluye una columna de 1s si se desea incluir un intercepto).</p>
<p>Es importante notar que: - Cada columna corresponde a una variable - Cada fila corresponde a un caso - Las dimensiones de las filas del vector <span class="math inline">\(y\)</span> y la matriz <span class="math inline">\(X\)</span> deben ser consistentes. - Todos los elementos de una misma fila deben tener los mismos índices.</p>
<p>Para estimar los parámetros de la recta de regresión, se utilizan diferentes métodos, siendo uno de los más populares el método de Mínimos Cuadrados Ordinarios (OLS).</p>
</div>
</div>
<div id="mínimos-cuadrados-ordinarios-ols-y-supuestos" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Mínimos Cuadrados Ordinarios (OLS) y supuestos<a href="modelos-de-regresión.html#mínimos-cuadrados-ordinarios-ols-y-supuestos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>OLS proporciona una estimación óptima de los parámetros de la recta de regresión, al encontrar la recta que minimiza la suma de los cuadrados de las diferencias entre los valores reales y los valores estimados de la variable dependiente. Sin embargo, para que este método sea un estimador adecuado de los parámetros, se deben cumplir ciertos supuestos:</p>
<ol style="list-style-type: decimal">
<li><p>Existe una <strong>relación lineal</strong> entre la variable dependiente y las variables independientes. Debido a esto, la relación entre las variables se puede modelar mediante una recta. Sin este supuesto, OLS no es apropiado y se debe recurrir a otros métodos.</p></li>
<li><p>Los errores tienen una <strong>distribución normal y tienen una media igual a cero</strong>. Es decir, los errores son insesgados y distribuyen de forma simétrica alrededor del cero. Si los errores no siguen una distribución normal, los resultados de la regresión pueden no ser confiables.</p></li>
<li><p>Los errores tienen una <strong>varianza constante</strong> (homocedasticidad). Esto significa que la varianza de los errores es la misma para todos los valores de las variables independientes. Si no se cumple este supuesto, los errores pueden estar influenciados por alguna variable independiente y los resultados pueden ser incorrectos.</p></li>
<li><p>Los errores son <strong>independientes entre sí</strong>. Es decir, no están correlacionados con los errores de otra observación. Si los errores están correlacionados, la varianza de los coeficientes puede ser demasiado baja, lo que puede llevar a una sobreestimación de la significancia estadística.</p></li>
<li><p>No existe <strong>multicolinealidad</strong> perfecta entre las variables independientes. La multicolinealidad perfecta se refiere a la existencia de una relación lineal exacta entre las variables independientes. Esto puede ocurrir cuando dos o más variables independientes están altamente correlacionadas. Si no se cumple este supuesto, los coeficientes estimados pueden no ser confiables y los resultados pueden ser incorrectos.</p></li>
</ol>
<p>En general, utilizamos OLS se utiliza porque proporciona una estimación óptima de los parámetros de la recta de regresión, es decir, los valores que mejor se ajustan a los datos. El método OLS minimiza la suma de los cuadrados de las diferencias entre los valores reales y los valores estimados de la variable dependiente. Esto se logra al encontrar los valores de los parámetros de la recta que minimizan esta suma de cuadrados.</p>
<div id="estimación" class="section level3 hasAnchor" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Estimación<a href="modelos-de-regresión.html#estimación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supongamos que queremos estimar los parámetros <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_n\)</span> de la recta de regresión <span class="math inline">\(Y = \beta_0 + \beta_1 x_1 + \cdots + \beta_n x_n + \epsilon\)</span>, donde <span class="math inline">\(\epsilon\)</span> es el término de error e <span class="math inline">\(Y\)</span> es la variable dependiente. Queremos encontrar los valores de los parámetros <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_n\)</span> que minimizan la suma de los cuadrados de las diferencias entre los valores reales y los valores estimados de <span class="math inline">\(Y\)</span>.</p>
<p>La idea detrás del método de Mínimos Cuadrados Ordinarios (OLS) es minimizar la función de pérdida <span class="math inline">\(S(\beta_0, \beta_1, \ldots, \beta_n) = \sum_{i=1}^N (Y_i - \beta_0 - \beta_1 x_{i1} - \cdots - \beta_n x_{in})^2\)</span>. La solución de este problema de optimización se puede encontrar a través del cálculo de las derivadas parciales de <span class="math inline">\(S\)</span> con respecto a cada uno de los parámetros <span class="math inline">\(\beta_j\)</span>, e igualar a cero. Esto nos lleva al siguiente sistema de ecuaciones</p>
<p><span class="math display">\[X^TX\hat{\beta}=X^TY\]</span></p>
<p>donde <span class="math inline">\(X\)</span> es la matriz de variables independientes, <span class="math inline">\(Y\)</span> es el vector de la variable dependiente y <span class="math inline">\(\hat{\beta}\)</span> es el vector de estimadores de mínimos cuadrados.</p>
<p>La solución de este sistema entrega los valores de los parámetros <span class="math inline">\(\beta_0, \beta_1, \ldots, \beta_n\)</span> que minimizan la función de pérdida <span class="math inline">\(S(\beta_0, \beta_1, \ldots, \beta_n)\)</span>. Estos valores se conocen como los estimadores de mínimos cuadrados de los parámetros de la recta de regresión. De manera matricial esto se escribe como <span class="math inline">\(\hat{\beta} = (X^TX)^{-1} X^TY\)</span>, donde <span class="math inline">\(\hat{\beta}\)</span> es el vector de estimadores de mínimos cuadrados, <span class="math inline">\(X\)</span> es la matriz de variables independientes e <span class="math inline">\(Y\)</span> es el vector de la variable dependiente.</p>
</div>
<div id="propiedades" class="section level3 hasAnchor" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Propiedades<a href="modelos-de-regresión.html#propiedades" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si se cumplen los supuestos anteriormente mencionados, mínimos cuadrados ordinarios cumple con las siguientes propiedades:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Insesgadez</strong>: Los estimadores de mínimos cuadrados son insesgados, lo que significa que, en promedio, su valor esperado es igual al verdadero valor del parámetro que se está estimando.</p></li>
<li><p><strong>Varianza mínima</strong>: Entre todos los estimadores insesgados y lineales, los estimadores de mínimos cuadrados tienen la menor varianza posible. Esto los convierte en los estimadores más precisos que se pueden obtener mediante una combinación lineal de las variables independientes.</p></li>
<li><p><strong>Linealidad</strong>: Los estimadores de mínimos cuadrados son lineales en la variable de respuesta <span class="math inline">\(Y\)</span>.</p></li>
<li><p><strong>Consistencia</strong>: Con un tamaño de muestra lo suficientemente grande, los estimadores de mínimos cuadrados se acercan al verdadero valor del parámetro que se está estimando.</p></li>
<li><p>El estimador máximo verosímil, para el caso lineal con errores normales <strong>coincide con el estimador de mínimos cuadrados</strong>.</p></li>
</ol>
</div>
</div>
<div id="estrategias-de-modelamiento" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Estrategias de Modelamiento<a href="modelos-de-regresión.html#estrategias-de-modelamiento" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="arte-vs.-procedimiento" class="section level3 hasAnchor" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Arte vs. Procedimiento<a href="modelos-de-regresión.html#arte-vs.-procedimiento" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El debate entre el arte y el procedimiento en el campo de la modelización y análisis de datos se ha intensificado en los últimos años con el auge de la inteligencia artificial y el aprendizaje automático. Los defensores del arte argumentan que la experiencia y la intuición del analista son esenciales para identificar patrones y relaciones complejas en los datos que no son evidentes a simple vista. Por otro lado, los defensores del procedimiento insisten en que la aplicación rigurosa de algoritmos y técnicas estadísticas es la única manera de garantizar la validez y precisión del modelo.</p>
<p>Es importante tener en cuenta que el uso exclusivo de uno u otro enfoque puede llevar a resultados subóptimos. Por ejemplo, un modelo construido únicamente a través del arte puede ser difícil de replicar o explicar a otros, lo que limita su utilidad práctica. Por otro lado, un modelo construido únicamente a través del procedimiento puede pasar por alto aspectos importantes de los datos que son evidentes para un experto en el campo.</p>
<p>En la práctica, los analistas suelen combinar ambos enfoques para construir modelos efectivos y útiles. Un aspecto clave en este proceso es la exploración exhaustiva de los datos y la definición de una lista de modelos candidatos, que pueden incluir diferentes técnicas de modelización y selección de variables. Luego, se pueden utilizar diversas métricas de ajuste y predicción para evaluar la calidad de cada modelo y seleccionar el que mejor se ajuste a los datos y sea capaz de hacer predicciones precisas.</p>
</div>
<div id="aprendizajes-preliminares" class="section level3 hasAnchor" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Aprendizajes Preliminares<a href="modelos-de-regresión.html#aprendizajes-preliminares" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el ámbito del modelado estadístico, existen innumerables modelos de regresión, lo que hace imposible determinar cuál es el mejor en términos absolutos.</p>
<p>Una forma de abordar este problema es equilibrar la complejidad del modelo con su capacidad explicativa. Esto significa que el modelo debe ser lo suficientemente simple como para ser fácilmente interpretable, pero lo suficientemente complejo como para capturar todas las relaciones relevantes entre las variables.</p>
<p>Para seleccionar un modelo de regresión adecuado, es fundamental tener conocimientos previos del negocio y realizar una exploración exhaustiva de los datos antes de aplicar cualquier modelo. Esta exploración ex-ante puede ayudar a identificar las variables más relevantes y las posibles relaciones entre ellas. Es importante evaluar cómo se relacionan las variables, qué variables tienen mayor dispersión y qué variables se mantienen relativamente constantes.</p>
<p>Después de la exploración ex-ante, es necesario aplicar el modelo y evaluar su rendimiento mediante la evaluación ex-post. Esto implica evaluar el modelo en datos nuevos y comprobar si se comporta de manera similar a cómo lo hizo en los datos de entrenamiento.</p>
<p><strong>1. Elegir nivel de agregación</strong></p>
<p>Uno de los aspectos clave del análisis de datos es determinar el nivel adecuado de agregación para realizar el análisis. Por ejemplo, se puede analizar las ventas de un producto en un supermercado por hora, día, semana, mes o año. También se puede considerar el análisis de ventas por SKU (código de identificación), marca, cadena o sala.</p>
<p>Es importante tener en cuenta que el problema de gestión puede imponer restricciones al nivel de agregación mínimo. Por ejemplo, si un gerente de una cadena de supermercados necesita tomar decisiones en tiempo real sobre la reposición de un producto, es posible que necesite datos a nivel de hora o día. En este caso, analizar las ventas a nivel de semana o mes no sería útil.</p>
<p>En el análisis de ventas, a menudo se enfrenta un trade-off entre la sensibilidad al precio y la programación de reposición. Si el análisis se realiza a nivel de SKU, se puede obtener una comprensión más detallada de cómo el precio afecta a las ventas. Sin embargo, si el análisis se realiza a nivel de cadena o sala, se puede obtener una mejor comprensión de los patrones de reposición.</p>
<p>Agregar los datos a un nivel de agregación más alto puede ser más fácil, ya que se requiere menos detalle y se puede tener una visión más general. Sin embargo, puede llevar a una pérdida de precisión por underfitting. Por ejemplo, si se analiza las ventas a nivel de mes, se puede perder información valiosa sobre patrones diarios o semanales. Por otro lado, si la cantidad de datos es limitada, es posible que se necesite mantener un nivel de agregación más alto para obtener un modelo preciso. En este caso, reducir el nivel de agregación puede significar la pérdida de información importante y la reducción de la precisión del modelo por overfitting.</p>
<p><strong>2. Descomposición en múltiples regresiones:</strong></p>
<p>La descomposición en múltiples regresiones es una técnica que permite abordar problemas complejos y de alta dimensionalidad mediante la partición del problema en componentes más pequeños y manejables. Este enfoque puede adoptar diversas formas, incluyendo la descomposición por índices y la descomposición por componentes latentes.</p>
<ul>
<li><p>Descomposición por Índices: Aunque en general es preferible utilizar una única regresión para analizar las relaciones entre las variables, en ciertas situaciones, como en casos de complejidad computacional elevada o cuando se abordan problemas con múltiples niveles de jerarquía, la descomposición por índices puede ser una solución adecuada. Esta técnica implica dividir el conjunto de datos en subconjuntos según algún criterio y ajustar modelos de regresión separados para cada subconjunto.</p></li>
<li><p>Regresión Lineal y Modelos Más Complejos: La regresión lineal es un enfoque simple y fácil de estimar que puede ser suficiente en muchos casos. Sin embargo, en situaciones donde las relaciones entre las variables no son lineales o donde se requiere una mayor flexibilidad en el modelado, se pueden justificar modelos más complejos, como regresiones polinómicas, regresiones no paramétricas o modelos de regresión con variables categóricas.</p></li>
<li><p>Descomposición por Componentes Latentes: En ciertos casos, la variable dependiente puede descomponerse de manera natural en componentes latentes, lo que facilita la interpretación de los resultados y la identificación de relaciones subyacentes entre las variables. Un ejemplo típico es la descomposición de las ventas en el número de compras y el número de unidades por compra. Al analizar estos componentes por separado, se puede obtener una comprensión más detallada de los factores que influyen en las ventas.</p></li>
<li><p>Caso del Cero Inflado (Zero Inflated): En algunas situaciones, se pueden observar una gran cantidad de ceros en los datos, lo que indica una distribución inflada en cero. En estos casos, se puede utilizar un modelo de regresión de ceros inflados que distingue entre dos procesos distintos: la incidencia de compra (probabilidad de que ocurra una compra) y el monto de compra (valor de la compra, condicional a que se haya realizado una compra). Este enfoque permite analizar de manera más efectiva los factores que afectan tanto la propensión a comprar como la cantidad gastada en las compras.</p></li>
</ul>
<p><strong>3. Transformación de Variables</strong></p>
<p>La transformación de variables es una técnica utilizada para mejorar la interpretación y el ajuste del modelo. Esta técnica consiste en aplicar funciones matemáticas a las variables con el objetivo de modificar su distribución y hacer que el modelo sea más interpretable y significativo.</p>
<p>Un ejemplo común de transformación de variables es el modelo doble log, en el cual se aplican logaritmos a las variables dependientes e independientes para transformar la relación no lineal en una relación lineal. Esta técnica puede ser útil cuando se analizan datos que siguen una distribución log-normal o cuando se busca interpretar los coeficientes de manera logarítmica.</p>
<p>Es importante tener en cuenta que, aunque la transformación de variables puede mejorar la bondad del ajuste y la precisión de las predicciones, no siempre es necesario aplicarla. En algunos casos, las variables ya están en una forma adecuada para el modelo y cualquier transformación adicional podría reducir la interpretabilidad del modelo. Por lo tanto, es importante tener una comprensión sólida de los datos y del problema a resolver antes de aplicar cualquier transformación de variables.</p>
<p><strong>4. Selección de Variables</strong></p>
<p>En el campo de la regresión, existen diferentes enfoques para la selección de variables, incluyendo métodos automáticos y manuales. Uno de los métodos automáticos más utilizados es la regresión paso a paso (stepwise regression), que implica la iterativa agregación o eliminación de variables en función de algún criterio de bondad de ajuste.</p>
<p>En el enfoque forward de la regresión paso a paso, las variables se van agregando al modelo una por una, comenzando con la variable que proporciona el mejor ajuste según el criterio establecido. En cada etapa, se evalúa si agregar una nueva variable mejora significativamente el ajuste del modelo.</p>
<p>Por otro lado, en el enfoque backward de la regresión paso a paso, todas las variables se incluyen inicialmente en el modelo y se van eliminando una por una, comenzando con la variable que menos contribuye al ajuste según el criterio establecido. En cada etapa, se evalúa si eliminar una variable mejora significativamente el ajuste del modelo.</p>
<p>Otro enfoque de selección de variables es la penalización de uso de parámetros no nulos al momento de minimizar la función de error. Dentro de este enfoque se encuentra la regresión Ridge y LASSO (Least Absolute Shrinkage and Selection Operator)</p>
<p><span class="math display">\[\text{Ridge: }\min_{β} \sum_{i}(y_i - \beta_0 - \sum_{j}\beta_{j}x_{ij})^2 + λ\sum_{j}\beta_{j}^2\]</span> <span class="math display">\[\text{LASSO: }\min_{β}\sum_{i}(y_i - \beta_0 - \sum_{j}\beta_{j}x_{ij})^2 + λ\sum_{j}|\beta_{j}|\]</span></p>
<p>Aunque estos enfoques automáticos de selección de variables pueden ser convenientes y ahorrar tiempo, es importante tener en cuenta algunas limitaciones. En primer lugar, las implementaciones automáticas de selección de variables no exploran todas las posibles combinaciones de variables, lo que significa que podrían pasar por alto combinaciones óptimas que un enfoque manual más exhaustivo podría descubrir.</p>
<p>Además, los resultados de la selección automática de variables pueden generar conjuntos de variables poco intuitivos y difíciles de interpretar. A veces, el algoritmo puede seleccionar variables que tienen una relación estadística con la variable de respuesta, pero carecen de una interpretación causal o intuitiva en el contexto del problema.</p>
<p>Una alternativa es utilizar una mixtura entre métodos automáticos y manuales, eligiendo aquellas variables que mejoran el modelo en ajuste y que igualmente tienen un sentido interpretativo para la resolución de la pregunta a responder.</p>
<p><strong>5. Selección de Índices</strong></p>
<p>La selección de índices en el análisis de regresión es un proceso discrecional que puede influir significativamente en la interpretación y el rendimiento de los modelos. Para abordar este problema de manera efectiva, se pueden seguir algunas pautas generales que ayuden a identificar y justificar la inclusión de índices en el análisis.</p>
<p>Condiciones para Indexar un Parámetro Es recomendable considerar la inclusión de un índice en un modelo de regresión si se cumplen las siguientes tres condiciones:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Relevancia para el problema de gestión: El índice debe ser importante para abordar el problema de gestión en cuestión, proporcionando una distinción significativa entre diferentes aspectos del problema.</p></li>
<li><p>Diferencias en el comportamiento de la variable dependiente: La variable dependiente debe mostrar comportamientos distintos para cada índice, lo que sugiere que la desagregación aporta información adicional útil.</p></li>
<li><p>Suficiencia de datos: Deben estar disponibles suficientes datos para estimar de manera confiable los parámetros desagregados. La falta de datos puede conducir a estimaciones poco fiables y a un mayor riesgo de sobreajuste.</p></li>
<li><p>Índices y Variables Binarias: En el análisis de regresión, los índices pueden representarse mediante variables binarias, también conocidas como variables <em>dummy</em>. Estas variables toman el valor de 1 cuando se cumple una condición específica (por ejemplo, si un producto pertenece a una categoría determinada) y 0 en caso contrario. Aunque la representación de índices mediante variables binarias es matemáticamente equivalente, la notación de índices suele ser más compacta y se prefiere en la mayoría de los casos.</p></li>
</ol>
<p><strong>6. Uso de Jerarquías</strong></p>
<p>Una jerarquía aparece cuando un parámetro del modelo aparece como una función de otros parámetros, el uso de esta técnica es útil para detectar posibles efectos de interacción entre las variables predictoras, de esta forma se pueden escribir modelos más parsinomios (es decir, modelos más sencillos y con menor cantidad de parámetros). Sin embargo, es importante tener en cuenta que la inclusión de jerarquías entre variables debe estar basada en una teoría clara o una justificación empírica, y no simplemente probando diferentes combinaciones de variables.</p>
</div>
</div>
<div id="evaluación-de-modelos" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Evaluación de modelos<a href="modelos-de-regresión.html#evaluación-de-modelos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La evaluación de modelos estadísticos es un tema amplio que involucra la aplicación de los mismos principios y técnicas básicas a un gran grupo de modelos. En la práctica, la evaluación de modelos se utiliza para determinar la calidad y utilidad de los modelos estadísticos, es decir, para determinar si un modelo se ajusta adecuadamente a los datos y si es útil para hacer predicciones o inferencias sobre la población de interés.</p>
<p>Es importante destacar que la evaluación de modelos estadísticos no es un proceso estático y que puede requerir ajustes y modificaciones a medida que se adquiere más información o se amplía el alcance del modelo. Por lo tanto, es fundamental seguir actualizando y refinando los modelos para asegurar su calidad y utilidad en la toma de decisiones basadas en datos.</p>
<p>En la evaluación de modelos estadísticos, se utilizan diversas técnicas que se verán a continuación.</p>
<div id="qué-buscamos-en-un-modelo" class="section level3 hasAnchor" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> ¿Qué buscamos en un modelo?<a href="modelos-de-regresión.html#qué-buscamos-en-un-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Lo deseable en un modelo es que cualitativamente puedan contar una buena historia, es decir, proporcionar información útil para poder tomar decisiones que vayan en línea de lo que se busca estimar. Por otra parte, se espera que cuantitativamente el modelo escogido ajuste bien a los datos utilizados como insumo para la calibración, de tal manera que reduzca el error de predicción y pueda generar un pronóstico creíble a partir de lo observado.</p>
<p>Con esto en mente, queremos un criterio bien definido para comparar modelos y determinar si un modelo dado es suficientemente bueno.</p>
</div>
<div id="ajuste-por-métricas-generales" class="section level3 hasAnchor" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Ajuste por métricas generales<a href="modelos-de-regresión.html#ajuste-por-métricas-generales" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las siguientes métricas de ajuste se basan en reducir los errores de predicción de los modelos, teniendo como fin cuantificar qué tanto error tiene un modelo al predecir un conjunto de datos dado:
1. Coeficiente de determinación o <span class="math inline">\(R^2\)</span>: Indica la cantidad de variación en la variable dependiente que puede ser explicada por las variable independientes en un modelo. Se define como:</p>
<p><span class="math display">\[ R^2 = \frac{\sum_{i=1}^n (\hat{y}_i - \bar{y})^2}{\sum_{i=1}^n (y_i - \bar{y})^2} \]</span></p>
<p>Donde <span class="math inline">\(\hat{y_i}\)</span> son los valores predichos por el modelo, <span class="math inline">\(\bar{y}\)</span> es la media de los valores observados <span class="math inline">\(y_i\)</span> y <span class="math inline">\(n\)</span> es el número de observaciones.</p>
<ol start="2" style="list-style-type: decimal">
<li>MAE (Mean Average Error):Calcula la diferencia promedio entre las predicciones del modelo y los valores reales observados en los datos.</li>
</ol>
<p><span class="math display">\[MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y_i}|\]</span></p>
<p>La función valor absoluto (<span class="math inline">\(|x|\)</span>) se utiliza para asegurar que el error siempre sea positivo.</p>
<ol start="3" style="list-style-type: decimal">
<li>MAPE (Mean Absolute Percentage Error): Se expresa en porcentaje y se calcula como el promedio de los valores absolutos de los errores porcentuales de cada observación.</li>
</ol>
<p><span class="math display">\[MAPE = \frac{1}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|\cdot 100\%\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>RMSE (Root Mean Squared Error): Es una medida de la diferencia entre los valores predichos y los valores reales en un conjunto de datos. La fórmula del RMSE es:</li>
</ol>
<p><span class="math display">\[ RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^n(y_i - \hat{y}_i)^2} \]</span></p>
</div>
<div id="ajuste-basado-en-la-probabilidad" class="section level3 hasAnchor" number="1.4.3">
<h3><span class="header-section-number">1.4.3</span> Ajuste basado en la probabilidad<a href="modelos-de-regresión.html#ajuste-basado-en-la-probabilidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>También es posible darle una interpretación probabilística al ajuste, es decir, elegir aquellos parámetros que más se asemejen a la distribución de probabilidad que generan los datos del modelo, para ello nos basamos en la función de verosimilitud.</p>
<p>La fórmula general de la función de verosimilitud para un conjunto de <span class="math inline">\(n\)</span> observaciones independientes y con distribución conjunta <span class="math inline">\(f(x_1, x_2, ..., x_n; θ)\)</span> es:</p>
<p><span class="math display">\[L(\theta | x_1, x_2, ..., x_n) = f(x_1, x_2, ..., x_n; \theta) = \prod_{i=1}^{n} f(x_i;\theta)\]</span></p>
<p>donde <span class="math inline">\(θ\)</span> es el vector de parámetros desconocidos que se quieren estimar y <span class="math inline">\(f(x_i; θ)\)</span> es la densidad de probabilidad (o función de masa de probabilidad) de la variable aleatoria <span class="math inline">\(x_i\)</span> para un valor de <span class="math inline">\(θ\)</span>.</p>
<p>Es común aplicar logaritmo a la función de verosimilitud, pues de esta forma se facilitan los cálculos manteniendo sus propiedades (dado que el logaritmo es una función monótona y creciente):</p>
<p><span class="math display">\[\ell(\theta | x) = \sum_{i=1}^{n} \log(f(x_i|\theta))\]</span></p>
<p>Las siguientes métricas se basan en la log-verosimilitud para evaluar el nivel de ajuste:</p>
<ol style="list-style-type: decimal">
<li>Razón de verosimilitud (o pseudo <span class="math inline">\(R^2\)</span>): Esta métrica es utilzada cuando la variable de resultado es nominal u ordinal, de modo que el coeficiente de determinación no se puede aplicar como una medida de bondad de ajuste. Se define como:</li>
</ol>
<p><span class="math display">\[\rho = 1 - \frac{\ell(\hat{\beta})}{\ell(0)} \text{(Asumiendo que $\beta=0$ es un modelo nulo razonable)}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Criterio de Información de Akaike (AIC): Basado en la teoría de información, es una medida de la calidad del modelo que penaliza aquellos que son más complejos, lo que ayuda a prevenir el sobreajuste de los datos.</li>
</ol>
<p><span class="math display">\[AIC = -2\ell({\hat{\beta}}) + 2k\]</span></p>
<p>Con <span class="math inline">\(k\)</span> el número de variables del modelo.</p>
<ol start="3" style="list-style-type: decimal">
<li>Criterio de Información Bayesiano (BIC): Este criterio penaliza la complejidad del modelo de manera más fuerte que el AIC, en función del número de parámetros del modelo y del tamaño de la muestra de datos. El BIC es más efectivo que el AIC para prevenir el sobreajuste del modelo, lo que significa que es más probable que seleccione un modelo más simple y generalizable.</li>
</ol>
<p><span class="math display">\[BIC = -2\ell(\hat{\beta}) + klog(n)\]</span></p>
<p>Con <span class="math inline">\(n\)</span> el número de observaciones en el set de datos.</p>
</div>
<div id="errores-dentro-y-fuera-de-la-muestra" class="section level3 hasAnchor" number="1.4.4">
<h3><span class="header-section-number">1.4.4</span> Errores dentro y fuera de la muestra<a href="modelos-de-regresión.html#errores-dentro-y-fuera-de-la-muestra" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En general, se busca contruir modelos que sean generalizables a otros datos fuera de aquellos que se utilizan para su construcción, para ello se suele dividir el conjunto de datos en un set de <strong>calibración</strong> y otro de <strong>validación</strong> para evaluar su capacidad de predicción.</p>
<p>En general, uno de los problemas que puede traer la excesiva complejización de un modelo es la poca adaptabilidad a nuevos conjuntos de datos, esto se conoce como sobreajuste (o overfitting), lo cual puede ser detectado al comparar los errores de predicción entre el set de calibración y validación:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="modelos-de-regresión.html#cb1-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/fitting.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:my-fig1"></span>
<img src="images/fitting.png" alt="Error de calibración vs predicción" width="50%" />
<p class="caption">
Figure 1.1: Error de calibración vs predicción
</p>
</div>
</div>
<div id="división-de-datos" class="section level3 hasAnchor" number="1.4.5">
<h3><span class="header-section-number">1.4.5</span> División de datos<a href="modelos-de-regresión.html#división-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La división de los datos en conjuntos de calibración y validación depende de la estructura de los mismos. Por lo general se utiliza el 80% de los datos en calibración y el 20% en validación. Si la estructura de datos lo permite, podemos realizar crossvalidación ejecutamos múltiples validaciones sobre diferentes muestras de prueba.</p>
</div>
<div id="validación-cruzada" class="section level3 hasAnchor" number="1.4.6">
<h3><span class="header-section-number">1.4.6</span> Validación cruzada<a href="modelos-de-regresión.html#validación-cruzada" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Algunos modelos, en especial en el mundo del <em>Machine learning</em>, requieren la calibración de sus hiperparámetros para una mejor predicción. Para ello existen múltiples técnicas, donde una de las más populares es la validación cruzada (<em>cross validation</em>).</p>
<p>El método de validación cruzada comienza con la división del conjunto en <span class="math inline">\(k\)</span> subconjuntos (<em>folds</em>), dónde <span class="math inline">\(k-1\)</span> servirán para calibrar el modelo, mientras que el conjunto restante se utilizará como validación. Este proceso se repite cambiando el conjunto de validación por cada uno de los <em>folds</em>, buscando los hiperparámetros que optimizan el rendimiento para cada una de las combinaciones. Finalmente, el valor de los hiperparámetros será la media de sus valores para cada <em>fold</em>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="modelos-de-regresión.html#cb2-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/cv.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:my-fig2"></span>
<img src="images/cv.png" alt="Ejemplo de validación cruzada" width="70%" />
<p class="caption">
Figure 1.2: Ejemplo de validación cruzada
</p>
</div>
</div>
<div id="test-de-hipótesis" class="section level3 hasAnchor" number="1.4.7">
<h3><span class="header-section-number">1.4.7</span> Test de hipótesis<a href="modelos-de-regresión.html#test-de-hipótesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Además de la evaluación del ajuste del modelo a partir de métricas, es posible hacer inferencias estadísticas sobre el modelo completo:</p>
<ol style="list-style-type: decimal">
<li>Pruebas de bondad de ajuste: Este tipo de tests intentan responder la pregunta de si el modelo es lo suficientemente <em>bueno</em> para confiar en su rendimiento. Una de las pruebas más utilizadas es el test de <span class="math inline">\(\chi ^2\)</span> de Pearson. Se busca testear la siguiente hipótesis nula:</li>
</ol>
<p><span class="math inline">\(H_0: \text{El modelo describe correctamente los datos observados}\)</span></p>
<p>Para ello se separan los datos en <span class="math inline">\(k\)</span> posible categorías y se construye el estadístico <span class="math inline">\(\chi^2\)</span></p>
<p><span class="math display">\[\chi^2 = \sum_{i = 1}^{K} \frac{(y_i - \hat{y_i})^2}{\hat{y_i}}\]</span></p>
<p>Se rechaza la hipótesis nula si <span class="math inline">\(\chi^2 &gt; \chi^{2}_{K-1, α}\)</span>.</p>
<p>Donde <span class="math inline">\(\mathbb{P}(\chi^2 &gt; \chi^{2}_{K-1, α}) = α\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Comparación de modelos anidados: Supongamos que tenemos dos modelos A y B, diremos que el modelo B está anidado en el modelo A si el modelo B puede derivarse imponiendo algunas restricciones sobre los parámetros de A.</li>
</ol>
<p>En el contexto de regresión, por ejemplo un modelo <span class="math inline">\(y=a+bx\)</span> está anidado en otro modelo <span class="math inline">\(y=a+bx+cz\)</span>, solo basta con imponer que <span class="math inline">\(c=0\)</span>.</p>
<p>Para evaluar si vale la pena agregar más complejidad al modelo se utiliza la prueba de <em>Likelihood Ratio</em>. De esta forma se puede determinar si la mejora del rendimiento de un modelo en comparación al modelo anidado se justifica en relación a la cantidad de nuevos parámetros.</p>
<p>La prueba de verosimilitud se basa en computar el estadístico del ratio:</p>
<p><span class="math display">\[LR = 2(LL_A - LL_B)\]</span></p>
<p>Supongamos que existen <span class="math inline">\(k\)</span> nuevos parámetros que se agregan en el modelo A.</p>
<p>Si <span class="math inline">\(LR &gt; \chi^2(0.05, k)\)</span>, entonces el modelo A es mejor que el modelo B (es decir, la adición de parámetros marca una diferencia estadísticamente significativa al rendimiento del modelo.)</p>
</div>
</div>
<div id="usos-y-limitaciones-del-análisis-de-regresión" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Usos y limitaciones del análisis de regresión<a href="modelos-de-regresión.html#usos-y-limitaciones-del-análisis-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez que se construye y se estima un modelo, el siguiente paso es interpretar sus resultados. Es posible enfocarse en el <strong>aprendizaje</strong> sobre los parámetros retornados del modelo y cómo estos explican el fenómeno a estudiar, como también es posible realizar un <strong>pronóstico</strong> a futuro del desempeño de las variables a predecir.</p>
<div id="aprendizaje-de-los-parámetros" class="section level3 hasAnchor" number="1.5.1">
<h3><span class="header-section-number">1.5.1</span> Aprendizaje de los parámetros<a href="modelos-de-regresión.html#aprendizaje-de-los-parámetros" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En general, la principal fuente de aprendizaje que provee un modelo de regresión son los coeficientes calculados, los cuales entregan información sobre el efecto de las variables independientes sobre lo que se desea estudiar.</p>
<p>Dentro de las preguntas más importantes a responder se encuentran:</p>
<ul>
<li>¿Poseen las variables del modelo el signo esperado?</li>
<li>¿Son estadísticamente significativos?</li>
<li>¿Es relevante la magnitud de su efecto?</li>
</ul>
<p>Para responder a estas preguntas se hace necesario el uso de heramientas estadsticas tales como <strong>t-test</strong> para evaluaciones individuales o <strong>F-test</strong> para la evaluación de un conjunto de regresores.</p>
</div>
<div id="interpretación-de-los-coeficientes" class="section level3 hasAnchor" number="1.5.2">
<h3><span class="header-section-number">1.5.2</span> Interpretación de los coeficientes<a href="modelos-de-regresión.html#interpretación-de-los-coeficientes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supongamos un modelo lineal simple definido por <span class="math inline">\(y = 12 + 1.5x\)</span>, es de toda lógica pensar que el efecto de <span class="math inline">\(x\)</span> sobre <span class="math inline">\(y\)</span> al incrementar en una unidad es, en promedio, de <span class="math inline">\(1.5\)</span>. Sin embargo, esta afirmación sería correcta <strong>sólo</strong> en el caso de que se tengan buenas razones para creer que <span class="math inline">\(x\)</span> tiene un <strong>efecto causal</strong> en <span class="math inline">\(y\)</span>.</p>
<p>Es importante recordar que los modelos de regresión solo indican la correlación entre las variables dependientes con las independientes, pero no necesariamente una relación causal entre ambas. Dentro de los fenómenos que pueden explicar la correlación sin causalidad entre variables, se encuentran los siguientes:</p>
<ul>
<li>Causalidad inversa: <span class="math inline">\(y\)</span> causa <span class="math inline">\(x\)</span></li>
<li>Simultaneidad: <span class="math inline">\(y\)</span> causa <span class="math inline">\(x\)</span> y <span class="math inline">\(x\)</span> causa <span class="math inline">\(y\)</span></li>
<li>Tercera variable: <span class="math inline">\(z\)</span> causa <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span></li>
</ul>
<p>Para averiguar qué es lo que hace que una variable independiente tenga un efecto sobre la variable dependiente, se suele recurrir a un método llamado <strong>análisis de mediación</strong>, el cual consiste en la investigación para examinar la relación entre una variable independiente y una variable dependiente a través de una variable intermedia, conocida como mediador. La mediación se produce cuando la relación entre la variable independiente y la variable dependiente se explica por completo o parcialmente por la influencia del mediador.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="modelos-de-regresión.html#cb3-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/Simple_Mediation_Model.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:my-fig3"></span>
<img src="images/Simple_Mediation_Model.png" alt="Modelo de mediación" width="70%" />
<p class="caption">
Figure 1.3: Modelo de mediación
</p>
</div>
<p>Es importante no confundir el análisis de mediación con un efecto de tercera variable. Por ejemplo, si <span class="math inline">\(z\)</span> causa <span class="math inline">\(x\)</span> y a la vez <span class="math inline">\(z\)</span> causa <span class="math inline">\(y\)</span>, entonces estamos bajo un escenario de tercera variable. Sin embargo, si <span class="math inline">\(x\)</span> causa <span class="math inline">\(z\)</span> y <span class="math inline">\(z\)</span> causa <span class="math inline">\(y\)</span>, es posible afirmar que <span class="math inline">\(z\)</span> es una variable mediadora entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p>
</div>
<div id="pronósticos" class="section level3 hasAnchor" number="1.5.3">
<h3><span class="header-section-number">1.5.3</span> Pronósticos<a href="modelos-de-regresión.html#pronósticos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La principal razón de realizar buenas predicciones con los modelos construidos es la toma de decisiones mediante la evaluación de resultados en diversos escenarios posibles. Bajo el enfoque de regresión lineal, el pronóstico está dado por la esperanza del valor de la variable dependiente, es decir <span class="math inline">\(\mathbb{E}[Y]\)</span>.</p>
<p>En el caso mas sencillo, el pronóstico está dado por <span class="math inline">\(\mathbb{E}[Y] = \beta X\)</span>, si dentro del desarrollo del modelo se decidiera utilizar una transformación funcional en el modelo, la expresión del pronóstico cambiará. Por ejemplo, para el caso de una regresión log-lineal, el término de error no desaparece del pronóstico, debido a que se está calculando la esperanza de una función de una variable aleatoria, luego el resultado que se obtiene es <span class="math inline">\(\mathbb{E}[Y] = exp(\beta X + \frac{1}{2}S_ϵ^2)\)</span>, con <span class="math inline">\(S_{ϵ}^2\)</span> la varianza muestral de <span class="math inline">\(ϵ\)</span>.</p>
</div>
<div id="errores-de-pronóstico" class="section level3 hasAnchor" number="1.5.4">
<h3><span class="header-section-number">1.5.4</span> Errores de pronóstico<a href="modelos-de-regresión.html#errores-de-pronóstico" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El error de pronóstico contiene dos componentes: errores residuales (debido a la dispersión de los datos) y errores de muestra. Se puede escribir de la siguiente manera:</p>
<p><span class="math display">\[\text{sef}(x_0) = s\sqrt{x_0^T(X^TX)^{-1}x_0 + 1}\]</span></p>
<p>La variabilidad en los prónosticos dependerá de las variables explicativas del modelo y de la muestra utilizada para estimar la forma funcional de la variable dependiente. Esta variabilidad debe ser considerada en la evaluación de escenarios al momento de tomar una decisión.</p>
</div>
<div id="principios-generales-de-pronóstico" class="section level3 hasAnchor" number="1.5.5">
<h3><span class="header-section-number">1.5.5</span> Principios generales de pronóstico<a href="modelos-de-regresión.html#principios-generales-de-pronóstico" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Incluir todas las variables que se esperan que contribuyan al pronóstico: A diferencia del enfoque anterior, no se está buscando el entendimiento de los parámetros sino predecir.</li>
<li>Evaluar si algunas variables pueden ser agregadas para crear índices: Puede suceder que varias variables capturan un mísmo fenómeno, y por ende causar ruido en la predicción. Para evitar esto, se puede construir una variable que las agrupe a todas en una sola componente.</li>
<li>Para variables importantes agregar interacciones: Puede que exista un efecto conjunto no observado.</li>
<li>Evaluar la inclusión de variables explicativas basadas en su signo esperado y significancia estadística:</li>
<li>Significativa y signo esperado: Mantener en el modelo.</li>
<li>No significativa y signo esperado: Mantener en el modelo.</li>
<li>Significativa y signo contrario: Puede causar ruido en el pronóstico, por lo que se debe quitar del modelo.</li>
<li>No significativa y signo contrario: Es posible que algo esté pasando con esa variable, es importante considerar trabajar con mas datos y/o variables.</li>
</ol>
</div>
<div id="limitaciones-de-los-modelos-de-regresión" class="section level3 hasAnchor" number="1.5.6">
<h3><span class="header-section-number">1.5.6</span> Limitaciones de los modelos de regresión<a href="modelos-de-regresión.html#limitaciones-de-los-modelos-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Debido a su simpleza, los modelos de regresión poseen ciertas limitaciones provocadas por la muestra de datos utilizadas, las variables escogidas para el modelo o por la naturaleza del método de estimación de mínimos cuadrados. Algunos de los problemas más frecuentes que se encuentran al trabajar con modelos de regresión son los siguientes:</p>
<ol style="list-style-type: decimal">
<li><strong>Colinealidad</strong>: Es la condición cuando uno o más regresores están correlacionados entre sí, dependiendo del grado de la misma se debe proceder de manera distinta. Si la correlación entre regresores es baja, no existe problema. Si la correlación es alta, se debe considerar eliminar una o más variables redundantes, reducir el número de variables en el modelo o transformar las variables para reducir su correlación. Finalmente, si existe <strong>colinealidad perfecta</strong> la matriz de regresores <span class="math inline">\(X\)</span> no es invertible y el modelo no puede ser calculado.</li>
<li>Es posible requerir de <strong>causalidad</strong> para afirmar que existe un efecto entre variables. Para determinar un efecto causal se pueden realizar experimentos, proponer modelos estructurales o utilizar variables instrumentales.</li>
<li><strong>Heteroscedasticidad</strong>: Es la correlación entre los términos de error y las variables del modelo. En otras palabras, la heteroscedasticidad significa que la dispersión de los errores en los datos es diferente para diferentes valores de las variables independientes. El estimador sigue siendo insesgado, pero se torna estadísticamente ineficiente. Para coregir heteroscedasticidad se utiliza mínimos cuadrados generalizados, ponderando según la magnitud del error de cada observación.</li>
<li><strong>Autocorrelación</strong>: Los errores estan correlacionados entre sí. Al igual que en el caso anterior el estimador sigue siendo insesgado, pero se torna estadísticamente ineficiente. Para enfrentar este fenómeno se recurre al uso de series de tiempo.</li>
</ol>
</div>
<div id="modelos-lineales-generalizados" class="section level3 hasAnchor" number="1.5.7">
<h3><span class="header-section-number">1.5.7</span> Modelos lineales generalizados<a href="modelos-de-regresión.html#modelos-lineales-generalizados" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Muchas veces los modelos lineales son muy restrictivos, para ello se utilizan modelos lineales generalizados, es decir, mantiene la linealidad en los parámetros, pero la respuesta del modelo puede tener una forma funcional distinta.</p>
<p>Dentro de la familia de modelos generalizados se encuentran:</p>
<ul>
<li>Regresión de Poisson (La variable dependiente es positiva y discreta)</li>
<li>Regresión logística (Se busca predecir número de sucesos de un total de intentos)</li>
<li>Mínimos cuadrados generalizados</li>
</ul>
</div>
</div>
<div id="alternativas-de-machine-learning-para-la-regresión" class="section level2 hasAnchor" number="1.6">
<h2><span class="header-section-number">1.6</span> Alternativas de Machine Learning para la regresión<a href="modelos-de-regresión.html#alternativas-de-machine-learning-para-la-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="qué-es-machine-learning" class="section level3 hasAnchor" number="1.6.1">
<h3><span class="header-section-number">1.6.1</span> ¿Qué es Machine Learning?<a href="modelos-de-regresión.html#qué-es-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El concepto de <em>Machine Learning</em> se ha vuelto muy popular últimamente, obteniendo mucha atención y usos en una gran cantidad de tareas, pero ¿A qué nos referimos cuando hablamos de modelos de <em>machine learning</em>?</p>
<p>En terminos sencillos, el aprendizaje automático, o <em>machine learning</em> en inglés, es una rama de la inteligencia artificial que se centra en el desarrollo de algoritmos y modelos que permiten a las computadoras aprender patrones y realizar tareas específicas sin ser programadas explícitamente. En lugar de seguir instrucciones detalladas, los sistemas de aprendizaje automático utilizan datos para mejorar su rendimiento en una tarea particular a lo largo del tiempo. Este enfoque permite a las máquinas adaptarse y mejorar su desempeño a medida que se exponen a más información.</p>
</div>
<div id="la-regresión-cuenta-como-un-modelo-de-ml" class="section level3 hasAnchor" number="1.6.2">
<h3><span class="header-section-number">1.6.2</span> ¿La regresión cuenta como un modelo de ML?<a href="modelos-de-regresión.html#la-regresión-cuenta-como-un-modelo-de-ml" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si bien la regresión utiliza datos para <em>aprender</em> a partir de ellos, no se suele considerar completamente un modelo de aprendizaje automático. El hecho de tener que seleccionar las variables adecuadas, aplicar transformaciones funcionales y tener que verificar el cumplimiento de supuestos estadísticos hace que la regresión sea menos automático que lo que normalmente se entiende como ML.</p>
<p>Un acercamiento más próximo a un modelo de ML se da al utilizar técnicas de selección automática de variables como Ridge o LASSO. De todas formas, los límites son difusos, en este curso se entenderá como ML a cualquier modelo que pueda aprender automáticamente sobre el conjunto de variables predictivas y sus formas funcionales.</p>
</div>
<div id="multivariate-adaptive-regression-splines-mars" class="section level3 hasAnchor" number="1.6.3">
<h3><span class="header-section-number">1.6.3</span> Multivariate Adaptive Regression Splines (MARS)<a href="modelos-de-regresión.html#multivariate-adaptive-regression-splines-mars" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>MARS extiende OLS generando para cada variable independiente <span class="math inline">\(x\)</span> una función bisagra (<em>hinge</em>) <span class="math inline">\(h(x, a) = \{ \max\{0, x-a\}, \max\{0, a-x\} \}\)</span>. De esta forma, un modelo MARS genera una aproximación lineal por tramos.</p>
<p>Por ejemplo:</p>
<p><span class="math display">\[\text{OLS: }y = \beta_0 + \beta_1 x\]</span>
<span class="math display">\[\text{MARS: }y = \gamma_0 + \gamma_1 \max\{0, x-a\} + \gamma_2 \max\{0, a-x\}\]</span></p>
<p>Además, MARS puede incluir multiplicaciones entre dos o más funciones bisagras para diferentes predictores, de tal manera que captura la interacción entre estos.</p>
<p>Inicialmente, MARS busca el único punto en el rango de <span class="math inline">\(x\)</span> donde dos relaciones lineales diferentes entre <span class="math inline">\(y\)</span> y <span class="math inline">\(x\)</span> logran un error más pequeño, este punto se convierte en el primer corte (<em>knot</em>) <span class="math inline">\(a\)</span> del modelo. Este procedimiento continúa hasta que se encuentren los demás puntos de corte. Para evitar el sobreajuste, MARS elimina términos que provoquen una pequeña contribución a la mejora del ajuste.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="modelos-de-regresión.html#cb4-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/mars.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mars"></span>
<img src="images/mars.png" alt="Regresión MARS para distinto número de bisagras" width="70%" />
<p class="caption">
Figure 1.4: Regresión MARS para distinto número de bisagras
</p>
</div>
</div>
<div id="k-nearest-neighbors-regression-knn" class="section level3 hasAnchor" number="1.6.4">
<h3><span class="header-section-number">1.6.4</span> K Nearest Neighbors Regression (KNN)<a href="modelos-de-regresión.html#k-nearest-neighbors-regression-knn" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En la regresión con KNN, el objetivo es predecir un valor numérico para una variable dependiente basándose en los valores de las variables independientes. A diferencia de la regresión lineal, que ajusta una línea o superficie a los datos, KNN no realiza una aproximación paramétrica. En cambio, hace predicciones basándose en la similitud entre los puntos de datos.</p>
<p>Hay una serie de parámetros que deben ajustarse en KNN. Para decidir qué funciona mejor, la práctica común es decidir basándose en el error de predicción:</p>
<ol style="list-style-type: decimal">
<li><p>Vecinos más cercanos (<em>Neighbors</em>): <span class="math inline">\(k\)</span> representa el número de vecinos más cercanos que se tomarán en cuenta para hacer una predicción. Se calcula la distancia entre el punto a predecir y los demás puntos del conjunto de entrenamiento.</p></li>
<li><p>Pesos (<em>Weights</em>): Para predecir el valor de la variable dependiente para un nuevo punto, se promedian los valores de la variable dependiente de los <span class="math inline">\(k\)</span> vecinos más cercanos. Uno de los parámetros del modelo es el peso que se le da a los vecinos más cercanos.</p></li>
<li><p>Distancia: La medida de distancia más comúnmente utilizada en KNN es la distancia euclidiana, pero otras medidas también pueden ser empleadas según el tipo de datos y el problema específico (Manhattan, Coseno, Mahalanobis, etc.)</p></li>
</ol>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="modelos-de-regresión.html#cb5-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/knn.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:knn"></span>
<img src="images/knn.png" alt="Regresión KNN para distinto número de vecinos cercanos" width="100%" />
<p class="caption">
Figure 1.5: Regresión KNN para distinto número de vecinos cercanos
</p>
</div>
</div>
<div id="regression-trees" class="section level3 hasAnchor" number="1.6.5">
<h3><span class="header-section-number">1.6.5</span> Regression trees<a href="modelos-de-regresión.html#regression-trees" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los arboles de regresión solo tienen sentido cuando el problema tiene múltiples regresores, el objetivo es dividir el espacio de regresores en subconjuntos y luego utilizar un modelo simple (constante) dentro de cada región. Las particiones son secuenciales mediante divisiones binarias generando una estructura de árbol.</p>
<p>El modelo busca cada valor distinto de cada variable de entrada para encontrar el predictor y dividir el valor que divide los datos en dos.
regiones <span class="math inline">\(R_1\)</span> y <span class="math inline">\(R_2\)</span>, con valores medios <span class="math inline">\(c_1\)</span> y <span class="math inline">\(c_2\)</span> para minimizar la suma de los errores al cuadrado</p>
<p><span class="math display">\[\min SSE = \min \left\{ \sum_{i \in R_1}(y_i - c_1)^2 + \sum_{i \in R_2} (y_i - c_2)^2 \right\}\]</span></p>
<p>Es común agregar hiperparámetros de penalización para evitar el sobreajuste.</p>
<p><strong>Ejemplo:</strong> Sea <span class="math inline">\(y = f(x_1, x_2)\)</span>. Los valores de <span class="math inline">\(x_1\)</span> y <span class="math inline">\(x_2\)</span> se pueden representar en el plano mientras que los valores de <span class="math inline">\(y\)</span> se representan con colores (cuanto más grandes, más oscuros)</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="modelos-de-regresión.html#cb6-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/tree1.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ej1"></span>
<img src="images/tree1.png" alt="Región de ejemplo" width="40%" />
<p class="caption">
Figure 1.6: Región de ejemplo
</p>
</div>
<p>Luego, un arbol que representa la separación en regiones según <span class="math inline">\(x_1\)</span> y <span class="math inline">\(x_2\)</span> es:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="modelos-de-regresión.html#cb7-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/tree2.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ej2"></span>
<img src="images/tree2.png" alt="Árbol de ejemplo" width="20%" />
<p class="caption">
Figure 1.7: Árbol de ejemplo
</p>
</div>
</div>
<div id="bagging-y-random-forests" class="section level3 hasAnchor" number="1.6.6">
<h3><span class="header-section-number">1.6.6</span> Bagging y Random forests<a href="modelos-de-regresión.html#bagging-y-random-forests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Un problema de los árboles de regresión es que son sensibles a pequeñas variaciones en los datos. En general para solucionar este problema se crean varios árboles y se promedian los resultados obtenidos, a esto se le llama bosque aleatorio (<em>random forest</em>).</p>
<p>Para la construcción de este conjunto de arboles de regresión se hace uso de una técnica llamada <em>Bagging</em> (<strong>B</strong>ootstrap <strong>Agg</strong>regation), la cual sigue los siguientes pasos:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Bootstrap Sampling:</strong> Se generan múltiples conjuntos de datos de entrenamiento mediante un muestreo con reemplazo, al que se conoce como <em>bootstrap</em>. Al hacerlo, algunos datos se pueden repetir en un conjunto de datos, mientras que otros pueden no aparecer en absoluto.</p></li>
<li><p><strong>Construcción de árboles de regresión:</strong> Se construyen múltiples árboles de decisión, generalmente utilizando el conjunto de datos de entrenamiento generado en cada iteración del <em>bootstrap</em>. Cada árbol se entrena de manera independiente y puede llegar a sobreajustarse a ciertos patrones del conjunto de datos de entrenamiento.</p></li>
<li><p><strong>Promediar resultados:</strong> Para hacer predicciones en un nuevo dato, se utiliza cada árbol de decisión para realizar una predicción, promediando los valores de cada árbol.</p></li>
</ol>
<p>La combinación de múltiples árboles entrenados de esta manera ayuda a reducir la varianza y mejora la capacidad de generalización del modelo. Además, el Random Forest introduce aleatoriedad adicional al seleccionar un subconjunto aleatorio de características para dividir en cada nodo de los árboles, lo que agrega más diversidad al conjunto de árboles.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelos-probabilisticos.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01-regresión.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
