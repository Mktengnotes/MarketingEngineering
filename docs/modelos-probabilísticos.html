<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 2 Modelos probabilísticos | Marketing Engineering</title>
  <meta name="description" content="Capítulo 2 Modelos probabilísticos | Marketing Engineering" />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 2 Modelos probabilísticos | Marketing Engineering" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Capítulo 2 Modelos probabilísticos | Marketing Engineering" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 2 Modelos probabilísticos | Marketing Engineering" />
  
  <meta name="twitter:description" content="Capítulo 2 Modelos probabilísticos | Marketing Engineering" />
  

<meta name="author" content="Marcel Goic" />


<meta name="date" content="2025-09-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modelos-de-regresión.html"/>
<link rel="next" href="modelos-estructurales.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Marketing Engineering</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path=""><a href="#pr%C3%B3logo"><i class="fa fa-check"></i>Prólogo</a></li>
<li class="chapter" data-level="1" data-path="02-probabilisticos.html"><a href="#modelos-de-regresi%C3%B3n"><i class="fa fa-check"></i><b>1</b> Modelos de Regresión</a>
<ul>
<li class="chapter" data-level="1.1" data-path="02-probabilisticos.html"><a href="#conceptos-b%C3%A1sicos-de-regresi%C3%B3n"><i class="fa fa-check"></i><b>1.1</b> Conceptos básicos de regresión</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="02-probabilisticos.html"><a href="#notaci%C3%B3n"><i class="fa fa-check"></i><b>1.1.1</b> Notación</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="02-probabilisticos.html"><a href="#m%C3%ADnimos-cuadrados-ordinarios-ols-y-supuestos"><i class="fa fa-check"></i><b>1.2</b> Mínimos Cuadrados Ordinarios (OLS) y supuestos</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="02-probabilisticos.html"><a href="#estimaci%C3%B3n"><i class="fa fa-check"></i><b>1.2.1</b> Estimación</a></li>
<li class="chapter" data-level="1.2.2" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html"><i class="fa fa-check"></i><b>1.2.2</b> Propiedades</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#estrategias-de-modelamiento"><i class="fa fa-check"></i><b>1.3</b> Estrategias de Modelamiento</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#arte-vs.-procedimiento"><i class="fa fa-check"></i><b>1.3.1</b> Arte vs. Procedimiento</a></li>
<li class="chapter" data-level="1.3.2" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#aprendizajes-preliminares"><i class="fa fa-check"></i><b>1.3.2</b> Aprendizajes Preliminares</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="02-probabilisticos.html"><a href="#evaluaci%C3%B3n-de-modelos"><i class="fa fa-check"></i><b>1.4</b> Evaluación de modelos</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="02-probabilisticos.html"><a href="#qu%C3%A9-buscamos-en-un-modelo"><i class="fa fa-check"></i><b>1.4.1</b> ¿Qué buscamos en un modelo?</a></li>
<li class="chapter" data-level="1.4.2" data-path="02-probabilisticos.html"><a href="#ajuste-por-m%C3%A9tricas-generales"><i class="fa fa-check"></i><b>1.4.2</b> Ajuste por métricas generales</a></li>
<li class="chapter" data-level="1.4.3" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#ajuste-basado-en-la-probabilidad"><i class="fa fa-check"></i><b>1.4.3</b> Ajuste basado en la probabilidad</a></li>
<li class="chapter" data-level="1.4.4" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#errores-dentro-y-fuera-de-la-muestra"><i class="fa fa-check"></i><b>1.4.4</b> Errores dentro y fuera de la muestra</a></li>
<li class="chapter" data-level="1.4.5" data-path="02-probabilisticos.html"><a href="#divisi%C3%B3n-de-datos"><i class="fa fa-check"></i><b>1.4.5</b> División de datos</a></li>
<li class="chapter" data-level="1.4.6" data-path="02-probabilisticos.html"><a href="#validaci%C3%B3n-cruzada"><i class="fa fa-check"></i><b>1.4.6</b> Validación cruzada</a></li>
<li class="chapter" data-level="1.4.7" data-path="02-probabilisticos.html"><a href="#test-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>1.4.7</b> Test de hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="02-probabilisticos.html"><a href="#usos-y-limitaciones-del-an%C3%A1lisis-de-regresi%C3%B3n"><i class="fa fa-check"></i><b>1.5</b> Usos y limitaciones del análisis de regresión</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="02-probabilisticos.html"><a href="#aprendizaje-de-los-par%C3%A1metros"><i class="fa fa-check"></i><b>1.5.1</b> Aprendizaje de los parámetros</a></li>
<li class="chapter" data-level="1.5.2" data-path="02-probabilisticos.html"><a href="#interpretaci%C3%B3n-de-los-coeficientes"><i class="fa fa-check"></i><b>1.5.2</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="1.5.3" data-path="02-probabilisticos.html"><a href="#pron%C3%B3sticos"><i class="fa fa-check"></i><b>1.5.3</b> Pronósticos</a></li>
<li class="chapter" data-level="1.5.4" data-path="02-probabilisticos.html"><a href="#errores-de-pron%C3%B3stico"><i class="fa fa-check"></i><b>1.5.4</b> Errores de pronóstico</a></li>
<li class="chapter" data-level="1.5.5" data-path="02-probabilisticos.html"><a href="#principios-generales-de-pron%C3%B3stico"><i class="fa fa-check"></i><b>1.5.5</b> Principios generales de pronóstico</a></li>
<li class="chapter" data-level="1.5.6" data-path="02-probabilisticos.html"><a href="#limitaciones-de-los-modelos-de-regresi%C3%B3n"><i class="fa fa-check"></i><b>1.5.6</b> Limitaciones de los modelos de regresión</a></li>
<li class="chapter" data-level="1.5.7" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#modelos-lineales-generalizados"><i class="fa fa-check"></i><b>1.5.7</b> Modelos lineales generalizados</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="02-probabilisticos.html"><a href="#alternativas-de-machine-learning-para-la-regresi%C3%B3n"><i class="fa fa-check"></i><b>1.6</b> Alternativas de Machine Learning para la regresión</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="02-probabilisticos.html"><a href="#qu%C3%A9-es-machine-learning"><i class="fa fa-check"></i><b>1.6.1</b> ¿Qué es Machine Learning?</a></li>
<li class="chapter" data-level="1.6.2" data-path="02-probabilisticos.html"><a href="#la-regresi%C3%B3n-cuenta-como-un-modelo-de-ml"><i class="fa fa-check"></i><b>1.6.2</b> ¿La regresión cuenta como un modelo de ML?</a></li>
<li class="chapter" data-level="1.6.3" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#multivariate-adaptive-regression-splines-mars"><i class="fa fa-check"></i><b>1.6.3</b> Multivariate Adaptive Regression Splines (MARS)</a></li>
<li class="chapter" data-level="1.6.4" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#k-nearest-neighbors-regression-knn"><i class="fa fa-check"></i><b>1.6.4</b> K Nearest Neighbors Regression (KNN)</a></li>
<li class="chapter" data-level="1.6.5" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#regression-trees"><i class="fa fa-check"></i><b>1.6.5</b> Regression trees</a></li>
<li class="chapter" data-level="1.6.6" data-path="modelos-de-regresión.html"><a href="modelos-de-regresión.html#bagging-y-random-forests"><i class="fa fa-check"></i><b>1.6.6</b> Bagging y Random forests</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="02-probabilisticos.html"><a href="#modelos-probabil%C3%ADsticos"><i class="fa fa-check"></i><b>2</b> Modelos probabilísticos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="02-probabilisticos.html"><a href="#introducci%C3%B3n"><i class="fa fa-check"></i><b>2.1</b> Introducción</a></li>
<li class="chapter" data-level="2.2" data-path="02-probabilisticos.html"><a href="#modelos-de-duraci%C3%B3n"><i class="fa fa-check"></i><b>2.2</b> Modelos de Duración</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="02-probabilisticos.html"><a href="#modelos-de-duraci%C3%B3n-de-tiempo-discreto"><i class="fa fa-check"></i><b>2.2.1</b> Modelos de duración de tiempo discreto</a></li>
<li class="chapter" data-level="2.2.2" data-path="02-probabilisticos.html"><a href="#modelos-de-duraci%C3%B3n-en-tiempo-continuo-sin-dependencia-en-la-duraci%C3%B3n"><i class="fa fa-check"></i><b>2.2.2</b> Modelos de duración en tiempo continuo sin dependencia en la duración</a></li>
<li class="chapter" data-level="2.2.3" data-path="02-probabilisticos.html"><a href="#modelos-de-duraci%C3%B3n-en-tiempo-continuo-con-dependencia-en-la-duraci%C3%B3n"><i class="fa fa-check"></i><b>2.2.3</b> Modelos de duración en tiempo continuo con dependencia en la duración</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html"><i class="fa fa-check"></i><b>2.3</b> Modelos de Conteo</a></li>
<li class="chapter" data-level="2.4" data-path="02-probabilisticos.html"><a href="#modelos-de-elecci%C3%B3n-binaria-binomial"><i class="fa fa-check"></i><b>2.4</b> Modelos de Elección Binaria binomial</a></li>
<li class="chapter" data-level="2.5" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#heterogeneidad-observable"><i class="fa fa-check"></i><b>2.5</b> Heterogeneidad observable</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="02-probabilisticos.html"><a href="#modelos-de-duraci%C3%B3n-en-tiempo-discreto"><i class="fa fa-check"></i><b>2.5.1</b> Modelos de duración en tiempo discreto</a></li>
<li class="chapter" data-level="2.5.2" data-path="02-probabilisticos.html"><a href="#modelos-de-duraci%C3%B3n-en-tiempo-continuo-sin-dependencia-de-la-duraci%C3%B3n"><i class="fa fa-check"></i><b>2.5.2</b> Modelos de duración en tiempo continuo sin dependencia de la duración</a></li>
<li class="chapter" data-level="2.5.3" data-path="02-probabilisticos.html"><a href="#modelos-de-duraci%C3%B3n-en-tiempo-continuo-con-dependencia-de-la-duraci%C3%B3n"><i class="fa fa-check"></i><b>2.5.3</b> Modelos de duración en tiempo continuo con dependencia de la duración</a></li>
<li class="chapter" data-level="2.5.4" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#modelos-de-conteo-1"><i class="fa fa-check"></i><b>2.5.4</b> Modelos de Conteo</a></li>
<li class="chapter" data-level="2.5.5" data-path="02-probabilisticos.html"><a href="#modelos-de-elecci%C3%B3n-binaria-binomial-1"><i class="fa fa-check"></i><b>2.5.5</b> Modelos de Elección Binaria binomial</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#esperanzas-condicionales"><i class="fa fa-check"></i><b>2.6</b> Esperanzas Condicionales</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#modelo-de-tiempo-discreto-combinado-con-beta"><i class="fa fa-check"></i><b>2.6.1</b> Modelo de Tiempo Discreto (Combinado con Beta)</a></li>
<li class="chapter" data-level="2.6.2" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#modelo-de-tiempo-continuo-combinado-con-gamma"><i class="fa fa-check"></i><b>2.6.2</b> Modelo de Tiempo Continuo (Combinado con Gamma)</a></li>
<li class="chapter" data-level="2.6.3" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#modelo-de-conteo-combinado-con-gamma"><i class="fa fa-check"></i><b>2.6.3</b> Modelo de Conteo (Combinado con Gamma)</a></li>
<li class="chapter" data-level="2.6.4" data-path="02-probabilisticos.html"><a href="#modelo-de-elecci%C3%B3n-binaria-binomial-combinado-con-beta"><i class="fa fa-check"></i><b>2.6.4</b> Modelo de Elección Binaria binomial (Combinado con Beta)</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#modelos-integrados"><i class="fa fa-check"></i><b>2.7</b> Modelos Integrados</a></li>
<li class="chapter" data-level="2.8" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#customer-lifetime-value-caso-contractual"><i class="fa fa-check"></i><b>2.8</b> Customer Lifetime Value: Caso Contractual</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#modelo-contractual-a-tiempo-discreto"><i class="fa fa-check"></i><b>2.8.1</b> Modelo contractual a tiempo discreto</a></li>
<li class="chapter" data-level="2.8.2" data-path="modelos-probabilísticos.html"><a href="modelos-probabilísticos.html#modelo-contractual-a-tiempo-continuo"><i class="fa fa-check"></i><b>2.8.2</b> Modelo contractual a tiempo continuo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html"><i class="fa fa-check"></i><b>3</b> Modelos Estructurales</a>
<ul>
<li class="chapter" data-level="3.1" data-path="02-probabilisticos.html"><a href="#introducci%C3%B3n-a-modelos-estructurales"><i class="fa fa-check"></i><b>3.1</b> Introducción a Modelos Estructurales</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="02-probabilisticos.html"><a href="#introducci%C3%B3n-1"><i class="fa fa-check"></i><b>3.1.1</b> Introducción</a></li>
<li class="chapter" data-level="3.1.2" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#modelos-estructurales-en-marketing"><i class="fa fa-check"></i><b>3.1.2</b> Modelos Estructurales en Marketing</a></li>
<li class="chapter" data-level="3.1.3" data-path="02-probabilisticos.html"><a href="#taxonom%C3%ADa-de-modelos-estrucuturales"><i class="fa fa-check"></i><b>3.1.3</b> Taxonomía de Modelos Estrucuturales</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#logit"><i class="fa fa-check"></i><b>3.2</b> Logit</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="02-probabilisticos.html"><a href="#modelos-de-elecci%C3%B3n-discreta"><i class="fa fa-check"></i><b>3.2.1</b> Modelos de Elección Discreta</a></li>
<li class="chapter" data-level="3.2.2" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#modelo-logit"><i class="fa fa-check"></i><b>3.2.2</b> Modelo Logit</a></li>
<li class="chapter" data-level="3.2.3" data-path="02-probabilisticos.html"><a href="#estimaci%C3%B3n-1"><i class="fa fa-check"></i><b>3.2.3</b> Estimación</a></li>
<li class="chapter" data-level="" data-path=""><a href="#ap%C3%A9ndice"><i class="fa fa-check"></i>Apéndice</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#probit"><i class="fa fa-check"></i><b>3.3</b> Probit</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="02-probabilisticos.html"><a href="#definici%C3%B3n"><i class="fa fa-check"></i><b>3.3.1</b> Definición</a></li>
<li class="chapter" data-level="3.3.2" data-path="02-probabilisticos.html"><a href="#patrones-de-substituci%C3%B3n"><i class="fa fa-check"></i><b>3.3.2</b> Patrones de substitución</a></li>
<li class="chapter" data-level="3.3.3" data-path="02-probabilisticos.html"><a href="#identificaci%C3%B3n"><i class="fa fa-check"></i><b>3.3.3</b> Identificación</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="modelos-estructurales.html"><a href="modelos-estructurales.html#mixed-logit"><i class="fa fa-check"></i><b>3.4</b> <em>Mixed Logit</em></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="02-probabilisticos.html"><a href="#ap%C3%A9ndices-t%C3%A9cnicos"><i class="fa fa-check"></i><b>4</b> Apéndices Técnicos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="02-probabilisticos.html"><a href="#m%C3%A9todos-de-estimaci%C3%B3n-y-evaluaci%C3%B3n-de-modelos"><i class="fa fa-check"></i><b>4.1</b> Métodos de Estimación y Evaluación de modelos</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Marketing Engineering</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelos-probabilísticos" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Capítulo 2</span> Modelos probabilísticos<a href="#modelos-probabil%C3%ADsticos" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introducción" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Introducción<a href="#introducci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Usualmente, y en el contexto de Marketing, interesa estudiar el
comportamiento de las personas, para realizar acciones estratégicas en
función de los aprendizajes adquiridos. Así, se pueden definir dos tipos
de enfoques a usar según distintos supuestos en el comportamiento de los
agentes (tomadores de decisiones):</p>
<ul>
<li><p><em>Enfoque Estructural</em>: Este enfoque asume que los los agentes se
comportan de manera racional, tomando decisiones de modo de
maximizar sus utilidades. Usualmente aparece cuando hay
disponibilidad de largos volúmenes de datos.</p></li>
<li><p><em>Modelos Probabilísticos</em>: Este enfoque asume que los agentes se
comportan en base a decisiones aleatorias. Usualmente aparece cuando
se tiene información reducida y/o agregada respecto al
comportamiento de los agentes en estudio.</p></li>
</ul>
<p>En esta unidad, se estudiará el enfoque probabilístico.</p>
<p><strong>Metodología</strong></p>
<p>La metodología consiste en:</p>
<ol style="list-style-type: decimal">
<li><p>Determinar el problema de decisión a estudiar y la información
requerida.</p></li>
<li><p>Identificar el comportamiento observable de interés a nivel
individual.</p></li>
<li><p>Seleccionar la distribución de probabilidad que caracterice el
comportamiento individual. Se consideran los parámetros de esta
distribución, como características latentes a nivel individual.</p></li>
<li><p>Escoger la distribución que caracterice cómo las características
latentes están distribuidas en la población. Se le llama
distribución mixta o heterogénea. Típicamente, se denota con
<span class="math inline">\(g(\theta)\)</span>.</p></li>
<li><p>Derivar la distribución agregada, o distribución observable, del
comportamiento de interés.</p>
<p><span class="math display">\[
\begin{array}{cc}
f(x) = \int f(x \mid \theta)\, g(\theta)\, d\theta &amp; \text{, para el caso continuo.} \\
p(x) = \sum_{i}f(x \mid \theta)\, \Pr(\theta = \theta_{i}) &amp; \text{, para el caso discreto.}
\end{array}
\]</span></p></li>
<li><p>Estimar los parámetros del modelo (de la distribución mixta),
mediante el ajuste de la distribución agregada a los datos
observados.</p></li>
<li><p>Usar los resultados para tomar una decisión sobre el problema de
marketing en cuestión.</p></li>
</ol>
<p>El enfoque de modelos probabilísticos permite abordar una gran cantidad
de problemas asociados al marketing, entre los cuales se considerarán:</p>
<ul>
<li><p><em>Duración</em>: Situaciones ligadas a la duración de una determinada
conducta de un cliente, como por ejemplo el tiempo de permanencia en
una compañía y el tiempo de adopción de un cierto producto
innovador.</p></li>
<li><p><em>Conteo</em>: Situaciones ligadas al estudio de llegadas de clientes y
contabilización de una determinada conducta, como por ejemplo el
número de visitas a un portal web y la cantidad de productos
comprados en una tienda de retail.</p></li>
<li><p><em>Elección</em>: Situaciones asociadas a las decisiones de elección de un
determinado cliente, como por ejemplo el número de clientes que
eligen responder una campaña publicitaria y la elección de cambiar o
no de canal de televisión.</p></li>
</ul>
</div>
<div id="modelos-de-duración" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Modelos de Duración<a href="#modelos-de-duraci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En años recientes, las mejoras en las tecnologías de información han
dado como resultado un aumento en la disponibilidad de data acerca de
los individuos en determinadas situaciones de consumo. Esta tendencia se
relaciona íntimamente con el creciente deseo de los gerentes de
marketing respecto a utilizar esta data disponible para aprender de
manera exhaustiva sobre el comportamiento de los clientes. Muchos
analistas tratan de describir y predecir el comportamiento de los
consumidores usando variables observables, como lo son variables
transaccionales (monto gastado, tienda donde se adquirió un determinado
producto, fecha de la compra, etc.), como así también variables que
caracterizan a los individuos (edad, nivel socio-económico, estado
civil, etc.). A partir de esta información es posible aplicar modelos de
regresión lineal o árboles de decisión, con el objetivo de poder
proyectar comportamientos, o bien rebatir hipótesis que previamente se
tenían respecto a un escenario determinado.</p>
<p>En este capítulo, se considera un enfoque distinto al anterior, en el
cual las decisiones de los individuos se desprenden de un comportamiento
<strong>aleatorio</strong>, en que las decisiones no dependen únicamente de variables
descriptivas del modelo, sino que también provienen del resultado de un
proceso estocástico no observable que opera intrínsecamente en los
individuos. Es decir, la asunción que el comportamiento se desprende de
una distribución de probabilidades que puede variar dependiendo del
modelo a estimar y de la complejidad del mismo. Alternativamente, se
puede considerar el enfoque racionalista que contempla a los individios
que siempre actúan racionalmente, lo que, de acuerdo a la experiencia
empírica, no se cumple siempre.</p>
<p><strong>Ejemplo 1</strong>: Supongamos que un cliente hizo 2 compras el año pasado de
nuestro producto. ¿Esto implica inmediatamente que el consumidor
mantendrá ese patrón y este año volverá a ese nivel de consumo? ¿O
existe alguna posibilidad de que el cliente incremente o disminuya su
consumo? ¿Cuál es el proceso que hay detrás?</p>
<p>En lo que sigue, se considera 3 tipos de modelos de duración a estimar:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Modelos de duración en tiempo discreto.</strong></p></li>
<li><p><strong>Modelos de duración en tiempo continuo sin dependencia en la
duración.</strong></p></li>
<li><p><strong>Modelos de duración en tiempo continuo con dependencia en la
duración.</strong></p></li>
</ol>
<div id="modelos-de-duración-de-tiempo-discreto" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Modelos de duración de tiempo discreto<a href="#modelos-de-duraci%C3%B3n-de-tiempo-discreto" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como ejemplo, se tiene el siguiente escenario: a través de una propuesta
de valor atractiva, una empresa consigue un cliente. ¿Durante cuántos
periodos estará afiliado a la compañía?</p>
<p>Se considera que cada periodo se puede cuantificar en términos discretos
(días, semanas, meses, años). Algunos ejemplos a considerar:</p>
<ul>
<li><p>Un usuario descarga una aplicación para su teléfono inteligente.
¿Por cuántos meses la utilizará?</p></li>
<li><p>Adquirimos un cliente en un banco. ¿Durante cuántos años permanecerá
como cliente?</p></li>
<li><p>Un cliente se suscribe a un plan telefónico o de internet. ¿Por
cuántos periodos se mantendrá suscrito?</p></li>
</ul>
<div id="modelo-geométrico-desplazado" class="section level4 unnumbered hasAnchor">
<h4>Modelo Geométrico Desplazado<a href="#modelo-geom%C3%A9trico-desplazado" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como ejemplo, se asume que se tiene una cartera de clientes que van
abandonando la relación comercial para <strong>nunca más retomarla</strong> en
cualquier periodo definido. Al final de cada periodo, un cliente decide
de manera aleatoria si continúa afiliado. De acuerdo a un proceso de
Bernoulli, hay una probabilidad <span class="math inline">\(\theta\)</span> de cancelar la relación
comercial con la empresa y con el complemento <span class="math inline">\(1-\theta\)</span> decide su
permanencia.</p>
<p>Para cada individuo, se asume que la probabilidad con la que decide no
cambia en el tiempo. Como primer acercamiento, se asume que dicha
probabilidad es igual e idénticamente distribuida (iid). Sea T la
variable aleatoria relativa a la duración de la relación comercial entre
el cliente y la compañía, es decir la variable que describe el instante
en el cual esta relación se acaba. De acuerdo a la descripción anterior,
la variable aleatoria T sigue una distribución Geométrica Desplazada
(sG) con parámetro <span class="math inline">\(\theta\)</span>, es decir, el comportamiento de los
individuos puede ser descrito formalmente de acuerdo a la siguiente
relación:</p>
<ol style="list-style-type: decimal">
<li>Probabilidad de que un individuo cualquiera abandone la relación
comercial exactamente en el periodo t:</li>
</ol>
<p><span class="math display">\[P(T=t| \theta) = \theta (1 - \theta)^{t-1}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Probabilidad de que un individuo cualquiera abandone la relación
comercial en un periodo posterior al periodo t:</li>
</ol>
<p><span class="math display">\[P(T&gt;t| \theta) = \theta (1 - \theta)^{t-1}\]</span></p>
<p>No es muy difícil aplicar un modelamiento a partir de lo anterior para
intentar dilucidar de qué forma se debería comportar un determinado
grupo de individuos a partir de la data transaccional que se tiene.</p>
<p><strong>Ejemplo:</strong> Se considera una cohorte inicial de 1000 clientes (indexado
por el número 0). Se toma el supuesto de que, año a año, un determinado
número de clientes se retira del negocio por razones que se desconocen a
priori, pero que provienen de un proceso estocástico en el que cada
cliente en forma independiente toma la decisión de permanecer o
abandonar a partir del lanzamiento de una moneda (Bernoulli). Esto es,
con probabilidad <span class="math inline">\(\theta\)</span> abandona y con probabilidad <span class="math inline">\(1 - \theta\)</span>
permanece en la compañía. La data histórica se presenta a continuación:</p>
<table>
<thead>
<tr class="header">
<th align="center">Año</th>
<th align="center"># de Clientes</th>
<th align="center">% de Permanencia</th>
<th align="center">% de Retención</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center">1000</td>
<td align="center">100%</td>
<td align="center">-</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">631</td>
<td align="center">63%</td>
<td align="center">63%</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">468</td>
<td align="center">47%</td>
<td align="center">74%</td>
</tr>
<tr class="even">
<td align="center">3</td>
<td align="center">382</td>
<td align="center">38%</td>
<td align="center">82%</td>
</tr>
<tr class="odd">
<td align="center">4</td>
<td align="center">326</td>
<td align="center">33%</td>
<td align="center">85%</td>
</tr>
<tr class="even">
<td align="center">5</td>
<td align="center">289</td>
<td align="center">29%</td>
<td align="center">89%</td>
</tr>
<tr class="odd">
<td align="center">6</td>
<td align="center">262</td>
<td align="center">26%</td>
<td align="center">91%</td>
</tr>
<tr class="even">
<td align="center">7</td>
<td align="center">241</td>
<td align="center">24%</td>
<td align="center">92%</td>
</tr>
</tbody>
</table>
<p>Donde el % de Retención como el porcentaje de clientes que se mantuvo en
la relación comercial respecto al periodo anterior.</p>
<p>Sin embargo, aún no se desconoce el valor de <span class="math inline">\(\theta\)</span> (es un parámetro
poblacional). Dicho valor se estima mediante el método de máxima
verosimilitud, que busca encontrar el valor del parámetro óptimo de
acuerdo a los datos observados y asumiendo independencia entre las
muestras:</p>
<ul>
<li>Densidad de probabilidades conjunta:</li>
</ul>
<p><span class="math display">\[f(x_1,x_2,...,x_n|\theta) = f(x_1|\theta) \cdot f(x_2|\theta) \cdot ... \cdot f(x_n|\theta)\]</span></p>
<ul>
<li>Función de verosimilitud:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
L(\theta)  &amp;= \left\{\prod_{t=1}^{\tau=7} P(T=t \mid \theta)^{\,n_t}\right\}\; P(T&gt;\tau \mid \theta)^{\,\bar n_{\tau}} \\  &amp;= \left\{\prod_{t=1}^{\tau=7} \big[\theta(1-\theta)^{t-1}\big]^{\,n_t}\right\}\; \big[(1-\theta)^{\tau}\big]^{\,\bar n_{\tau}}
\end{aligned}
\]</span> Notar que <span class="math inline">\(\bar{n}_t\)</span> es el número de clientes activos en <span class="math inline">\(t\)</span>, <span class="math inline">\(n_t\)</span>
es el número de abandonos (si hay 369 abandonos, se multiplica 369
veces), y <span class="math inline">\(x_i\)</span> el año. A partir de esto y de la data disponible, las
contribuciones a la verosimilitud son las siguientes (asumiendo como
modelo de comportamiento la distribución geométrica desplazada)</p>
<table>
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="37%" />
</colgroup>
<thead>
<tr class="header">
<th>Año</th>
<th># de Clientes</th>
<th># de Abandonos</th>
<th>Pr</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1000</td>
<td>-</td>
<td>-</td>
</tr>
<tr class="even">
<td>1</td>
<td>631</td>
<td>369</td>
<td><span class="math inline">\(P(T=1\|\theta) = \theta^{369}\)</span></td>
</tr>
<tr class="odd">
<td>2</td>
<td>468</td>
<td>163</td>
<td><span class="math inline">\(P(T=2\|\theta) = ((1 - \theta)^{(2-1)} \cdot \theta)^{163}\)</span></td>
</tr>
<tr class="even">
<td>3</td>
<td>382</td>
<td>86</td>
<td><span class="math inline">\(P(T=3\|\theta) = ((1 - \theta)^{(3-1)} \cdot \theta)^{86}\)</span></td>
</tr>
<tr class="odd">
<td>4</td>
<td>326</td>
<td>56</td>
<td><span class="math inline">\(P(T=4\|\theta) = ((1 - \theta)^{(4-1)} \cdot \theta)^{56}\)</span></td>
</tr>
<tr class="even">
<td>5</td>
<td>289</td>
<td>37</td>
<td><span class="math inline">\(P(T=5\|\theta) = ((1 - \theta)^{(5-1)} \cdot \theta)^{37}\)</span></td>
</tr>
<tr class="odd">
<td>6</td>
<td>262</td>
<td>27</td>
<td><span class="math inline">\(P(T=6\|\theta) = ((1 - \theta)^{(6-1)} \cdot \theta)^{27}\)</span></td>
</tr>
<tr class="even">
<td>7</td>
<td>241</td>
<td>21</td>
<td><span class="math inline">\(P(T=7\|\theta) = ((1 - \theta)^{(7-1)} \cdot \theta)^{21}\)</span></td>
</tr>
<tr class="odd">
<td>&gt;7</td>
<td>-</td>
<td>-</td>
<td><span class="math inline">\(P(T&gt;7\|\theta) = ((1-\theta)^7)^{241}\)</span></td>
</tr>
</tbody>
</table>
<p>Dado que maximizar un producto es complicado, se aplica logaritmo a lo
anterior, de modo de construir la función de log verosimilitud:</p>
<ul>
<li>Función de log verosimilitud:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\hat{\ell}(\theta)  &amp;= \sum_{t=1}^{\tau} n_t \,\ln P(T=t \mid \theta)\;+\;\bar n_{\tau}\,\ln P(T&gt;\tau \mid \theta) \\  &amp;= \sum_{t=1}^{\tau} n_t \big[\ln \theta + (t-1)\ln(1-\theta)\big]\;+\;\bar n_{\tau}\,\tau\ln(1-\theta) \end{aligned}
\]</span> Con lo anterior, es sencillo maximizar la función de log
verosimilitud para un <span class="math inline">\(\theta\)</span> desconocido utilizando un paquete
estadístico como R, con lo que se tiene:</p>
<p><span class="math display" id="eq:homogeneo">\[
\begin{aligned}
\hat{\theta} &amp;= 0, 226027 \\
\hat{l} &amp;= -1794,62
\end{aligned}
\quad \tag{2.1}
\]</span>El modelo presentado, si bien permite tomar medidas de gestión a
partir de un modelo sencillo, es poco realista, pues se asume que la
población posee igual probabilidad de abandono.</p>
<p>Una manera de incluir mayor complejidad al modelo y hacerlo más robusto,
se asume que la población no es homogénea, sino que existen segmentos de
individuos quienes al ser agrupados, presentan un comportamiento similar
(heterogéneo). La forma más sencilla de modelar esto es asumiendo que la
población presenta 2 patrones de comportamiento o 2 segmentos. Para un
segmento de individuos, la decisión de abandonar o permanecer se
identifica a partir de un parámetro <span class="math inline">\(\theta_1\)</span> (del mismo modo que en el
caso anterior) y, para el otro segmento, la decisión se determina a
partir de un parámetro <span class="math inline">\(\theta_2\)</span> distinto de <span class="math inline">\(\theta_1\)</span>.</p>
<p>Formalmente, las relaciones que describen de mejor manera esto son las
siguientes:</p>
<ol style="list-style-type: decimal">
<li>Probabilidad de que un individuo cualquiera abandone la relación
comercial exactamente en el periodo <span class="math inline">\(t\)</span> en una población con 2
segmentos:</li>
</ol>
<p><span class="math display">\[P(T=t|\theta_1, \theta_2, \pi)= \theta_1 (1-\theta_1)^{t-1} \pi + \theta_2(1-\theta_2)^{t-1}(1-\pi)\]</span>
2. Probabilidad de que un individuo cualquiera abandone la relación
comercial en un periodo posterior al periodo <span class="math inline">\(t\)</span> en una población con 2
segmentos:</p>
<p><span class="math display">\[P(T&gt;t|\theta_1, \theta_2, \pi)= (1-\theta_1)^{t} \pi + (1-\theta_2)^{t}(1-\pi)\]</span></p>
<p>En el modelo anterior, <span class="math inline">\(\pi\)</span> representa el porcentaje de la población
que pertenece al segmento 1, de tal forma que su complemento <span class="math inline">\(1-\pi\)</span>
representa el porcentaje de la población que pertenece al segmento 2.
Cabe mencionar que se puede expandir a más segmentos, siempre que
sepamos su proporción <span class="math inline">\(\pi\)</span>.</p>
</div>
<div id="modelo-beta-geométrico-desplazado" class="section level4 unnumbered hasAnchor">
<h4>Modelo Beta Geométrico desplazado<a href="#modelo-beta-geom%C3%A9trico-desplazado" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Los modelos anteriores funcionan bien cuando la población se comporta de
manera distinta entre clases latentes, y similar al interior de cada
clase latente. Sin embargo, puede ser mucho más realista e interesante
asumir que existe una heterogeneidad continua en la población, es decir,
que existe un número infinito de segmentos (o al menos tendiente a
infinito) de manera de capturar todas las preferencias individuales de
cada miembro de la población considerada.</p>
<p>Para estos propósitos, ya no asumiremos que la probabilidad de abandono
<span class="math inline">\(\theta\)</span> sigue una distribución discreta de Bernoulli (éxito-fracaso),
sino que asumiremos que el parámetro proviene de una distribución
continua <span class="math inline">\(\text{Beta}\)</span> de parámetros <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>.</p>
<p>Por tanto, es posible calcular las probabilidades antes presentadas en
forma análoga, aplicando el enfoque antes mencionado (probabilidades
totales):</p>
<ol style="list-style-type: decimal">
<li><p>Probabilidad de que un individuo cualquiera abandone la relación
comercial exactamente en el periodo t:</p>
<p><span class="math display">\[P(T=t|\alpha,\beta) = \int_0^1 P(T=t|\theta)B(\theta|\alpha,\beta)d\theta\]</span></p>
<p>Donde:</p></li>
</ol>
<p><span class="math display">\[B(\theta|\alpha,\beta) = \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}\]</span></p>
<p><span class="math display">\[B(\alpha,\beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}\]</span>
2. Probabilidad de que un individuo cualquiera abandone la relación
comercial en un periodo posterior al periodo t:</p>
<p><span class="math display">\[P(T&gt;t|\alpha,\beta) = \int_0^1 (T&gt;t|\theta)B(\theta|\alpha,\beta)d\theta\]</span>
Al desarrollar la primera integral antes mencionada, y reconociendo las
relaciones de la distribución <em>Beta</em>, se tiene que:</p>
<p><span class="math display">\[
\begin{aligned} P(T = t \mid \alpha, \beta) &amp;= \int_0^1 \left( \theta(1-\theta)^{t-1} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) d\theta \\ &amp;= \frac{1}{B(\alpha, \beta)} \int_0^1 (\theta \cdot \theta^{\alpha-1}) \cdot ((1-\theta)^{t-1} \cdot (1-\theta)^{\beta-1}) d\theta \\ &amp;= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha} (1-\theta)^{t+\beta-2} d\theta \\ &amp;= \frac{B(\alpha+1, t+\beta-1)}{B(\alpha, \beta)} \end{aligned}
\]</span></p>
<p>Notar que se usa indistintamente el <span class="math inline">\(B(\alpha,\beta)\)</span> para hacer alusión
tanto a la <strong>función</strong> como a la <strong>distribución Beta</strong>. Bajo ninguna
circunstancia dichos objetos son iguales.</p>
<p>El desarrollo de la segunda integral es:</p>
<p><span class="math display">\[
\begin{aligned}
P(T &gt; t \mid \alpha, \beta) &amp;= \int_0^1 (1-\theta)^{t} \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) d\theta \\
&amp;= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha-1} \cdot ((1-\theta)^{t} \cdot (1-\theta)^{\beta-1}) d\theta \\
&amp;= \frac{1}{B(\alpha, \beta)} \int_0^1 \theta^{\alpha-1} (1-\theta)^{t+\beta-1} d\theta \\
&amp;= \frac{B(\alpha, t+\beta)}{B(\alpha, \beta)}
\end{aligned}
\]</span></p>
<p><strong>Ejemplo:</strong> Considerando la misma situación que se presentó en el
ejemplo anterior (clientes que año a año abandonan la relación
comercial), pero ahora asumiendo que existe un comportamiento
heterogéneo en la población, es posible reconocer que existe una
recursividad en la fórmula del cálculo de la probabilidad de abandono en
cada período:</p>
<p><span class="math display">\[
\begin{aligned}
\text{Caso Base (t=1):}&amp; \\
P(T=1 \mid \alpha, \beta) &amp;= \frac{B(\alpha+1, \beta)}{B(\alpha, \beta)} \\
&amp;= \frac{\frac{\Gamma(\alpha+1)\Gamma(\beta)}{\Gamma(\alpha+1+\beta)}}{\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}} \\
&amp;= \frac{\Gamma(\alpha+1)}{\Gamma(\alpha)} \cdot \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha+\beta+1)} \\
&amp;= \frac{\alpha\Gamma(\alpha)}{\Gamma(\alpha)} \cdot \frac{\Gamma(\alpha+\beta)}{(\alpha+\beta)\Gamma(\alpha+\beta)} \\
&amp;= \frac{\alpha}{\alpha+\beta} \\
\\
\text{Paso Recursivo (t &gt; 1):}&amp; \\
\frac{P(T=t \mid \alpha, \beta)}{P(T=t-1 \mid \alpha, \beta)} &amp;= \frac{B(\alpha+1, t+\beta-1)}{B(\alpha+1, t+\beta-2)} \\
&amp;= \frac{\frac{\Gamma(\alpha+1)\Gamma(t+\beta-1)}{\Gamma(\alpha+t+\beta)}}{\frac{\Gamma(\alpha+1)\Gamma(t+\beta-2)}{\Gamma(\alpha+t+\beta-1)}} \\
&amp;= \frac{\Gamma(t+\beta-1)}{\Gamma(t+\beta-2)} \cdot \frac{\Gamma(\alpha+t+\beta-1)}{\Gamma(\alpha+t+\beta)} \\
&amp;= \frac{(t+\beta-2)\Gamma(t+\beta-2)}{\Gamma(t+\beta-2)} \cdot \frac{\Gamma(\alpha+t+\beta-1)}{(\alpha+t+\beta-1)\Gamma(\alpha+t+\beta-1)} \\
&amp;= \frac{\beta+t-2}{\alpha+\beta+t-1} \\
&amp;= P(T=t-1 \mid \alpha, \beta) \frac{\beta+t-2}{\alpha+\beta+t-1}
\end{aligned}
\]</span></p>
<p>Modelo que al ser evaluado, da el siguiente resultado:</p>
<p><span class="math display" id="eq:heterogeneo">\[
\begin{array}{c}
\hat{\alpha} = 0,7041\\
\hat{\beta}= 1,1820\\
\hat{l} = -1680,27
\end{array}
\quad \tag{2.2}
\]</span></p>
<p>Notar que existe una notoria diferencia en cuanto al valor de la log
verosimilitud obtenida por el modelo <a href="modelos-probabilísticos.html#eq:heterogeneo">(2.2)</a> respecto al
modelo <a href="modelos-probabilísticos.html#eq:homogeneo">(2.1)</a>. Si bien esto indica una mejora del modelo,
es necesario realizar la comparación en base a métricas de evaluación
mas precisas (AIC, BIC, etc.)</p>
</div>
</div>
<div id="modelos-de-duración-en-tiempo-continuo-sin-dependencia-en-la-duración" class="section level3 hasAnchor" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Modelos de duración en tiempo continuo sin dependencia en la duración<a href="#modelos-de-duraci%C3%B3n-en-tiempo-continuo-sin-dependencia-en-la-duraci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para algunos modelos, medir el tiempo como si fueran períodos discretos
puede ser un buena aproximación de acuerdo a los objetivos del análisis
que se desea llevar a cabo.</p>
<p>En otros casos, puede ser en cambio más útil considerar el tiempo como
una variable continua, debido a que podría interesar medir la ocurrencia
de un suceso de manera más exacta. Algunos casos relativos a este
enfoque son:</p>
<ul>
<li><p>Tiempos de respuesta a una campaña promocional de marketing directo.</p></li>
<li><p>Tiempo entre visitas a nuestro website.</p></li>
<li><p>Tiempos entre llamadas en un call center.</p></li>
<li><p>Tiempos de operación en la industria de servicios.</p></li>
</ul>
<p>Al igual que en el caso de los modelos en tiempo discreto, lo que
interesa estudiar es poder implementar un modelo que tenga una forma
funcional flexible para ser trabajada y modificada fácilmente, que logre
ajustar a la data histórica que se tiene y proyectar el comportamiento
futuro de los clientes, es decir, que sea un buen modelo predictivo para
tomar acciones en función de aquello.</p>
<div id="modelo-exponencial" class="section level4 unnumbered hasAnchor">
<h4>Modelo Exponencial<a href="modelos-probabilísticos.html#modelo-exponencial" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Se puede medir el tiempo que pasa desde que se lanza un producto hasta
que el consumidor decide adquirirlo. Existen muchos factores externos
que determinan esta decisión: exposición a publicidad, número de visitas
a la tienda, llamadas recibidas por call center, entre otras. Nuevamente
se asume que el comportamiento es aleatorio, es decir, que los
consumidores deciden el momento en el cuál van a consumir a partir de
una distribución de probabilidades.</p>
<p>Esto puede verse con una distribución exponencial, con la variable
aleatoria <span class="math inline">\(t\)</span> definida como el tiempo en que un cliente va a consumir el
producto por primera vez. Se asume que esta variable está
exponencialmente distribuida con una tasa <span class="math inline">\(\lambda\)</span>. De esta forma, se
tiene que el comportamiento de los consumidores puede verse como:</p>
<ol style="list-style-type: decimal">
<li><p>Probabilidad de que ocurra en <span class="math inline">\(t\)</span> o antes:</p>
<p><span class="math display">\[P(T \leq t) = 1 - e^{-\lambda t}\]</span></p></li>
<li><p>Probabilidad de que ocurra después de <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[
P(T &gt; t) = e^{-\lambda t}
\]</span></p></li>
</ol>
<p>Por tanto, su función de verosimilitud para un tiempo continuo
corresponde a:</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) &amp;= \prod_{i \in A} f(t_i | \theta) \prod_{i \notin A} (1 - P(T \leq t)) \\
&amp;= \prod_{i \in A} (\theta e^{-\theta t_i}) \prod_{i \notin A} (e^{-\theta \tau_i})
\end{aligned}
\]</span></p>
<p>Acá <span class="math inline">\(f(t_i \mid \theta)\)</span> es la función de densidad, es decir, la
derivada de la función de probabilidad acumulada <span class="math inline">\(P(T \leq t)\)</span>. El
índice <span class="math inline">\(i\)</span> corresponde a cada cliente y <span class="math inline">\(A\)</span> es el conjunto de clientes
que adquiere un producto o servicio. El parámetro <span class="math inline">\(\tau\)</span>, al igual que
en el modelo de duración discreta, corresponde al tiempo máximo
observado.</p>
<p>Ahora bien, esto inmediatamente deja en evidencia una limitante a este
modelo: para un <span class="math inline">\(t\)</span> muy grande, todos los consumidores van a tener un
caso de éxito (Recordar que <span class="math inline">\(\text{lim } e^{-t} = 0\)</span>), lo cual no es una
situación del todo realista. Es necesario, en consecuencia, imponer que
existe una fracción de clientes dentro de la muestra considerada que
nunca probará el producto (caso de éxito) y, así, es posible solucionar
la limitante encontrada (2 clases latentes).</p>
<ol style="list-style-type: decimal">
<li><p>Segmento que prueba: Tamaño <span class="math inline">\(\pi\)</span>:</p>
<p><span class="math display">\[
\begin{array}{c}
\lambda = \theta\\
\Rightarrow P(T \leq t) = 1 - e^{-\theta t}
\end{array}
\]</span></p></li>
<li><p>Segmento que no prueba: Tamaño (<span class="math inline">\(1-\pi\)</span>):</p>
<p><span class="math display">\[
\begin{array}{c}
\lambda = 0\\
\Rightarrow P(T \leq t) = 0
\end{array}
\]</span></p></li>
</ol>
<p>Luego, la probabilidad total será:</p>
<p><span class="math display">\[
\begin{array}{c}
P(T \leq t) = P(T \leq t | \text{Prueba}) P(\text{Prueba}) + P(T \leq t | \text{No Prueba}) P(\text{No Prueba}) \\
= 1 - e^{-\theta t}\pi
\end{array}
\]</span></p>
<p>Es importante notar que si bien el modelo describe probabilidades en
tiempo continuo, la data aún se presenta y obtiene en tiempo discreto.
Incorporando esto, es posible construir la función de log verosimilitud
calculando las probabilidades de adopción del producto entre los límites
del intervalo temporal definido por el periodo de medición, es decir:</p>
<p><span class="math display">\[P(t_0 \leq T \leq t_1) = F(t_1) - F(t_0)\]</span> Cconsiderando n periodos
discretos para el cálculo, la log-verosimilitud es:</p>
<p><span class="math display">\[LL(\pi,\theta|\text{data}) = N_1 ln[P(1\leq T \leq 2)] + ... + (N_{panel} - \sum_{i=1}^{n}N_i)ln[P(T&gt;n)]\]</span>
Adicionalmente, es de interés calcular los valores predichos por el
modelo, de modo de realizar predicciones futuras. <span class="math inline">\(F(t)\)</span> representa la
probabilidad que un cliente escogido aleatoriamente pruebe el producto
en <span class="math inline">\(t\)</span>, tal que <span class="math inline">\(t=0\)</span> corresponde al instante de lanzamiento del
producto. La estimación del futuro se puede hacer a través de la
esperanza:</p>
<p><span class="math display">\[\mathbb{E}[T(t)] = N_{\text{panel }} \cdot \hat{F}(t) \]</span></p>
<p>Antes de avanzar, es importante aclarar la distinción de un modelo <em>sin
dependencia en la duración</em>. Esto se puede explicar con la propiedad
fundamental de la distribución exponencial:</p>
<p><strong>Propiedad fundamental:</strong> La distribución exponencial no tiene memoria,
es decir, poseer información de que un elemento ha sobrevivido un tiempo
’s’ hasta este momento no modifica la probabilidad de que sobreviva un
periodo <span class="math inline">\(t\)</span> más. Es decir la probabilidad de que ocurra un suceso no
depende del tiempo en que aún no ha ocurrido. Se puede demostrar
matemáticamente:</p>
<p><span class="math display">\[P(T &gt; s + t|T&gt;s) = \frac{P(T&gt; s+t)}{P(T&gt; s)} = \frac{1-P(T \leq s+t)}{1-P(T \leq s)}= \frac{e^{-\lambda(s+t)}}{e^{-\lambda s}} = e^{-\lambda t}\]</span></p>
</div>
<div id="modelo-gamma-exponencial" class="section level4 hasAnchor" number="2.2.2.1">
<h4><span class="header-section-number">2.2.2.1</span> Modelo Gamma Exponencial<a href="modelos-probabilísticos.html#modelo-gamma-exponencial" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Análogamente al caso de duración discreta, hay casos en que el
comportamiento de la población heterogéneo. Esto busca complejizar la
suposición que antes se hizo al considerar un grupo de clientes que
nunca consume. Por tanto, el modelo con heterogeneidad no observada
ahora considerará que la tasa de prueba <span class="math inline">\(\lambda\)</span> se distribuye <em>Gamma</em>
en la población:</p>
<p><span class="math display">\[g(\lambda) = \frac{\alpha^r \lambda^{r-1} e^{-\alpha \lambda}}{\Gamma(r)}\]</span>Donde
<span class="math inline">\(r\)</span> es un parámetro de forma mide la morfología. Con <span class="math inline">\(r=1\)</span> se reduce a
una exponencial y, a medida que crece, su la forma se vuelve más
simétrica y similar a una normal. Por otro lado, <span class="math inline">\(\alpha\)</span> es un
parámetro de escala que estira la distribución a medida que crece, o la
comprime en la medida que decrece.</p>
<p>Al incorporar la heterogeneidad mencionada, la probabilidad que un
cliente adquiera un producto antes de un tiempo <span class="math inline">\(t\)</span> es la siguiente:</p>
<p><span class="math display">\[
\begin{aligned} P(T\leq t) &amp;= \int_{0}^{\infty} P(T \leq t|\lambda) g(\lambda)d \lambda \\ &amp;= \int_{0}^{\infty} (1 - e^{-\lambda t}) \left( \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} \right) d\lambda \\ &amp;= \int_{0}^{\infty} \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} d\lambda - \int_{0}^{\infty} e^{-\lambda t} \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha \lambda} d\lambda \\ &amp;= 1 - \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \frac{\lambda^{r-1} e^{-\lambda(\alpha+t)} \Gamma(r) (\alpha + t)^r}{\Gamma(r) (\alpha + t)^r} d\lambda \\ &amp;= 1 - \frac{\alpha^r}{\Gamma(r)} \frac{\Gamma(r)}{(\alpha+t)^r} \\ &amp;= 1 - \left(\frac{\alpha}{\alpha + t}\right)^r \end{aligned} \]</span></p>
<p>Donde en el cuarto paso se agregó un 1 en forma de
<span class="math inline">\(\frac{\Gamma(r) (\alpha + t)^r}{\Gamma(r) (\alpha + t)^r}\)</span> para obtener
una función de acumulación de dominio completo para la distribución
gamma (lo que al integrarlo da 1).</p>
</div>
</div>
<div id="modelos-de-duración-en-tiempo-continuo-con-dependencia-en-la-duración" class="section level3 hasAnchor" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Modelos de duración en tiempo continuo con dependencia en la duración<a href="#modelos-de-duraci%C3%B3n-en-tiempo-continuo-con-dependencia-en-la-duraci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Otra de las grandes limitantes del modelo <em>Exponencial</em> es que posee
pérdida de memoria. En algunas aplicacioens se requiere incorporar esta
distinción, es decir, la probabilidad de que un evento ocurra dado que
hasta este momento no ha ocurrido. Esto último se conoce como <em>tasa de
riesgo</em> o <em>hazard rate</em>:</p>
<p><span class="math display">\[h(t) = \frac{f(t)}{1 - F(t)}\]</span></p>
<p>Donde</p>
<p><span class="math display">\[
\begin{aligned}
f(t) &amp;= \frac{d}{dt} F(t) \\
&amp;= -c\lambda t^{c-1} e^{-\lambda t^c}
\end{aligned}
\]</span></p>
<p>Gráficamente, la tasa de riesgo se comporta de la siguiente manera:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="modelos-probabilísticos.html#cb1-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/tasa_riesgo.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:my-fig"></span>
<img src="images/tasa_riesgo.png" alt="Ejemplos de tasas de riesgo" width="50%" />
<p class="caption">
Figure 2.1: Ejemplos de tasas de riesgo
</p>
</div>
<p>En el primer caso, la intuición es que si una persona no ha respondido a
un e-mail, cada vez es menos probable que lo responda, pues en general
las personas tienden a ignorar los correos con una antigüedad superior a
un par de días. En la llegada de un bus - si bien en ramos pasados se ha
modelado con una exponencial - se asume que a medida que más se demora
en llegar al paradero, cada vez la espera debe ser menor, pues tarde o
temprano este deberá llegar. Con respecto al divorcio, es más probable
que en el caso de haber, este no ocurra inmediatamente y, con menor
probabilidad, ocurrirá en las etapas tardías de la vida del matrimonio.
Con respecto a la falla del disco duro, este tiene un comportamiento no
lineal (cuadrático). Sus mayores posibilidades de fallar se dan al
principio y al final de su vida útil esperada.</p>
<p>A partir de la tasa de riesgo, se puede definir unívocamente la
distribución de una variable aleatoria no negativa a través de la
siguiente integral:</p>
<p><span class="math display">\[F(t) = 1 - exp \left( -\int_{0}^{t} h(u)du \right)\]</span>Este concepto será
útil para definir los modelos de duración en tiempo continuo en que la
duración sí es un factor relevante</p>
<div id="modelo-weibull" class="section level4 unnumbered hasAnchor">
<h4>Modelo Weibull<a href="modelos-probabilísticos.html#modelo-weibull" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A pesar de las generalizaciones de las funciones de tasas de riesgo para
generar modelos de tiempo de ocurrencia, el foco será puesto en la
distribución Weibull, debido a que es fácil de trabajar y entrega una
fórmula cerrada muy similar a la de la distribución exponencial. Se
tiene que, para la misma variable aleatoria <span class="math inline">\(T\)</span> que se definió en la
sección anterior, la probabilidad de ocurrencia de que un cliente pruebe
nuestro producto en un tiempo inferior a t será:</p>
<p><span class="math display">\[F(t) = P(T \leq t) = 1 - e^{-\lambda t ^c}\]</span> Y la tasa de riesgo
asociada a esta distribución:</p>
<p><span class="math display">\[h(t) = c \lambda t ^{c-1}\]</span>El primer parámetro <span class="math inline">\(\lambda\)</span> que compone
la fórmula es un parámetro de escala, mientras que el parámetro c es el
parámetro de forma. Es importante notar que para <span class="math inline">\(c=1\)</span>, la distribución
se convierte en la distribución exponencial, por lo que se puede decir
que la distribución Weibull es una generalización de la exponencial.
Notar que para <span class="math inline">\(c=1\)</span>, la tasa de riesgo es constante, lo que es
consistente con la propiedad de pérdida de memoria de la distribución
exponencial.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="modelos-probabilísticos.html#cb2-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="fu">rep</span>(<span class="st">&quot;images/tasa_riesgo_c.png&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:riesgoc"></span>
<img src="images/tasa_riesgo_c.png" alt="Ejemplos de tasas de riesgo para distintos valores de c" width="50%" />
<p class="caption">
Figure 2.2: Ejemplos de tasas de riesgo para distintos valores de c
</p>
</div>
<p>En la distribución de Weibull generalizada la propiedad de pérdida de
memoria no aplica como en el caso de la exponencial, es decir, la
probabilidad de ocurrencia varía a medida que pasa el tiempo:</p>
<p><span class="math display">\[P(T &gt; s + t|T&gt;s) = \frac{P(T&gt; s+t)}{P(T&gt; s)} = \frac{1-P(T \leq s+t)}{1-P(T \leq s)}= \frac{e^{-\lambda(s+t)^c}}{e^{-\lambda s^c}} \]</span></p>
</div>
<div id="modelo-gamma-weibull" class="section level4 unnumbered hasAnchor">
<h4>Modelo Gamma Weibull<a href="modelos-probabilísticos.html#modelo-gamma-weibull" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Una de las propiedades interesantes de la distribución Weibull, es que
es sencillo introducir heterogeneidad sobre los parámetros y, de esa
forma, capturar los distintos posibles comportamientos de la población.</p>
<p>Al igual que en el modelo Gamma-Exponencial, asumiremos que el parámetro
de escala <span class="math inline">\(\alpha\)</span> está distribuido <span class="math inline">\(\text{Gamma}(\alpha,r)\)</span> en la
población. La probabilidad de ocurrencia del consumo de los clientes se
puede modelar a través de la</p>
<p><span class="math display">\[
\begin{aligned} P(T \leq t \mid \alpha,r, c) &amp;= \int_{0}^{\infty} \frac{(1 - e^{-\lambda t^c}) \alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda \\ &amp;= \int_{0}^{\infty} \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda - \int_{0}^{\infty} \frac{e^{-\lambda t^c} \alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} d\lambda \\ &amp;= 1 - \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{r-1}e^{-\lambda(\alpha + t^c)} d\lambda \\ &amp;= 1 - \frac{\alpha^r}{\Gamma(r)} \frac{\Gamma(r)}{(\alpha + t^c)^r} \\ &amp;= 1 - \left(\frac{\alpha}{\alpha + t^c}\right)^r \end{aligned}
\]</span></p>
<p>Si <span class="math inline">\(c=1\)</span>, se recupera el modelo de duración Gamma-Exponencial.</p>
</div>
</div>
</div>
<div id="modelos-de-conteo" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Modelos de Conteo<a href="modelos-probabilísticos.html#modelos-de-conteo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Permiten modelar cuántas veces los consumidores incurrirán en un
comportamiento determinado en un período de tiempo (ejemplo: problema de
exposición publicitaria).</p>
<p>Algunas medidas de efectividad son:</p>
<ul>
<li><p><strong>Alcance:</strong> Proporción de la población expuesta al evento al menos
una vez durante el período: <span class="math inline">\(1 − P(X_t = 0)\)</span>.</p></li>
<li><p><strong>Frecuencia promedio:</strong> número promedio de exposiciones en el
período entre aquellos que han experimentado el evento (por ejemplo,
ver la valla publicitaria). <span class="math display">\[\frac{\mathbb{E}(X_t)}{1-P(X_t =0)}\]</span></p></li>
<li><p><strong>Puntos de rating brutos (GRPs):</strong> número promedio de exposiciones
por cada 100 personas.</p></li>
</ul>
<p><span class="math display">\[100 \cdot \mathbb{E}(X_t)\]</span></p>
<p>El fenómeno que se quiere estudiar es el número de veces que cada
individuo ve la valla publicitaria. Para ello, se define el modelo
individual <em>Poisson</em>.</p>
<p><span class="math display" id="eq:poisson">\[
P(N_t=m|\lambda) = \frac{(\lambda t)^m e^{-\lambda t}}{m!} \quad \tag{2.3}
\]</span></p>
<p>lo cual corresponde a la probabilidad de que el número de exposiciones
sea <span class="math inline">\(m\)</span> en un intervalo de largo <span class="math inline">\(t\)</span>.</p>
<p>Su verosimilitud corresponde a:</p>
<p><span class="math display">\[
\begin{aligned}
L(\lambda) &amp;= \prod_{m} P(N_t = m | \lambda)^{n_m} \\
&amp;= \prod_{m} \left( \frac{(\lambda t)^m e^{-\lambda t}}{m!} \right)^{n_m}
\end{aligned}
\]</span></p>
<p>Mientras que su log verosimilitud es:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\lambda) &amp;= \sum_{m} n_m \ln \left( P(N_t = m | \lambda) \right) \\
&amp;= \sum_{m} n_m \ln \left( \frac{(\lambda t)^m e^{-\lambda t}}{m!} \right)
\end{aligned}
\]</span></p>
<p>Donde <span class="math inline">\(m\)</span> corresponde al número de ocurrencias de un suceso (cuántas
personas han visto un determinado número de anuncios), <span class="math inline">\(n_m\)</span> es el
número de casos en donde hubieron <span class="math inline">\(m\)</span> ocurrencias de un suceso (cuántas
veces un usuario ha visto un anuncio) y no se utiliza cuando las
observaciones están desagregadas (datos en los cuales cada fila del
conjunto de datos corresponde a una observación única y específica).
Cuando el tiempo es unitario, el modelo se simplifica a <span class="math inline">\(t = 1\)</span>.</p>
<p>Al igual que en los modelos anteriores, es posible incluir
heterogeneidad asumiendo que el parámetro <span class="math inline">\(\lambda\)</span> no es el mismo para
todos. Para el caso en donde existe una mezcla finita y hay dos
segmentos, las tasas de eventos de la población pueden ser <span class="math inline">\(\lambda_1\)</span> o
<span class="math inline">\(\lambda_2\)</span>, con una probabilidad <span class="math inline">\(\pi\)</span> de pertenecer al primer
segmento. El modelo de probabilidad queda representado por:</p>
<p><span class="math display">\[
P(N_t = m | \lambda_1, \lambda_2, \pi) = \left( \frac{(\lambda_1 t)^m e^{-\lambda_1 t}}{m!} \right) \pi + \left( \frac{(\lambda_2 t)^m e^{-\lambda_2 t}}{m!} \right) (1-\pi) \quad (\#eq-mfp)
\]</span></p>
<p>Para los modelos de heterogeneidad continua, <span class="math inline">\(\lambda\)</span> distribuye de
acuerdo a una determinada distribución. Suponiendo que dicha
distribución es <em>Gamma</em>.</p>
<p><span class="math display" id="eq:gamma">\[
g(\lambda|\alpha, r) = \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)} \quad \tag{2.4}
\]</span></p>
<p>Usando el modelo individual en <a href="modelos-probabilísticos.html#eq:poisson">(2.3)</a> y la distribución en
<a href="modelos-probabilísticos.html#eq:gamma">(2.4)</a>, se puede estimar la probabilidad de un número de
exposiciones, conocido como modelo <strong>Gamma Poisson (NBD):</strong></p>
<p><span class="math display" id="eq:gammita">\[
\begin{aligned}
P(N_t = m \mid r, \alpha) &amp;= \int_{0}^{\infty} P(N_t = m|\lambda) g(\lambda)d\lambda \\
&amp;= \int_{0}^{\infty} \frac{(\lambda t)^m e^{-\lambda t}}{m!} \cdot \frac{\alpha^r \lambda^{r-1}e^{-\alpha \lambda}}{\Gamma(r)}d\lambda \\
&amp;= \frac{t^m \alpha^r}{m! \Gamma(r)} \int_{0}^{\infty} \lambda^m \lambda^{r-1} e^{-\lambda t} e^{-\alpha \lambda} d\lambda \\
&amp;= \frac{t^m \alpha^r}{m! \Gamma(r)} \int_{0}^{\infty} \lambda^{(r+m)-1} e^{-\lambda(\alpha+t)} d\lambda \\
&amp;= \frac{t^m \alpha^r}{m! \Gamma(r)} \cdot \frac{\Gamma(r+m)}{(\alpha+t)^{r+m}} \\
&amp;= \frac{\alpha^r}{(\alpha+t)^r} \cdot \frac{t^m}{(\alpha+t)^m} \cdot \frac{\Gamma(r+m)}{\Gamma(r)m!} \\
&amp;= \left( \frac{\alpha}{\alpha+t}\right)^r \left( \frac{t}{\alpha + t}\right)^m \frac{\Gamma(r+m)}{\Gamma(r)m!}
\end{aligned}
\quad \tag{2.5}
\]</span></p>
</div>
<div id="modelos-de-elección-binaria-binomial" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Modelos de Elección Binaria binomial<a href="#modelos-de-elecci%C3%B3n-binaria-binomial" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Permiten modelar la probabilidad de que los individuos elijan un
determinado comportamiento, dado que tienen varias opciones para elegir.
Es aplicable en una situación de compras en un supermercado, exposición
a varios anuncios, las variadas formas de uso de un producto, etc.</p>
<p>Consideremos como variable de interés la probabilidad de que un
individuo perteneciente a un segmento responda positivamente a una
campaña de marketing. En el enfoque tradicional, se realiza una
segmentación de clientes en grupos homogéneos, se envía mensajes a
muestras aleatorias de cada segmento y se implementa un campaña en
segmentos con tasa de respuesta (TR) sobre cierto corte, por ejemplo,
<span class="math inline">\(TR &gt; \frac{\text{Costo de envío}}{\text{Margen unitario}}\)</span>.</p>
<p>Sin embargo, es posible incorporar un enfoque de modelos probabilísticos
para abordar el problema. Si se considera la probabilidad de responder
de manera positiva que tiene un segmento <span class="math inline">\(s\)</span>, en particular <span class="math inline">\(p_s\)</span>, es
posible interpretar de manera sencilla la cantidad de respuestas
obtenidas. Recordando que la suma de experimentos de <span class="math inline">\(\text{Bernoulli}\)</span>
corresponde a una variable aleatoria Binomial, es posible interpretar
<span class="math inline">\(X_s\)</span> como la cantidad de respuestas obtenidas de un total de <span class="math inline">\(m_s\)</span>
enviadas. Luego:</p>
<p><span class="math display" id="eq:bin">\[P(X_s = x_s|m_s,p_s) = \binom{m_s}{x_s} p_s^{x_s}(1-p_s)^{m_s\tag{2.6}ad (#eq:bin)\]</span></p>
<p>donde <span class="math inline">\(m_s\)</span> es la población del segmento <span class="math inline">\(s\)</span> y <span class="math inline">\(p_s\)</span> es la probabilidad
de respuesta del segmento <span class="math inline">\(s\)</span>.</p>
<p>Se tiene que la verosimilitud es expresada como:</p>
<p><span class="math display">\[
\begin{aligned}
L(\theta) &amp;= \prod_{s=1}^{S} P(X_s = x_s | m_s, \theta) \\
&amp;= \prod_{s=1}^{S} \binom{m_s}{x_s} \theta^{x_s} (1-\theta)^{m_s - x_s}
\end{aligned}
\quad (\#eq:verosimilitud:bin)
\]</span></p>
<p>Mientras que su log verosimilitud es:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\theta) &amp;= \sum_{s=1}^{S} \ln \left( P(X_s = x_s | m_s, \theta) \right) \\
&amp;= \sum_{s=1}^{S} \ln \left( \binom{m_s}{x_s} \theta^{x_s} (1-\theta)^{m_s - x_s} \right) \\
&amp;= \sum_{s=1}^{S} \left[ \ln\binom{m_s}{x_s} + \ln(\theta^{x_s}) + \ln((1-\theta)^{m_s - x_s}) \right] \\
&amp;= \sum_{s=1}^{S} \left[ \ln\binom{m_s}{x_s} + x_s \ln(\theta) + (m_s - x_s) \ln(1-\theta) \right]
\end{aligned}
\quad (\#eq:logverosimilitud:bin)
\]</span></p>
<p>Con respecto a la heterogeneidad, en el caso de una mezcla finita en
donde la probabilidad de éxito en cada uno de los intentos es distinta
de acuerdo a dos segmentos identificables, la probabilidad adopta el
valor de <span class="math inline">\(\theta_1\)</span> y <span class="math inline">\(\theta_2\)</span>, donde <span class="math inline">\(\pi\)</span> corresponde a la
probabilidad de pertencer al primer segmento. El modelo de probabilidad
queda representado por:</p>
<p><span class="math display">\[P(X_s = x_s | m_s, \theta_1, \theta_2, \pi) = \binom{m_s}{x_s} \left[ \theta_1^{x_s}(1-\theta_1)^{m_s-x_s}\pi + \theta_2^{x_s}(1-\theta_2)^{m_s-x_s}(1-\pi) \right] \quad (\#eq:mezcla:binomial)\]</span></p>
<p>En el caso de mezcla infinita, la heterogeneidad no observable se extrae
aprovechando la distribución <span class="math inline">\(B(\alpha,\beta)\)</span>:</p>
<p><span class="math display" id="eq:beta-binomial">\[
\begin{aligned}
P(X_s = x_s \mid \alpha, \beta) &amp;= \int_{0}^{1} P(X_s = x_s|m_s,\theta_s) g(\theta_s|\alpha,\beta)d\theta_s \\
&amp;= \int_{0}^{1} \binom{m_s}{x_s} \theta_s^{x_s}(1-\theta_s)^{m_s-x_s} \frac{\theta_s^{\alpha-1}(1-\theta_s)^{\beta -1}}{B(\alpha,\beta)}d\theta_s \\
&amp;= \frac{\binom{m_s}{x_s}}{B(\alpha,\beta)} \int_{0}^{1} \theta_s^{x_s+\alpha-1}(1-\theta_s)^{m_s-x_s+\beta-1} d\theta_s \\
&amp;= \binom{m_s}{x_s} \frac{B(\alpha + x_s, \beta + m_s - x_s)}{B(\alpha,\beta)}
\end{aligned}
\quad \tag{2.7}
\]</span></p>
</div>
<div id="heterogeneidad-observable" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Heterogeneidad observable<a href="modelos-probabilísticos.html#heterogeneidad-observable" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Se ha expuesto modelos que intentan explicar y predecir el tiempo en que
los individuos realizarán una determinada acción (e.g: proponer la
probabilidad de fuga de un cliente), considerando que el comportamiento
de los agentes se debe netamente a factores aleatorios.</p>
<p>En esta sección se incorporará heterogeneidad observable a un modelo de
duración en tiempo continuo sin dependencia en la duración. Entendemos
por heterogeneidad observable, aquellos factores observables (que están
en los datos) intrínsecos a los individuos que los hacen distintos,
tales como sexo, edad, nivel socioeconómico, género, entre otras.</p>
<div id="modelos-de-duración-en-tiempo-discreto" class="section level3 hasAnchor" number="2.5.1">
<h3><span class="header-section-number">2.5.1</span> Modelos de duración en tiempo discreto<a href="#modelos-de-duraci%C3%B3n-en-tiempo-discreto" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(T_i\)</span> la variable aleatoria que describe el instante en que el
individuo <span class="math inline">\(i\)</span> termina su relación comercial. Se modelará dicha variable
con una distribución Geométrica Desplazada de parámetro <span class="math inline">\(\theta_i\)</span>, que
es la probabilidad de abandono para el individuo <span class="math inline">\(i\)</span>.</p>
<p><span class="math display">\[\mathbb{P}(T_i=t_i|\theta_i) = \theta_i(1-\theta_i)^{t_i-1}\]</span></p>
<p>Dado que se cuenta con información a nivel individual, es posible
estimar un parámetro de abandono para cada persona.</p>
<p>Sea <span class="math inline">\(x_i\)</span> el vector que contiene las variables explicativas del
individuo <span class="math inline">\(i\)</span>. Se modela la probabilidad de abandono <span class="math inline">\(\theta_i\)</span>
utilizando una transformación logística para asegurar que el resultado
se mantenga entre 0 y 1:</p>
<p><span class="math display">\[\theta_i = \frac{\exp(\beta_0 + \beta&#39;x_i)}{1 + \exp(\beta_0 + \beta&#39;x_i)} = \frac{1}{1 + \exp(-(\beta_0 + \beta&#39;x_i))}\]</span></p>
<p>Donde <span class="math inline">\(\beta\)</span> corresponde al vector de coeficientes asociados a las
variables explicativas. La inclusión de esta función permite capturar el
efecto de las covariables sin restringir el signo de los coeficientes.</p>
<p>En el caso donde la probabilidad de abandono depende de las
características de cada individuo (heterogeneidad observable), la
probabilidad de que el individuo <span class="math inline">\(i\)</span> abandone en el tiempo <span class="math inline">\(t_i\)</span> es:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{P}(T_i = t_i|\beta_0, \beta) &amp;= \theta_i (1 - \theta_i)^{t_i-1} \\
\text{donde } \theta_i &amp;= \frac{1}{1 + \exp(-(\beta_0 + \beta&#39;x_i))}
\end{aligned}
\]</span></p>
<p>Con lo cual, para un panel de <span class="math inline">\(N\)</span> individuos, donde algunos abandonan en
el período <span class="math inline">\(t_i\)</span> y otros permanecen activos (censurados a la derecha),
la log-verosimilitud del problema resulta:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\beta_0, \beta) &amp;= \sum_{i \in \text{abandono}} \ln(\mathbb{P}(T_i = t_i|\beta_0, \beta)) + \sum_{i \in \text{activos}} \ln(\mathbb{P}(T_i &gt; t_i|\beta_0, \beta)) \\
&amp;= \sum_{i \in \text{abandono}} \left[ \ln(\theta_i) + (t_i-1)\ln(1-\theta_i) \right] + \sum_{i \in \text{activos}} t_i \ln(1-\theta_i)
\end{aligned}
\]</span></p>
<p>Para introducir heterogeneidad no observable en el modelo y así mezclar
ambos efectos, es análogo al desarrollo de la integral del Modelo
Beta-Geométrico desplazado. Se modelan los parámetros <span class="math inline">\(\alpha_i\)</span> y
<span class="math inline">\(\beta_i\)</span> de la distribución Beta de la siguiente forma para asegurar
que sean positivos:</p>
<p><span class="math display">\[\alpha_i = \exp(a&#39;x_i) \quad \text{y} \quad \beta_i = \exp(b&#39;x_i)\]</span></p>
<p>La obtención de la expresión de probabilidad con heterogeneidad mixta es
análoga a la obtención de la probabilidad con heterogeneidad no
observable, salvo que la interpretación de los coeficientes <span class="math inline">\(\alpha_i\)</span> y
<span class="math inline">\(\beta_i\)</span> son distintas.</p>
<p>Finalmente, la función de log-verosimilitud para el modelo mixto
resulta, con <span class="math inline">\(\theta_{params} = (a, b)\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\theta_{params}) &amp;= \sum_{i \in \text{abandono}} \ln(\mathbb{P}(T_i = t_i|a, b)) + \sum_{i \in \text{activos}} \ln(\mathbb{P}(T_i &gt; t_i|a, b)) \\
&amp;= \sum_{i \in \text{abandono}} \ln\left(\frac{B(\alpha_i+1, t_i+\beta_i-1)}{B(\alpha_i, \beta_i)}\right) + \sum_{i \in \text{activos}} \ln\left(\frac{B(\alpha_i, \beta_i+t_i)}{B(\alpha_i, \beta_i)}\right)
\end{aligned}
\]</span></p>
</div>
<div id="modelos-de-duración-en-tiempo-continuo-sin-dependencia-de-la-duración" class="section level3 hasAnchor" number="2.5.2">
<h3><span class="header-section-number">2.5.2</span> Modelos de duración en tiempo continuo sin dependencia de la duración<a href="#modelos-de-duraci%C3%B3n-en-tiempo-continuo-sin-dependencia-de-la-duraci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(T_i\)</span> la variable aleatoria que describe el instante en que el
individuo <span class="math inline">\(i\)</span> realiza una determinada acción. Se modelará dicha variable
aleatoria con una distribución exponencial de parámetro <span class="math inline">\(\lambda_i\)</span>:</p>
<p><span class="math display">\[\mathbb{P}(T_i&lt;t_i|\lambda_i) = 1-e^{-\lambda_it_i}\]</span>Cabe destacar
que, dada la naturaleza de los datos, el comportamiento descrito se
realizará de manera desagregada (dependencia de <span class="math inline">\(i\)</span> en el parámetro), es
decir, dado que existe información individual para cada individuo, es
posible estimar el parámetro de cada uno de éstos (no así en los casos
agregados vistos anteriormente).</p>
<p>Sea <span class="math inline">\(x_i\)</span> el vector que contiene las variables explicativas pertinentes
del individuo <span class="math inline">\(i\)</span>. Se modela la tasa de llegada de <span class="math inline">\(i\)</span> de la siguiente
manera:</p>
<p><span class="math display">\[\lambda_i = exp(\beta_0 + \beta&#39;x_i) = \lambda_0 exp(\beta&#39;x_i)\]</span>
Donde <span class="math inline">\(\beta\)</span> corresponde al vector de coeficientes asociados a las
variables explicativas en cuestión.</p>
<p>La inclusión de la exponencial se debe a que, por razones de
convergencia e interpretación, la tasa de respuesta individual debe ser
positiva. De esta forma, se puede capturar el efecto marginal de las
variables demográficas sin restricción de signos. Así, el modelo no
tendrá problemas si hay valores de <span class="math inline">\(\beta\)</span> negativos.</p>
<p>En el caso con tasa homogénea (la misma para toda la población), la
probabilidad que un individuo <span class="math inline">\(i\)</span> realice un evento determinado antes
del tiempo <span class="math inline">\(t_i\)</span>, incluyendo su información observable, es:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{P}(T_i &lt; t_i|\beta,\lambda_0) &amp;= 1 - e^{-\lambda_it_i}\\
&amp;= 1 - e^{-\lambda_0 \exp(\beta&#39;x_i)t_i}
\end{aligned}
\]</span></p>
<p>Con lo cual (considerando instantes de tiempo <span class="math inline">\(t_i^-\)</span> y <span class="math inline">\(t_i^+\)</span> para
discretizar el tiempo, un panel de <span class="math inline">\(N\)</span> individuos y un vector de
parámetros <span class="math inline">\(\theta = (\beta,\lambda_0)\)</span>), la log verosimilitud del
problema resulta:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\theta) &amp;= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- &lt; T_i &lt; t_i^+|\beta,\lambda_0)) \\
&amp;= \sum_{i=1}^{N} \ln((\mathbb{P}(T_i &lt; t_i^+|\beta,\lambda_0)) - \mathbb{P}(T_i &lt; t_i^-|\beta,\lambda_0)) \\
&amp;=  \sum_{i=1}^{N} \ln \left((1 - e^{-\lambda_0 \exp(\beta&#39;x_i)t_i^+}) - (1 - e^{-\lambda_0 \exp(\beta&#39;x_i)t_i^-}) \right)\\
&amp;= \sum_{i=1}^{N} \ln (e^{-\lambda_0 \exp(\beta&#39;x_i)t_i^-} - e^{-\lambda_0 \exp(\beta&#39;x_i)t_i^+})
\end{aligned}
\]</span></p>
<p>Para introducir heterogeneidad no observable en el modelo, se dejará el
parámetro <span class="math inline">\(\lambda_0\)</span> distribuyendo de manera continua en la población
según una ley <span class="math inline">\(\Gamma(\alpha,r)\)</span> pues, de esta forma, es posible mezclar
tanto la heterogeneidad no observable, como la observable. El desarrollo
de la integral es análogo al caso con heterogeneidad no observable, con
la diferencia de que se multiplica la constante <span class="math inline">\(exp(\beta&#39; x_i)\)</span> a la
variable del tiempo <span class="math inline">\(t\)</span> .</p>
<p>Finalmente, la función de log verosimilitud resulta, con
<span class="math inline">\(\theta = (\beta,\alpha,r)\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\theta) &amp;= \sum_{i=1}^{N} \ln(\mathbb{P} (t_i^-&lt;T_i&lt;t_i^+|\alpha,r,\beta))\\
&amp;= \sum_{i=1}^{N} \ln \left(\left(\frac{\alpha}{ \alpha + \exp(\beta&#39;x_i)t_i^-}\right)^r - \left(\frac{\alpha}{ \alpha + \exp(\beta&#39;x_i)t_i^+}\right)^r\right)
\end{aligned}
\]</span></p>
</div>
<div id="modelos-de-duración-en-tiempo-continuo-con-dependencia-de-la-duración" class="section level3 hasAnchor" number="2.5.3">
<h3><span class="header-section-number">2.5.3</span> Modelos de duración en tiempo continuo con dependencia de la duración<a href="#modelos-de-duraci%C3%B3n-en-tiempo-continuo-con-dependencia-de-la-duraci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cuando el tiempo en que ocurre un determinado suceso posee dependencia
en la duración, el procedimiento es análogo que en el caso sin dicha
dependencia, pero considerando que <span class="math inline">\(T_i\)</span> distribuye según una ley
Weibull.</p>
<p><span class="math display">\[\mathbb{P}(T_i &lt; t_i|\lambda_i,c) = 1 - e^{-\lambda_it_i^c}\]</span></p>
<p>En el caso con tasa homogénea (la misma para toda la población), la
probabilidad que un individuo <span class="math inline">\(i\)</span> realice un evento determinado antes
del tiempo <span class="math inline">\(t_i\)</span>, incluyendo su información observable, es:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{P}(T_i &lt; t_i|\beta,\lambda_0,c) &amp;= 1 - e^{-\lambda_i t_i}\\
&amp;= 1 - e^{-\lambda_0 \exp(\beta&#39;x_i) t_i^c}
\end{aligned}
\]</span></p>
<p>Por lo que, la función de log verosimilitud toma la siguiente forma:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\theta) &amp;= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- &lt; T_i &lt; t_i^+|\beta,\lambda_0,c)) \\
&amp;= \sum_{i=1}^{N} \ln((\mathbb{P}(T_i &lt; t_i^+|\beta,\lambda_0,c)) - \mathbb{P}(T_i &lt; t_i^-|\beta,\lambda_0,c)) \\
&amp;=  \sum_{i=1}^{N} \ln \left((1 - e^{-\lambda_0 \exp(\beta&#39;x_i)(t_i^+)^c}) - (1 - e^{-\lambda_0 \exp(\beta&#39;x_i)(t_i^-)^c}) \right)\\
&amp;= \sum_{i=1}^{N} \ln (e^{-\lambda_0 \exp(\beta&#39;x_i)(t_i^-)^c} - e^{-\lambda_0 \exp(\beta&#39;x_i)(t_i^+)^c})
\end{aligned}
\]</span></p>
<p>De manera análoga al caso anterior, se puede introducir adicionalmente
heterogeneidad no observable mediante el parámetro <span class="math inline">\(\lambda_0\)</span> según una
distribución <span class="math inline">\(\Gamma(\alpha,r)\)</span>. Dando como conocido este resultado, la
log-verosimilitud queda descrita como:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\theta) &amp;= \sum_{i=1}^{N} \ln(\mathbb{P}(t_i^- &lt; T_i &lt; t_i^+|\beta,\lambda_0,r,c)) \\
&amp;= \sum_{i=1}^{N} \ln \left( \left(\frac{\alpha}{\alpha + \exp(\beta&#39;x_i)(t_i^-)^c}\right)^r - \left(\frac{\alpha}{\alpha + \exp(\beta&#39;x_i)(t_i^+)^c}\right)^r \right)
\end{aligned}
\]</span></p>
</div>
<div id="modelos-de-conteo-1" class="section level3 hasAnchor" number="2.5.4">
<h3><span class="header-section-number">2.5.4</span> Modelos de Conteo<a href="modelos-probabilísticos.html#modelos-de-conteo-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(Y_i\)</span> la variable aleatoria que describe el número de veces que el
individuo <span class="math inline">\(i\)</span> incurre en un determinado comportamiento durante un
período de tiempo. Se modelará dicha variable con una distribución
<strong>Poisson</strong> de parámetro <span class="math inline">\(\lambda_i\)</span>, que representa la tasa de
ocurrencia para el individuo <span class="math inline">\(i\)</span>.</p>
<p><span class="math display">\[\mathbb{P}(Y_i=y_i|\lambda_i) = \frac{\lambda_i^{y_i} e^{-\lambda_i}}{y_i!}\]</span></p>
<p>Para incorporar heterogeneidad observable, se modela la tasa individual
<span class="math inline">\(\lambda_i\)</span> como una función de un vector <span class="math inline">\(x_i\)</span> que contiene las
variables explicativas del individuo:</p>
<p><span class="math display">\[\lambda_i = \exp(\beta_0 + \beta&#39;x_i) = \lambda_0 \exp(\beta&#39;x_i)\]</span></p>
<p>Donde <span class="math inline">\(\beta\)</span> es el vector de coeficientes y <span class="math inline">\(\lambda_0 = \exp(\beta_0)\)</span>
es la tasa base. La probabilidad de que el individuo <span class="math inline">\(i\)</span> realice el
evento <span class="math inline">\(y_i\)</span> veces es:</p>
<p><span class="math display">\[
\mathbb{P}(Y_i = y_i|\beta_0, \beta) = \frac{(\lambda_0 \exp(\beta&#39;x_i))^{y_i} \exp(-\lambda_0 \exp(\beta&#39;x_i))}{y_i!}
\]</span></p>
<p>La función de log-verosimilitud para estimar los parámetros <span class="math inline">\(\beta_0\)</span> y
<span class="math inline">\(\beta\)</span> a partir de los datos de <span class="math inline">\(N\)</span> individuos es la suma de las
log-probabilidades individuales:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\beta_0, \beta) &amp;= \sum_{i=1}^{N} \ln(\mathbb{P}(Y_i=y_i|\beta_0, \beta)) \\
&amp;= \sum_{i=1}^{N} \left[ y_i \ln(\lambda_i) - \lambda_i - \ln(y_i!) \right] \\
&amp;= \sum_{i=1}^{N} \left[ y_i (\beta_0 + \beta&#39;x_i) - \exp(\beta_0 + \beta&#39;x_i) - \ln(y_i!) \right]
\end{aligned}
\]</span></p>
<p>Para introducir heterogeneidad no observable y mezclarla con la
observable, se asume que la tasa base <span class="math inline">\(\lambda_0\)</span>no es fija para toda la
población, sino que sigue una distribución Gamma con parámetros de forma
<span class="math inline">\(r\)</span> y de escala <span class="math inline">\(\alpha\)</span>.</p>
<p><span class="math display">\[g(\lambda_0|r, \alpha) = \frac{\alpha^r \lambda_0^{r-1}e^{-\alpha\lambda_0}}{\Gamma(r)}\]</span></p>
<p>El desarrollo de la integral para obtener la probabilidad marginal es
análogo al caso NBD (Distribución Binomial Negativa) sin covariables. El
resultado es la distribución de probabilidad para un modelo de Regresión
Binomial Negativa:</p>
<p><span class="math display">\[
\mathbb{P} (Y_i = y_i|r, \alpha, \beta) = \frac{\Gamma(r+y_i)}{\Gamma(r)y_i!} \left(\frac{\alpha}{\alpha + \exp(\beta&#39;x_i)}\right)^r \left(\frac{\exp(\beta&#39;x_i)}{\alpha + \exp(\beta&#39;x_i)}\right)^{y_i}
\]</span></p>
<p>Finalmente, la función de <strong>log-verosimilitud</strong> para el modelo mixto
(Regresión NBD) que estima los parámetros <span class="math inline">\((r, \alpha, \beta)\)</span> es: <span class="math display">\[
LL(r, \alpha, \beta) = \sum_{i=1}^{N} \ln(\mathbb{P}(Y_i = y_i|r, \alpha, \beta))
\]</span></p>
</div>
<div id="modelos-de-elección-binaria-binomial-1" class="section level3 hasAnchor" number="2.5.5">
<h3><span class="header-section-number">2.5.5</span> Modelos de Elección Binaria binomial<a href="#modelos-de-elecci%C3%B3n-binaria-binomial-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(X_i\)</span> la variable aleatoria que describe el número de “éxitos” (ej.
respuestas a una campaña, compras) en <span class="math inline">\(m_i\)</span> intentos para un individuo o
segmento <span class="math inline">\(i\)</span>. Se modelará dicha variable con una distribución con
parámetros <span class="math inline">\(m_i\)</span> y <span class="math inline">\(\theta_i\)</span>, donde <span class="math inline">\(\theta_i\)</span> es la probabilidad de
éxito para el individuo <span class="math inline">\(i\)</span>.</p>
<p><span class="math display">\[\mathbb{P}(X_i=x_i|m_i, \theta_i) = \binom{m_i}{x_i} \theta_i^{x_i}(1-\theta_i)^{m_i-x_i}\]</span></p>
<p>Para incorporar heterogeneidad observable, se modela la probabilidad de
éxito individual <span class="math inline">\(\theta_i\)</span> como una función de un vector de covariables
<span class="math inline">\(x_i\)</span>. Al igual que en el modelo de duración discreta, se utiliza una
transformación logística para asegurar que <span class="math inline">\(\theta_i\)</span> se mantenga en el
intervalo <span class="math inline">\((0,1)\)</span>:</p>
<p><span class="math display">\[\theta_i = \frac{\exp(\beta_0 + \beta&#39;x_i)}{1 + \exp(\beta_0 + \beta&#39;x_i)} = \frac{1}{1 + \exp(-(\beta_0 + \beta&#39;x_i))}\]</span></p>
<p>Donde <span class="math inline">\(\beta\)</span> es el vector de coeficientes que captura el efecto de las
características observables.</p>
<p>La función de log verosimilitud para estimar los parámetros <span class="math inline">\(\beta_0\)</span> y
<span class="math inline">\(\beta\)</span> a partir de los datos de <span class="math inline">\(N\)</span> individuos o segmentos es la suma
de las log-probabilidades binomiales individuales:</p>
<p><span class="math display">\[
\begin{aligned}
LL(\beta_0, \beta) &amp;= \sum_{i=1}^{N} \ln(\mathbb{P}(X_i=x_i|\beta_0, \beta)) \\
&amp;= \sum_{i=1}^{N} \left[ \ln\binom{m_i}{x_i} + x_i \ln(\theta_i) + (m_i - x_i) \ln(1-\theta_i) \right]
\end{aligned}
\]</span></p>
<p>Para introducir heterogeneidad no observable y mezclarla con la
observable, se asume que la probabilidad de éxito <span class="math inline">\(\theta_i\)</span> no es fija,
sino que sigue una distribución Beta. Para incorporar las covariables,
se modelan los parámetros <span class="math inline">\(\alpha_i\)</span> y <span class="math inline">\(\beta_i\)</span> de la distribución Beta
como una función de las características <span class="math inline">\(x_i\)</span>:</p>
<p><span class="math display">\[\alpha_i = \exp(a&#39;x_i) \quad \text{y} \quad \beta_i = \exp(b&#39;x_i)\]</span></p>
<p>La probabilidad marginal de observar <span class="math inline">\(x_i\)</span> éxitos en <span class="math inline">\(m_i\)</span> intentos para
el individuo <span class="math inline">\(i\)</span> se obtiene a través de la integral análoga al caso sin
covariables:</p>
<p><span class="math display">\[
\mathbb{P} (X_i = x_i|a, b) = \binom{m_i}{x_i} \frac{B(\alpha_i + x_i, \beta_i + m_i - x_i)}{B(\alpha_i,\beta_i)}
\]</span></p>
<p>Finalmente, la función de log verosimilitud para el modelo mixto
(Regresión Beta Binomial) que estima los parámetros <span class="math inline">\((a, b)\)</span> es: <span class="math display">\[
LL(a, b) = \sum_{i=1}^{N} \ln \left( \binom{m_i}{x_i} \frac{B(\alpha_i + x_i, \beta_i + m_i - x_i)}{B(\alpha_i,\beta_i)} \right)
\]</span></p>
</div>
</div>
<div id="esperanzas-condicionales" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Esperanzas Condicionales<a href="modelos-probabilísticos.html#esperanzas-condicionales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Primero, es fundamental establecer el valor esperado de las
distribuciones que se usaron para modelar la heterogeneidad no
observable. A continuación, se muestra el desarrollo para obtener la
esperanza de las distribuciones Gamma y Beta.</p>
<ul>
<li><p><strong>Esperanza de la distribución Gamma</strong></p>
<p>Para la distribución Gamma, con parámetro de forma <span class="math inline">\(r\)</span> y de tasa
<span class="math inline">\(\alpha\)</span>, que se utiliza para modelar tasas de ocurrencia (ej.
<span class="math inline">\(\lambda\)</span>), su función de densidad de probabilidad es:
<span class="math display">\[g(\lambda|r,\alpha) = \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha\lambda}\]</span>
La esperanza de una variable aleatoria <span class="math inline">\(\lambda\)</span> que sigue esta
distribución es: <span class="math display">\[
\mathbb{E}[\lambda] = \frac{r}{\alpha}
\]</span>Este resultado se obtiene a partir de la definición de valor
esperado para una variable continua: <span class="math display">\[
\begin{aligned}
\mathbb{E}[\lambda] &amp;= \int_{0}^{\infty} \lambda \cdot g(\lambda|r,\alpha) d\lambda \\
&amp;= \int_{0}^{\infty} \lambda \cdot \frac{\alpha^r}{\Gamma(r)} \lambda^{r-1} e^{-\alpha\lambda} d\lambda \\
&amp;= \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{r} e^{-\alpha\lambda} d\lambda \\
&amp;= \frac{\alpha^r}{\Gamma(r)} \int_{0}^{\infty} \lambda^{(r+1)-1} e^{-\alpha\lambda} d\lambda \\
\end{aligned}
\]</span> Reconociendo que la integral
<span class="math inline">\(\int_{0}^{\infty} x^{k-1}e^{-\theta x}dx = \frac{\Gamma(k)}{\theta^k}\)</span>,
con <span class="math inline">\(k=r+1\)</span> y <span class="math inline">\(\theta=\alpha\)</span>: <span class="math display">\[
\begin{aligned}
\mathbb{E}[\lambda] &amp;= \frac{\alpha^r}{\Gamma(r)} \left[ \frac{\Gamma(r+1)}{\alpha^{r+1}} \right] \\
&amp;= \frac{\alpha^r}{\Gamma(r)} \cdot \frac{r\Gamma(r)}{\alpha^r \cdot \alpha} \\
&amp;= \frac{r}{\alpha}
\end{aligned}
\]</span></p></li>
<li><p><strong>Esperanza de la distribución Beta</strong></p>
<p>Para la distribución Beta con parámetros <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span> que se
utilizan para modelar probabilidades (ej. <span class="math inline">\(\theta\)</span>), su función de
densidad de probabilidad es:
<span class="math display">\[g(\theta|\alpha,\beta) = \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)}\]</span>
El desarrollo para obtener esta esperanza es el siguiente: <span class="math display">\[
\begin{aligned}
\mathbb{E}[\theta] &amp;= \int_{0}^{1} \theta \cdot g(\theta|\alpha,\beta) d\theta \\
&amp;= \int_{0}^{1} \theta \cdot \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)} d\theta \\
&amp;= \frac{1}{B(\alpha,\beta)} \int_{0}^{1} \theta^{\alpha}(1-\theta)^{\beta-1} d\theta \\
&amp;= \frac{1}{B(\alpha,\beta)} \int_{0}^{1} \theta^{(\alpha+1)-1}(1-\theta)^{\beta-1} d\theta \\
\end{aligned}
\]</span> Reconociendo que la integral
<span class="math inline">\(\int_{0}^{1} x^{a-1}(1-x)^{b-1}dx = B(a,b)\)</span>, con <span class="math inline">\(a=\alpha+1\)</span> y
<span class="math inline">\(b=\beta\)</span>: <span class="math display">\[
\begin{aligned}
\mathbb{E}[\theta] &amp;= \frac{1}{B(\alpha,\beta)} \left[ B(\alpha+1, \beta) \right] \\
&amp;= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} \cdot \frac{\Gamma(\alpha+1)\Gamma(\beta)}{\Gamma(\alpha+1+\beta)} \\
&amp;= \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)} \cdot \frac{\alpha\Gamma(\alpha)}{(\alpha+\beta)\Gamma(\alpha+\beta)} \\
&amp;= \frac{\alpha}{\alpha+\beta}
\end{aligned}
\]</span></p></li>
</ul>
<div id="modelo-de-tiempo-discreto-combinado-con-beta" class="section level3 hasAnchor" number="2.6.1">
<h3><span class="header-section-number">2.6.1</span> Modelo de Tiempo Discreto (Combinado con Beta)<a href="modelos-probabilísticos.html#modelo-de-tiempo-discreto-combinado-con-beta" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para el modelo de duración en tiempo discreto, una pregunta válida es
cuál es la probabilidad de abandono esperada para un cliente
determinado, dado su historial con la empresa. Intuitivamente, esta
probabilidad debería estar entre la tasa de abandono promedio de la
población y el comportamiento observado de ese cliente.</p>
<p>Recordando que la distribución del parámetro <span class="math inline">\(\theta\)</span> (la probabilidad
de abandono), condicionada a los datos observados de un cliente, se
obtiene por el Teorema de Bayes:</p>
<p><span class="math display" id="eq:thetabayes">\[ g(\theta|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\theta)g(\theta)}{\int \mathbb{P}(\text{datos}|\theta)g(\th\tag{2.8}ad (#eq:thetabayes) \]</span></p>
<p>donde <span class="math inline">\(g(\theta)\)</span> es la distribución a priori del parámetro (Beta) y
<span class="math inline">\(\mathbb{P}(\text{datos}|\theta)\)</span> es la verosimilitud del comportamiento
observado (Geométrica). Para el modelo Beta-Geométrico, la distribución
posterior de <span class="math inline">\(\theta\)</span> también es una distribución Beta con parámetros
actualizados.</p>
<p>Para el Modelo de Tiempo Discreto (Beta), la esperanza condicional
<span class="math inline">\(E[\theta|t]\)</span> representa la probabilidad de abandono esperada para un
cliente, la cual se actualiza y ajusta en función de su tiempo de
permanencia observado <span class="math inline">\(t\)</span>.</p>
<p>El cálculo de esta esperanza se basa en el Teorema de Bayes, que
actualiza el conocimiento previo sobre el parámetro <span class="math inline">\(\theta\)</span> a la luz de
los datos observados:</p>
<p><span class="math display">\[ g(\theta|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\theta) \cdot g(\theta)}{\int \mathbb{P}(\text{datos} \mid \theta) \cdot g(\theta) d\theta} \]</span></p>
<p>El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:</p>
<ul>
<li><p><strong>Distribución a Priori</strong>: Se asume que la heterogeneidad en la
probabilidad de abandono <span class="math inline">\(\theta\)</span> en la población sigue una
distribución <strong>Beta</strong>:
<span class="math display">\[ g(\theta|\alpha, \beta) \sim \text{Beta}(\alpha, \beta) \]</span></p></li>
<li><p><strong>Función de Verosimilitud</strong>: El comportamiento de abandono
individual se modela con una distribución Geométrica Desplazada, que
indica la probabilidad de que el evento ocurra exactamente en el
período <span class="math inline">\(t\)</span>: <span class="math display">\[ \mathbb{P}(T=t|\theta) = \theta(1-\theta)^{t-1} \]</span></p></li>
</ul>
<p>Con respecto a la Ley de Probabilidades Totales, ya se ha calculado en
anterioridad para el Modelo Beta Geométrico-Desplazado. A continuación,
se muestra el desarrollo: <span class="math display">\[
\begin{aligned}
g(\theta|T=t) &amp;= \frac{\mathbb{P}(T=t|\theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(T=t|\theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&amp;= \frac{ \left( \theta(1-\theta)^{t-1} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \frac{B(\alpha+1, \beta+t-1)}{B(\alpha, \beta)} } \\
&amp;= \frac{\theta^{\alpha}(1-\theta)^{\beta+t-2}}{B(\alpha+1, \beta+t-1)}
\end{aligned}
\]</span></p>
<p>La expresión resultante es la función de densidad de una distribución
Beta, con los parámetros actualizados.
<span class="math display">\[g(\theta|T=t) \sim \text{Beta}(\alpha+1, \beta+t-1)\]</span></p>
<p>De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
<span class="math display">\[ \mathbb{E}(\theta|T=t) = \frac{\alpha+1}{\alpha+\beta+t} \]</span></p>
<p>Esta expresión representa la probabilidad de abandono esperada y
actualizada para un cliente que ha permanecido exactamente <span class="math inline">\(t\)</span> períodos.
El resultado combina la información previa sobre la población (contenida
en <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>) con la observación específica del cliente (su
duración <span class="math inline">\(t\)</span>).</p>
<p>De forma análoga, para un cliente que sigue activo después de <span class="math inline">\(t\)</span>
períodos (observación censurada):</p>
<ul>
<li><strong>Función de Verosimilitud</strong>: La probabilidad de que el evento aún
no haya ocurrido es la función de supervivencia:
<span class="math display">\[ \mathbb{P}(T&gt;t|\theta) = (1-\theta)^{t} \]</span></li>
</ul>
<p>Obteniendo la distribución posterior: <span class="math display">\[
\begin{aligned}
g(\theta|T &gt; t) &amp;= \frac{\mathbb{P}(T &gt; t|\theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(T &gt; t|\theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&amp;= \frac{ \left( (1-\theta)^{t} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \frac{B(\alpha, \beta+t)}{B(\alpha, \beta)} } \\
&amp;= \frac{\theta^{\alpha-1}(1-\theta)^{\beta+t-1}}{B(\alpha, \beta+t)}
\end{aligned}
\]</span></p>
<p>La expresión resultante es la función de densidad de otra distribución
Beta, con los parámetros actualizados.
<span class="math display">\[g(\theta|T&gt;t) \sim \text{Beta}(\alpha, \beta+t)\]</span></p>
<p>De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
<span class="math display">\[ \mathbb{E}(\theta|T&gt;t) = \frac{\alpha}{\alpha+\beta+t} \]</span></p>
<p>Se podría replantear una regla de decisión y, por ejemplo, dirigir una
campaña de retención a los clientes aún activos después de <span class="math inline">\(t\)</span> períodos
si su probabilidad de abandono esperada supera cierto umbral:</p>
<p><span class="math display">\[\mathbb{E} (\theta|T &gt; t) = \frac{\alpha}{\alpha + \beta + t} &gt; \frac{\text{Costo de Retención}}{\text{Valor del Cliente}}\]</span></p>
<p><span class="math display">\[
\mathbb{E}(\theta \mid T&gt;t) = \frac{\alpha}{\alpha + \beta + t} (\#eq:esp:discrete)
\]</span></p>
</div>
<div id="modelo-de-tiempo-continuo-combinado-con-gamma" class="section level3 hasAnchor" number="2.6.2">
<h3><span class="header-section-number">2.6.2</span> Modelo de Tiempo Continuo (Combinado con Gamma)<a href="modelos-probabilísticos.html#modelo-de-tiempo-continuo-combinado-con-gamma" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para el modelo de duración en tiempo continuo, una pregunta válida es
cuál es la tasa de eventos esperada para un cliente determinado, dado su
historial. Intuitivamente, esta tasa debería estar entre la tasa
promedio de la población y el comportamiento observado de ese cliente.</p>
<p>Recordando que la distribución del parámetro <span class="math inline">\(\lambda\)</span> (la tasa de
eventos), condicionada a los datos observados de un cliente, se obtiene
por el Teorema de Bayes:</p>
<p><span class="math display" id="eq:thetabayes">\[ g(\lambda|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\lambda)g(\lambda)}{\int \mathbb{P}(\text{datos}|\lambda)g(\lamb\tag{2.8}ad (#eq:thetabayes) \]</span></p>
<p>La esperanza condicional <span class="math inline">\(E[\lambda|t]\)</span> representa la tasa de ocurrencia
esperada para un cliente, la cual se actualiza y ajusta en función del
tiempo transcurrido <span class="math inline">\(t\)</span>.</p>
<p>El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:</p>
<ul>
<li><p><strong>Distribución a Priori</strong>: Se asume que la heterogeneidad en la tasa
de eventos <span class="math inline">\(\lambda\)</span> en la población sigue una distribución
<strong>Gamma</strong>: <span class="math display">\[ g(\lambda|r, \alpha) \sim \text{Gamma}(r, \alpha) \]</span></p></li>
<li><p><strong>Función de Verosimilitud</strong>: El comportamiento del tiempo hasta el
evento se modela con una distribución Exponencial, que indica la
probabilidad (densidad) de que el evento ocurra exactamente en el
instante <span class="math inline">\(t\)</span>:
<span class="math display">\[ \mathbb{P}(T=t|\lambda) = f(t|\lambda) = \lambda e^{-\lambda t} \]</span></p></li>
</ul>
<p>Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Gamma-Exponencial. A continuación, se muestra el
desarrollo de la distribución posterior: <span class="math display">\[
\begin{aligned}
g(\lambda|T=t) &amp;= \frac{\mathbb{P}(T=t|\lambda) \cdot g(\lambda|r, \alpha)}{\int_0^\infty \mathbb{P}(T=t|\lambda) \cdot g(\lambda|r, \alpha) d\lambda} \\
&amp;= \frac{ \left( \lambda t e^{-\lambda t} \right) \left( \frac{\alpha^r \lambda^{r-1} e^{-\alpha\lambda}}{\Gamma(r)} \right) }{\left(\frac{rt}{\alpha + t} \right) \left(\frac{1}{\alpha + t} \right)^r} \\
&amp;= \frac{(\alpha+t)^{r+1}}{\Gamma(r+1)}\lambda^{r}e^{-\lambda(\alpha+t)}
\end{aligned}
\]</span></p>
<p>La expresión resultante es la función de densidad de una distribución
Gamma, con los parámetros actualizados.
<span class="math display">\[g(\lambda|T=t) \sim \text{Gamma}(r+1, \alpha+t)\]</span></p>
<p>De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
<span class="math display">\[ \mathbb{E}(\lambda|T=t) = \frac{r+1}{\alpha+t} \]</span></p>
</div>
<div id="modelo-de-conteo-combinado-con-gamma" class="section level3 hasAnchor" number="2.6.3">
<h3><span class="header-section-number">2.6.3</span> Modelo de Conteo (Combinado con Gamma)<a href="modelos-probabilísticos.html#modelo-de-conteo-combinado-con-gamma" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para el modelo de conteo, una pregunta válida es cuál es la tasa de
eventos esperada para un cliente determinado, dado su historial de
eventos en un período de tiempo <span class="math inline">\(t\)</span>.</p>
<p>Recordando que la distribución del parámetro <span class="math inline">\(\lambda\)</span> (la tasa de
eventos), condicionada a los datos observados de un cliente, se obtiene
por el Teorema de Bayes:</p>
<p><span class="math display" id="eq:thetabayes">\[ g(\lambda|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\lambda)g(\lambda)}{\int \mathbb{P}(\text{datos}|\lambda)g(\lamb\tag{2.8}ad (#eq:thetabayes) \]</span></p>
<p>El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:</p>
<ul>
<li><p><strong>Distribución a Priori</strong>: Se asume que la heterogeneidad en la tasa
de eventos <span class="math inline">\(\lambda\)</span> en la población sigue una distribución
<strong>Gamma</strong>: <span class="math display">\[ g(\lambda|r, \alpha) \sim \text{Gamma}(r, \alpha) \]</span></p></li>
<li><p><strong>Función de Verosimilitud</strong>: El comportamiento de conteo de eventos
se modela con una distribución <strong>Poisson</strong>, que indica la
probabilidad de que ocurran exactamente <span class="math inline">\(y\)</span> eventos en un período de
duración <span class="math inline">\(t\)</span>:
<span class="math display">\[ \mathbb{P}(Y_t=y|\lambda,t) = \frac{(\lambda t)^y e^{-\lambda t}}{y!} \]</span></p></li>
</ul>
<p>Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Gamma-Poisson (NBD). A continuación, se muestra el
desarrollo de la distribución posterior: <span class="math display">\[
\begin{aligned}
g(\lambda|Y_t=y) &amp;= \frac{\mathbb{P}(Y_t=y|\lambda, t) \cdot g(\lambda|r, \alpha)}{\int_0^\infty \mathbb{P}(Y_t=y|\lambda, t) \cdot g(\lambda|r, \alpha) d\lambda} \\
&amp;= \frac{ \left( \frac{(\lambda t)^y e^{-\lambda t}}{y!} \right) \left( \frac{\alpha^r \lambda^{r-1} e^{-\alpha\lambda}}{\Gamma(r)} \right) }{ \frac{\Gamma(r+y)}{\Gamma(r)y!} \left(\frac{\alpha}{\alpha+t}\right)^r \left(\frac{t}{\alpha+t}\right)^{y} } \\
&amp;= \frac{(\alpha+t)^{r+y}}{\Gamma(r+y)}\lambda^{r+y-1}e^{-\lambda(\alpha+t)}
\end{aligned}
\]</span></p>
<p>La expresión resultante es la función de densidad de una distribución
Gamma, con los parámetros actualizados.
<span class="math display">\[g(\lambda|Y_t=y) \sim \text{Gamma}(r+y, \alpha+t)\]</span></p>
<p>De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
<span class="math display">\[ \mathbb{E}(\lambda|Y_t=y) = \frac{r+y}{\alpha+t} \]</span></p>
</div>
<div id="modelo-de-elección-binaria-binomial-combinado-con-beta" class="section level3 hasAnchor" number="2.6.4">
<h3><span class="header-section-number">2.6.4</span> Modelo de Elección Binaria binomial (Combinado con Beta)<a href="#modelo-de-elecci%C3%B3n-binaria-binomial-combinado-con-beta" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recordando que la distribución del parámetro <span class="math inline">\(\theta\)</span> (la probabilidad
de éxito), condicionada a los datos observados, se obtiene por el
Teorema de Bayes:</p>
<p><span class="math display" id="eq:thetabayes">\[ g(\theta|\text{datos}) = \frac{\mathbb{P}(\text{datos}|\theta)g(\theta)}{\int \mathbb{P}(\text{datos}|\theta)g(\th\tag{2.8}ad (#eq:thetabayes) \]</span></p>
<p>El proceso para derivar la esperanza condicional se descompone de la
siguiente manera:</p>
<ul>
<li><p><strong>Distribución a Priori</strong>: Se asume que la heterogeneidad en la
probabilidad de éxito <span class="math inline">\(\theta\)</span> en la población sigue una
distribución <strong>Beta</strong>:
<span class="math display">\[ g(\theta|\alpha, \beta) \sim \text{Beta}(\alpha, \beta) \]</span></p></li>
<li><p><strong>Función de Verosimilitud</strong>: El comportamiento de elección se
modela con una distribución Binomial, que indica la probabilidad de
obtener exactamente <span class="math inline">\(x\)</span> éxitos en <span class="math inline">\(m\)</span> intentos:
<span class="math display">\[ \mathbb{P}(X=x|m, \theta) = \binom{m}{x} \theta^x (1-\theta)^{m-x} \]</span></p></li>
</ul>
<p>Con respecto a la Ley de Probabilidades Totales, el denominador de la
expresión de Bayes corresponde a la probabilidad en heterogeneidad no
observada del modelo Beta-Binomial. A continuación, se muestra el
desarrollo de la distribución posterior: <span class="math display">\[
\begin{aligned}
g(\theta|X=x) &amp;= \frac{\mathbb{P}(X=x|m, \theta) \cdot g(\theta|\alpha, \beta)}{\int_0^1 \mathbb{P}(X=x|m, \theta) \cdot g(\theta|\alpha, \beta) d\theta} \\
&amp;= \frac{ \left( \binom{m}{x} \theta^x (1-\theta)^{m-x} \right) \left( \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)} \right) }{ \binom{m}{x} \frac{B(\alpha+x, \beta+m-x)}{B(\alpha, \beta)} } \\
&amp;= \frac{\theta^{\alpha+x-1}(1-\theta)^{\beta+m-x-1}}{B(\alpha+x, \beta+m-x)}
\end{aligned}
\]</span></p>
<p>La expresión resultante es la función de densidad de una distribución
Beta, con los parámetros actualizados.
<span class="math display">\[g(\theta|X=x) \sim \text{Beta}(\alpha+x, \beta+m-x)\]</span></p>
<p>De esta distribución posterior se deduce la Esperanza Condicional, que
es simplemente la media de dicha distribución:
<span class="math display">\[ \mathbb{E}(\theta|X=x) = \frac{\alpha+x}{\alpha+\beta+m} \]</span></p>
<p>En el modelo de elección en donde la <span class="math inline">\(P(X_s = x_s)\)</span> quedaba definida en
<a href="modelos-probabilísticos.html#eq:bin">(2.6)</a>. Una pregunta válida que se puede hacer es cuál es la tasa
de respuesta de un segmento <span class="math inline">\(s\)</span> determinado. Intuitivamente debería
estar entre la tasa de respuesta esperada de la población y la
observada, es decir,</p>
<p><span class="math display" id="eq:tasa">\[ \mathbb{E}(\theta_s|m_s,x_s)=\gamma \frac{\alpha}{\alpha+\beta} + (1-\gamma) \frac{x_s\tag{2.9}ad (#eq:tasa) \]</span></p>
<p>Esta última igualdad se encuentra al hacer el reemplazo
<span class="math inline">\(\gamma = \frac{\alpha + \beta}{\alpha + \beta + m_s}\)</span>, la cual coincide
con <a href="modelos-probabilísticos.html#eq:thetabayes">(2.8)</a>. Se podría replantear la regla de decisión y
enviar catálogos a los segmentos <span class="math inline">\(s\)</span> tales que</p>
<p><span class="math display">\[\mathbb{E} (\theta_s|x_s) =\frac{\alpha + x_s}{\alpha + \beta + m_s} &gt; \frac{\text{costo de envío}}{\text{margen unitario}}\]</span></p>
<p><span class="math display" id="eq:esp">\[ \mathbb{E}(\theta_s \mid x_s) = \frac{\alpha + x_s}{\alpha + \tag{2.10}_s}(#eq:esp) \]</span></p>
<p><a href="modelos-probabilísticos.html#eq:esp">(2.10)</a></p>
</div>
</div>
<div id="modelos-integrados" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Modelos Integrados<a href="modelos-probabilísticos.html#modelos-integrados" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los Modelos Integrados permiten modelar fenómenos complejos que
incorporan más de uno de los modelos básicos planteados anteriormente.</p>
<p>En un caso hipótetico de los items no reportados, se tiene que estos
siguen una distribución de <em>Poisson</em>. Por otro lado, la elección para
escoger cuántos items declarar sigue una distribución <em>Binomial</em>. La
heterogeneidad se incluye con una distribución <em>Gamma</em> para la tasa del
modelo de conteo y con una distribución Beta para la probabilidad de
declaración. Entonces:</p>
<p><span class="math display" id="eq:integrado">\[
\begin{aligned}
P(X=k) &amp;= \sum_{n=k}^{\infty} P(X=k|N=n)\cdot P(N=n)\\
&amp;= \sum_{n=k}^{\infty} \left[ \int_{0}^{1} \binom{n}{k} \theta^k(1 - \theta)^{n-k} \cdot \frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha,\beta)} d\theta \right] \\
&amp;\qquad \cdot \left[ \int_{0}^{\infty} \frac{\lambda^n e^{-\lambda}}{n!}\cdot \frac{r^\alpha \lambda^{\alpha-1}e^{-r\lambda}}{\Gamma(\alpha)}d\lambda \right] \\
&amp;= \frac{\Gamma(\alpha+k)}{\Gamma(\alpha)k!} \left(\frac{r}{r+1}\right)^\alpha \left(\frac{1}{r+1}\right)^k \frac{\Gamma(\alpha&#39;+k)}{\Gamma(\alpha&#39;)} \frac{\Gamma(\alpha&#39;+\beta&#39;)}{\Gamma(\alpha&#39;+\beta&#39;+k)} \\
&amp;\qquad \cdot {_2F_1}\left(r+k, \beta&#39;; \alpha&#39;+\beta&#39;+k; \frac{1}{r+1}\right)
\end{aligned}
\quad \tag{2.11}
\]</span></p>
<p>El último termino es la función <em>Hypergeométrica Gaussiana</em>. Esta
función queda definida como:</p>
<p><span class="math display" id="eq:hypergauss">\[
\begin{aligned}
_2 F_1 (a,b;c;z) = \frac{\Gamma(c)}{\Gamma(a)\Gamma(b)} \sum_{j=0}^{\infty} \frac{\Gamma(a+j)\Gamma(b+j)}{\Gamma(c+j)} \frac{z^j}{j!}
\end{aligned}
\quad \tag{2.12}
\]</span></p>
<p>Como su cálculo puede ser complicado, puede usarse la siguiente
recursión:</p>
<p><span class="math display" id="eq:recursion">\[
\begin{aligned}
_2 F_1 (a,b;v;z) = \sum_{j=0}^{\infty} u_j \approx \sum_{j=0}^{M} u_j
\end{aligned}
\quad \tag{2.13}
\]</span></p>
<p>donde</p>
<ul>
<li><span class="math display">\[u_0=1\]</span></li>
<li></li>
</ul>
<p><span class="math display">\[\frac{u_j}{u_{j-1}}=\frac{(a+j-1)(b+j-1)}{(c+j-1)j} \text{           ,} \forall j \geq 1\]</span></p>
</div>
<div id="customer-lifetime-value-caso-contractual" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Customer Lifetime Value: Caso Contractual<a href="modelos-probabilísticos.html#customer-lifetime-value-caso-contractual" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><em>Database Marketing</em> posee dos elementos esenciales, tiempo de
permanencia con la firma e intensidad de compra mientras el cliente está
en la firma. Para el caso determinista se define Life Time Value (CLV)
como</p>
<p><span class="math display" id="eq:clv">\[
\begin{aligned}
CLV = \sum_{t=0}^T m \cdot \frac{r^t}{(1+d)^t}
\end{aligned}
\quad \tag{2.14}
\]</span></p>
<p>donde <span class="math inline">\(m\)</span> es el flujo neto por período (si el cliente está activo); <span class="math inline">\(r\)</span>
es la tasa de retención; <span class="math inline">\(d\)</span> es la tasa de descuento; y T es el
horizonte de evaluación.</p>
<p>Para el caso estocástico, sean <span class="math inline">\(\mathbb{E}(v(t))\)</span> valor esperado de los
flujos del cliente en el instante <span class="math inline">\(t\)</span> (asumiendo que está activo);
<span class="math inline">\(S(t)\)</span> la probabilidad que el cliente siga activo en el instante <span class="math inline">\(t\)</span>; y
<span class="math inline">\(d(t)\)</span> el factor de descuento que refleja el valor presente del dinero
recibido en el instante <span class="math inline">\(t\)</span>. El cálculo de CLV es:</p>
<p><span class="math display" id="eq:eclv">\[
\begin{aligned}
\mathbb{E}(CLV) = \int_{0}^{\infty} \mathbb{E}(v(t))S(t)d(t)dt
\end{aligned}
\quad \tag{2.15}
\]</span></p>
<p>Esta definición es inútil a menos que se operacionalice
<span class="math inline">\(\mathbb{E}(v(t))\)</span>, <span class="math inline">\(S(t)\)</span> y <span class="math inline">\(d(t)\)</span> para la situación particular.</p>
<p>Es importante distinguir entre situaciones contractuales y no
contractuales:</p>
<ul>
<li><p><strong>Contractual:</strong> Observamos cuando un cliente deja de estar activo.
Ejemplo: suscripción a una revista, plan VTR, etc.</p></li>
<li><p><strong>No Contractual:</strong> No observamos cuando un cliente deja de estarlo.</p></li>
</ul>
<p>El desafío de lo mercados contractuales: ¿Cómo diferenciamos aquellos
clientes que han terminado su relación con la firma, de aquellos que
simplemente están en un largo período de inactividad?</p>
<p>También se debe distinguir según la oportunidad de hacer la transacción:</p>
<ul>
<li><p><strong>Discreta:</strong> La acción puede realizarse en un número discreto de
ocasiones.</p></li>
<li><p><strong>Continua:</strong> La acción puede realizarse en cualquier momento.
Ejemplo, transacción con una tarjeta de crédito.</p></li>
</ul>
<div id="modelo-contractual-a-tiempo-discreto" class="section level3 hasAnchor" number="2.8.1">
<h3><span class="header-section-number">2.8.1</span> Modelo contractual a tiempo discreto<a href="modelos-probabilísticos.html#modelo-contractual-a-tiempo-discreto" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>En el mercado de las revistas, típicamente el 30 % renueva al final de
su primera suscripción, pero ese número salta al 50 % para la segunda
renovación y hasta el 75 % para subscriptores de mayor antigüedad
(Fielding, Michael (2005), “Get Circulation Going: DM Redesign Increases
Renewal Rates for Magazines”, Marketing News, September 1, 9-10).</em></p>
<p>Al evaluar las tasas de retención de una base de clientes, es necesario
considerar las diferencias entre las cohortes y proyectar los
comportamientos más allá de los que observamos.</p>
<p>Explicaciones alternativas (y complementarias) para el incremento de las
tasas de retención: Dinámicas a nivel individual (incremento de lealtad)
y un cambio en la mezcla de la composición de la población.</p>
<p><strong>Ejemplo:</strong> En un caso donde se analiza una cohorte de 10.000 clientes
que, en promedio, gastan $100 por período y que corresponden a dos
tipos de clientes:</p>
<ul>
<li><p><strong>Segmento 1:</strong> Un tercio de los clientes tiene una tasa de
retención (constante en el tiempo) de 0.9.</p></li>
<li><p><strong>Segmento 2:</strong> Dos tercios de los clientes tienen una tasa de
retención anual de 0.5.</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th></th>
<th>#Clientes activos</th>
<th></th>
<th></th>
<th>Tasa de retención</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Año</td>
<td>Seg-1</td>
<td>Seg-2</td>
<td>Total</td>
<td>Seg-1</td>
<td>Seg-2</td>
<td>Total</td>
</tr>
<tr class="even">
<td>1</td>
<td>3.333</td>
<td>6.667</td>
<td>10</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>2</td>
<td>3</td>
<td>3.334</td>
<td>6.334</td>
<td>0.9</td>
<td>0.5</td>
<td><span style="color: red;">0.633</span></td>
</tr>
<tr class="even">
<td>3</td>
<td>2.7</td>
<td>1.667</td>
<td>4.367</td>
<td>0.9</td>
<td>0.5</td>
<td><span style="color: red;">0.689</span></td>
</tr>
<tr class="odd">
<td>4</td>
<td>2.43</td>
<td>0.834</td>
<td>3.264</td>
<td>0.9</td>
<td>0.5</td>
<td><span style="color: red;">0.747</span></td>
</tr>
<tr class="even">
<td>5</td>
<td>2.187</td>
<td>0.417</td>
<td>2.604</td>
<td>0.9</td>
<td>0.5</td>
<td><span style="color: red;">0.798</span></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[\text{Cuadro 1.1: Rol de la heterogeneidad}\]</span></p>
<p>En el Cuadro 1.1 la tasa de retención agregada (en rojo en la tabla) es
decreciente aún cuando a nivel individual las retenciones son constantes
en el tiempo.</p>
<p>El valor residual de un cliente activo del cohorte, si pertenece al
segmento 1 es:</p>
<p><span class="math display" id="eq:erlv1">\[
\begin{aligned}
\mathbb{E}(RLV) = \sum_{t=1}^{\infty} \$100 \cdot \frac{0.9^t}{(1+0.1)^{t-1}} = \$495
\end{aligned}
\quad \tag{2.16}
\]</span></p>
<p>Si el cliente pertenece al segmento 2:</p>
<p><span class="math display" id="eq:erlv2">\[
\begin{aligned}
\mathbb{E}(RLV) = \sum_{t=1}^{\infty} \$100 \cdot \frac{0.5^t}{(1+0.1)^{t-1}} = \$92
\end{aligned}
\quad \tag{2.17}
\]</span></p>
<p>Sin embargo, la regla de Bayes permite mostrar que, condicional en estar
activo, un cliente es más probable que tenga una alta tasa de retención:</p>
<p><span class="math display">\[
\begin{aligned}
P(\text{seg-1|renovar 4 veces}) &amp;= \frac{P(\text{renovar 4 veces|seg-1}) P(\text{seg-1})}{P(\text{renovar 4 veces})}\\
&amp;= \frac{0.9^4 \cdot 0.3333}{0.9^4 \cdot 0.333 + 0.5^4 \cdot 0.6667}\\
&amp;= 0.84
\end{aligned}
\]</span></p>
<p>Luego, el <em>Lifetime Value Residual</em> viene dado por:</p>
<p><span class="math display">\[\mathbb{E}(RLV) = 0.84 \cdot  \$495 + (0.84) \cdot \$ 92 = \$493.08 \]</span>En
mercados contractuales, ¿cuánto se pierde si no no se considera la
heterogeneidad?. En este ejemplo, si se toma en cuenta la tasa de
retención agregada, el valor de la base de clientes es $4.945.049. En
cambio, si se distingue por segmentos, este valor asciende a
$7.940.992.</p>
<p>En estudios con bases de datos reales muestran que el error en el CLV se
eleva hasta el 50%. El impacto sobre el CLV de aumentar las tasas de
retención es hasta un 50%. Para calcular CLV hay que hacerlo condicional
en la duración.</p>
<p>Se postulan los siguientes supuestos para el caso discreto:</p>
<ol style="list-style-type: decimal">
<li><p>La tasa de retención a nivel individual es <span class="math inline">\(1- \theta\)</span>:</p>
<p><span class="math display" id="eq:treti">\[
\begin{array}{cc}
S(t|\theta) = (1-\theta)^t, &amp;t=1,2,3,...
\end{array}
\quad \tag{2.18}
\]</span></p></li>
<li><p>La heterogeneidad en <span class="math inline">\(\theta\)</span> es capturada por una distribución
<span class="math inline">\(\text{Beta}\)</span><em>:</em></p>
<p><span class="math display" id="eq:hetebeta">\[
f(\theta|\alpha,\beta) = \frac{\theta^{\alpha -1}(1-\theta)^{\beta -1}}{B(\alpha,\beta)} \quad \tag{2.19}
\]</span></p></li>
</ol>
<p>La probabilidad de que el cliente siga activo en <span class="math inline">\(t\)</span>:</p>
<p><span class="math display">\[
\begin{array}{cc}
S(t|\alpha,\beta) = \int_{0}^{1} S(t|\theta) f(\theta|\alpha,\beta) d\theta = \frac{B(\alpha,\beta+t)}{B(\alpha,\beta)}, &amp;t = 1,2,3,...
\end{array}
\]</span></p>
<p>Considerando a un cliente que ha estado activo por n períodos:</p>
<p><span class="math display" id="eq:erlvactivo">\[
\begin{aligned}
\mathbb{E}(\text{RLV}(d| \text{activo en } n \text{ períodos})) &amp;= \sum_{t=n+1}^{\infty} \mathbb{E}(v(t)) \cdot \frac{S(t|t&gt;n)}{(1+d)^{t-n}}\\
&amp;= \bar{v} \sum_{t=n+1}^{\infty} \frac{S(t|t&gt;n)}{(1+d)^{t-n}}, \quad \text{Asumiendo flujos constantes}
\end{aligned}
\quad \tag{2.20}
\]</span></p>
<p>DERL es el valor esperado residual del cliente (condicional en la
antigüedad). Para el caso de la distribución geométrica desplazada:</p>
<p><span class="math display" id="eq:derl">\[
\begin{aligned}
\text{DERL}(d| \text{activo en } n \text{ períodos}) &amp;= \sum_{t=n}^{\infty} \frac{S(t)}{S(n-1)} \cdot \left(\frac{a}{a+d}\right)^{t-n}\\
&amp;= \frac{(1-\theta)(1+d)}{d+\theta}
\end{aligned}
\quad \tag{2.21}
\]</span></p>
<p>Cuando la tasa de abandono <span class="math inline">\(\theta\)</span> no es observable, hay que encontrar
la distribución de esta variable en la población. Para ello se usa la
regla de Bayes para calcular la distribución posterior condicional en la
antigüedad.</p>
<p><span class="math display" id="eq:derlno">\[
\begin{aligned}
\text{DERL}(d|\alpha,\beta, \text{activo en } n \text{ períodos}) &amp;= \int_0^1 \frac{(1-\theta)(1+d)}{d+\theta} \cdot \frac{S(n-1|\theta)f(\theta|\alpha,\beta)}{S(n-1|\alpha, \beta)} d\theta \\
&amp;= \left(\frac{\beta + n - 1}{\alpha + \beta + n - 1}\right) \\
&amp;\quad \cdot_2 F_1 \left( 1,\beta + n; \alpha + \beta + n; \frac{1}{1+d}\right)
\end{aligned}
\quad \tag{2.22}
\]</span></p>
</div>
<div id="modelo-contractual-a-tiempo-continuo" class="section level3 hasAnchor" number="2.8.2">
<h3><span class="header-section-number">2.8.2</span> Modelo contractual a tiempo continuo<a href="modelos-probabilísticos.html#modelo-contractual-a-tiempo-continuo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Algunos supuestos son:</p>
<ol style="list-style-type: decimal">
<li><p>La duración de la relación de un cliente con la firma está
caracterizada por una distribución exponencial, con densidad y
función de sobrevivencia dadas por:</p>
<p><span class="math display" id="eq:fsur">\[
f(t|\lambda) = \lambda e^{-\lambda t} \quad \tag{2.23}
\]</span> <span class="math display" id="eq:ssur">\[
S(t|\lambda) = e^{-\lambda t} \quad \tag{2.24}
\]</span></p></li>
<li><p>La heterogeneidad en <span class="math inline">\(\lambda\)</span> es capturada por una distribución
<span class="math inline">\(\text{Gamma}\)</span>:</p>
<p><span class="math display" id="eq:hgamma">\[
g(\lambda|r,\alpha) = \frac{\alpha^r\lambda^{r-1}e^{-\alpha\lambda}}{\Gamma(r)} \quad \tag{2.25}
\]</span></p></li>
</ol>
<p>Entonces, la probabilidad de seguir activo en <span class="math inline">\(t\)</span> es:</p>
<p><span class="math display" id="eq:sactiv">\[
\begin{aligned}
S(t|r,\alpha) &amp;= \int_0^{\infty} S(t|\lambda)g(\lambda|r,\alpha)d\lambda\\
&amp;= \left(\frac{\alpha}{\alpha+t}\right)^r
\end{aligned}
\quad \tag{2.26}
\]</span></p>
<p>El valor esperado de <span class="math inline">\(\text{Residual Lifetime Value}\)</span> es:</p>
<p><span class="math display" id="eq:sactiv">\[
\begin{aligned}
\mathbb{E}(\text{RLV}(\delta|\text{activo en }s)) &amp;= \int_{s}^{\infty} \mathbb{E}(v(t))S(t|t&gt;s)\delta(t)dt\\
&amp;= \bar{v} \cdot \text{DERL}(\delta|r,\alpha,\text{activo en }s)
\end{aligned}
\quad \tag{2.26}
\]</span></p>
<p>donde</p>
<p><span class="math display" id="eq:drldos">\[
\text{DERL}(\delta|r,\alpha,\text{activo en }s) = (\alpha+s)^r\delta \Psi (r;r;(\alpha +s) \delta) \quad \tag{2.27}
\]</span></p>
<p><span class="math inline">\(\Psi\)</span> es la <em>función hiper geométrica confluyente del segundo tipo</em>.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modelos-de-regresión.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="modelos-estructurales.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/rstudio/bookdown-demo/edit/master/02-probabilisticos.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
