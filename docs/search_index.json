[["modelos-probabilísticos.html", "Capítulo 2 Modelos probabilísticos 2.1 Introducción 2.2 Modelos de Duración 2.3 Modelos de Conteo 2.4 Modelos de Elección Binaria binomial 2.5 Heterogeneidad observable 2.6 Esperanzas Condicionales", " Capítulo 2 Modelos probabilísticos 2.1 Introducción Usualmente, y en el contexto de Marketing, interesa estudiar el comportamiento de las personas, para realizar acciones estratégicas en función de los aprendizajes adquiridos. Así, se pueden definir dos tipos de enfoques a usar según distintos supuestos en el comportamiento de los agentes (tomadores de decisiones): Enfoque Estructural: Este enfoque asume que los los agentes se comportan de manera racional, tomando decisiones de modo de maximizar sus utilidades. Usualmente aparece cuando hay disponibilidad de largos volúmenes de datos. Modelos Probabilísticos: Este enfoque asume que los agentes se comportan en base a decisiones aleatorias. Usualmente aparece cuando se tiene información reducida y/o agregada respecto al comportamiento de los agentes en estudio. En esta unidad, se estudiará el enfoque probabilístico. Metodología La metodología consiste en: Determinar el problema de decisión a estudiar y la información requerida. Identificar el comportamiento observable de interés a nivel individual. Seleccionar la distribución de probabilidad que caracterice el comportamiento individual. Se consideran los parámetros de esta distribución, como características latentes a nivel individual. Escoger la distribución que caracterice cómo las características latentes están distribuidas en la población. Se le llama distribución mixta o heterogénea. Típicamente, se denota con \\(g(\\theta)\\). Derivar la distribución agregada, o distribución observable, del comportamiento de interés. \\[ \\begin{array}{cc} f(x) = \\int f(x \\mid \\theta)\\, g(\\theta)\\, d\\theta &amp; \\text{, para el caso continuo.} \\\\ p(x) = \\sum_{i}f(x \\mid \\theta)\\, \\Pr(\\theta = \\theta_{i}) &amp; \\text{, para el caso discreto.} \\end{array} \\] Estimar los parámetros del modelo (de la distribución mixta), mediante el ajuste de la distribución agregada a los datos observados. Usar los resultados para tomar una decisión sobre el problema de marketing en cuestión. El enfoque de modelos probabilísticos permite abordar una gran cantidad de problemas asociados al marketing, entre los cuales se considerarán: Duración: Situaciones ligadas a la duración de una determinada conducta de un cliente, como por ejemplo el tiempo de permanencia en una compañía y el tiempo de adopción de un cierto producto innovador. Conteo: Situaciones ligadas al estudio de llegadas de clientes y contabilización de una determinada conducta, como por ejemplo el número de visitas a un portal web y la cantidad de productos comprados en una tienda de retail. Elección: Situaciones asociadas a las decisiones de elección de un determinado cliente, como por ejemplo el número de clientes que eligen responder una campaña publicitaria y la elección de cambiar o no de canal de televisión. 2.2 Modelos de Duración En años recientes, las mejoras en las tecnologías de información han dado como resultado un aumento en la disponibilidad de data acerca de los individuos en determinadas situaciones de consumo. Esta tendencia se relaciona íntimamente con el creciente deseo de los gerentes de marketing respecto a utilizar esta data disponible para aprender de manera exhaustiva sobre el comportamiento de los clientes. Muchos analistas tratan de describir y predecir el comportamiento de los consumidores usando variables observables, como lo son variables transaccionales (monto gastado, tienda donde se adquirió un determinado producto, fecha de la compra, etc.), como así también variables que caracterizan a los individuos (edad, nivel socio-económico, estado civil, etc.). A partir de esta información es posible aplicar modelos de regresión lineal o árboles de decisión, con el objetivo de poder proyectar comportamientos, o bien rebatir hipótesis que previamente se tenían respecto a un escenario determinado. En este capítulo, se considera un enfoque distinto al anterior, en el cual las decisiones de los individuos se desprenden de un comportamiento aleatorio, en que las decisiones no dependen únicamente de variables descriptivas del modelo, sino que también provienen del resultado de un proceso estocástico no observable que opera intrínsecamente en los individuos. Es decir, la asunción que el comportamiento se desprende de una distribución de probabilidades que puede variar dependiendo del modelo a estimar y de la complejidad del mismo. Alternativamente, se puede considerar el enfoque racionalista que contempla a los individios que siempre actúan racionalmente, lo que, de acuerdo a la experiencia empírica, no se cumple siempre. Ejemplo 1: Supongamos que un cliente hizo 2 compras el año pasado de nuestro producto. ¿Esto implica inmediatamente que el consumidor mantendrá ese patrón y este año volverá a ese nivel de consumo? ¿O existe alguna posibilidad de que el cliente incremente o disminuya su consumo? ¿Cuál es el proceso que hay detrás? En lo que sigue, se considera 3 tipos de modelos de duración a estimar: Modelos de duración en tiempo discreto. Modelos de duración en tiempo continuo sin dependencia en la duración. Modelos de duración en tiempo continuo con dependencia en la duración. 2.2.1 Modelos de duración de tiempo discreto Como ejemplo, se tiene el siguiente escenario: a través de una propuesta de valor atractiva, una empresa consigue un cliente. ¿Durante cuántos periodos estará afiliado a la compañía? Se considera que cada periodo se puede cuantificar en términos discretos (días, semanas, meses, años). Algunos ejemplos a considerar: Un usuario descarga una aplicación para su teléfono inteligente. ¿Por cuántos meses la utilizará? Adquirimos un cliente en un banco. ¿Durante cuántos años permanecerá como cliente? Un cliente se suscribe a un plan telefónico o de internet. ¿Por cuántos periodos se mantendrá suscrito? Modelo Geométrico Desplazado Como ejemplo, se asume que se tiene una cartera de clientes que van abandonando la relación comercial para nunca más retomarla en cualquier periodo definido. Al final de cada periodo, un cliente decide de manera aleatoria si continúa afiliado. De acuerdo a un proceso de Bernoulli, hay una probabilidad \\(\\theta\\) de cancelar la relación comercial con la empresa y con el complemento \\(1-\\theta\\) decide su permanencia. Para cada individuo, se asume que la probabilidad con la que decide no cambia en el tiempo. Como primer acercamiento, se asume que dicha probabilidad es igual e idénticamente distribuida (iid). Sea T la variable aleatoria relativa a la duración de la relación comercial entre el cliente y la compañía, es decir la variable que describe el instante en el cual esta relación se acaba. De acuerdo a la descripción anterior, la variable aleatoria T sigue una distribución Geométrica Desplazada (sG) con parámetro \\(\\theta\\), es decir, el comportamiento de los individuos puede ser descrito formalmente de acuerdo a la siguiente relación: Probabilidad de que un individuo cualquiera abandone la relación comercial exactamente en el periodo t: \\[P(T=t| \\theta) = \\theta (1 - \\theta)^{t-1}\\] Probabilidad de que un individuo cualquiera abandone la relación comercial en un periodo posterior al periodo t: \\[P(T&gt;\\tau| \\theta) = \\theta (1 - \\theta)^{\\tau}\\] No es muy difícil aplicar un modelamiento a partir de lo anterior para intentar dilucidar de qué forma se debería comportar un determinado grupo de individuos a partir de la data transaccional que se tiene. Ejemplo: Se considera una cohorte inicial de 1000 clientes (indexado por el número 0). Se toma el supuesto de que, año a año, un determinado número de clientes se retira del negocio por razones que se desconocen a priori, pero que provienen de un proceso estocástico en el que cada cliente en forma independiente toma la decisión de permanecer o abandonar a partir del lanzamiento de una moneda (Bernoulli). Esto es, con probabilidad \\(\\theta\\) abandona y con probabilidad \\(1 - \\theta\\) permanece en la compañía. La data histórica se presenta a continuación: Año # de Clientes % de Permanencia % de Retención 0 1000 100% - 1 631 63% 63% 2 468 47% 74% 3 382 38% 82% 4 326 33% 85% 5 289 29% 89% 6 262 26% 91% 7 241 24% 92% Donde el % de Retención como el porcentaje de clientes que se mantuvo en la relación comercial respecto al periodo anterior. Sin embargo, aún no se desconoce el valor de \\(\\theta\\) (es un parámetro poblacional). Dicho valor se estima mediante el método de máxima verosimilitud, que busca encontrar el valor del parámetro óptimo de acuerdo a los datos observados y asumiendo independencia entre las muestras: Densidad de probabilidades conjunta: \\[f(x_1,x_2,...,x_n|\\theta) = f(x_1|\\theta) \\cdot f(x_2|\\theta) \\cdot ... \\cdot f(x_n|\\theta)\\] Función de verosimilitud: \\[ \\begin{aligned} L(\\theta) &amp;= \\left\\{\\prod_{t=1}^{\\tau=7} P(T=t \\mid \\theta)^{\\,n_t}\\right\\}\\; P(T&gt;\\tau \\mid \\theta)^{\\,n_{\\tau}} \\\\ &amp;= \\left\\{\\prod_{t=1}^{\\tau=7} \\big[\\theta(1-\\theta)^{t-1}\\big]^{\\,n_t}\\right\\}\\; \\big[(1-\\theta)^{\\tau}\\big]^{\\,n_{\\tau}} \\end{aligned} \\] Notar que \\(n_\\tau\\) es el número de clientes activos después del máximo tiempo observable \\(\\tau\\), \\(n_t\\) es el número de abandonos (si hay 369 abandonos, se multiplica 369 veces), y \\(x_i\\) el año. A partir de esto y de la data disponible, las contribuciones a la verosimilitud son las siguientes (asumiendo como modelo de comportamiento la distribución geométrica desplazada) Año # de Clientes # de Abandonos Pr 0 1000 - - 1 631 369 \\(P(T=1\\|\\theta) = \\theta^{369}\\) 2 468 163 \\(P(T=2\\|\\theta) = ((1 - \\theta)^{(2-1)} \\cdot \\theta)^{163}\\) 3 382 86 \\(P(T=3\\|\\theta) = ((1 - \\theta)^{(3-1)} \\cdot \\theta)^{86}\\) 4 326 56 \\(P(T=4\\|\\theta) = ((1 - \\theta)^{(4-1)} \\cdot \\theta)^{56}\\) 5 289 37 \\(P(T=5\\|\\theta) = ((1 - \\theta)^{(5-1)} \\cdot \\theta)^{37}\\) 6 262 27 \\(P(T=6\\|\\theta) = ((1 - \\theta)^{(6-1)} \\cdot \\theta)^{27}\\) 7 241 21 \\(P(T=7\\|\\theta) = ((1 - \\theta)^{(7-1)} \\cdot \\theta)^{21}\\) &gt;7 - - \\(P(T&gt;7\\|\\theta) = ((1-\\theta)^7)^{241}\\) Dado que maximizar un producto es complicado, se aplica logaritmo a lo anterior, de modo de construir la función de log verosimilitud: Función de log verosimilitud: \\[ \\begin{aligned} \\hat{\\ell}(\\theta) &amp;= \\sum_{t=1}^{\\tau} n_t \\,\\ln P(T=t \\mid \\theta)\\;+\\; n_{\\tau}\\,\\ln P(T&gt;\\tau \\mid \\theta) \\\\ &amp;= \\sum_{t=1}^{\\tau} n_t \\big[\\ln \\theta + (t-1)\\ln(1-\\theta)\\big]\\;+\\;n_{\\tau}\\,\\tau\\ln(1-\\theta) \\end{aligned} \\] Con lo anterior, es sencillo maximizar la función de log verosimilitud para un \\(\\theta\\) desconocido utilizando un paquete estadístico como R, con lo que se tiene: \\[ \\begin{aligned} \\hat{\\theta} &amp;= 0, 226027 \\\\ \\hat{l} &amp;= -1794,62 \\end{aligned} \\quad \\tag{2.1} \\]El modelo presentado, si bien permite tomar medidas de gestión a partir de un modelo sencillo, es poco realista, pues se asume que la población posee igual probabilidad de abandono. Una manera de incluir mayor complejidad al modelo y hacerlo más robusto, se asume que la población no es homogénea, sino que existen segmentos de individuos quienes al ser agrupados, presentan un comportamiento similar (heterogéneo). La forma más sencilla de modelar esto es asumiendo que la población presenta 2 patrones de comportamiento o 2 segmentos. Para un segmento de individuos, la decisión de abandonar o permanecer se identifica a partir de un parámetro \\(\\theta_1\\) (del mismo modo que en el caso anterior) y, para el otro segmento, la decisión se determina a partir de un parámetro \\(\\theta_2\\) distinto de \\(\\theta_1\\). Formalmente, las relaciones que describen de mejor manera esto son las siguientes: Probabilidad de que un individuo cualquiera abandone la relación comercial exactamente en el periodo \\(t\\) en una población con 2 segmentos: \\[P(T=t|\\theta_1, \\theta_2, \\pi)= \\theta_1 (1-\\theta_1)^{t-1} \\pi + \\theta_2(1-\\theta_2)^{t-1}(1-\\pi)\\] 2. Probabilidad de que un individuo cualquiera abandone la relación comercial en un periodo posterior al periodo \\(t\\) en una población con 2 segmentos: \\[P(T&gt;t|\\theta_1, \\theta_2, \\pi)= (1-\\theta_1)^{t} \\pi + (1-\\theta_2)^{t}(1-\\pi)\\] En el modelo anterior, \\(\\pi\\) representa el porcentaje de la población que pertenece al segmento 1, de tal forma que su complemento \\(1-\\pi\\) representa el porcentaje de la población que pertenece al segmento 2. Cabe mencionar que se puede expandir a más segmentos, siempre que sepamos su proporción \\(\\pi\\). Modelo Beta Geométrico desplazado Los modelos anteriores funcionan bien cuando la población se comporta de manera distinta entre clases latentes, y similar al interior de cada clase latente. Sin embargo, puede ser mucho más realista e interesante asumir que existe una heterogeneidad continua en la población, es decir, que existe un número infinito de segmentos (o al menos tendiente a infinito) de manera de capturar todas las preferencias individuales de cada miembro de la población considerada. Para estos propósitos, ya no asumiremos que la probabilidad de abandono \\(\\theta\\) sigue una distribución discreta de Bernoulli (éxito-fracaso), sino que asumiremos que el parámetro proviene de una distribución continua \\(\\text{Beta}\\) de parámetros \\(\\alpha\\) y \\(\\beta\\). Por tanto, es posible calcular las probabilidades antes presentadas en forma análoga, aplicando el enfoque antes mencionado (probabilidades totales): Probabilidad de que un individuo cualquiera abandone la relación comercial exactamente en el periodo t: \\[P(T=t|\\alpha,\\beta) = \\int_0^1 P(T=t|\\theta)B(\\theta|\\alpha,\\beta)d\\theta\\] Donde: \\[B(\\theta|\\alpha,\\beta) = \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)}\\] \\[B(\\alpha,\\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\\] 2. Probabilidad de que un individuo cualquiera abandone la relación comercial en un periodo posterior al periodo t: \\[P(T&gt;t|\\alpha,\\beta) = \\int_0^1 (T&gt;t|\\theta)B(\\theta|\\alpha,\\beta)d\\theta\\] Al desarrollar la primera integral antes mencionada, y reconociendo las relaciones de la distribución Beta, se tiene que: \\[ \\begin{aligned} P(T = t \\mid \\alpha, \\beta) &amp;= \\int_0^1 \\left( \\theta(1-\\theta)^{t-1} \\right) \\left( \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)} \\right) d\\theta \\\\ &amp;= \\frac{1}{B(\\alpha, \\beta)} \\int_0^1 (\\theta \\cdot \\theta^{\\alpha-1}) \\cdot ((1-\\theta)^{t-1} \\cdot (1-\\theta)^{\\beta-1}) d\\theta \\\\ &amp;= \\frac{1}{B(\\alpha, \\beta)} \\int_0^1 \\theta^{\\alpha} (1-\\theta)^{t+\\beta-2} d\\theta \\\\ &amp;= \\frac{B(\\alpha+1, t+\\beta-1)}{B(\\alpha, \\beta)} \\end{aligned} \\] Notar que se usa indistintamente el \\(B(\\alpha,\\beta)\\) para hacer alusión tanto a la función como a la distribución Beta. Bajo ninguna circunstancia dichos objetos son iguales. El desarrollo de la segunda integral es: \\[ \\begin{aligned} P(T &gt; t \\mid \\alpha, \\beta) &amp;= \\int_0^1 (1-\\theta)^{t} \\left( \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)} \\right) d\\theta \\\\ &amp;= \\frac{1}{B(\\alpha, \\beta)} \\int_0^1 \\theta^{\\alpha-1} \\cdot ((1-\\theta)^{t} \\cdot (1-\\theta)^{\\beta-1}) d\\theta \\\\ &amp;= \\frac{1}{B(\\alpha, \\beta)} \\int_0^1 \\theta^{\\alpha-1} (1-\\theta)^{t+\\beta-1} d\\theta \\\\ &amp;= \\frac{B(\\alpha, t+\\beta)}{B(\\alpha, \\beta)} \\end{aligned} \\] Ejemplo: Considerando la misma situación que se presentó en el ejemplo anterior (clientes que año a año abandonan la relación comercial), pero ahora asumiendo que existe un comportamiento heterogéneo en la población, es posible reconocer que existe una recursividad en la fórmula del cálculo de la probabilidad de abandono en cada período: \\[ \\begin{aligned} \\text{Caso Base (t=1):}&amp; \\\\ P(T=1 \\mid \\alpha, \\beta) &amp;= \\frac{B(\\alpha+1, \\beta)}{B(\\alpha, \\beta)} \\\\ &amp;= \\frac{\\frac{\\Gamma(\\alpha+1)\\Gamma(\\beta)}{\\Gamma(\\alpha+1+\\beta)}}{\\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}} \\\\ &amp;= \\frac{\\Gamma(\\alpha+1)}{\\Gamma(\\alpha)} \\cdot \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha+\\beta+1)} \\\\ &amp;= \\frac{\\alpha\\Gamma(\\alpha)}{\\Gamma(\\alpha)} \\cdot \\frac{\\Gamma(\\alpha+\\beta)}{(\\alpha+\\beta)\\Gamma(\\alpha+\\beta)} \\\\ &amp;= \\frac{\\alpha}{\\alpha+\\beta} \\\\ \\\\ \\text{Paso Recursivo (t &gt; 1):}&amp; \\\\ \\frac{P(T=t \\mid \\alpha, \\beta)}{P(T=t-1 \\mid \\alpha, \\beta)} &amp;= \\frac{B(\\alpha+1, t+\\beta-1)}{B(\\alpha+1, t+\\beta-2)} \\\\ &amp;= \\frac{\\frac{\\Gamma(\\alpha+1)\\Gamma(t+\\beta-1)}{\\Gamma(\\alpha+t+\\beta)}}{\\frac{\\Gamma(\\alpha+1)\\Gamma(t+\\beta-2)}{\\Gamma(\\alpha+t+\\beta-1)}} \\\\ &amp;= \\frac{\\Gamma(t+\\beta-1)}{\\Gamma(t+\\beta-2)} \\cdot \\frac{\\Gamma(\\alpha+t+\\beta-1)}{\\Gamma(\\alpha+t+\\beta)} \\\\ &amp;= \\frac{(t+\\beta-2)\\Gamma(t+\\beta-2)}{\\Gamma(t+\\beta-2)} \\cdot \\frac{\\Gamma(\\alpha+t+\\beta-1)}{(\\alpha+t+\\beta-1)\\Gamma(\\alpha+t+\\beta-1)} \\\\ &amp;= \\frac{\\beta+t-2}{\\alpha+\\beta+t-1} \\\\ &amp;= P(T=t-1 \\mid \\alpha, \\beta) \\frac{\\beta+t-2}{\\alpha+\\beta+t-1} \\end{aligned} \\] Modelo que al ser evaluado, da el siguiente resultado: \\[ \\begin{array}{c} \\hat{\\alpha} = 0,7041\\\\ \\hat{\\beta}= 1,1820\\\\ \\hat{l} = -1680,27 \\end{array} \\quad \\tag{2.2} \\] Notar que existe una notoria diferencia en cuanto al valor de la log verosimilitud obtenida por el modelo (2.2) respecto al modelo (2.1). Si bien esto indica una mejora del modelo, es necesario realizar la comparación en base a métricas de evaluación mas precisas (AIC, BIC, etc.) 2.2.2 Modelos de duración en tiempo continuo sin dependencia en la duración Para algunos modelos, medir el tiempo como si fueran períodos discretos puede ser un buena aproximación de acuerdo a los objetivos del análisis que se desea llevar a cabo. En otros casos, puede ser en cambio más útil considerar el tiempo como una variable continua, debido a que podría interesar medir la ocurrencia de un suceso de manera más exacta. Algunos casos relativos a este enfoque son: Tiempos de respuesta a una campaña promocional de marketing directo. Tiempo entre visitas a nuestro website. Tiempos entre llamadas en un call center. Tiempos de operación en la industria de servicios. Al igual que en el caso de los modelos en tiempo discreto, lo que interesa estudiar es poder implementar un modelo que tenga una forma funcional flexible para ser trabajada y modificada fácilmente, que logre ajustar a la data histórica que se tiene y proyectar el comportamiento futuro de los clientes, es decir, que sea un buen modelo predictivo para tomar acciones en función de aquello. Modelo Exponencial Se puede medir el tiempo que pasa desde que se lanza un producto hasta que el consumidor decide adquirirlo. Existen muchos factores externos que determinan esta decisión: exposición a publicidad, número de visitas a la tienda, llamadas recibidas por call center, entre otras. Nuevamente se asume que el comportamiento es aleatorio, es decir, que los consumidores deciden el momento en el cuál van a consumir a partir de una distribución de probabilidades. Esto puede verse con una distribución exponencial, con la variable aleatoria \\(t\\) definida como el tiempo en que un cliente va a consumir el producto por primera vez. Se asume que esta variable está exponencialmente distribuida con una tasa \\(\\lambda\\). De esta forma, se tiene que el comportamiento de los consumidores puede verse como: Probabilidad de que ocurra en \\(t\\) o antes: \\[P(T \\leq t) = 1 - e^{-\\lambda t}\\] Probabilidad de que ocurra después de \\(t\\): \\[ P(T &gt; t) = e^{-\\lambda t} \\] Por tanto, su función de verosimilitud para un tiempo continuo corresponde a: \\[ \\begin{aligned} L(\\theta) &amp;= \\prod_{i \\in A} f(t_i | \\theta) \\prod_{i \\notin A} (1 - P(T \\leq t)) \\\\ &amp;= \\prod_{i \\in A} (\\theta e^{-\\theta t_i}) \\prod_{i \\notin A} (e^{-\\theta \\tau_i}) \\end{aligned} \\] Acá \\(f(t_i \\mid \\theta)\\) es la función de densidad, es decir, la derivada de la función de probabilidad acumulada \\(P(T \\leq t)\\). El índice \\(i\\) corresponde a cada cliente y \\(A\\) es el conjunto de clientes que adquiere un producto o servicio. El parámetro \\(\\tau\\), al igual que en el modelo de duración discreta, corresponde al tiempo máximo observado. Ahora bien, esto inmediatamente deja en evidencia una limitante a este modelo: para un \\(t\\) muy grande, todos los consumidores van a tener un caso de éxito (Recordar que \\(\\text{lim } e^{-t} = 0\\)), lo cual no es una situación del todo realista. Es necesario, en consecuencia, imponer que existe una fracción de clientes dentro de la muestra considerada que nunca probará el producto (caso de éxito) y, así, es posible solucionar la limitante encontrada (2 clases latentes). Segmento que prueba: Tamaño \\(\\pi\\): \\[ \\begin{array}{c} \\lambda = \\theta\\\\ \\Rightarrow P(T \\leq t) = 1 - e^{-\\theta t} \\end{array} \\] Segmento que no prueba: Tamaño (\\(1-\\pi\\)): \\[ \\begin{array}{c} \\lambda = 0\\\\ \\Rightarrow P(T \\leq t) = 0 \\end{array} \\] Luego, la probabilidad total será: \\[ \\begin{array}{c} P(T \\leq t) = P(T \\leq t | \\text{Prueba}) P(\\text{Prueba}) + P(T \\leq t | \\text{No Prueba}) P(\\text{No Prueba}) \\\\ = 1 - e^{-\\theta t}\\pi \\end{array} \\] Es importante notar que si bien el modelo describe probabilidades en tiempo continuo, la data aún se presenta y obtiene en tiempo discreto. Incorporando esto, es posible construir la función de log verosimilitud calculando las probabilidades de adopción del producto entre los límites del intervalo temporal definido por el periodo de medición, es decir: \\[P(t_0 \\leq T \\leq t_1) = F(t_1) - F(t_0)\\] Cconsiderando n periodos discretos para el cálculo, la log-verosimilitud es: \\[LL(\\pi,\\theta|\\text{data}) = N_1 ln[P(1\\leq T \\leq 2)] + ... + (N_{panel} - \\sum_{i=1}^{n}N_i)ln[P(T&gt;n)]\\] Adicionalmente, es de interés calcular los valores predichos por el modelo, de modo de realizar predicciones futuras. \\(F(t)\\) representa la probabilidad que un cliente escogido aleatoriamente pruebe el producto en \\(t\\), tal que \\(t=0\\) corresponde al instante de lanzamiento del producto. La estimación del futuro se puede hacer a través de la esperanza: \\[\\mathbb{E}[T(t)] = N_{\\text{panel }} \\cdot \\hat{F}(t) \\] Antes de avanzar, es importante aclarar la distinción de un modelo sin dependencia en la duración. Esto se puede explicar con la propiedad fundamental de la distribución exponencial: Propiedad fundamental: La distribución exponencial no tiene memoria, es decir, poseer información de que un elemento ha sobrevivido un tiempo ’s’ hasta este momento no modifica la probabilidad de que sobreviva un periodo \\(t\\) más. Es decir la probabilidad de que ocurra un suceso no depende del tiempo en que aún no ha ocurrido. Se puede demostrar matemáticamente: \\[P(T &gt; s + t|T&gt;s) = \\frac{P(T&gt; s+t)}{P(T&gt; s)} = \\frac{1-P(T \\leq s+t)}{1-P(T \\leq s)}= \\frac{e^{-\\lambda(s+t)}}{e^{-\\lambda s}} = e^{-\\lambda t}\\] 2.2.2.1 Modelo Gamma Exponencial Análogamente al caso de duración discreta, hay casos en que el comportamiento de la población heterogéneo. Esto busca complejizar la suposición que antes se hizo al considerar un grupo de clientes que nunca consume. Por tanto, el modelo con heterogeneidad no observada ahora considerará que la tasa de prueba \\(\\lambda\\) se distribuye Gamma en la población: \\[g(\\lambda) = \\frac{\\alpha^r \\lambda^{r-1} e^{-\\alpha \\lambda}}{\\Gamma(r)}\\]Donde \\(r\\) es un parámetro de forma mide la morfología. Con \\(r=1\\) se reduce a una exponencial y, a medida que crece, su la forma se vuelve más simétrica y similar a una normal. Por otro lado, \\(\\alpha\\) es un parámetro de escala que estira la distribución a medida que crece, o la comprime en la medida que decrece. Al incorporar la heterogeneidad mencionada, la probabilidad que un cliente adquiera un producto antes de un tiempo \\(t\\) es la siguiente: \\[ \\begin{aligned} P(T\\leq t) &amp;= \\int_{0}^{\\infty} P(T \\leq t|\\lambda) g(\\lambda)d \\lambda \\\\ &amp;= \\int_{0}^{\\infty} (1 - e^{-\\lambda t}) \\left( \\frac{\\alpha^r}{\\Gamma(r)} \\lambda^{r-1} e^{-\\alpha \\lambda} \\right) d\\lambda \\\\ &amp;= \\int_{0}^{\\infty} \\frac{\\alpha^r}{\\Gamma(r)} \\lambda^{r-1} e^{-\\alpha \\lambda} d\\lambda - \\int_{0}^{\\infty} e^{-\\lambda t} \\frac{\\alpha^r}{\\Gamma(r)} \\lambda^{r-1} e^{-\\alpha \\lambda} d\\lambda \\\\ &amp;= 1 - \\frac{\\alpha^r}{\\Gamma(r)} \\int_{0}^{\\infty} \\frac{\\lambda^{r-1} e^{-\\lambda(\\alpha+t)} \\Gamma(r) (\\alpha + t)^r}{\\Gamma(r) (\\alpha + t)^r} d\\lambda \\\\ &amp;= 1 - \\frac{\\alpha^r}{\\Gamma(r)} \\frac{\\Gamma(r)}{(\\alpha+t)^r} \\\\ &amp;= 1 - \\left(\\frac{\\alpha}{\\alpha + t}\\right)^r \\end{aligned} \\] Donde en el cuarto paso se agregó un 1 en forma de \\(\\frac{\\Gamma(r) (\\alpha + t)^r}{\\Gamma(r) (\\alpha + t)^r}\\) para obtener una función de acumulación de dominio completo para la distribución gamma (lo que al integrarlo da 1). 2.2.3 Modelos de duración en tiempo continuo con dependencia en la duración Otra de las grandes limitantes del modelo Exponencial es que posee pérdida de memoria. En algunas aplicacioens se requiere incorporar esta distinción, es decir, la probabilidad de que un evento ocurra dado que hasta este momento no ha ocurrido. Esto último se conoce como tasa de riesgo o hazard rate: \\[h(t) = \\frac{f(t)}{1 - F(t)}\\] Donde \\[ \\begin{aligned} f(t) &amp;= \\frac{d}{dt} F(t) \\\\ &amp;= -c\\lambda t^{c-1} e^{-\\lambda t^c} \\end{aligned} \\] Gráficamente, la tasa de riesgo se comporta de la siguiente manera: knitr::include_graphics(rep(&quot;images/tasa_riesgo.png&quot;)) Figure 2.1: Ejemplos de tasas de riesgo En el primer caso, la intuición es que si una persona no ha respondido a un e-mail, cada vez es menos probable que lo responda, pues en general las personas tienden a ignorar los correos con una antigüedad superior a un par de días. En la llegada de un bus - si bien en ramos pasados se ha modelado con una exponencial - se asume que a medida que más se demora en llegar al paradero, cada vez la espera debe ser menor, pues tarde o temprano este deberá llegar. Con respecto al divorcio, es más probable que en el caso de haber, este no ocurra inmediatamente y, con menor probabilidad, ocurrirá en las etapas tardías de la vida del matrimonio. Con respecto a la falla del disco duro, este tiene un comportamiento no lineal (cuadrático). Sus mayores posibilidades de fallar se dan al principio y al final de su vida útil esperada. A partir de la tasa de riesgo, se puede definir unívocamente la distribución de una variable aleatoria no negativa a través de la siguiente integral: \\[F(t) = 1 - exp \\left( -\\int_{0}^{t} h(u)du \\right)\\]Este concepto será útil para definir los modelos de duración en tiempo continuo en que la duración sí es un factor relevante Modelo Weibull A pesar de las generalizaciones de las funciones de tasas de riesgo para generar modelos de tiempo de ocurrencia, el foco será puesto en la distribución Weibull, debido a que es fácil de trabajar y entrega una fórmula cerrada muy similar a la de la distribución exponencial. Se tiene que, para la misma variable aleatoria \\(T\\) que se definió en la sección anterior, la probabilidad de ocurrencia de que un cliente pruebe nuestro producto en un tiempo inferior a t será: \\[F(t) = P(T \\leq t) = 1 - e^{-\\lambda t ^c}\\] Y la tasa de riesgo asociada a esta distribución: \\[h(t) = c \\lambda t ^{c-1}\\]El primer parámetro \\(\\lambda\\) que compone la fórmula es un parámetro de escala, mientras que el parámetro c es el parámetro de forma. Es importante notar que para \\(c=1\\), la distribución se convierte en la distribución exponencial, por lo que se puede decir que la distribución Weibull es una generalización de la exponencial. Notar que para \\(c=1\\), la tasa de riesgo es constante, lo que es consistente con la propiedad de pérdida de memoria de la distribución exponencial. knitr::include_graphics(rep(&quot;images/tasa_riesgo_c.png&quot;)) Figure 2.2: Ejemplos de tasas de riesgo para distintos valores de c En la distribución de Weibull generalizada la propiedad de pérdida de memoria no aplica como en el caso de la exponencial, es decir, la probabilidad de ocurrencia varía a medida que pasa el tiempo: \\[P(T &gt; s + t|T&gt;s) = \\frac{P(T&gt; s+t)}{P(T&gt; s)} = \\frac{1-P(T \\leq s+t)}{1-P(T \\leq s)}= \\frac{e^{-\\lambda(s+t)^c}}{e^{-\\lambda s^c}} \\] Modelo Gamma Weibull Una de las propiedades interesantes de la distribución Weibull, es que es sencillo introducir heterogeneidad sobre los parámetros y, de esa forma, capturar los distintos posibles comportamientos de la población. Al igual que en el modelo Gamma-Exponencial, asumiremos que el parámetro de escala \\(\\alpha\\) está distribuido \\(\\text{Gamma}(\\alpha,r)\\) en la población. La probabilidad de ocurrencia del consumo de los clientes se puede modelar a través de la \\[ \\begin{aligned} P(T \\leq t \\mid \\alpha,r, c) &amp;= \\int_{0}^{\\infty} \\frac{(1 - e^{-\\lambda t^c}) \\alpha^r \\lambda^{r-1}e^{-\\alpha \\lambda}}{\\Gamma(r)} d\\lambda \\\\ &amp;= \\int_{0}^{\\infty} \\frac{\\alpha^r \\lambda^{r-1}e^{-\\alpha \\lambda}}{\\Gamma(r)} d\\lambda - \\int_{0}^{\\infty} \\frac{e^{-\\lambda t^c} \\alpha^r \\lambda^{r-1}e^{-\\alpha \\lambda}}{\\Gamma(r)} d\\lambda \\\\ &amp;= 1 - \\frac{\\alpha^r}{\\Gamma(r)} \\int_{0}^{\\infty} \\lambda^{r-1}e^{-\\lambda(\\alpha + t^c)} d\\lambda \\\\ &amp;= 1 - \\frac{\\alpha^r}{\\Gamma(r)} \\frac{\\Gamma(r)}{(\\alpha + t^c)^r} \\\\ &amp;= 1 - \\left(\\frac{\\alpha}{\\alpha + t^c}\\right)^r \\end{aligned} \\] Si \\(c=1\\), se recupera el modelo de duración Gamma-Exponencial. 2.3 Modelos de Conteo Permiten modelar cuántas veces los consumidores incurrirán en un comportamiento determinado en un período de tiempo (ejemplo: problema de exposición publicitaria). Algunas medidas de efectividad son: Alcance: Proporción de la población expuesta al evento al menos una vez durante el período: \\(1 − P(X_t = 0)\\). Frecuencia promedio: número promedio de exposiciones en el período entre aquellos que han experimentado el evento (por ejemplo, ver la valla publicitaria). \\[\\frac{\\mathbb{E}(X_t)}{1-P(X_t =0)}\\] Puntos de rating brutos (GRPs): número promedio de exposiciones por cada 100 personas. \\[100 \\cdot \\mathbb{E}(X_t)\\] El fenómeno que se quiere estudiar es el número de veces que cada individuo ve la valla publicitaria. Para ello, se define el modelo individual Poisson. \\[ P(N_t=m|\\lambda) = \\frac{(\\lambda t)^m e^{-\\lambda t}}{m!} \\quad \\tag{2.3} \\] lo cual corresponde a la probabilidad de que el número de exposiciones sea \\(m\\) en un intervalo de largo \\(t\\). Su verosimilitud corresponde a: \\[ \\begin{aligned} L(\\lambda) &amp;= \\prod_{m} P(N_t = m | \\lambda)^{n_m} \\\\ &amp;= \\prod_{m} \\left( \\frac{(\\lambda t)^m e^{-\\lambda t}}{m!} \\right)^{n_m} \\end{aligned} \\] Mientras que su log verosimilitud es: \\[ \\begin{aligned} LL(\\lambda) &amp;= \\sum_{m} n_m \\ln \\left( P(N_t = m | \\lambda) \\right) \\\\ &amp;= \\sum_{m} n_m \\ln \\left( \\frac{(\\lambda t)^m e^{-\\lambda t}}{m!} \\right) \\end{aligned} \\] Donde \\(m\\) corresponde al número de ocurrencias de un suceso (cuántas personas han visto un determinado número de anuncios), \\(n_m\\) es el número de casos en donde hubieron \\(m\\) ocurrencias de un suceso (cuántas veces un usuario ha visto un anuncio) y no se utiliza cuando las observaciones están desagregadas (datos en los cuales cada fila del conjunto de datos corresponde a una observación única y específica). Cuando el tiempo es unitario, el modelo se simplifica a \\(t = 1\\). Al igual que en los modelos anteriores, es posible incluir heterogeneidad asumiendo que el parámetro \\(\\lambda\\) no es el mismo para todos. Para el caso en donde existe una mezcla finita y hay dos segmentos, las tasas de eventos de la población pueden ser \\(\\lambda_1\\) o \\(\\lambda_2\\), con una probabilidad \\(\\pi\\) de pertenecer al primer segmento. El modelo de probabilidad queda representado por: \\[ P(N_t = m | \\lambda_1, \\lambda_2, \\pi) = \\left( \\frac{(\\lambda_1 t)^m e^{-\\lambda_1 t}}{m!} \\right) \\pi + \\left( \\frac{(\\lambda_2 t)^m e^{-\\lambda_2 t}}{m!} \\right) (1-\\pi) \\quad (\\#eq-mfp) \\] Para los modelos de heterogeneidad continua, \\(\\lambda\\) distribuye de acuerdo a una determinada distribución. Suponiendo que dicha distribución es Gamma. \\[ g(\\lambda|\\alpha, r) = \\frac{\\alpha^r \\lambda^{r-1}e^{-\\alpha \\lambda}}{\\Gamma(r)} \\quad \\tag{2.4} \\] Usando el modelo individual en (2.3) y la distribución en (2.4), se puede estimar la probabilidad de un número de exposiciones, conocido como modelo Gamma Poisson (NBD): \\[ \\begin{aligned} P(N_t = m \\mid r, \\alpha) &amp;= \\int_{0}^{\\infty} P(N_t = m|\\lambda) g(\\lambda)d\\lambda \\\\ &amp;= \\int_{0}^{\\infty} \\frac{(\\lambda t)^m e^{-\\lambda t}}{m!} \\cdot \\frac{\\alpha^r \\lambda^{r-1}e^{-\\alpha \\lambda}}{\\Gamma(r)}d\\lambda \\\\ &amp;= \\frac{t^m \\alpha^r}{m! \\Gamma(r)} \\int_{0}^{\\infty} \\lambda^m \\lambda^{r-1} e^{-\\lambda t} e^{-\\alpha \\lambda} d\\lambda \\\\ &amp;= \\frac{t^m \\alpha^r}{m! \\Gamma(r)} \\int_{0}^{\\infty} \\lambda^{(r+m)-1} e^{-\\lambda(\\alpha+t)} d\\lambda \\\\ &amp;= \\frac{t^m \\alpha^r}{m! \\Gamma(r)} \\cdot \\frac{\\Gamma(r+m)}{(\\alpha+t)^{r+m}} \\\\ &amp;= \\frac{\\alpha^r}{(\\alpha+t)^r} \\cdot \\frac{t^m}{(\\alpha+t)^m} \\cdot \\frac{\\Gamma(r+m)}{\\Gamma(r)m!} \\\\ &amp;= \\left( \\frac{\\alpha}{\\alpha+t}\\right)^r \\left( \\frac{t}{\\alpha + t}\\right)^m \\frac{\\Gamma(r+m)}{\\Gamma(r)m!} \\end{aligned} \\quad \\tag{2.5} \\] 2.4 Modelos de Elección Binaria binomial Permiten modelar la probabilidad de que los individuos elijan un determinado comportamiento, dado que tienen varias opciones para elegir. Es aplicable en una situación de compras en un supermercado, exposición a varios anuncios, las variadas formas de uso de un producto, etc. Consideremos como variable de interés la probabilidad de que un individuo perteneciente a un segmento responda positivamente a una campaña de marketing. En el enfoque tradicional, se realiza una segmentación de clientes en grupos homogéneos, se envía mensajes a muestras aleatorias de cada segmento y se implementa un campaña en segmentos con tasa de respuesta (TR) sobre cierto corte, por ejemplo, \\(TR &gt; \\frac{\\text{Costo de envío}}{\\text{Margen unitario}}\\). Sin embargo, es posible incorporar un enfoque de modelos probabilísticos para abordar el problema. Si se considera la probabilidad de responder de manera positiva que tiene un segmento \\(s\\), en particular \\(p_s\\), es posible interpretar de manera sencilla la cantidad de respuestas obtenidas. Recordando que la suma de experimentos de \\(\\text{Bernoulli}\\) corresponde a una variable aleatoria Binomial, es posible interpretar \\(X_s\\) como la cantidad de respuestas obtenidas de un total de \\(m_s\\) enviadas. Luego: \\[ \\begin{aligned} P(X_s = x_s|m_s,p_s) &amp;= \\binom{m_s}{x_s} p_s^{x_s}(1-p_s)^{m_s-x_s} \\end{aligned} \\quad \\tag{2.6}\\] donde \\(m_s\\) es la población del segmento \\(s\\) y \\(p_s\\) es la probabilidad de respuesta del segmento \\(s\\). Se tiene que la verosimilitud es expresada como: \\[ \\begin{aligned} L(\\theta) &amp;= \\prod_{s=1}^{S} P(X_s = x_s | m_s, \\theta) \\\\ &amp;= \\prod_{s=1}^{S} \\binom{m_s}{x_s} \\theta^{x_s} (1-\\theta)^{m_s - x_s} \\end{aligned} \\quad (\\#eq:verosimilitud:bin) \\] Mientras que su log verosimilitud es: \\[ \\begin{aligned} LL(\\theta) &amp;= \\sum_{s=1}^{S} \\ln \\left( P(X_s = x_s | m_s, \\theta) \\right) \\\\ &amp;= \\sum_{s=1}^{S} \\ln \\left( \\binom{m_s}{x_s} \\theta^{x_s} (1-\\theta)^{m_s - x_s} \\right) \\\\ &amp;= \\sum_{s=1}^{S} \\left[ \\ln\\binom{m_s}{x_s} + \\ln(\\theta^{x_s}) + \\ln((1-\\theta)^{m_s - x_s}) \\right] \\\\ &amp;= \\sum_{s=1}^{S} \\left[ \\ln\\binom{m_s}{x_s} + x_s \\ln(\\theta) + (m_s - x_s) \\ln(1-\\theta) \\right] \\end{aligned} \\quad (\\#eq:logverosimilitud:bin) \\] Con respecto a la heterogeneidad, en el caso de una mezcla finita en donde la probabilidad de éxito en cada uno de los intentos es distinta de acuerdo a dos segmentos identificables, la probabilidad adopta el valor de \\(\\theta_1\\) y \\(\\theta_2\\), donde \\(\\pi\\) corresponde a la probabilidad de pertencer al primer segmento. El modelo de probabilidad queda representado por: \\[P(X_s = x_s | m_s, \\theta_1, \\theta_2, \\pi) = \\binom{m_s}{x_s} \\left[ \\theta_1^{x_s}(1-\\theta_1)^{m_s-x_s}\\pi + \\theta_2^{x_s}(1-\\theta_2)^{m_s-x_s}(1-\\pi) \\right] \\quad (\\#eq:mezcla:b)\\] En el caso de mezcla infinita, la heterogeneidad no observable se extrae aprovechando la distribución \\(B(\\alpha,\\beta)\\): \\[ \\begin{aligned} P(X_s = x_s \\mid \\alpha, \\beta) &amp;= \\int_{0}^{1} P(X_s = x_s|m_s,\\theta_s) g(\\theta_s|\\alpha,\\beta)d\\theta_s \\\\ &amp;= \\int_{0}^{1} \\binom{m_s}{x_s} \\theta_s^{x_s}(1-\\theta_s)^{m_s-x_s} \\frac{\\theta_s^{\\alpha-1}(1-\\theta_s)^{\\beta -1}}{B(\\alpha,\\beta)}d\\theta_s \\\\ &amp;= \\frac{\\binom{m_s}{x_s}}{B(\\alpha,\\beta)} \\int_{0}^{1} \\theta_s^{x_s+\\alpha-1}(1-\\theta_s)^{m_s-x_s+\\beta-1} d\\theta_s \\\\ &amp;= \\binom{m_s}{x_s} \\frac{B(\\alpha + x_s, \\beta + m_s - x_s)}{B(\\alpha,\\beta)} \\end{aligned} \\quad \\tag{2.7} \\] 2.5 Heterogeneidad observable Se ha expuesto modelos que intentan explicar y predecir el tiempo en que los individuos realizarán una determinada acción (e.g: proponer la probabilidad de fuga de un cliente), considerando que el comportamiento de los agentes se debe netamente a factores aleatorios. En esta sección se incorporará heterogeneidad observable a un modelo de duración en tiempo continuo sin dependencia en la duración. Entendemos por heterogeneidad observable, aquellos factores observables (que están en los datos) intrínsecos a los individuos que los hacen distintos, tales como sexo, edad, nivel socioeconómico, género, entre otras. 2.5.1 Modelos de duración en tiempo discreto Sea \\(T_i\\) la variable aleatoria que describe el instante en que el individuo \\(i\\) termina su relación comercial. Se modelará dicha variable con una distribución Geométrica Desplazada de parámetro \\(\\theta_i\\), que es la probabilidad de abandono para el individuo \\(i\\). \\[\\mathbb{P}(T_i=t_i|\\theta_i) = \\theta_i(1-\\theta_i)^{t_i-1}\\] Dado que se cuenta con información a nivel individual, es posible estimar un parámetro de abandono para cada persona. Sea \\(x_i\\) el vector que contiene las variables explicativas del individuo \\(i\\). Se modela la probabilidad de abandono \\(\\theta_i\\) utilizando una transformación logística para asegurar que el resultado se mantenga entre 0 y 1: \\[\\theta_i = \\frac{\\exp(\\beta_0 + \\beta&#39;x_i)}{1 + \\exp(\\beta_0 + \\beta&#39;x_i)} = \\frac{1}{1 + \\exp(-(\\beta_0 + \\beta&#39;x_i))}\\] Donde \\(\\beta\\) corresponde al vector de coeficientes asociados a las variables explicativas. La inclusión de esta función permite capturar el efecto de las covariables sin restringir el signo de los coeficientes. En el caso donde la probabilidad de abandono depende de las características de cada individuo (heterogeneidad observable), la probabilidad de que el individuo \\(i\\) abandone en el tiempo \\(t_i\\) es: \\[ \\begin{aligned} \\mathbb{P}(T_i = t_i|\\beta_0, \\beta) &amp;= \\theta_i (1 - \\theta_i)^{t_i-1} \\\\ \\text{donde } \\theta_i &amp;= \\frac{1}{1 + \\exp(-(\\beta_0 + \\beta&#39;x_i))} \\end{aligned} \\] Con lo cual, para un panel de \\(N\\) individuos, donde algunos abandonan en el período \\(t_i\\) y otros permanecen activos (censurados a la derecha), la log-verosimilitud del problema resulta: \\[ \\begin{aligned} LL(\\beta_0, \\beta) &amp;= \\sum_{i \\in \\text{abandono}} \\ln(\\mathbb{P}(T_i = t_i|\\beta_0, \\beta)) + \\sum_{i \\in \\text{activos}} \\ln(\\mathbb{P}(T_i &gt; t_i|\\beta_0, \\beta)) \\\\ &amp;= \\sum_{i \\in \\text{abandono}} \\left[ \\ln(\\theta_i) + (t_i-1)\\ln(1-\\theta_i) \\right] + \\sum_{i \\in \\text{activos}} t_i \\ln(1-\\theta_i) \\end{aligned} \\] Para introducir heterogeneidad no observable en el modelo y así mezclar ambos efectos, es análogo al desarrollo de la integral del Modelo Beta-Geométrico desplazado. Se modelan los parámetros \\(\\alpha_i\\) y \\(\\beta_i\\) de la distribución Beta de la siguiente forma para asegurar que sean positivos: \\[\\alpha_i = \\exp(a&#39;x_i) \\quad \\text{y} \\quad \\beta_i = \\exp(b&#39;x_i)\\] La obtención de la expresión de probabilidad con heterogeneidad mixta es análoga a la obtención de la probabilidad con heterogeneidad no observable, salvo que la interpretación de los coeficientes \\(\\alpha_i\\) y \\(\\beta_i\\) son distintas. Finalmente, la función de log-verosimilitud para el modelo mixto resulta, con \\(\\theta_{params} = (a, b)\\): \\[ \\begin{aligned} LL(\\theta_{params}) &amp;= \\sum_{i \\in \\text{abandono}} \\ln(\\mathbb{P}(T_i = t_i|a, b)) + \\sum_{i \\in \\text{activos}} \\ln(\\mathbb{P}(T_i &gt; t_i|a, b)) \\\\ &amp;= \\sum_{i \\in \\text{abandono}} \\ln\\left(\\frac{B(\\alpha_i+1, t_i+\\beta_i-1)}{B(\\alpha_i, \\beta_i)}\\right) + \\sum_{i \\in \\text{activos}} \\ln\\left(\\frac{B(\\alpha_i, \\beta_i+t_i)}{B(\\alpha_i, \\beta_i)}\\right) \\end{aligned} \\] 2.5.2 Modelos de duración en tiempo continuo sin dependencia de la duración Sea \\(T_i\\) la variable aleatoria que describe el instante en que el individuo \\(i\\) realiza una determinada acción. Se modelará dicha variable aleatoria con una distribución exponencial de parámetro \\(\\lambda_i\\): \\[\\mathbb{P}(T_i&lt;t_i|\\lambda_i) = 1-e^{-\\lambda_it_i}\\]Cabe destacar que, dada la naturaleza de los datos, el comportamiento descrito se realizará de manera desagregada (dependencia de \\(i\\) en el parámetro), es decir, dado que existe información individual para cada individuo, es posible estimar el parámetro de cada uno de éstos (no así en los casos agregados vistos anteriormente). Sea \\(x_i\\) el vector que contiene las variables explicativas pertinentes del individuo \\(i\\). Se modela la tasa de llegada de \\(i\\) de la siguiente manera: \\[\\lambda_i = exp(\\beta_0 + \\beta&#39;x_i) = \\lambda_0 exp(\\beta&#39;x_i)\\] Donde \\(\\beta\\) corresponde al vector de coeficientes asociados a las variables explicativas en cuestión. La inclusión de la exponencial se debe a que, por razones de convergencia e interpretación, la tasa de respuesta individual debe ser positiva. De esta forma, se puede capturar el efecto marginal de las variables demográficas sin restricción de signos. Así, el modelo no tendrá problemas si hay valores de \\(\\beta\\) negativos. En el caso con tasa homogénea (la misma para toda la población), la probabilidad que un individuo \\(i\\) realice un evento determinado antes del tiempo \\(t_i\\), incluyendo su información observable, es: \\[ \\begin{aligned} \\mathbb{P}(T_i &lt; t_i|\\beta,\\lambda_0) &amp;= 1 - e^{-\\lambda_it_i}\\\\ &amp;= 1 - e^{-\\lambda_0 \\exp(\\beta&#39;x_i)t_i} \\end{aligned} \\] Con lo cual (considerando instantes de tiempo \\(t_i^-\\) y \\(t_i^+\\) para discretizar el tiempo, un panel de \\(N\\) individuos y un vector de parámetros \\(\\theta = (\\beta,\\lambda_0)\\)), la log verosimilitud del problema resulta: \\[ \\begin{aligned} LL(\\theta) &amp;= \\sum_{i=1}^{N} \\ln(\\mathbb{P}(t_i^- &lt; T_i &lt; t_i^+|\\beta,\\lambda_0)) \\\\ &amp;= \\sum_{i=1}^{N} \\ln((\\mathbb{P}(T_i &lt; t_i^+|\\beta,\\lambda_0)) - \\mathbb{P}(T_i &lt; t_i^-|\\beta,\\lambda_0)) \\\\ &amp;= \\sum_{i=1}^{N} \\ln \\left((1 - e^{-\\lambda_0 \\exp(\\beta&#39;x_i)t_i^+}) - (1 - e^{-\\lambda_0 \\exp(\\beta&#39;x_i)t_i^-}) \\right)\\\\ &amp;= \\sum_{i=1}^{N} \\ln (e^{-\\lambda_0 \\exp(\\beta&#39;x_i)t_i^-} - e^{-\\lambda_0 \\exp(\\beta&#39;x_i)t_i^+}) \\end{aligned} \\] Para introducir heterogeneidad no observable en el modelo, se dejará el parámetro \\(\\lambda_0\\) distribuyendo de manera continua en la población según una ley \\(\\Gamma(\\alpha,r)\\) pues, de esta forma, es posible mezclar tanto la heterogeneidad no observable, como la observable. El desarrollo de la integral es análogo al caso con heterogeneidad no observable, con la diferencia de que se multiplica la constante \\(exp(\\beta&#39; x_i)\\) a la variable del tiempo \\(t\\) . Finalmente, la función de log verosimilitud resulta, con \\(\\theta = (\\beta,\\alpha,r)\\): \\[ \\begin{aligned} LL(\\theta) &amp;= \\sum_{i=1}^{N} \\ln(\\mathbb{P} (t_i^-&lt;T_i&lt;t_i^+|\\alpha,r,\\beta))\\\\ &amp;= \\sum_{i=1}^{N} \\ln \\left(\\left(\\frac{\\alpha}{ \\alpha + \\exp(\\beta&#39;x_i)t_i^-}\\right)^r - \\left(\\frac{\\alpha}{ \\alpha + \\exp(\\beta&#39;x_i)t_i^+}\\right)^r\\right) \\end{aligned} \\] 2.5.3 Modelos de duración en tiempo continuo con dependencia de la duración Cuando el tiempo en que ocurre un determinado suceso posee dependencia en la duración, el procedimiento es análogo que en el caso sin dicha dependencia, pero considerando que \\(T_i\\) distribuye según una ley Weibull. \\[\\mathbb{P}(T_i &lt; t_i|\\lambda_i,c) = 1 - e^{-\\lambda_it_i^c}\\] En el caso con tasa homogénea (la misma para toda la población), la probabilidad que un individuo \\(i\\) realice un evento determinado antes del tiempo \\(t_i\\), incluyendo su información observable, es: \\[ \\begin{aligned} \\mathbb{P}(T_i &lt; t_i|\\beta,\\lambda_0,c) &amp;= 1 - e^{-\\lambda_i t_i}\\\\ &amp;= 1 - e^{-\\lambda_0 \\exp(\\beta&#39;x_i) t_i^c} \\end{aligned} \\] Por lo que, la función de log verosimilitud toma la siguiente forma: \\[ \\begin{aligned} LL(\\theta) &amp;= \\sum_{i=1}^{N} \\ln(\\mathbb{P}(t_i^- &lt; T_i &lt; t_i^+|\\beta,\\lambda_0,c)) \\\\ &amp;= \\sum_{i=1}^{N} \\ln((\\mathbb{P}(T_i &lt; t_i^+|\\beta,\\lambda_0,c)) - \\mathbb{P}(T_i &lt; t_i^-|\\beta,\\lambda_0,c)) \\\\ &amp;= \\sum_{i=1}^{N} \\ln \\left((1 - e^{-\\lambda_0 \\exp(\\beta&#39;x_i)(t_i^+)^c}) - (1 - e^{-\\lambda_0 \\exp(\\beta&#39;x_i)(t_i^-)^c}) \\right)\\\\ &amp;= \\sum_{i=1}^{N} \\ln (e^{-\\lambda_0 \\exp(\\beta&#39;x_i)(t_i^-)^c} - e^{-\\lambda_0 \\exp(\\beta&#39;x_i)(t_i^+)^c}) \\end{aligned} \\] De manera análoga al caso anterior, se puede introducir adicionalmente heterogeneidad no observable mediante el parámetro \\(\\lambda_0\\) según una distribución \\(\\Gamma(\\alpha,r)\\). Dando como conocido este resultado, la log-verosimilitud queda descrita como: \\[ \\begin{aligned} LL(\\theta) &amp;= \\sum_{i=1}^{N} \\ln(\\mathbb{P}(t_i^- &lt; T_i &lt; t_i^+|\\beta,\\lambda_0,r,c)) \\\\ &amp;= \\sum_{i=1}^{N} \\ln \\left( \\left(\\frac{\\alpha}{\\alpha + \\exp(\\beta&#39;x_i)(t_i^-)^c}\\right)^r - \\left(\\frac{\\alpha}{\\alpha + \\exp(\\beta&#39;x_i)(t_i^+)^c}\\right)^r \\right) \\end{aligned} \\] 2.5.4 Modelos de Conteo Sea \\(Y_i\\) la variable aleatoria que describe el número de veces que el individuo \\(i\\) incurre en un determinado comportamiento durante un período de tiempo. Se modelará dicha variable con una distribución Poisson de parámetro \\(\\lambda_i\\), que representa la tasa de ocurrencia para el individuo \\(i\\). \\[\\mathbb{P}(Y_i=y_i|\\lambda_i) = \\frac{\\lambda_i^{y_i} e^{-\\lambda_i}}{y_i!}\\] Para incorporar heterogeneidad observable, se modela la tasa individual \\(\\lambda_i\\) como una función de un vector \\(x_i\\) que contiene las variables explicativas del individuo: \\[\\lambda_i = \\exp(\\beta_0 + \\beta&#39;x_i) = \\lambda_0 \\exp(\\beta&#39;x_i)\\] Donde \\(\\beta\\) es el vector de coeficientes y \\(\\lambda_0 = \\exp(\\beta_0)\\) es la tasa base. La probabilidad de que el individuo \\(i\\) realice el evento \\(y_i\\) veces es: \\[ \\mathbb{P}(Y_i = y_i|\\beta_0, \\beta) = \\frac{(\\lambda_0 \\exp(\\beta&#39;x_i))^{y_i} \\exp(-\\lambda_0 \\exp(\\beta&#39;x_i))}{y_i!} \\] La función de log-verosimilitud para estimar los parámetros \\(\\beta_0\\) y \\(\\beta\\) a partir de los datos de \\(N\\) individuos es la suma de las log-probabilidades individuales: \\[ \\begin{aligned} LL(\\beta_0, \\beta) &amp;= \\sum_{i=1}^{N} \\ln(\\mathbb{P}(Y_i=y_i|\\beta_0, \\beta)) \\\\ &amp;= \\sum_{i=1}^{N} \\left[ y_i \\ln(\\lambda_i) - \\lambda_i - \\ln(y_i!) \\right] \\\\ &amp;= \\sum_{i=1}^{N} \\left[ y_i (\\beta_0 + \\beta&#39;x_i) - \\exp(\\beta_0 + \\beta&#39;x_i) - \\ln(y_i!) \\right] \\end{aligned} \\] Para introducir heterogeneidad no observable y mezclarla con la observable, se asume que la tasa base \\(\\lambda_0\\)no es fija para toda la población, sino que sigue una distribución Gamma con parámetros de forma \\(r\\) y de escala \\(\\alpha\\). \\[g(\\lambda_0|r, \\alpha) = \\frac{\\alpha^r \\lambda_0^{r-1}e^{-\\alpha\\lambda_0}}{\\Gamma(r)}\\] El desarrollo de la integral para obtener la probabilidad marginal es análogo al caso NBD (Distribución Binomial Negativa) sin covariables. El resultado es la distribución de probabilidad para un modelo de Regresión Binomial Negativa: \\[ \\mathbb{P} (Y_i = y_i|r, \\alpha, \\beta) = \\frac{\\Gamma(r+y_i)}{\\Gamma(r)y_i!} \\left(\\frac{\\alpha}{\\alpha + \\exp(\\beta&#39;x_i)}\\right)^r \\left(\\frac{\\exp(\\beta&#39;x_i)}{\\alpha + \\exp(\\beta&#39;x_i)}\\right)^{y_i} \\] Finalmente, la función de log-verosimilitud para el modelo mixto (Regresión NBD) que estima los parámetros \\((r, \\alpha, \\beta)\\) es: \\[ LL(r, \\alpha, \\beta) = \\sum_{i=1}^{N} \\ln(\\mathbb{P}(Y_i = y_i|r, \\alpha, \\beta)) \\] 2.5.5 Modelos de Elección Binaria binomial Sea \\(X_i\\) la variable aleatoria que describe el número de “éxitos” (ej. respuestas a una campaña, compras) en \\(m_i\\) intentos para un individuo o segmento \\(i\\). Se modelará dicha variable con una distribución con parámetros \\(m_i\\) y \\(\\theta_i\\), donde \\(\\theta_i\\) es la probabilidad de éxito para el individuo \\(i\\). \\[\\mathbb{P}(X_i=x_i|m_i, \\theta_i) = \\binom{m_i}{x_i} \\theta_i^{x_i}(1-\\theta_i)^{m_i-x_i}\\] Para incorporar heterogeneidad observable, se modela la probabilidad de éxito individual \\(\\theta_i\\) como una función de un vector de covariables \\(x_i\\). Al igual que en el modelo de duración discreta, se utiliza una transformación logística para asegurar que \\(\\theta_i\\) se mantenga en el intervalo \\((0,1)\\): \\[\\theta_i = \\frac{\\exp(\\beta_0 + \\beta&#39;x_i)}{1 + \\exp(\\beta_0 + \\beta&#39;x_i)} = \\frac{1}{1 + \\exp(-(\\beta_0 + \\beta&#39;x_i))}\\] Donde \\(\\beta\\) es el vector de coeficientes que captura el efecto de las características observables. La función de log verosimilitud para estimar los parámetros \\(\\beta_0\\) y \\(\\beta\\) a partir de los datos de \\(N\\) individuos o segmentos es la suma de las log-probabilidades binomiales individuales: \\[ \\begin{aligned} LL(\\beta_0, \\beta) &amp;= \\sum_{i=1}^{N} \\ln(\\mathbb{P}(X_i=x_i|\\beta_0, \\beta)) \\\\ &amp;= \\sum_{i=1}^{N} \\left[ \\ln\\binom{m_i}{x_i} + x_i \\ln(\\theta_i) + (m_i - x_i) \\ln(1-\\theta_i) \\right] \\end{aligned} \\] Para introducir heterogeneidad no observable y mezclarla con la observable, se asume que la probabilidad de éxito \\(\\theta_i\\) no es fija, sino que sigue una distribución Beta. Para incorporar las covariables, se modelan los parámetros \\(\\alpha_i\\) y \\(\\beta_i\\) de la distribución Beta como una función de las características \\(x_i\\): \\[\\alpha_i = \\exp(a&#39;x_i) \\quad \\text{y} \\quad \\beta_i = \\exp(b&#39;x_i)\\] La probabilidad marginal de observar \\(x_i\\) éxitos en \\(m_i\\) intentos para el individuo \\(i\\) se obtiene a través de la integral análoga al caso sin covariables: \\[ \\mathbb{P} (X_i = x_i|a, b) = \\binom{m_i}{x_i} \\frac{B(\\alpha_i + x_i, \\beta_i + m_i - x_i)}{B(\\alpha_i,\\beta_i)} \\] Finalmente, la función de log verosimilitud para el modelo mixto (Regresión Beta Binomial) que estima los parámetros \\((a, b)\\) es: \\[ LL(a, b) = \\sum_{i=1}^{N} \\ln \\left( \\binom{m_i}{x_i} \\frac{B(\\alpha_i + x_i, \\beta_i + m_i - x_i)}{B(\\alpha_i,\\beta_i)} \\right) \\] 2.6 Esperanzas Condicionales Primero, es fundamental establecer el valor esperado de las distribuciones que se usaron para modelar la heterogeneidad no observable. A continuación, se muestra el desarrollo para obtener la esperanza de las distribuciones Gamma y Beta. Esperanza de la distribución Gamma Para la distribución Gamma, con parámetro de forma \\(r\\) y de tasa \\(\\alpha\\), que se utiliza para modelar tasas de ocurrencia (ej. \\(\\lambda\\)), su función de densidad de probabilidad es: \\[g(\\lambda|r,\\alpha) = \\frac{\\alpha^r}{\\Gamma(r)} \\lambda^{r-1} e^{-\\alpha\\lambda}\\] La esperanza de una variable aleatoria \\(\\lambda\\) que sigue esta distribución es: \\[ \\mathbb{E}[\\lambda] = \\frac{r}{\\alpha} \\]Este resultado se obtiene a partir de la definición de valor esperado para una variable continua: \\[ \\begin{aligned} \\mathbb{E}[\\lambda] &amp;= \\int_{0}^{\\infty} \\lambda \\cdot g(\\lambda|r,\\alpha) d\\lambda \\\\ &amp;= \\int_{0}^{\\infty} \\lambda \\cdot \\frac{\\alpha^r}{\\Gamma(r)} \\lambda^{r-1} e^{-\\alpha\\lambda} d\\lambda \\\\ &amp;= \\frac{\\alpha^r}{\\Gamma(r)} \\int_{0}^{\\infty} \\lambda^{r} e^{-\\alpha\\lambda} d\\lambda \\\\ &amp;= \\frac{\\alpha^r}{\\Gamma(r)} \\int_{0}^{\\infty} \\lambda^{(r+1)-1} e^{-\\alpha\\lambda} d\\lambda \\\\ \\end{aligned} \\] Reconociendo que la integral \\(\\int_{0}^{\\infty} x^{k-1}e^{-\\theta x}dx = \\frac{\\Gamma(k)}{\\theta^k}\\), con \\(k=r+1\\) y \\(\\theta=\\alpha\\): \\[ \\begin{aligned} \\mathbb{E}[\\lambda] &amp;= \\frac{\\alpha^r}{\\Gamma(r)} \\left[ \\frac{\\Gamma(r+1)}{\\alpha^{r+1}} \\right] \\\\ &amp;= \\frac{\\alpha^r}{\\Gamma(r)} \\cdot \\frac{r\\Gamma(r)}{\\alpha^r \\cdot \\alpha} \\\\ &amp;= \\frac{r}{\\alpha} \\end{aligned} \\] Esperanza de la distribución Beta Para la distribución Beta con parámetros \\(\\alpha\\) y \\(\\beta\\) que se utilizan para modelar probabilidades (ej. \\(\\theta\\)), su función de densidad de probabilidad es: \\[g(\\theta|\\alpha,\\beta) = \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)}\\] El desarrollo para obtener esta esperanza es el siguiente: \\[ \\begin{aligned} \\mathbb{E}[\\theta] &amp;= \\int_{0}^{1} \\theta \\cdot g(\\theta|\\alpha,\\beta) d\\theta \\\\ &amp;= \\int_{0}^{1} \\theta \\cdot \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)} d\\theta \\\\ &amp;= \\frac{1}{B(\\alpha,\\beta)} \\int_{0}^{1} \\theta^{\\alpha}(1-\\theta)^{\\beta-1} d\\theta \\\\ &amp;= \\frac{1}{B(\\alpha,\\beta)} \\int_{0}^{1} \\theta^{(\\alpha+1)-1}(1-\\theta)^{\\beta-1} d\\theta \\\\ \\end{aligned} \\] Reconociendo que la integral \\(\\int_{0}^{1} x^{a-1}(1-x)^{b-1}dx = B(a,b)\\), con \\(a=\\alpha+1\\) y \\(b=\\beta\\): \\[ \\begin{aligned} \\mathbb{E}[\\theta] &amp;= \\frac{1}{B(\\alpha,\\beta)} \\left[ B(\\alpha+1, \\beta) \\right] \\\\ &amp;= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\cdot \\frac{\\Gamma(\\alpha+1)\\Gamma(\\beta)}{\\Gamma(\\alpha+1+\\beta)} \\\\ &amp;= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)} \\cdot \\frac{\\alpha\\Gamma(\\alpha)}{(\\alpha+\\beta)\\Gamma(\\alpha+\\beta)} \\\\ &amp;= \\frac{\\alpha}{\\alpha+\\beta} \\end{aligned} \\] 2.6.1 Modelo de Tiempo Discreto (Combinado con Beta) Para el modelo de duración en tiempo discreto, una pregunta válida es cuál es la probabilidad de abandono esperada para un cliente determinado, dado su historial con la empresa. Intuitivamente, esta probabilidad debería estar entre la tasa de abandono promedio de la población y el comportamiento observado de ese cliente. Recordando que la distribución del parámetro \\(\\theta\\) (la probabilidad de abandono), condicionada a los datos observados de un cliente, se obtiene por el Teorema de Bayes: \\[ \\begin{aligned} g(\\theta|\\text{datos}) &amp;= \\frac{\\mathbb{P}(\\text{datos}|\\theta)g(\\theta)}{\\int \\mathbb{P}(\\text{datos}|\\theta)g(\\theta)d\\theta} \\end{aligned} \\quad \\tag{2.8} \\] donde \\(g(\\theta)\\) es la distribución a priori del parámetro (Beta) y \\(\\mathbb{P}(\\text{datos}|\\theta)\\) es la verosimilitud del comportamiento observado (Geométrica). Para el modelo Beta-Geométrico, la distribución posterior de \\(\\theta\\) también es una distribución Beta con parámetros actualizados. Para el Modelo de Tiempo Discreto (Beta), la esperanza condicional \\(E[\\theta|t]\\) representa la probabilidad de abandono esperada para un cliente, la cual se actualiza y ajusta en función de su tiempo de permanencia observado \\(t\\). El cálculo de esta esperanza se basa en el Teorema de Bayes, que actualiza el conocimiento previo sobre el parámetro \\(\\theta\\) a la luz de los datos observados: \\[ g(\\theta|\\text{datos}) = \\frac{\\mathbb{P}(\\text{datos}|\\theta) \\cdot g(\\theta)}{\\int \\mathbb{P}(\\text{datos} \\mid \\theta) \\cdot g(\\theta) d\\theta} \\] El proceso para derivar la esperanza condicional se descompone de la siguiente manera: Distribución a Priori: Se asume que la heterogeneidad en la probabilidad de abandono \\(\\theta\\) en la población sigue una distribución Beta: \\[ g(\\theta|\\alpha, \\beta) \\sim \\text{Beta}(\\alpha, \\beta) \\] Función de Verosimilitud: El comportamiento de abandono individual se modela con una distribución Geométrica Desplazada, que indica la probabilidad de que el evento ocurra exactamente en el período \\(t\\): \\[ \\mathbb{P}(T=t|\\theta) = \\theta(1-\\theta)^{t-1} \\] Con respecto a la Ley de Probabilidades Totales, ya se ha calculado en anterioridad para el Modelo Beta Geométrico-Desplazado. A continuación, se muestra el desarrollo: \\[ \\begin{aligned} g(\\theta|T=t) &amp;= \\frac{\\mathbb{P}(T=t|\\theta) \\cdot g(\\theta|\\alpha, \\beta)}{\\int_0^1 \\mathbb{P}(T=t|\\theta) \\cdot g(\\theta|\\alpha, \\beta) d\\theta} \\\\ &amp;= \\frac{ \\left( \\theta(1-\\theta)^{t-1} \\right) \\left( \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)} \\right) }{ \\frac{B(\\alpha+1, \\beta+t-1)}{B(\\alpha, \\beta)} } \\\\ &amp;= \\frac{\\theta^{\\alpha}(1-\\theta)^{\\beta+t-2}}{B(\\alpha+1, \\beta+t-1)} \\end{aligned} \\] La expresión resultante es la función de densidad de una distribución Beta, con los parámetros actualizados. \\[g(\\theta|T=t) \\sim \\text{Beta}(\\alpha+1, \\beta+t-1)\\] De esta distribución posterior se deduce la Esperanza Condicional, que es simplemente la media de dicha distribución: \\[ \\mathbb{E}(\\theta|T=t) = \\frac{\\alpha+1}{\\alpha+\\beta+t} \\] Esta expresión representa la probabilidad de abandono esperada y actualizada para un cliente que ha permanecido exactamente \\(t\\) períodos. El resultado combina la información previa sobre la población (contenida en \\(\\alpha\\) y \\(\\beta\\)) con la observación específica del cliente (su duración \\(t\\)). De forma análoga, para un cliente que sigue activo después de \\(t\\) períodos (observación censurada): Función de Verosimilitud: La probabilidad de que el evento aún no haya ocurrido es la función de supervivencia: \\[ \\mathbb{P}(T&gt;t|\\theta) = (1-\\theta)^{t} \\] Obteniendo la distribución posterior: \\[ \\begin{aligned} g(\\theta|T &gt; t) &amp;= \\frac{\\mathbb{P}(T &gt; t|\\theta) \\cdot g(\\theta|\\alpha, \\beta)}{\\int_0^1 \\mathbb{P}(T &gt; t|\\theta) \\cdot g(\\theta|\\alpha, \\beta) d\\theta} \\\\ &amp;= \\frac{ \\left( (1-\\theta)^{t} \\right) \\left( \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)} \\right) }{ \\frac{B(\\alpha, \\beta+t)}{B(\\alpha, \\beta)} } \\\\ &amp;= \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta+t-1}}{B(\\alpha, \\beta+t)} \\end{aligned} \\] La expresión resultante es la función de densidad de otra distribución Beta, con los parámetros actualizados. \\[g(\\theta|T&gt;t) \\sim \\text{Beta}(\\alpha, \\beta+t)\\] De esta distribución posterior se deduce la Esperanza Condicional, que es simplemente la media de dicha distribución: \\[ \\mathbb{E}(\\theta|T&gt;t) = \\frac{\\alpha}{\\alpha+\\beta+t} \\] Se podría replantear una regla de decisión y, por ejemplo, dirigir una campaña de retención a los clientes aún activos después de \\(t\\) períodos si su probabilidad de abandono esperada supera cierto umbral: \\[\\mathbb{E} (\\theta|T &gt; t) = \\frac{\\alpha}{\\alpha + \\beta + t} &gt; \\frac{\\text{Costo de Retención}}{\\text{Valor del Cliente}}\\] \\[ \\mathbb{E}(\\theta \\mid T&gt;t) = \\frac{\\alpha}{\\alpha + \\beta + t} (\\#eq:esp:discrete) \\] 2.6.2 Modelo de Tiempo Continuo (Combinado con Gamma) Para el modelo de duración en tiempo continuo, una pregunta válida es cuál es la tasa de eventos esperada para un cliente determinado, dado su historial. Intuitivamente, esta tasa debería estar entre la tasa promedio de la población y el comportamiento observado de ese cliente. Recordando que la distribución del parámetro \\(\\lambda\\) (la tasa de eventos), condicionada a los datos observados de un cliente, se obtiene por el Teorema de Bayes: \\[ \\begin{aligned} g(\\lambda|\\text{datos}) &amp;= \\frac{\\mathbb{P}(\\text{datos}|\\lambda)g(\\lambda)}{\\int \\mathbb{P}(\\text{datos}|\\lambda)g(\\lambda)d\\lambda} \\end{aligned} \\quad \\tag{2.8} \\] La esperanza condicional \\(E[\\lambda|t]\\) representa la tasa de ocurrencia esperada para un cliente, la cual se actualiza y ajusta en función del tiempo transcurrido \\(t\\). El proceso para derivar la esperanza condicional se descompone de la siguiente manera: Distribución a Priori: Se asume que la heterogeneidad en la tasa de eventos \\(\\lambda\\) en la población sigue una distribución Gamma: \\[ g(\\lambda|r, \\alpha) \\sim \\text{Gamma}(r, \\alpha) \\] Función de Verosimilitud: El comportamiento del tiempo hasta el evento se modela con una distribución Exponencial, que indica la probabilidad (densidad) de que el evento ocurra exactamente en el instante \\(t\\): \\[ \\mathbb{P}(T=t|\\lambda) = f(t|\\lambda) = \\lambda e^{-\\lambda t} \\] Con respecto a la Ley de Probabilidades Totales, el denominador de la expresión de Bayes corresponde a la probabilidad en heterogeneidad no observada del modelo Gamma-Exponencial. A continuación, se muestra el desarrollo de la distribución posterior: \\[ \\begin{aligned} g(\\lambda|T=t) &amp;= \\frac{\\mathbb{P}(T=t|\\lambda) \\cdot g(\\lambda|r, \\alpha)}{\\int_0^\\infty \\mathbb{P}(T=t|\\lambda) \\cdot g(\\lambda|r, \\alpha) d\\lambda} \\\\ &amp;= \\frac{ \\left( \\lambda t e^{-\\lambda t} \\right) \\left( \\frac{\\alpha^r \\lambda^{r-1} e^{-\\alpha\\lambda}}{\\Gamma(r)} \\right) }{\\left(\\frac{rt}{\\alpha + t} \\right) \\left(\\frac{1}{\\alpha + t} \\right)^r} \\\\ &amp;= \\frac{(\\alpha+t)^{r+1}}{\\Gamma(r+1)}\\lambda^{r}e^{-\\lambda(\\alpha+t)} \\end{aligned} \\] La expresión resultante es la función de densidad de una distribución Gamma, con los parámetros actualizados. \\[g(\\lambda|T=t) \\sim \\text{Gamma}(r+1, \\alpha+t)\\] De esta distribución posterior se deduce la Esperanza Condicional, que es simplemente la media de dicha distribución: \\[ \\mathbb{E}(\\lambda|T=t) = \\frac{r+1}{\\alpha+t} \\] 2.6.3 Modelo de Conteo (Combinado con Gamma) Para el modelo de conteo, una pregunta válida es cuál es la tasa de eventos esperada para un cliente determinado, dado su historial de eventos en un período de tiempo \\(t\\). Recordando que la distribución del parámetro \\(\\lambda\\) (la tasa de eventos), condicionada a los datos observados de un cliente, se obtiene por el Teorema de Bayes: \\[ \\begin{aligned} g(\\lambda|\\text{datos}) = \\frac{\\mathbb{P}(\\text{datos}|\\lambda)g(\\lambda)}{\\int \\mathbb{P}(\\text{datos}|\\lambda)g(\\lambda)d\\lambda} \\end{aligned} \\quad \\tag{2.8} \\] El proceso para derivar la esperanza condicional se descompone de la siguiente manera: Distribución a Priori: Se asume que la heterogeneidad en la tasa de eventos \\(\\lambda\\) en la población sigue una distribución Gamma: \\[ g(\\lambda|r, \\alpha) \\sim \\text{Gamma}(r, \\alpha) \\] Función de Verosimilitud: El comportamiento de conteo de eventos se modela con una distribución Poisson, que indica la probabilidad de que ocurran exactamente \\(y\\) eventos en un período de duración \\(t\\): \\[ \\mathbb{P}(Y_t=y|\\lambda,t) = \\frac{(\\lambda t)^y e^{-\\lambda t}}{y!} \\] Con respecto a la Ley de Probabilidades Totales, el denominador de la expresión de Bayes corresponde a la probabilidad en heterogeneidad no observada del modelo Gamma-Poisson (NBD). A continuación, se muestra el desarrollo de la distribución posterior: \\[ \\begin{aligned} g(\\lambda|Y_t=y) &amp;= \\frac{\\mathbb{P}(Y_t=y|\\lambda, t) \\cdot g(\\lambda|r, \\alpha)}{\\int_0^\\infty \\mathbb{P}(Y_t=y|\\lambda, t) \\cdot g(\\lambda|r, \\alpha) d\\lambda} \\\\ &amp;= \\frac{ \\left( \\frac{(\\lambda t)^y e^{-\\lambda t}}{y!} \\right) \\left( \\frac{\\alpha^r \\lambda^{r-1} e^{-\\alpha\\lambda}}{\\Gamma(r)} \\right) }{ \\frac{\\Gamma(r+y)}{\\Gamma(r)y!} \\left(\\frac{\\alpha}{\\alpha+t}\\right)^r \\left(\\frac{t}{\\alpha+t}\\right)^{y} } \\\\ &amp;= \\frac{(\\alpha+t)^{r+y}}{\\Gamma(r+y)}\\lambda^{r+y-1}e^{-\\lambda(\\alpha+t)} \\end{aligned} \\] La expresión resultante es la función de densidad de una distribución Gamma, con los parámetros actualizados. \\[g(\\lambda|Y_t=y) \\sim \\text{Gamma}(r+y, \\alpha+t)\\] De esta distribución posterior se deduce la Esperanza Condicional, que es simplemente la media de dicha distribución: \\[ \\mathbb{E}(\\lambda|Y_t=y) = \\frac{r+y}{\\alpha+t} \\] 2.6.4 Modelo de Elección Binaria binomial (Combinado con Beta) Recordando que la distribución del parámetro \\(\\theta\\) (la probabilidad de éxito), condicionada a los datos observados, se obtiene por el Teorema de Bayes: \\[ \\begin{aligned} g(\\theta|\\text{datos}) &amp;= \\frac{\\mathbb{P}(\\text{datos}|\\theta)g(\\theta)}{\\int \\mathbb{P}(\\text{datos}|\\theta)g(\\theta)d\\theta} \\end{aligned} \\quad \\tag{2.8} \\] El proceso para derivar la esperanza condicional se descompone de la siguiente manera: Distribución a Priori: Se asume que la heterogeneidad en la probabilidad de éxito \\(\\theta\\) en la población sigue una distribución Beta: \\[ g(\\theta|\\alpha, \\beta) \\sim \\text{Beta}(\\alpha, \\beta) \\] Función de Verosimilitud: El comportamiento de elección se modela con una distribución Binomial, que indica la probabilidad de obtener exactamente \\(x\\) éxitos en \\(m\\) intentos: \\[ \\mathbb{P}(X=x|m, \\theta) = \\binom{m}{x} \\theta^x (1-\\theta)^{m-x} \\] Con respecto a la Ley de Probabilidades Totales, el denominador de la expresión de Bayes corresponde a la probabilidad en heterogeneidad no observada del modelo Beta-Binomial. A continuación, se muestra el desarrollo de la distribución posterior: \\[ \\begin{aligned} g(\\theta|X=x) &amp;= \\frac{\\mathbb{P}(X=x|m, \\theta) \\cdot g(\\theta|\\alpha, \\beta)}{\\int_0^1 \\mathbb{P}(X=x|m, \\theta) \\cdot g(\\theta|\\alpha, \\beta) d\\theta} \\\\ &amp;= \\frac{ \\left( \\binom{m}{x} \\theta^x (1-\\theta)^{m-x} \\right) \\left( \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha, \\beta)} \\right) }{ \\binom{m}{x} \\frac{B(\\alpha+x, \\beta+m-x)}{B(\\alpha, \\beta)} } \\\\ &amp;= \\frac{\\theta^{\\alpha+x-1}(1-\\theta)^{\\beta+m-x-1}}{B(\\alpha+x, \\beta+m-x)} \\end{aligned} \\] La expresión resultante es la función de densidad de una distribución Beta, con los parámetros actualizados. \\[g(\\theta|X=x) \\sim \\text{Beta}(\\alpha+x, \\beta+m-x)\\] De esta distribución posterior se deduce la Esperanza Condicional, que es simplemente la media de dicha distribución: \\[ \\mathbb{E}(\\theta|X=x) = \\frac{\\alpha+x}{\\alpha+\\beta+m} \\] En el modelo de elección en donde la \\(P(X_s = x_s)\\) quedaba definida en (2.6). Una pregunta válida que se puede hacer es cuál es la tasa de respuesta de un segmento \\(s\\) determinado. Intuitivamente debería estar entre la tasa de respuesta esperada de la población y la observada, es decir, \\[ \\begin{aligned} \\mathbb{E}(\\theta_s|m_s,x_s)=\\gamma \\frac{\\alpha}{\\alpha+\\beta} + (1-\\gamma) \\frac{x_s}{m_s} \\end{aligned} \\quad \\tag{2.9} \\] Esta última igualdad se encuentra al hacer el reemplazo \\(\\gamma = \\frac{\\alpha + \\beta}{\\alpha + \\beta + m_s}\\), la cual coincide con (2.8). Se podría replantear la regla de decisión y enviar catálogos a los segmentos \\(s\\) tales que \\[\\mathbb{E} (\\theta_s|x_s) =\\frac{\\alpha + x_s}{\\alpha + \\beta + m_s} &gt; \\frac{\\text{costo de envío}}{\\text{margen unitario}}\\] \\[ \\begin{aligned} \\mathbb{E}(\\theta_s \\mid x_s) &amp;= \\frac{\\alpha + x_s}{\\alpha + \\beta + m_s} \\end{aligned} \\quad \\tag{2.10} \\] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
